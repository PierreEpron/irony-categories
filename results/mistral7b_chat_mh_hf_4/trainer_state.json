{
  "best_metric": 1.3001418113708496,
  "best_model_checkpoint": "results/mistral7b_chat_mh_hf_4/checkpoint-4548",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 7580,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 434.0,
      "learning_rate": 0.00014998021108179418,
      "loss": 2.6719,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 184.0,
      "learning_rate": 0.00014996042216358838,
      "loss": 3.4375,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 504.0,
      "learning_rate": 0.00014994063324538258,
      "loss": 12.3125,
      "step": 3
    },
    {
      "epoch": 0.01,
      "grad_norm": 298.0,
      "learning_rate": 0.00014992084432717678,
      "loss": 2.4219,
      "step": 4
    },
    {
      "epoch": 0.01,
      "grad_norm": 376.0,
      "learning_rate": 0.00014990105540897098,
      "loss": 6.75,
      "step": 5
    },
    {
      "epoch": 0.01,
      "grad_norm": 498.0,
      "learning_rate": 0.00014988126649076518,
      "loss": 4.5938,
      "step": 6
    },
    {
      "epoch": 0.01,
      "grad_norm": 104.5,
      "learning_rate": 0.00014986147757255935,
      "loss": 1.5391,
      "step": 7
    },
    {
      "epoch": 0.01,
      "grad_norm": 196.0,
      "learning_rate": 0.00014984168865435354,
      "loss": 1.7812,
      "step": 8
    },
    {
      "epoch": 0.01,
      "grad_norm": 704.0,
      "learning_rate": 0.00014982189973614774,
      "loss": 10.4375,
      "step": 9
    },
    {
      "epoch": 0.01,
      "grad_norm": 404.0,
      "learning_rate": 0.00014980211081794194,
      "loss": 2.75,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 179.0,
      "learning_rate": 0.00014978232189973614,
      "loss": 1.6484,
      "step": 11
    },
    {
      "epoch": 0.02,
      "grad_norm": 560.0,
      "learning_rate": 0.00014976253298153034,
      "loss": 9.875,
      "step": 12
    },
    {
      "epoch": 0.02,
      "grad_norm": 256.0,
      "learning_rate": 0.00014974274406332453,
      "loss": 2.0938,
      "step": 13
    },
    {
      "epoch": 0.02,
      "grad_norm": 900.0,
      "learning_rate": 0.00014972295514511873,
      "loss": 15.125,
      "step": 14
    },
    {
      "epoch": 0.02,
      "grad_norm": 228.0,
      "learning_rate": 0.00014970316622691293,
      "loss": 3.0469,
      "step": 15
    },
    {
      "epoch": 0.02,
      "grad_norm": 520.0,
      "learning_rate": 0.0001496833773087071,
      "loss": 6.7812,
      "step": 16
    },
    {
      "epoch": 0.02,
      "grad_norm": 172.0,
      "learning_rate": 0.0001496635883905013,
      "loss": 1.75,
      "step": 17
    },
    {
      "epoch": 0.02,
      "grad_norm": 47.0,
      "learning_rate": 0.0001496437994722955,
      "loss": 0.21,
      "step": 18
    },
    {
      "epoch": 0.03,
      "grad_norm": 177.0,
      "learning_rate": 0.0001496240105540897,
      "loss": 1.5469,
      "step": 19
    },
    {
      "epoch": 0.03,
      "grad_norm": 123.5,
      "learning_rate": 0.0001496042216358839,
      "loss": 0.8086,
      "step": 20
    },
    {
      "epoch": 0.03,
      "grad_norm": 125.0,
      "learning_rate": 0.0001495844327176781,
      "loss": 0.5664,
      "step": 21
    },
    {
      "epoch": 0.03,
      "grad_norm": 223.0,
      "learning_rate": 0.0001495646437994723,
      "loss": 1.4453,
      "step": 22
    },
    {
      "epoch": 0.03,
      "grad_norm": 528.0,
      "learning_rate": 0.00014954485488126646,
      "loss": 3.125,
      "step": 23
    },
    {
      "epoch": 0.03,
      "grad_norm": 234.0,
      "learning_rate": 0.00014952506596306066,
      "loss": 0.5312,
      "step": 24
    },
    {
      "epoch": 0.03,
      "grad_norm": 2992.0,
      "learning_rate": 0.00014950527704485486,
      "loss": 27.75,
      "step": 25
    },
    {
      "epoch": 0.03,
      "grad_norm": 15104.0,
      "learning_rate": 0.00014948548812664906,
      "loss": 22.125,
      "step": 26
    },
    {
      "epoch": 0.04,
      "grad_norm": 840.0,
      "learning_rate": 0.00014946569920844325,
      "loss": 1.4922,
      "step": 27
    },
    {
      "epoch": 0.04,
      "grad_norm": 6304.0,
      "learning_rate": 0.00014944591029023745,
      "loss": 23.625,
      "step": 28
    },
    {
      "epoch": 0.04,
      "grad_norm": 1448.0,
      "learning_rate": 0.00014942612137203165,
      "loss": 1.5312,
      "step": 29
    },
    {
      "epoch": 0.04,
      "grad_norm": 556.0,
      "learning_rate": 0.00014940633245382585,
      "loss": 1.9844,
      "step": 30
    },
    {
      "epoch": 0.04,
      "grad_norm": 198.0,
      "learning_rate": 0.00014938654353562005,
      "loss": 1.5312,
      "step": 31
    },
    {
      "epoch": 0.04,
      "grad_norm": 121.0,
      "learning_rate": 0.00014936675461741424,
      "loss": 1.3906,
      "step": 32
    },
    {
      "epoch": 0.04,
      "grad_norm": 848.0,
      "learning_rate": 0.00014934696569920844,
      "loss": 6.0938,
      "step": 33
    },
    {
      "epoch": 0.04,
      "grad_norm": 470.0,
      "learning_rate": 0.00014932717678100264,
      "loss": 6.9688,
      "step": 34
    },
    {
      "epoch": 0.05,
      "grad_norm": 1012.0,
      "learning_rate": 0.0001493073878627968,
      "loss": 11.4375,
      "step": 35
    },
    {
      "epoch": 0.05,
      "grad_norm": 452.0,
      "learning_rate": 0.000149287598944591,
      "loss": 1.1016,
      "step": 36
    },
    {
      "epoch": 0.05,
      "grad_norm": 117.0,
      "learning_rate": 0.0001492678100263852,
      "loss": 0.6719,
      "step": 37
    },
    {
      "epoch": 0.05,
      "grad_norm": 123.0,
      "learning_rate": 0.0001492480211081794,
      "loss": 0.6797,
      "step": 38
    },
    {
      "epoch": 0.05,
      "grad_norm": 354.0,
      "learning_rate": 0.0001492282321899736,
      "loss": 2.7969,
      "step": 39
    },
    {
      "epoch": 0.05,
      "grad_norm": 167.0,
      "learning_rate": 0.0001492084432717678,
      "loss": 1.2812,
      "step": 40
    },
    {
      "epoch": 0.05,
      "grad_norm": 159.0,
      "learning_rate": 0.000149188654353562,
      "loss": 1.3281,
      "step": 41
    },
    {
      "epoch": 0.06,
      "grad_norm": 152.0,
      "learning_rate": 0.0001491688654353562,
      "loss": 0.4492,
      "step": 42
    },
    {
      "epoch": 0.06,
      "grad_norm": 107.5,
      "learning_rate": 0.0001491490765171504,
      "loss": 0.8594,
      "step": 43
    },
    {
      "epoch": 0.06,
      "grad_norm": 278.0,
      "learning_rate": 0.0001491292875989446,
      "loss": 1.7266,
      "step": 44
    },
    {
      "epoch": 0.06,
      "grad_norm": 148.0,
      "learning_rate": 0.0001491094986807388,
      "loss": 0.4297,
      "step": 45
    },
    {
      "epoch": 0.06,
      "grad_norm": 49.5,
      "learning_rate": 0.00014908970976253296,
      "loss": 0.5312,
      "step": 46
    },
    {
      "epoch": 0.06,
      "grad_norm": 25.75,
      "learning_rate": 0.00014906992084432716,
      "loss": 0.4512,
      "step": 47
    },
    {
      "epoch": 0.06,
      "grad_norm": 77.0,
      "learning_rate": 0.00014905013192612136,
      "loss": 0.4238,
      "step": 48
    },
    {
      "epoch": 0.06,
      "grad_norm": 348.0,
      "learning_rate": 0.00014903034300791556,
      "loss": 4.2188,
      "step": 49
    },
    {
      "epoch": 0.07,
      "grad_norm": 167.0,
      "learning_rate": 0.00014901055408970975,
      "loss": 0.6328,
      "step": 50
    },
    {
      "epoch": 0.07,
      "grad_norm": 16.875,
      "learning_rate": 0.00014899076517150395,
      "loss": 0.3496,
      "step": 51
    },
    {
      "epoch": 0.07,
      "grad_norm": 370.0,
      "learning_rate": 0.00014897097625329812,
      "loss": 5.0,
      "step": 52
    },
    {
      "epoch": 0.07,
      "grad_norm": 652.0,
      "learning_rate": 0.00014895118733509232,
      "loss": 10.5625,
      "step": 53
    },
    {
      "epoch": 0.07,
      "grad_norm": 84.5,
      "learning_rate": 0.00014893139841688652,
      "loss": 0.4961,
      "step": 54
    },
    {
      "epoch": 0.07,
      "grad_norm": 712.0,
      "learning_rate": 0.00014891160949868072,
      "loss": 8.625,
      "step": 55
    },
    {
      "epoch": 0.07,
      "grad_norm": 103.0,
      "learning_rate": 0.00014889182058047492,
      "loss": 0.4844,
      "step": 56
    },
    {
      "epoch": 0.08,
      "grad_norm": 576.0,
      "learning_rate": 0.00014887203166226911,
      "loss": 8.625,
      "step": 57
    },
    {
      "epoch": 0.08,
      "grad_norm": 80.5,
      "learning_rate": 0.0001488522427440633,
      "loss": 0.4238,
      "step": 58
    },
    {
      "epoch": 0.08,
      "grad_norm": 352.0,
      "learning_rate": 0.0001488324538258575,
      "loss": 2.4219,
      "step": 59
    },
    {
      "epoch": 0.08,
      "grad_norm": 65.0,
      "learning_rate": 0.0001488126649076517,
      "loss": 0.5625,
      "step": 60
    },
    {
      "epoch": 0.08,
      "grad_norm": 213.0,
      "learning_rate": 0.0001487928759894459,
      "loss": 1.4219,
      "step": 61
    },
    {
      "epoch": 0.08,
      "grad_norm": 193.0,
      "learning_rate": 0.0001487730870712401,
      "loss": 0.8906,
      "step": 62
    },
    {
      "epoch": 0.08,
      "grad_norm": 169.0,
      "learning_rate": 0.0001487532981530343,
      "loss": 0.9688,
      "step": 63
    },
    {
      "epoch": 0.08,
      "grad_norm": 41.0,
      "learning_rate": 0.00014873350923482847,
      "loss": 1.1094,
      "step": 64
    },
    {
      "epoch": 0.09,
      "grad_norm": 168.0,
      "learning_rate": 0.00014871372031662267,
      "loss": 0.9688,
      "step": 65
    },
    {
      "epoch": 0.09,
      "grad_norm": 153.0,
      "learning_rate": 0.00014869393139841687,
      "loss": 1.0781,
      "step": 66
    },
    {
      "epoch": 0.09,
      "grad_norm": 580.0,
      "learning_rate": 0.00014867414248021107,
      "loss": 4.8125,
      "step": 67
    },
    {
      "epoch": 0.09,
      "grad_norm": 322.0,
      "learning_rate": 0.00014865435356200527,
      "loss": 2.0156,
      "step": 68
    },
    {
      "epoch": 0.09,
      "grad_norm": 66.5,
      "learning_rate": 0.00014863456464379946,
      "loss": 0.1758,
      "step": 69
    },
    {
      "epoch": 0.09,
      "grad_norm": 119.5,
      "learning_rate": 0.00014861477572559366,
      "loss": 0.7305,
      "step": 70
    },
    {
      "epoch": 0.09,
      "grad_norm": 700.0,
      "learning_rate": 0.00014859498680738786,
      "loss": 6.1875,
      "step": 71
    },
    {
      "epoch": 0.09,
      "grad_norm": 400.0,
      "learning_rate": 0.00014857519788918206,
      "loss": 2.75,
      "step": 72
    },
    {
      "epoch": 0.1,
      "grad_norm": 296.0,
      "learning_rate": 0.00014855540897097626,
      "loss": 2.3125,
      "step": 73
    },
    {
      "epoch": 0.1,
      "grad_norm": 103.5,
      "learning_rate": 0.00014853562005277045,
      "loss": 0.6484,
      "step": 74
    },
    {
      "epoch": 0.1,
      "grad_norm": 254.0,
      "learning_rate": 0.00014851583113456465,
      "loss": 1.8516,
      "step": 75
    },
    {
      "epoch": 0.1,
      "grad_norm": 149.0,
      "learning_rate": 0.00014849604221635882,
      "loss": 0.7266,
      "step": 76
    },
    {
      "epoch": 0.1,
      "grad_norm": 152.0,
      "learning_rate": 0.00014847625329815302,
      "loss": 0.957,
      "step": 77
    },
    {
      "epoch": 0.1,
      "grad_norm": 198.0,
      "learning_rate": 0.00014845646437994722,
      "loss": 0.9727,
      "step": 78
    },
    {
      "epoch": 0.1,
      "grad_norm": 152.0,
      "learning_rate": 0.00014843667546174142,
      "loss": 0.7617,
      "step": 79
    },
    {
      "epoch": 0.11,
      "grad_norm": 90.5,
      "learning_rate": 0.00014841688654353561,
      "loss": 0.5781,
      "step": 80
    },
    {
      "epoch": 0.11,
      "grad_norm": 632.0,
      "learning_rate": 0.00014839709762532979,
      "loss": 3.9844,
      "step": 81
    },
    {
      "epoch": 0.11,
      "grad_norm": 83.0,
      "learning_rate": 0.00014837730870712398,
      "loss": 0.207,
      "step": 82
    },
    {
      "epoch": 0.11,
      "grad_norm": 38.0,
      "learning_rate": 0.00014835751978891818,
      "loss": 0.0845,
      "step": 83
    },
    {
      "epoch": 0.11,
      "grad_norm": 624.0,
      "learning_rate": 0.00014833773087071238,
      "loss": 6.9375,
      "step": 84
    },
    {
      "epoch": 0.11,
      "grad_norm": 180.0,
      "learning_rate": 0.00014831794195250658,
      "loss": 1.6484,
      "step": 85
    },
    {
      "epoch": 0.11,
      "grad_norm": 276.0,
      "learning_rate": 0.00014829815303430078,
      "loss": 2.4375,
      "step": 86
    },
    {
      "epoch": 0.11,
      "grad_norm": 127.5,
      "learning_rate": 0.00014827836411609497,
      "loss": 0.8164,
      "step": 87
    },
    {
      "epoch": 0.12,
      "grad_norm": 180.0,
      "learning_rate": 0.00014825857519788917,
      "loss": 1.5234,
      "step": 88
    },
    {
      "epoch": 0.12,
      "grad_norm": 167.0,
      "learning_rate": 0.00014823878627968337,
      "loss": 1.0547,
      "step": 89
    },
    {
      "epoch": 0.12,
      "grad_norm": 116.5,
      "learning_rate": 0.00014821899736147757,
      "loss": 0.6211,
      "step": 90
    },
    {
      "epoch": 0.12,
      "grad_norm": 105.5,
      "learning_rate": 0.00014819920844327177,
      "loss": 0.4883,
      "step": 91
    },
    {
      "epoch": 0.12,
      "grad_norm": 4128.0,
      "learning_rate": 0.00014817941952506596,
      "loss": 10.6875,
      "step": 92
    },
    {
      "epoch": 0.12,
      "grad_norm": 193.0,
      "learning_rate": 0.00014815963060686014,
      "loss": 1.2734,
      "step": 93
    },
    {
      "epoch": 0.12,
      "grad_norm": 748.0,
      "learning_rate": 0.00014813984168865433,
      "loss": 8.6875,
      "step": 94
    },
    {
      "epoch": 0.13,
      "grad_norm": 680.0,
      "learning_rate": 0.00014812005277044853,
      "loss": 7.7812,
      "step": 95
    },
    {
      "epoch": 0.13,
      "grad_norm": 470.0,
      "learning_rate": 0.00014810026385224273,
      "loss": 5.1562,
      "step": 96
    },
    {
      "epoch": 0.13,
      "grad_norm": 175.0,
      "learning_rate": 0.00014808047493403693,
      "loss": 1.0078,
      "step": 97
    },
    {
      "epoch": 0.13,
      "grad_norm": 135.0,
      "learning_rate": 0.00014806068601583113,
      "loss": 0.75,
      "step": 98
    },
    {
      "epoch": 0.13,
      "grad_norm": 326.0,
      "learning_rate": 0.00014804089709762532,
      "loss": 1.9141,
      "step": 99
    },
    {
      "epoch": 0.13,
      "grad_norm": 144.0,
      "learning_rate": 0.00014802110817941952,
      "loss": 0.8125,
      "step": 100
    },
    {
      "epoch": 0.13,
      "grad_norm": 235.0,
      "learning_rate": 0.00014800131926121372,
      "loss": 1.8281,
      "step": 101
    },
    {
      "epoch": 0.13,
      "grad_norm": 182.0,
      "learning_rate": 0.00014798153034300792,
      "loss": 1.5156,
      "step": 102
    },
    {
      "epoch": 0.14,
      "grad_norm": 86.5,
      "learning_rate": 0.00014796174142480212,
      "loss": 0.2031,
      "step": 103
    },
    {
      "epoch": 0.14,
      "grad_norm": 260.0,
      "learning_rate": 0.00014794195250659631,
      "loss": 2.0625,
      "step": 104
    },
    {
      "epoch": 0.14,
      "grad_norm": 1584.0,
      "learning_rate": 0.00014792216358839048,
      "loss": 7.9062,
      "step": 105
    },
    {
      "epoch": 0.14,
      "grad_norm": 504.0,
      "learning_rate": 0.00014790237467018468,
      "loss": 4.8438,
      "step": 106
    },
    {
      "epoch": 0.14,
      "grad_norm": 498.0,
      "learning_rate": 0.00014788258575197888,
      "loss": 4.4375,
      "step": 107
    },
    {
      "epoch": 0.14,
      "grad_norm": 656.0,
      "learning_rate": 0.00014786279683377308,
      "loss": 4.5938,
      "step": 108
    },
    {
      "epoch": 0.14,
      "grad_norm": 336.0,
      "learning_rate": 0.00014784300791556725,
      "loss": 2.1562,
      "step": 109
    },
    {
      "epoch": 0.15,
      "grad_norm": 490.0,
      "learning_rate": 0.00014782321899736145,
      "loss": 3.5938,
      "step": 110
    },
    {
      "epoch": 0.15,
      "grad_norm": 175.0,
      "learning_rate": 0.00014780343007915565,
      "loss": 0.9375,
      "step": 111
    },
    {
      "epoch": 0.15,
      "grad_norm": 504.0,
      "learning_rate": 0.00014778364116094984,
      "loss": 3.5156,
      "step": 112
    },
    {
      "epoch": 0.15,
      "grad_norm": 434.0,
      "learning_rate": 0.00014776385224274404,
      "loss": 3.0,
      "step": 113
    },
    {
      "epoch": 0.15,
      "grad_norm": 172.0,
      "learning_rate": 0.00014774406332453824,
      "loss": 1.7734,
      "step": 114
    },
    {
      "epoch": 0.15,
      "grad_norm": 200.0,
      "learning_rate": 0.00014772427440633244,
      "loss": 1.9922,
      "step": 115
    },
    {
      "epoch": 0.15,
      "grad_norm": 432.0,
      "learning_rate": 0.00014770448548812664,
      "loss": 3.9219,
      "step": 116
    },
    {
      "epoch": 0.15,
      "grad_norm": 432.0,
      "learning_rate": 0.00014768469656992083,
      "loss": 4.25,
      "step": 117
    },
    {
      "epoch": 0.16,
      "grad_norm": 220.0,
      "learning_rate": 0.00014766490765171503,
      "loss": 1.3359,
      "step": 118
    },
    {
      "epoch": 0.16,
      "grad_norm": 142.0,
      "learning_rate": 0.00014764511873350923,
      "loss": 1.0547,
      "step": 119
    },
    {
      "epoch": 0.16,
      "grad_norm": 121.0,
      "learning_rate": 0.00014762532981530343,
      "loss": 1.5,
      "step": 120
    },
    {
      "epoch": 0.16,
      "grad_norm": 362.0,
      "learning_rate": 0.0001476055408970976,
      "loss": 2.6406,
      "step": 121
    },
    {
      "epoch": 0.16,
      "grad_norm": 760.0,
      "learning_rate": 0.0001475857519788918,
      "loss": 5.375,
      "step": 122
    },
    {
      "epoch": 0.16,
      "grad_norm": 560.0,
      "learning_rate": 0.000147565963060686,
      "loss": 2.5625,
      "step": 123
    },
    {
      "epoch": 0.16,
      "grad_norm": 250.0,
      "learning_rate": 0.0001475461741424802,
      "loss": 0.9219,
      "step": 124
    },
    {
      "epoch": 0.16,
      "grad_norm": 150.0,
      "learning_rate": 0.0001475263852242744,
      "loss": 0.9648,
      "step": 125
    },
    {
      "epoch": 0.17,
      "grad_norm": 144.0,
      "learning_rate": 0.0001475065963060686,
      "loss": 0.7695,
      "step": 126
    },
    {
      "epoch": 0.17,
      "grad_norm": 139.0,
      "learning_rate": 0.0001474868073878628,
      "loss": 0.9531,
      "step": 127
    },
    {
      "epoch": 0.17,
      "grad_norm": 214.0,
      "learning_rate": 0.00014746701846965699,
      "loss": 1.1406,
      "step": 128
    },
    {
      "epoch": 0.17,
      "grad_norm": 780.0,
      "learning_rate": 0.00014744722955145118,
      "loss": 8.5,
      "step": 129
    },
    {
      "epoch": 0.17,
      "grad_norm": 604.0,
      "learning_rate": 0.00014742744063324538,
      "loss": 6.625,
      "step": 130
    },
    {
      "epoch": 0.17,
      "grad_norm": 251.0,
      "learning_rate": 0.00014740765171503958,
      "loss": 0.9023,
      "step": 131
    },
    {
      "epoch": 0.17,
      "grad_norm": 14.5625,
      "learning_rate": 0.00014738786279683378,
      "loss": 0.4238,
      "step": 132
    },
    {
      "epoch": 0.18,
      "grad_norm": 83.0,
      "learning_rate": 0.00014736807387862795,
      "loss": 0.5312,
      "step": 133
    },
    {
      "epoch": 0.18,
      "grad_norm": 640.0,
      "learning_rate": 0.00014734828496042215,
      "loss": 6.3125,
      "step": 134
    },
    {
      "epoch": 0.18,
      "grad_norm": 61.5,
      "learning_rate": 0.00014732849604221635,
      "loss": 0.4375,
      "step": 135
    },
    {
      "epoch": 0.18,
      "grad_norm": 42.0,
      "learning_rate": 0.00014730870712401054,
      "loss": 0.3848,
      "step": 136
    },
    {
      "epoch": 0.18,
      "grad_norm": 828.0,
      "learning_rate": 0.00014728891820580474,
      "loss": 10.375,
      "step": 137
    },
    {
      "epoch": 0.18,
      "grad_norm": 153.0,
      "learning_rate": 0.0001472691292875989,
      "loss": 0.7617,
      "step": 138
    },
    {
      "epoch": 0.18,
      "grad_norm": 378.0,
      "learning_rate": 0.0001472493403693931,
      "loss": 4.6875,
      "step": 139
    },
    {
      "epoch": 0.18,
      "grad_norm": 90.0,
      "learning_rate": 0.0001472295514511873,
      "loss": 0.2344,
      "step": 140
    },
    {
      "epoch": 0.19,
      "grad_norm": 245.0,
      "learning_rate": 0.0001472097625329815,
      "loss": 1.3984,
      "step": 141
    },
    {
      "epoch": 0.19,
      "grad_norm": 896.0,
      "learning_rate": 0.0001471899736147757,
      "loss": 8.625,
      "step": 142
    },
    {
      "epoch": 0.19,
      "grad_norm": 632.0,
      "learning_rate": 0.0001471701846965699,
      "loss": 4.625,
      "step": 143
    },
    {
      "epoch": 0.19,
      "grad_norm": 197.0,
      "learning_rate": 0.0001471503957783641,
      "loss": 0.8047,
      "step": 144
    },
    {
      "epoch": 0.19,
      "grad_norm": 251.0,
      "learning_rate": 0.0001471306068601583,
      "loss": 0.8594,
      "step": 145
    },
    {
      "epoch": 0.19,
      "grad_norm": 228.0,
      "learning_rate": 0.0001471108179419525,
      "loss": 1.3906,
      "step": 146
    },
    {
      "epoch": 0.19,
      "grad_norm": 155.0,
      "learning_rate": 0.0001470910290237467,
      "loss": 1.2969,
      "step": 147
    },
    {
      "epoch": 0.2,
      "grad_norm": 468.0,
      "learning_rate": 0.0001470712401055409,
      "loss": 2.0938,
      "step": 148
    },
    {
      "epoch": 0.2,
      "grad_norm": 149.0,
      "learning_rate": 0.0001470514511873351,
      "loss": 2.375,
      "step": 149
    },
    {
      "epoch": 0.2,
      "grad_norm": 600.0,
      "learning_rate": 0.00014703166226912926,
      "loss": 1.0781,
      "step": 150
    },
    {
      "epoch": 0.2,
      "grad_norm": 125.5,
      "learning_rate": 0.00014701187335092346,
      "loss": 0.5703,
      "step": 151
    },
    {
      "epoch": 0.2,
      "grad_norm": 44.25,
      "learning_rate": 0.00014699208443271766,
      "loss": 0.543,
      "step": 152
    },
    {
      "epoch": 0.2,
      "grad_norm": 105.0,
      "learning_rate": 0.00014697229551451186,
      "loss": 0.5273,
      "step": 153
    },
    {
      "epoch": 0.2,
      "grad_norm": 548.0,
      "learning_rate": 0.00014695250659630605,
      "loss": 5.2812,
      "step": 154
    },
    {
      "epoch": 0.2,
      "grad_norm": 42.75,
      "learning_rate": 0.00014693271767810025,
      "loss": 0.4082,
      "step": 155
    },
    {
      "epoch": 0.21,
      "grad_norm": 364.0,
      "learning_rate": 0.00014691292875989445,
      "loss": 3.375,
      "step": 156
    },
    {
      "epoch": 0.21,
      "grad_norm": 83.5,
      "learning_rate": 0.00014689313984168865,
      "loss": 0.1816,
      "step": 157
    },
    {
      "epoch": 0.21,
      "grad_norm": 368.0,
      "learning_rate": 0.00014687335092348285,
      "loss": 3.3125,
      "step": 158
    },
    {
      "epoch": 0.21,
      "grad_norm": 446.0,
      "learning_rate": 0.00014685356200527704,
      "loss": 3.4844,
      "step": 159
    },
    {
      "epoch": 0.21,
      "grad_norm": 73.5,
      "learning_rate": 0.00014683377308707124,
      "loss": 0.3535,
      "step": 160
    },
    {
      "epoch": 0.21,
      "grad_norm": 67.0,
      "learning_rate": 0.00014681398416886544,
      "loss": 0.668,
      "step": 161
    },
    {
      "epoch": 0.21,
      "grad_norm": 141.0,
      "learning_rate": 0.0001467941952506596,
      "loss": 1.0781,
      "step": 162
    },
    {
      "epoch": 0.22,
      "grad_norm": 242.0,
      "learning_rate": 0.0001467744063324538,
      "loss": 1.5391,
      "step": 163
    },
    {
      "epoch": 0.22,
      "grad_norm": 152.0,
      "learning_rate": 0.000146754617414248,
      "loss": 0.9453,
      "step": 164
    },
    {
      "epoch": 0.22,
      "grad_norm": 195.0,
      "learning_rate": 0.0001467348284960422,
      "loss": 1.2422,
      "step": 165
    },
    {
      "epoch": 0.22,
      "grad_norm": 113.0,
      "learning_rate": 0.0001467150395778364,
      "loss": 0.7266,
      "step": 166
    },
    {
      "epoch": 0.22,
      "grad_norm": 125.0,
      "learning_rate": 0.00014669525065963057,
      "loss": 1.1641,
      "step": 167
    },
    {
      "epoch": 0.22,
      "grad_norm": 428.0,
      "learning_rate": 0.00014667546174142477,
      "loss": 2.7812,
      "step": 168
    },
    {
      "epoch": 0.22,
      "grad_norm": 700.0,
      "learning_rate": 0.00014665567282321897,
      "loss": 11.125,
      "step": 169
    },
    {
      "epoch": 0.22,
      "grad_norm": 115.5,
      "learning_rate": 0.00014663588390501317,
      "loss": 1.0781,
      "step": 170
    },
    {
      "epoch": 0.23,
      "grad_norm": 720.0,
      "learning_rate": 0.00014661609498680737,
      "loss": 9.875,
      "step": 171
    },
    {
      "epoch": 0.23,
      "grad_norm": 150.0,
      "learning_rate": 0.00014659630606860157,
      "loss": 0.9102,
      "step": 172
    },
    {
      "epoch": 0.23,
      "grad_norm": 166.0,
      "learning_rate": 0.00014657651715039576,
      "loss": 0.7266,
      "step": 173
    },
    {
      "epoch": 0.23,
      "grad_norm": 115.0,
      "learning_rate": 0.00014655672823218996,
      "loss": 0.6797,
      "step": 174
    },
    {
      "epoch": 0.23,
      "grad_norm": 36.5,
      "learning_rate": 0.00014653693931398416,
      "loss": 0.4258,
      "step": 175
    },
    {
      "epoch": 0.23,
      "grad_norm": 18.5,
      "learning_rate": 0.00014651715039577836,
      "loss": 0.4219,
      "step": 176
    },
    {
      "epoch": 0.23,
      "grad_norm": 724.0,
      "learning_rate": 0.00014649736147757256,
      "loss": 7.375,
      "step": 177
    },
    {
      "epoch": 0.23,
      "grad_norm": 53.25,
      "learning_rate": 0.00014647757255936675,
      "loss": 0.3672,
      "step": 178
    },
    {
      "epoch": 0.24,
      "grad_norm": 356.0,
      "learning_rate": 0.00014645778364116092,
      "loss": 4.2812,
      "step": 179
    },
    {
      "epoch": 0.24,
      "grad_norm": 21.0,
      "learning_rate": 0.00014643799472295512,
      "loss": 0.2773,
      "step": 180
    },
    {
      "epoch": 0.24,
      "grad_norm": 378.0,
      "learning_rate": 0.00014641820580474932,
      "loss": 2.7344,
      "step": 181
    },
    {
      "epoch": 0.24,
      "grad_norm": 370.0,
      "learning_rate": 0.00014639841688654352,
      "loss": 4.0938,
      "step": 182
    },
    {
      "epoch": 0.24,
      "grad_norm": 43.5,
      "learning_rate": 0.00014637862796833772,
      "loss": 0.3711,
      "step": 183
    },
    {
      "epoch": 0.24,
      "grad_norm": 564.0,
      "learning_rate": 0.00014635883905013191,
      "loss": 5.4375,
      "step": 184
    },
    {
      "epoch": 0.24,
      "grad_norm": 52.5,
      "learning_rate": 0.0001463390501319261,
      "loss": 0.4512,
      "step": 185
    },
    {
      "epoch": 0.25,
      "grad_norm": 420.0,
      "learning_rate": 0.0001463192612137203,
      "loss": 2.5938,
      "step": 186
    },
    {
      "epoch": 0.25,
      "grad_norm": 306.0,
      "learning_rate": 0.0001462994722955145,
      "loss": 1.6719,
      "step": 187
    },
    {
      "epoch": 0.25,
      "grad_norm": 544.0,
      "learning_rate": 0.0001462796833773087,
      "loss": 4.375,
      "step": 188
    },
    {
      "epoch": 0.25,
      "grad_norm": 292.0,
      "learning_rate": 0.0001462598944591029,
      "loss": 0.5938,
      "step": 189
    },
    {
      "epoch": 0.25,
      "grad_norm": 185.0,
      "learning_rate": 0.0001462401055408971,
      "loss": 1.1094,
      "step": 190
    },
    {
      "epoch": 0.25,
      "grad_norm": 143.0,
      "learning_rate": 0.00014622031662269127,
      "loss": 1.6719,
      "step": 191
    },
    {
      "epoch": 0.25,
      "grad_norm": 151.0,
      "learning_rate": 0.00014620052770448547,
      "loss": 2.1406,
      "step": 192
    },
    {
      "epoch": 0.25,
      "grad_norm": 180.0,
      "learning_rate": 0.00014618073878627967,
      "loss": 2.1562,
      "step": 193
    },
    {
      "epoch": 0.26,
      "grad_norm": 213.0,
      "learning_rate": 0.00014616094986807387,
      "loss": 1.8984,
      "step": 194
    },
    {
      "epoch": 0.26,
      "grad_norm": 8640.0,
      "learning_rate": 0.00014614116094986807,
      "loss": 2.4531,
      "step": 195
    },
    {
      "epoch": 0.26,
      "grad_norm": 556.0,
      "learning_rate": 0.00014612137203166224,
      "loss": 3.5312,
      "step": 196
    },
    {
      "epoch": 0.26,
      "grad_norm": 1032.0,
      "learning_rate": 0.00014610158311345644,
      "loss": 2.1406,
      "step": 197
    },
    {
      "epoch": 0.26,
      "grad_norm": 688.0,
      "learning_rate": 0.00014608179419525063,
      "loss": 3.8594,
      "step": 198
    },
    {
      "epoch": 0.26,
      "grad_norm": 1792.0,
      "learning_rate": 0.00014606200527704483,
      "loss": 7.625,
      "step": 199
    },
    {
      "epoch": 0.26,
      "grad_norm": 17280.0,
      "learning_rate": 0.00014604221635883903,
      "loss": 13.75,
      "step": 200
    },
    {
      "epoch": 0.27,
      "grad_norm": 96.0,
      "learning_rate": 0.00014602242744063323,
      "loss": 0.5352,
      "step": 201
    },
    {
      "epoch": 0.27,
      "grad_norm": 1792.0,
      "learning_rate": 0.00014600263852242743,
      "loss": 5.4688,
      "step": 202
    },
    {
      "epoch": 0.27,
      "grad_norm": 354.0,
      "learning_rate": 0.00014598284960422162,
      "loss": 1.1406,
      "step": 203
    },
    {
      "epoch": 0.27,
      "grad_norm": 13120.0,
      "learning_rate": 0.00014596306068601582,
      "loss": 9.4375,
      "step": 204
    },
    {
      "epoch": 0.27,
      "grad_norm": 222.0,
      "learning_rate": 0.00014594327176781002,
      "loss": 0.3887,
      "step": 205
    },
    {
      "epoch": 0.27,
      "grad_norm": 272.0,
      "learning_rate": 0.00014592348284960422,
      "loss": 2.0312,
      "step": 206
    },
    {
      "epoch": 0.27,
      "grad_norm": 47.0,
      "learning_rate": 0.0001459036939313984,
      "loss": 0.4082,
      "step": 207
    },
    {
      "epoch": 0.27,
      "grad_norm": 2160.0,
      "learning_rate": 0.0001458839050131926,
      "loss": 4.6562,
      "step": 208
    },
    {
      "epoch": 0.28,
      "grad_norm": 736.0,
      "learning_rate": 0.00014586411609498678,
      "loss": 11.625,
      "step": 209
    },
    {
      "epoch": 0.28,
      "grad_norm": 3936.0,
      "learning_rate": 0.00014584432717678098,
      "loss": 7.25,
      "step": 210
    },
    {
      "epoch": 0.28,
      "grad_norm": 1040.0,
      "learning_rate": 0.00014582453825857518,
      "loss": 2.7344,
      "step": 211
    },
    {
      "epoch": 0.28,
      "grad_norm": 1896.0,
      "learning_rate": 0.00014580474934036938,
      "loss": 12.3125,
      "step": 212
    },
    {
      "epoch": 0.28,
      "grad_norm": 38.25,
      "learning_rate": 0.00014578496042216358,
      "loss": 0.1396,
      "step": 213
    },
    {
      "epoch": 0.28,
      "grad_norm": 182.0,
      "learning_rate": 0.00014576517150395778,
      "loss": 0.4688,
      "step": 214
    },
    {
      "epoch": 0.28,
      "grad_norm": 728.0,
      "learning_rate": 0.00014574538258575197,
      "loss": 4.4688,
      "step": 215
    },
    {
      "epoch": 0.28,
      "grad_norm": 175.0,
      "learning_rate": 0.00014572559366754617,
      "loss": 0.6562,
      "step": 216
    },
    {
      "epoch": 0.29,
      "grad_norm": 175.0,
      "learning_rate": 0.00014570580474934037,
      "loss": 1.2969,
      "step": 217
    },
    {
      "epoch": 0.29,
      "grad_norm": 135.0,
      "learning_rate": 0.00014568601583113457,
      "loss": 0.543,
      "step": 218
    },
    {
      "epoch": 0.29,
      "grad_norm": 193.0,
      "learning_rate": 0.00014566622691292874,
      "loss": 1.375,
      "step": 219
    },
    {
      "epoch": 0.29,
      "grad_norm": 158.0,
      "learning_rate": 0.00014564643799472294,
      "loss": 0.9219,
      "step": 220
    },
    {
      "epoch": 0.29,
      "grad_norm": 414.0,
      "learning_rate": 0.00014562664907651713,
      "loss": 7.3125,
      "step": 221
    },
    {
      "epoch": 0.29,
      "grad_norm": 820.0,
      "learning_rate": 0.00014560686015831133,
      "loss": 12.25,
      "step": 222
    },
    {
      "epoch": 0.29,
      "grad_norm": 664.0,
      "learning_rate": 0.00014558707124010553,
      "loss": 6.125,
      "step": 223
    },
    {
      "epoch": 0.3,
      "grad_norm": 358.0,
      "learning_rate": 0.00014556728232189973,
      "loss": 2.6406,
      "step": 224
    },
    {
      "epoch": 0.3,
      "grad_norm": 130.0,
      "learning_rate": 0.00014554749340369393,
      "loss": 0.6758,
      "step": 225
    },
    {
      "epoch": 0.3,
      "grad_norm": 61.75,
      "learning_rate": 0.0001455277044854881,
      "loss": 1.0781,
      "step": 226
    },
    {
      "epoch": 0.3,
      "grad_norm": 222.0,
      "learning_rate": 0.0001455079155672823,
      "loss": 2.1875,
      "step": 227
    },
    {
      "epoch": 0.3,
      "grad_norm": 536.0,
      "learning_rate": 0.0001454881266490765,
      "loss": 2.6719,
      "step": 228
    },
    {
      "epoch": 0.3,
      "grad_norm": 210.0,
      "learning_rate": 0.0001454683377308707,
      "loss": 1.0391,
      "step": 229
    },
    {
      "epoch": 0.3,
      "grad_norm": 1256.0,
      "learning_rate": 0.0001454485488126649,
      "loss": 14.1875,
      "step": 230
    },
    {
      "epoch": 0.3,
      "grad_norm": 72.0,
      "learning_rate": 0.0001454287598944591,
      "loss": 0.9297,
      "step": 231
    },
    {
      "epoch": 0.31,
      "grad_norm": 138.0,
      "learning_rate": 0.00014540897097625329,
      "loss": 0.582,
      "step": 232
    },
    {
      "epoch": 0.31,
      "grad_norm": 53.75,
      "learning_rate": 0.00014538918205804748,
      "loss": 0.4902,
      "step": 233
    },
    {
      "epoch": 0.31,
      "grad_norm": 35.75,
      "learning_rate": 0.00014536939313984168,
      "loss": 0.291,
      "step": 234
    },
    {
      "epoch": 0.31,
      "grad_norm": 66.0,
      "learning_rate": 0.00014534960422163588,
      "loss": 0.3125,
      "step": 235
    },
    {
      "epoch": 0.31,
      "grad_norm": 78.0,
      "learning_rate": 0.00014532981530343005,
      "loss": 0.2178,
      "step": 236
    },
    {
      "epoch": 0.31,
      "grad_norm": 59.5,
      "learning_rate": 0.00014531002638522425,
      "loss": 0.3145,
      "step": 237
    },
    {
      "epoch": 0.31,
      "grad_norm": 544.0,
      "learning_rate": 0.00014529023746701845,
      "loss": 11.4375,
      "step": 238
    },
    {
      "epoch": 0.32,
      "grad_norm": 394.0,
      "learning_rate": 0.00014527044854881265,
      "loss": 8.1875,
      "step": 239
    },
    {
      "epoch": 0.32,
      "grad_norm": 93.5,
      "learning_rate": 0.00014525065963060684,
      "loss": 0.2412,
      "step": 240
    },
    {
      "epoch": 0.32,
      "grad_norm": 180.0,
      "learning_rate": 0.00014523087071240104,
      "loss": 1.3047,
      "step": 241
    },
    {
      "epoch": 0.32,
      "grad_norm": 88.5,
      "learning_rate": 0.00014521108179419524,
      "loss": 0.7695,
      "step": 242
    },
    {
      "epoch": 0.32,
      "grad_norm": 69.0,
      "learning_rate": 0.00014519129287598944,
      "loss": 0.5156,
      "step": 243
    },
    {
      "epoch": 0.32,
      "grad_norm": 99.0,
      "learning_rate": 0.00014517150395778364,
      "loss": 0.5117,
      "step": 244
    },
    {
      "epoch": 0.32,
      "grad_norm": 118.5,
      "learning_rate": 0.00014515171503957783,
      "loss": 0.7109,
      "step": 245
    },
    {
      "epoch": 0.32,
      "grad_norm": 71.0,
      "learning_rate": 0.00014513192612137203,
      "loss": 0.3848,
      "step": 246
    },
    {
      "epoch": 0.33,
      "grad_norm": 780.0,
      "learning_rate": 0.00014511213720316623,
      "loss": 9.0,
      "step": 247
    },
    {
      "epoch": 0.33,
      "grad_norm": 348.0,
      "learning_rate": 0.0001450923482849604,
      "loss": 3.5938,
      "step": 248
    },
    {
      "epoch": 0.33,
      "grad_norm": 266.0,
      "learning_rate": 0.0001450725593667546,
      "loss": 1.9297,
      "step": 249
    },
    {
      "epoch": 0.33,
      "grad_norm": 132.0,
      "learning_rate": 0.0001450527704485488,
      "loss": 0.4922,
      "step": 250
    },
    {
      "epoch": 0.33,
      "grad_norm": 508.0,
      "learning_rate": 0.000145032981530343,
      "loss": 4.9375,
      "step": 251
    },
    {
      "epoch": 0.33,
      "grad_norm": 103.0,
      "learning_rate": 0.0001450131926121372,
      "loss": 0.9805,
      "step": 252
    },
    {
      "epoch": 0.33,
      "grad_norm": 146.0,
      "learning_rate": 0.0001449934036939314,
      "loss": 1.7578,
      "step": 253
    },
    {
      "epoch": 0.34,
      "grad_norm": 90.0,
      "learning_rate": 0.0001449736147757256,
      "loss": 0.8398,
      "step": 254
    },
    {
      "epoch": 0.34,
      "grad_norm": 138.0,
      "learning_rate": 0.0001449538258575198,
      "loss": 0.8984,
      "step": 255
    },
    {
      "epoch": 0.34,
      "grad_norm": 616.0,
      "learning_rate": 0.00014493403693931396,
      "loss": 4.7812,
      "step": 256
    },
    {
      "epoch": 0.34,
      "grad_norm": 50.75,
      "learning_rate": 0.00014491424802110816,
      "loss": 0.5117,
      "step": 257
    },
    {
      "epoch": 0.34,
      "grad_norm": 47.5,
      "learning_rate": 0.00014489445910290235,
      "loss": 0.3281,
      "step": 258
    },
    {
      "epoch": 0.34,
      "grad_norm": 134.0,
      "learning_rate": 0.00014487467018469655,
      "loss": 0.8867,
      "step": 259
    },
    {
      "epoch": 0.34,
      "grad_norm": 34.5,
      "learning_rate": 0.00014485488126649075,
      "loss": 0.3223,
      "step": 260
    },
    {
      "epoch": 0.34,
      "grad_norm": 115.5,
      "learning_rate": 0.00014483509234828495,
      "loss": 0.6523,
      "step": 261
    },
    {
      "epoch": 0.35,
      "grad_norm": 326.0,
      "learning_rate": 0.00014481530343007915,
      "loss": 5.0312,
      "step": 262
    },
    {
      "epoch": 0.35,
      "grad_norm": 138.0,
      "learning_rate": 0.00014479551451187334,
      "loss": 0.75,
      "step": 263
    },
    {
      "epoch": 0.35,
      "grad_norm": 16.5,
      "learning_rate": 0.00014477572559366754,
      "loss": 0.2002,
      "step": 264
    },
    {
      "epoch": 0.35,
      "grad_norm": 476.0,
      "learning_rate": 0.00014475593667546171,
      "loss": 5.9688,
      "step": 265
    },
    {
      "epoch": 0.35,
      "grad_norm": 77.5,
      "learning_rate": 0.0001447361477572559,
      "loss": 0.6602,
      "step": 266
    },
    {
      "epoch": 0.35,
      "grad_norm": 17.375,
      "learning_rate": 0.0001447163588390501,
      "loss": 0.2354,
      "step": 267
    },
    {
      "epoch": 0.35,
      "grad_norm": 312.0,
      "learning_rate": 0.0001446965699208443,
      "loss": 3.8906,
      "step": 268
    },
    {
      "epoch": 0.35,
      "grad_norm": 420.0,
      "learning_rate": 0.0001446767810026385,
      "loss": 3.7188,
      "step": 269
    },
    {
      "epoch": 0.36,
      "grad_norm": 21.25,
      "learning_rate": 0.0001446569920844327,
      "loss": 0.4492,
      "step": 270
    },
    {
      "epoch": 0.36,
      "grad_norm": 93.0,
      "learning_rate": 0.0001446372031662269,
      "loss": 0.5898,
      "step": 271
    },
    {
      "epoch": 0.36,
      "grad_norm": 77.5,
      "learning_rate": 0.0001446174142480211,
      "loss": 0.293,
      "step": 272
    },
    {
      "epoch": 0.36,
      "grad_norm": 56.5,
      "learning_rate": 0.0001445976253298153,
      "loss": 0.8828,
      "step": 273
    },
    {
      "epoch": 0.36,
      "grad_norm": 560.0,
      "learning_rate": 0.0001445778364116095,
      "loss": 7.0312,
      "step": 274
    },
    {
      "epoch": 0.36,
      "grad_norm": 151.0,
      "learning_rate": 0.0001445580474934037,
      "loss": 0.7578,
      "step": 275
    },
    {
      "epoch": 0.36,
      "grad_norm": 316.0,
      "learning_rate": 0.0001445382585751979,
      "loss": 2.8906,
      "step": 276
    },
    {
      "epoch": 0.37,
      "grad_norm": 516.0,
      "learning_rate": 0.00014451846965699206,
      "loss": 7.0,
      "step": 277
    },
    {
      "epoch": 0.37,
      "grad_norm": 394.0,
      "learning_rate": 0.00014449868073878626,
      "loss": 4.2812,
      "step": 278
    },
    {
      "epoch": 0.37,
      "grad_norm": 338.0,
      "learning_rate": 0.00014447889182058046,
      "loss": 3.8125,
      "step": 279
    },
    {
      "epoch": 0.37,
      "grad_norm": 138.0,
      "learning_rate": 0.00014445910290237466,
      "loss": 0.9375,
      "step": 280
    },
    {
      "epoch": 0.37,
      "grad_norm": 132.0,
      "learning_rate": 0.00014443931398416886,
      "loss": 1.5781,
      "step": 281
    },
    {
      "epoch": 0.37,
      "grad_norm": 101.0,
      "learning_rate": 0.00014441952506596305,
      "loss": 0.9414,
      "step": 282
    },
    {
      "epoch": 0.37,
      "grad_norm": 106.0,
      "learning_rate": 0.00014439973614775725,
      "loss": 1.1406,
      "step": 283
    },
    {
      "epoch": 0.37,
      "grad_norm": 296.0,
      "learning_rate": 0.00014437994722955145,
      "loss": 3.4844,
      "step": 284
    },
    {
      "epoch": 0.38,
      "grad_norm": 95.0,
      "learning_rate": 0.00014436015831134565,
      "loss": 0.7852,
      "step": 285
    },
    {
      "epoch": 0.38,
      "grad_norm": 240.0,
      "learning_rate": 0.00014434036939313982,
      "loss": 3.0938,
      "step": 286
    },
    {
      "epoch": 0.38,
      "grad_norm": 155.0,
      "learning_rate": 0.00014432058047493402,
      "loss": 1.0312,
      "step": 287
    },
    {
      "epoch": 0.38,
      "grad_norm": 231.0,
      "learning_rate": 0.00014430079155672821,
      "loss": 2.375,
      "step": 288
    },
    {
      "epoch": 0.38,
      "grad_norm": 462.0,
      "learning_rate": 0.0001442810026385224,
      "loss": 6.1562,
      "step": 289
    },
    {
      "epoch": 0.38,
      "grad_norm": 104.0,
      "learning_rate": 0.0001442612137203166,
      "loss": 1.2109,
      "step": 290
    },
    {
      "epoch": 0.38,
      "grad_norm": 31.0,
      "learning_rate": 0.0001442414248021108,
      "loss": 1.25,
      "step": 291
    },
    {
      "epoch": 0.39,
      "grad_norm": 117.5,
      "learning_rate": 0.000144221635883905,
      "loss": 1.0625,
      "step": 292
    },
    {
      "epoch": 0.39,
      "grad_norm": 364.0,
      "learning_rate": 0.00014420184696569918,
      "loss": 5.0,
      "step": 293
    },
    {
      "epoch": 0.39,
      "grad_norm": 23.5,
      "learning_rate": 0.00014418205804749338,
      "loss": 0.2969,
      "step": 294
    },
    {
      "epoch": 0.39,
      "grad_norm": 200.0,
      "learning_rate": 0.00014416226912928757,
      "loss": 2.2188,
      "step": 295
    },
    {
      "epoch": 0.39,
      "grad_norm": 256.0,
      "learning_rate": 0.00014414248021108177,
      "loss": 2.75,
      "step": 296
    },
    {
      "epoch": 0.39,
      "grad_norm": 410.0,
      "learning_rate": 0.00014412269129287597,
      "loss": 5.5625,
      "step": 297
    },
    {
      "epoch": 0.39,
      "grad_norm": 41.75,
      "learning_rate": 0.00014410290237467017,
      "loss": 0.3887,
      "step": 298
    },
    {
      "epoch": 0.39,
      "grad_norm": 31.0,
      "learning_rate": 0.00014408311345646437,
      "loss": 0.3613,
      "step": 299
    },
    {
      "epoch": 0.4,
      "grad_norm": 95.0,
      "learning_rate": 0.00014406332453825856,
      "loss": 0.9023,
      "step": 300
    },
    {
      "epoch": 0.4,
      "grad_norm": 69.0,
      "learning_rate": 0.00014404353562005276,
      "loss": 0.7695,
      "step": 301
    },
    {
      "epoch": 0.4,
      "grad_norm": 103.0,
      "learning_rate": 0.00014402374670184696,
      "loss": 0.8242,
      "step": 302
    },
    {
      "epoch": 0.4,
      "grad_norm": 35.5,
      "learning_rate": 0.00014400395778364116,
      "loss": 0.3633,
      "step": 303
    },
    {
      "epoch": 0.4,
      "grad_norm": 216.0,
      "learning_rate": 0.00014398416886543536,
      "loss": 2.8125,
      "step": 304
    },
    {
      "epoch": 0.4,
      "grad_norm": 11.3125,
      "learning_rate": 0.00014396437994722953,
      "loss": 0.293,
      "step": 305
    },
    {
      "epoch": 0.4,
      "grad_norm": 420.0,
      "learning_rate": 0.00014394459102902373,
      "loss": 5.75,
      "step": 306
    },
    {
      "epoch": 0.41,
      "grad_norm": 544.0,
      "learning_rate": 0.00014392480211081792,
      "loss": 6.6562,
      "step": 307
    },
    {
      "epoch": 0.41,
      "grad_norm": 59.0,
      "learning_rate": 0.00014390501319261212,
      "loss": 0.5039,
      "step": 308
    },
    {
      "epoch": 0.41,
      "grad_norm": 450.0,
      "learning_rate": 0.00014388522427440632,
      "loss": 4.0,
      "step": 309
    },
    {
      "epoch": 0.41,
      "grad_norm": 324.0,
      "learning_rate": 0.00014386543535620052,
      "loss": 5.0312,
      "step": 310
    },
    {
      "epoch": 0.41,
      "grad_norm": 75.5,
      "learning_rate": 0.00014384564643799472,
      "loss": 0.7266,
      "step": 311
    },
    {
      "epoch": 0.41,
      "grad_norm": 83.5,
      "learning_rate": 0.00014382585751978891,
      "loss": 1.1719,
      "step": 312
    },
    {
      "epoch": 0.41,
      "grad_norm": 276.0,
      "learning_rate": 0.0001438060686015831,
      "loss": 3.7812,
      "step": 313
    },
    {
      "epoch": 0.41,
      "grad_norm": 108.0,
      "learning_rate": 0.0001437862796833773,
      "loss": 1.5859,
      "step": 314
    },
    {
      "epoch": 0.42,
      "grad_norm": 217.0,
      "learning_rate": 0.0001437664907651715,
      "loss": 3.2344,
      "step": 315
    },
    {
      "epoch": 0.42,
      "grad_norm": 198.0,
      "learning_rate": 0.00014374670184696568,
      "loss": 3.0469,
      "step": 316
    },
    {
      "epoch": 0.42,
      "grad_norm": 78.0,
      "learning_rate": 0.00014372691292875988,
      "loss": 1.0625,
      "step": 317
    },
    {
      "epoch": 0.42,
      "grad_norm": 51.75,
      "learning_rate": 0.00014370712401055408,
      "loss": 1.0156,
      "step": 318
    },
    {
      "epoch": 0.42,
      "grad_norm": 125.5,
      "learning_rate": 0.00014368733509234827,
      "loss": 1.2812,
      "step": 319
    },
    {
      "epoch": 0.42,
      "grad_norm": 91.5,
      "learning_rate": 0.00014366754617414247,
      "loss": 1.1328,
      "step": 320
    },
    {
      "epoch": 0.42,
      "grad_norm": 184.0,
      "learning_rate": 0.00014364775725593667,
      "loss": 3.9375,
      "step": 321
    },
    {
      "epoch": 0.42,
      "grad_norm": 159.0,
      "learning_rate": 0.00014362796833773084,
      "loss": 3.3125,
      "step": 322
    },
    {
      "epoch": 0.43,
      "grad_norm": 34.75,
      "learning_rate": 0.00014360817941952504,
      "loss": 0.2324,
      "step": 323
    },
    {
      "epoch": 0.43,
      "grad_norm": 157.0,
      "learning_rate": 0.00014358839050131924,
      "loss": 2.5781,
      "step": 324
    },
    {
      "epoch": 0.43,
      "grad_norm": 19.375,
      "learning_rate": 0.00014356860158311343,
      "loss": 0.1465,
      "step": 325
    },
    {
      "epoch": 0.43,
      "grad_norm": 312.0,
      "learning_rate": 0.00014354881266490763,
      "loss": 3.5625,
      "step": 326
    },
    {
      "epoch": 0.43,
      "grad_norm": 145.0,
      "learning_rate": 0.00014352902374670183,
      "loss": 1.6953,
      "step": 327
    },
    {
      "epoch": 0.43,
      "grad_norm": 86.5,
      "learning_rate": 0.00014350923482849603,
      "loss": 0.9062,
      "step": 328
    },
    {
      "epoch": 0.43,
      "grad_norm": 79.0,
      "learning_rate": 0.00014348944591029023,
      "loss": 1.2891,
      "step": 329
    },
    {
      "epoch": 0.44,
      "grad_norm": 118.0,
      "learning_rate": 0.00014346965699208442,
      "loss": 1.5,
      "step": 330
    },
    {
      "epoch": 0.44,
      "grad_norm": 118.5,
      "learning_rate": 0.00014344986807387862,
      "loss": 1.3047,
      "step": 331
    },
    {
      "epoch": 0.44,
      "grad_norm": 102.5,
      "learning_rate": 0.00014343007915567282,
      "loss": 1.3359,
      "step": 332
    },
    {
      "epoch": 0.44,
      "grad_norm": 56.75,
      "learning_rate": 0.00014341029023746702,
      "loss": 0.4668,
      "step": 333
    },
    {
      "epoch": 0.44,
      "grad_norm": 82.0,
      "learning_rate": 0.0001433905013192612,
      "loss": 0.4609,
      "step": 334
    },
    {
      "epoch": 0.44,
      "grad_norm": 57.75,
      "learning_rate": 0.0001433707124010554,
      "loss": 0.2969,
      "step": 335
    },
    {
      "epoch": 0.44,
      "grad_norm": 37.0,
      "learning_rate": 0.00014335092348284959,
      "loss": 0.6172,
      "step": 336
    },
    {
      "epoch": 0.44,
      "grad_norm": 88.0,
      "learning_rate": 0.00014333113456464378,
      "loss": 0.8867,
      "step": 337
    },
    {
      "epoch": 0.45,
      "grad_norm": 112.0,
      "learning_rate": 0.00014331134564643798,
      "loss": 0.7969,
      "step": 338
    },
    {
      "epoch": 0.45,
      "grad_norm": 217.0,
      "learning_rate": 0.00014329155672823218,
      "loss": 3.5625,
      "step": 339
    },
    {
      "epoch": 0.45,
      "grad_norm": 188.0,
      "learning_rate": 0.00014327176781002638,
      "loss": 1.6797,
      "step": 340
    },
    {
      "epoch": 0.45,
      "grad_norm": 10.0625,
      "learning_rate": 0.00014325197889182058,
      "loss": 0.3574,
      "step": 341
    },
    {
      "epoch": 0.45,
      "grad_norm": 358.0,
      "learning_rate": 0.00014323218997361477,
      "loss": 10.0625,
      "step": 342
    },
    {
      "epoch": 0.45,
      "grad_norm": 11.1875,
      "learning_rate": 0.00014321240105540897,
      "loss": 0.332,
      "step": 343
    },
    {
      "epoch": 0.45,
      "grad_norm": 189.0,
      "learning_rate": 0.00014319261213720317,
      "loss": 3.4219,
      "step": 344
    },
    {
      "epoch": 0.46,
      "grad_norm": 176.0,
      "learning_rate": 0.00014317282321899737,
      "loss": 3.0469,
      "step": 345
    },
    {
      "epoch": 0.46,
      "grad_norm": 284.0,
      "learning_rate": 0.00014315303430079154,
      "loss": 6.4375,
      "step": 346
    },
    {
      "epoch": 0.46,
      "grad_norm": 36.25,
      "learning_rate": 0.00014313324538258574,
      "loss": 0.4004,
      "step": 347
    },
    {
      "epoch": 0.46,
      "grad_norm": 19.75,
      "learning_rate": 0.00014311345646437994,
      "loss": 0.4355,
      "step": 348
    },
    {
      "epoch": 0.46,
      "grad_norm": 202.0,
      "learning_rate": 0.00014309366754617413,
      "loss": 4.5,
      "step": 349
    },
    {
      "epoch": 0.46,
      "grad_norm": 28.25,
      "learning_rate": 0.00014307387862796833,
      "loss": 0.3535,
      "step": 350
    },
    {
      "epoch": 0.46,
      "grad_norm": 32.25,
      "learning_rate": 0.0001430540897097625,
      "loss": 0.4023,
      "step": 351
    },
    {
      "epoch": 0.46,
      "grad_norm": 205.0,
      "learning_rate": 0.0001430343007915567,
      "loss": 2.7656,
      "step": 352
    },
    {
      "epoch": 0.47,
      "grad_norm": 44.0,
      "learning_rate": 0.0001430145118733509,
      "loss": 0.5312,
      "step": 353
    },
    {
      "epoch": 0.47,
      "grad_norm": 173.0,
      "learning_rate": 0.0001429947229551451,
      "loss": 3.25,
      "step": 354
    },
    {
      "epoch": 0.47,
      "grad_norm": 82.5,
      "learning_rate": 0.0001429749340369393,
      "loss": 2.0938,
      "step": 355
    },
    {
      "epoch": 0.47,
      "grad_norm": 108.0,
      "learning_rate": 0.0001429551451187335,
      "loss": 1.8594,
      "step": 356
    },
    {
      "epoch": 0.47,
      "grad_norm": 338.0,
      "learning_rate": 0.0001429353562005277,
      "loss": 5.625,
      "step": 357
    },
    {
      "epoch": 0.47,
      "grad_norm": 26.25,
      "learning_rate": 0.0001429155672823219,
      "loss": 0.3223,
      "step": 358
    },
    {
      "epoch": 0.47,
      "grad_norm": 25.125,
      "learning_rate": 0.0001428957783641161,
      "loss": 0.3008,
      "step": 359
    },
    {
      "epoch": 0.47,
      "grad_norm": 17.625,
      "learning_rate": 0.00014287598944591029,
      "loss": 0.1147,
      "step": 360
    },
    {
      "epoch": 0.48,
      "grad_norm": 340.0,
      "learning_rate": 0.00014285620052770448,
      "loss": 7.75,
      "step": 361
    },
    {
      "epoch": 0.48,
      "grad_norm": 34.5,
      "learning_rate": 0.00014283641160949868,
      "loss": 0.3047,
      "step": 362
    },
    {
      "epoch": 0.48,
      "grad_norm": 41.25,
      "learning_rate": 0.00014281662269129285,
      "loss": 0.6055,
      "step": 363
    },
    {
      "epoch": 0.48,
      "grad_norm": 175.0,
      "learning_rate": 0.00014279683377308705,
      "loss": 2.9688,
      "step": 364
    },
    {
      "epoch": 0.48,
      "grad_norm": 136.0,
      "learning_rate": 0.00014277704485488125,
      "loss": 2.25,
      "step": 365
    },
    {
      "epoch": 0.48,
      "grad_norm": 15.375,
      "learning_rate": 0.00014275725593667545,
      "loss": 0.3516,
      "step": 366
    },
    {
      "epoch": 0.48,
      "grad_norm": 17.625,
      "learning_rate": 0.00014273746701846964,
      "loss": 0.2676,
      "step": 367
    },
    {
      "epoch": 0.49,
      "grad_norm": 42.5,
      "learning_rate": 0.00014271767810026384,
      "loss": 0.6016,
      "step": 368
    },
    {
      "epoch": 0.49,
      "grad_norm": 29.25,
      "learning_rate": 0.00014269788918205804,
      "loss": 0.2119,
      "step": 369
    },
    {
      "epoch": 0.49,
      "grad_norm": 133.0,
      "learning_rate": 0.00014267810026385224,
      "loss": 1.8125,
      "step": 370
    },
    {
      "epoch": 0.49,
      "grad_norm": 20.75,
      "learning_rate": 0.00014265831134564644,
      "loss": 0.5156,
      "step": 371
    },
    {
      "epoch": 0.49,
      "grad_norm": 294.0,
      "learning_rate": 0.00014263852242744063,
      "loss": 5.5938,
      "step": 372
    },
    {
      "epoch": 0.49,
      "grad_norm": 298.0,
      "learning_rate": 0.00014261873350923483,
      "loss": 4.125,
      "step": 373
    },
    {
      "epoch": 0.49,
      "grad_norm": 250.0,
      "learning_rate": 0.00014259894459102903,
      "loss": 4.9688,
      "step": 374
    },
    {
      "epoch": 0.49,
      "grad_norm": 512.0,
      "learning_rate": 0.0001425791556728232,
      "loss": 9.625,
      "step": 375
    },
    {
      "epoch": 0.5,
      "grad_norm": 103.5,
      "learning_rate": 0.0001425593667546174,
      "loss": 1.5391,
      "step": 376
    },
    {
      "epoch": 0.5,
      "grad_norm": 36.0,
      "learning_rate": 0.0001425395778364116,
      "loss": 0.4805,
      "step": 377
    },
    {
      "epoch": 0.5,
      "grad_norm": 35.75,
      "learning_rate": 0.0001425197889182058,
      "loss": 0.625,
      "step": 378
    },
    {
      "epoch": 0.5,
      "grad_norm": 70.0,
      "learning_rate": 0.0001425,
      "loss": 0.6875,
      "step": 379
    },
    {
      "epoch": 0.5,
      "grad_norm": 38.25,
      "learning_rate": 0.00014248021108179417,
      "loss": 0.625,
      "step": 380
    },
    {
      "epoch": 0.5,
      "grad_norm": 27.375,
      "learning_rate": 0.00014246042216358836,
      "loss": 0.3125,
      "step": 381
    },
    {
      "epoch": 0.5,
      "grad_norm": 109.0,
      "learning_rate": 0.00014244063324538256,
      "loss": 1.7109,
      "step": 382
    },
    {
      "epoch": 0.51,
      "grad_norm": 68.5,
      "learning_rate": 0.00014242084432717676,
      "loss": 0.7305,
      "step": 383
    },
    {
      "epoch": 0.51,
      "grad_norm": 124.5,
      "learning_rate": 0.00014240105540897096,
      "loss": 2.0625,
      "step": 384
    },
    {
      "epoch": 0.51,
      "grad_norm": 46.0,
      "learning_rate": 0.00014238126649076516,
      "loss": 0.3398,
      "step": 385
    },
    {
      "epoch": 0.51,
      "grad_norm": 60.25,
      "learning_rate": 0.00014236147757255935,
      "loss": 0.4238,
      "step": 386
    },
    {
      "epoch": 0.51,
      "grad_norm": 26.625,
      "learning_rate": 0.00014234168865435355,
      "loss": 0.5391,
      "step": 387
    },
    {
      "epoch": 0.51,
      "grad_norm": 21.25,
      "learning_rate": 0.00014232189973614775,
      "loss": 0.4941,
      "step": 388
    },
    {
      "epoch": 0.51,
      "grad_norm": 322.0,
      "learning_rate": 0.00014230211081794195,
      "loss": 6.7188,
      "step": 389
    },
    {
      "epoch": 0.51,
      "grad_norm": 152.0,
      "learning_rate": 0.00014228232189973615,
      "loss": 2.3906,
      "step": 390
    },
    {
      "epoch": 0.52,
      "grad_norm": 264.0,
      "learning_rate": 0.00014226253298153034,
      "loss": 5.2812,
      "step": 391
    },
    {
      "epoch": 0.52,
      "grad_norm": 33.75,
      "learning_rate": 0.00014224274406332451,
      "loss": 0.5859,
      "step": 392
    },
    {
      "epoch": 0.52,
      "grad_norm": 300.0,
      "learning_rate": 0.0001422229551451187,
      "loss": 6.0625,
      "step": 393
    },
    {
      "epoch": 0.52,
      "grad_norm": 272.0,
      "learning_rate": 0.0001422031662269129,
      "loss": 5.7812,
      "step": 394
    },
    {
      "epoch": 0.52,
      "grad_norm": 41.25,
      "learning_rate": 0.0001421833773087071,
      "loss": 0.582,
      "step": 395
    },
    {
      "epoch": 0.52,
      "grad_norm": 41.0,
      "learning_rate": 0.0001421635883905013,
      "loss": 0.3965,
      "step": 396
    },
    {
      "epoch": 0.52,
      "grad_norm": 100.0,
      "learning_rate": 0.0001421437994722955,
      "loss": 1.5703,
      "step": 397
    },
    {
      "epoch": 0.53,
      "grad_norm": 176.0,
      "learning_rate": 0.0001421240105540897,
      "loss": 2.7344,
      "step": 398
    },
    {
      "epoch": 0.53,
      "grad_norm": 84.0,
      "learning_rate": 0.0001421042216358839,
      "loss": 1.3203,
      "step": 399
    },
    {
      "epoch": 0.53,
      "grad_norm": 30.125,
      "learning_rate": 0.0001420844327176781,
      "loss": 0.4121,
      "step": 400
    },
    {
      "epoch": 0.53,
      "grad_norm": 40.25,
      "learning_rate": 0.0001420646437994723,
      "loss": 0.3535,
      "step": 401
    },
    {
      "epoch": 0.53,
      "grad_norm": 69.5,
      "learning_rate": 0.0001420448548812665,
      "loss": 0.9688,
      "step": 402
    },
    {
      "epoch": 0.53,
      "grad_norm": 159.0,
      "learning_rate": 0.0001420250659630607,
      "loss": 2.7656,
      "step": 403
    },
    {
      "epoch": 0.53,
      "grad_norm": 32.0,
      "learning_rate": 0.00014200527704485486,
      "loss": 0.7852,
      "step": 404
    },
    {
      "epoch": 0.53,
      "grad_norm": 28.25,
      "learning_rate": 0.00014198548812664906,
      "loss": 0.334,
      "step": 405
    },
    {
      "epoch": 0.54,
      "grad_norm": 103.0,
      "learning_rate": 0.00014196569920844326,
      "loss": 1.9219,
      "step": 406
    },
    {
      "epoch": 0.54,
      "grad_norm": 116.5,
      "learning_rate": 0.00014194591029023746,
      "loss": 1.5547,
      "step": 407
    },
    {
      "epoch": 0.54,
      "grad_norm": 32.25,
      "learning_rate": 0.00014192612137203163,
      "loss": 0.875,
      "step": 408
    },
    {
      "epoch": 0.54,
      "grad_norm": 44.75,
      "learning_rate": 0.00014190633245382583,
      "loss": 0.373,
      "step": 409
    },
    {
      "epoch": 0.54,
      "grad_norm": 36.5,
      "learning_rate": 0.00014188654353562003,
      "loss": 0.582,
      "step": 410
    },
    {
      "epoch": 0.54,
      "grad_norm": 4.375,
      "learning_rate": 0.00014186675461741422,
      "loss": 0.04,
      "step": 411
    },
    {
      "epoch": 0.54,
      "grad_norm": 102.5,
      "learning_rate": 0.00014184696569920842,
      "loss": 1.3984,
      "step": 412
    },
    {
      "epoch": 0.54,
      "grad_norm": 111.0,
      "learning_rate": 0.00014182717678100262,
      "loss": 1.0156,
      "step": 413
    },
    {
      "epoch": 0.55,
      "grad_norm": 358.0,
      "learning_rate": 0.00014180738786279682,
      "loss": 3.1875,
      "step": 414
    },
    {
      "epoch": 0.55,
      "grad_norm": 37.0,
      "learning_rate": 0.00014178759894459102,
      "loss": 0.5781,
      "step": 415
    },
    {
      "epoch": 0.55,
      "grad_norm": 7.65625,
      "learning_rate": 0.00014176781002638521,
      "loss": 0.0684,
      "step": 416
    },
    {
      "epoch": 0.55,
      "grad_norm": 49.0,
      "learning_rate": 0.0001417480211081794,
      "loss": 0.6172,
      "step": 417
    },
    {
      "epoch": 0.55,
      "grad_norm": 548.0,
      "learning_rate": 0.0001417282321899736,
      "loss": 13.125,
      "step": 418
    },
    {
      "epoch": 0.55,
      "grad_norm": 272.0,
      "learning_rate": 0.0001417084432717678,
      "loss": 5.5312,
      "step": 419
    },
    {
      "epoch": 0.55,
      "grad_norm": 170.0,
      "learning_rate": 0.00014168865435356198,
      "loss": 0.9883,
      "step": 420
    },
    {
      "epoch": 0.56,
      "grad_norm": 235.0,
      "learning_rate": 0.00014166886543535618,
      "loss": 3.1406,
      "step": 421
    },
    {
      "epoch": 0.56,
      "grad_norm": 41.75,
      "learning_rate": 0.00014164907651715038,
      "loss": 0.5547,
      "step": 422
    },
    {
      "epoch": 0.56,
      "grad_norm": 130.0,
      "learning_rate": 0.00014162928759894457,
      "loss": 1.1172,
      "step": 423
    },
    {
      "epoch": 0.56,
      "grad_norm": 94.5,
      "learning_rate": 0.00014160949868073877,
      "loss": 1.3594,
      "step": 424
    },
    {
      "epoch": 0.56,
      "grad_norm": 56.25,
      "learning_rate": 0.00014158970976253297,
      "loss": 0.8984,
      "step": 425
    },
    {
      "epoch": 0.56,
      "grad_norm": 74.5,
      "learning_rate": 0.00014156992084432717,
      "loss": 0.7344,
      "step": 426
    },
    {
      "epoch": 0.56,
      "grad_norm": 35.0,
      "learning_rate": 0.00014155013192612137,
      "loss": 1.1953,
      "step": 427
    },
    {
      "epoch": 0.56,
      "grad_norm": 219.0,
      "learning_rate": 0.00014153034300791556,
      "loss": 4.5,
      "step": 428
    },
    {
      "epoch": 0.57,
      "grad_norm": 79.0,
      "learning_rate": 0.00014151055408970976,
      "loss": 1.25,
      "step": 429
    },
    {
      "epoch": 0.57,
      "grad_norm": 79.5,
      "learning_rate": 0.00014149076517150396,
      "loss": 1.2812,
      "step": 430
    },
    {
      "epoch": 0.57,
      "grad_norm": 26.875,
      "learning_rate": 0.00014147097625329816,
      "loss": 0.4805,
      "step": 431
    },
    {
      "epoch": 0.57,
      "grad_norm": 24.375,
      "learning_rate": 0.00014145118733509233,
      "loss": 0.5156,
      "step": 432
    },
    {
      "epoch": 0.57,
      "grad_norm": 31.75,
      "learning_rate": 0.00014143139841688653,
      "loss": 0.2812,
      "step": 433
    },
    {
      "epoch": 0.57,
      "grad_norm": 318.0,
      "learning_rate": 0.00014141160949868072,
      "loss": 8.0625,
      "step": 434
    },
    {
      "epoch": 0.57,
      "grad_norm": 184.0,
      "learning_rate": 0.00014139182058047492,
      "loss": 4.75,
      "step": 435
    },
    {
      "epoch": 0.58,
      "grad_norm": 400.0,
      "learning_rate": 0.00014137203166226912,
      "loss": 9.625,
      "step": 436
    },
    {
      "epoch": 0.58,
      "grad_norm": 16.625,
      "learning_rate": 0.0001413522427440633,
      "loss": 0.3594,
      "step": 437
    },
    {
      "epoch": 0.58,
      "grad_norm": 99.0,
      "learning_rate": 0.0001413324538258575,
      "loss": 2.6875,
      "step": 438
    },
    {
      "epoch": 0.58,
      "grad_norm": 106.5,
      "learning_rate": 0.0001413126649076517,
      "loss": 3.3438,
      "step": 439
    },
    {
      "epoch": 0.58,
      "grad_norm": 28.375,
      "learning_rate": 0.00014129287598944589,
      "loss": 0.6016,
      "step": 440
    },
    {
      "epoch": 0.58,
      "grad_norm": 26.25,
      "learning_rate": 0.00014127308707124008,
      "loss": 0.3262,
      "step": 441
    },
    {
      "epoch": 0.58,
      "grad_norm": 93.0,
      "learning_rate": 0.00014125329815303428,
      "loss": 2.2812,
      "step": 442
    },
    {
      "epoch": 0.58,
      "grad_norm": 19.125,
      "learning_rate": 0.00014123350923482848,
      "loss": 0.4512,
      "step": 443
    },
    {
      "epoch": 0.59,
      "grad_norm": 25.5,
      "learning_rate": 0.00014121372031662268,
      "loss": 0.4688,
      "step": 444
    },
    {
      "epoch": 0.59,
      "grad_norm": 50.5,
      "learning_rate": 0.00014119393139841688,
      "loss": 0.7227,
      "step": 445
    },
    {
      "epoch": 0.59,
      "grad_norm": 150.0,
      "learning_rate": 0.00014117414248021107,
      "loss": 3.7031,
      "step": 446
    },
    {
      "epoch": 0.59,
      "grad_norm": 14.9375,
      "learning_rate": 0.00014115435356200527,
      "loss": 0.4062,
      "step": 447
    },
    {
      "epoch": 0.59,
      "grad_norm": 92.0,
      "learning_rate": 0.00014113456464379947,
      "loss": 1.8359,
      "step": 448
    },
    {
      "epoch": 0.59,
      "grad_norm": 15.9375,
      "learning_rate": 0.00014111477572559364,
      "loss": 0.3535,
      "step": 449
    },
    {
      "epoch": 0.59,
      "grad_norm": 22.5,
      "learning_rate": 0.00014109498680738784,
      "loss": 0.1914,
      "step": 450
    },
    {
      "epoch": 0.59,
      "grad_norm": 107.0,
      "learning_rate": 0.00014107519788918204,
      "loss": 2.1875,
      "step": 451
    },
    {
      "epoch": 0.6,
      "grad_norm": 99.5,
      "learning_rate": 0.00014105540897097624,
      "loss": 1.6484,
      "step": 452
    },
    {
      "epoch": 0.6,
      "grad_norm": 29.125,
      "learning_rate": 0.00014103562005277043,
      "loss": 0.5625,
      "step": 453
    },
    {
      "epoch": 0.6,
      "grad_norm": 358.0,
      "learning_rate": 0.00014101583113456463,
      "loss": 10.1875,
      "step": 454
    },
    {
      "epoch": 0.6,
      "grad_norm": 183.0,
      "learning_rate": 0.00014099604221635883,
      "loss": 5.0312,
      "step": 455
    },
    {
      "epoch": 0.6,
      "grad_norm": 20.125,
      "learning_rate": 0.00014097625329815303,
      "loss": 0.4414,
      "step": 456
    },
    {
      "epoch": 0.6,
      "grad_norm": 186.0,
      "learning_rate": 0.00014095646437994723,
      "loss": 4.375,
      "step": 457
    },
    {
      "epoch": 0.6,
      "grad_norm": 22.625,
      "learning_rate": 0.00014093667546174142,
      "loss": 0.2969,
      "step": 458
    },
    {
      "epoch": 0.61,
      "grad_norm": 88.0,
      "learning_rate": 0.00014091688654353562,
      "loss": 1.5781,
      "step": 459
    },
    {
      "epoch": 0.61,
      "grad_norm": 16.5,
      "learning_rate": 0.00014089709762532982,
      "loss": 0.3281,
      "step": 460
    },
    {
      "epoch": 0.61,
      "grad_norm": 165.0,
      "learning_rate": 0.000140877308707124,
      "loss": 3.6094,
      "step": 461
    },
    {
      "epoch": 0.61,
      "grad_norm": 154.0,
      "learning_rate": 0.0001408575197889182,
      "loss": 2.4375,
      "step": 462
    },
    {
      "epoch": 0.61,
      "grad_norm": 179.0,
      "learning_rate": 0.0001408377308707124,
      "loss": 3.6094,
      "step": 463
    },
    {
      "epoch": 0.61,
      "grad_norm": 199.0,
      "learning_rate": 0.00014081794195250659,
      "loss": 2.8438,
      "step": 464
    },
    {
      "epoch": 0.61,
      "grad_norm": 77.5,
      "learning_rate": 0.00014079815303430078,
      "loss": 1.3984,
      "step": 465
    },
    {
      "epoch": 0.61,
      "grad_norm": 136.0,
      "learning_rate": 0.00014077836411609498,
      "loss": 2.4531,
      "step": 466
    },
    {
      "epoch": 0.62,
      "grad_norm": 264.0,
      "learning_rate": 0.00014075857519788915,
      "loss": 3.2812,
      "step": 467
    },
    {
      "epoch": 0.62,
      "grad_norm": 70.0,
      "learning_rate": 0.00014073878627968335,
      "loss": 0.9219,
      "step": 468
    },
    {
      "epoch": 0.62,
      "grad_norm": 119.0,
      "learning_rate": 0.00014071899736147755,
      "loss": 2.1719,
      "step": 469
    },
    {
      "epoch": 0.62,
      "grad_norm": 62.25,
      "learning_rate": 0.00014069920844327175,
      "loss": 1.0703,
      "step": 470
    },
    {
      "epoch": 0.62,
      "grad_norm": 70.5,
      "learning_rate": 0.00014067941952506594,
      "loss": 1.2188,
      "step": 471
    },
    {
      "epoch": 0.62,
      "grad_norm": 43.75,
      "learning_rate": 0.00014065963060686014,
      "loss": 0.625,
      "step": 472
    },
    {
      "epoch": 0.62,
      "grad_norm": 290.0,
      "learning_rate": 0.00014063984168865434,
      "loss": 3.1719,
      "step": 473
    },
    {
      "epoch": 0.63,
      "grad_norm": 77.5,
      "learning_rate": 0.00014062005277044854,
      "loss": 1.0469,
      "step": 474
    },
    {
      "epoch": 0.63,
      "grad_norm": 120.5,
      "learning_rate": 0.00014060026385224274,
      "loss": 1.4766,
      "step": 475
    },
    {
      "epoch": 0.63,
      "grad_norm": 44.5,
      "learning_rate": 0.00014058047493403694,
      "loss": 0.7891,
      "step": 476
    },
    {
      "epoch": 0.63,
      "grad_norm": 51.5,
      "learning_rate": 0.00014056068601583113,
      "loss": 1.0156,
      "step": 477
    },
    {
      "epoch": 0.63,
      "grad_norm": 290.0,
      "learning_rate": 0.0001405408970976253,
      "loss": 4.8438,
      "step": 478
    },
    {
      "epoch": 0.63,
      "grad_norm": 52.0,
      "learning_rate": 0.0001405211081794195,
      "loss": 1.25,
      "step": 479
    },
    {
      "epoch": 0.63,
      "grad_norm": 44.25,
      "learning_rate": 0.0001405013192612137,
      "loss": 0.9023,
      "step": 480
    },
    {
      "epoch": 0.63,
      "grad_norm": 19.75,
      "learning_rate": 0.0001404815303430079,
      "loss": 0.2178,
      "step": 481
    },
    {
      "epoch": 0.64,
      "grad_norm": 19.875,
      "learning_rate": 0.0001404617414248021,
      "loss": 0.4043,
      "step": 482
    },
    {
      "epoch": 0.64,
      "grad_norm": 169.0,
      "learning_rate": 0.0001404419525065963,
      "loss": 3.8438,
      "step": 483
    },
    {
      "epoch": 0.64,
      "grad_norm": 35.0,
      "learning_rate": 0.0001404221635883905,
      "loss": 0.6641,
      "step": 484
    },
    {
      "epoch": 0.64,
      "grad_norm": 139.0,
      "learning_rate": 0.0001404023746701847,
      "loss": 1.5938,
      "step": 485
    },
    {
      "epoch": 0.64,
      "grad_norm": 85.0,
      "learning_rate": 0.0001403825857519789,
      "loss": 0.7227,
      "step": 486
    },
    {
      "epoch": 0.64,
      "grad_norm": 26.75,
      "learning_rate": 0.0001403627968337731,
      "loss": 0.3633,
      "step": 487
    },
    {
      "epoch": 0.64,
      "grad_norm": 155.0,
      "learning_rate": 0.00014034300791556728,
      "loss": 3.5312,
      "step": 488
    },
    {
      "epoch": 0.65,
      "grad_norm": 47.0,
      "learning_rate": 0.00014032321899736148,
      "loss": 0.707,
      "step": 489
    },
    {
      "epoch": 0.65,
      "grad_norm": 9.8125,
      "learning_rate": 0.00014030343007915565,
      "loss": 0.2734,
      "step": 490
    },
    {
      "epoch": 0.65,
      "grad_norm": 115.5,
      "learning_rate": 0.00014028364116094985,
      "loss": 3.625,
      "step": 491
    },
    {
      "epoch": 0.65,
      "grad_norm": 29.875,
      "learning_rate": 0.00014026385224274405,
      "loss": 0.416,
      "step": 492
    },
    {
      "epoch": 0.65,
      "grad_norm": 62.5,
      "learning_rate": 0.00014024406332453825,
      "loss": 1.4531,
      "step": 493
    },
    {
      "epoch": 0.65,
      "grad_norm": 49.75,
      "learning_rate": 0.00014022427440633245,
      "loss": 0.9141,
      "step": 494
    },
    {
      "epoch": 0.65,
      "grad_norm": 19.875,
      "learning_rate": 0.00014020448548812664,
      "loss": 0.3926,
      "step": 495
    },
    {
      "epoch": 0.65,
      "grad_norm": 7.625,
      "learning_rate": 0.00014018469656992084,
      "loss": 0.4453,
      "step": 496
    },
    {
      "epoch": 0.66,
      "grad_norm": 15.75,
      "learning_rate": 0.000140164907651715,
      "loss": 0.1455,
      "step": 497
    },
    {
      "epoch": 0.66,
      "grad_norm": 49.5,
      "learning_rate": 0.0001401451187335092,
      "loss": 0.8125,
      "step": 498
    },
    {
      "epoch": 0.66,
      "grad_norm": 13.1875,
      "learning_rate": 0.0001401253298153034,
      "loss": 0.2617,
      "step": 499
    },
    {
      "epoch": 0.66,
      "grad_norm": 76.0,
      "learning_rate": 0.0001401055408970976,
      "loss": 1.3281,
      "step": 500
    },
    {
      "epoch": 0.66,
      "grad_norm": 16.0,
      "learning_rate": 0.0001400857519788918,
      "loss": 0.1475,
      "step": 501
    },
    {
      "epoch": 0.66,
      "grad_norm": 151.0,
      "learning_rate": 0.000140065963060686,
      "loss": 5.4062,
      "step": 502
    },
    {
      "epoch": 0.66,
      "grad_norm": 22.625,
      "learning_rate": 0.0001400461741424802,
      "loss": 0.5195,
      "step": 503
    },
    {
      "epoch": 0.66,
      "grad_norm": 22.5,
      "learning_rate": 0.0001400263852242744,
      "loss": 0.5273,
      "step": 504
    },
    {
      "epoch": 0.67,
      "grad_norm": 84.0,
      "learning_rate": 0.0001400065963060686,
      "loss": 3.0781,
      "step": 505
    },
    {
      "epoch": 0.67,
      "grad_norm": 11.0,
      "learning_rate": 0.00013998680738786277,
      "loss": 0.3438,
      "step": 506
    },
    {
      "epoch": 0.67,
      "grad_norm": 124.5,
      "learning_rate": 0.00013996701846965697,
      "loss": 3.9531,
      "step": 507
    },
    {
      "epoch": 0.67,
      "grad_norm": 77.5,
      "learning_rate": 0.00013994722955145116,
      "loss": 2.3281,
      "step": 508
    },
    {
      "epoch": 0.67,
      "grad_norm": 106.5,
      "learning_rate": 0.00013992744063324536,
      "loss": 3.0938,
      "step": 509
    },
    {
      "epoch": 0.67,
      "grad_norm": 34.0,
      "learning_rate": 0.00013990765171503956,
      "loss": 0.875,
      "step": 510
    },
    {
      "epoch": 0.67,
      "grad_norm": 26.5,
      "learning_rate": 0.00013988786279683376,
      "loss": 0.6953,
      "step": 511
    },
    {
      "epoch": 0.68,
      "grad_norm": 93.5,
      "learning_rate": 0.00013986807387862796,
      "loss": 2.2656,
      "step": 512
    },
    {
      "epoch": 0.68,
      "grad_norm": 31.875,
      "learning_rate": 0.00013984828496042215,
      "loss": 0.6875,
      "step": 513
    },
    {
      "epoch": 0.68,
      "grad_norm": 68.0,
      "learning_rate": 0.00013982849604221635,
      "loss": 2.2969,
      "step": 514
    },
    {
      "epoch": 0.68,
      "grad_norm": 76.0,
      "learning_rate": 0.00013980870712401055,
      "loss": 2.1875,
      "step": 515
    },
    {
      "epoch": 0.68,
      "grad_norm": 17.75,
      "learning_rate": 0.00013978891820580475,
      "loss": 0.6016,
      "step": 516
    },
    {
      "epoch": 0.68,
      "grad_norm": 28.5,
      "learning_rate": 0.00013976912928759895,
      "loss": 0.4629,
      "step": 517
    },
    {
      "epoch": 0.68,
      "grad_norm": 113.0,
      "learning_rate": 0.00013974934036939312,
      "loss": 2.9219,
      "step": 518
    },
    {
      "epoch": 0.68,
      "grad_norm": 114.5,
      "learning_rate": 0.00013972955145118732,
      "loss": 3.0938,
      "step": 519
    },
    {
      "epoch": 0.69,
      "grad_norm": 5.9375,
      "learning_rate": 0.00013970976253298151,
      "loss": 0.1445,
      "step": 520
    },
    {
      "epoch": 0.69,
      "grad_norm": 9.75,
      "learning_rate": 0.0001396899736147757,
      "loss": 0.4336,
      "step": 521
    },
    {
      "epoch": 0.69,
      "grad_norm": 26.75,
      "learning_rate": 0.0001396701846965699,
      "loss": 0.3223,
      "step": 522
    },
    {
      "epoch": 0.69,
      "grad_norm": 9.9375,
      "learning_rate": 0.0001396503957783641,
      "loss": 0.3613,
      "step": 523
    },
    {
      "epoch": 0.69,
      "grad_norm": 7.96875,
      "learning_rate": 0.0001396306068601583,
      "loss": 0.1533,
      "step": 524
    },
    {
      "epoch": 0.69,
      "grad_norm": 15.3125,
      "learning_rate": 0.0001396108179419525,
      "loss": 0.1367,
      "step": 525
    },
    {
      "epoch": 0.69,
      "grad_norm": 168.0,
      "learning_rate": 0.0001395910290237467,
      "loss": 4.875,
      "step": 526
    },
    {
      "epoch": 0.7,
      "grad_norm": 36.0,
      "learning_rate": 0.00013957124010554087,
      "loss": 0.3945,
      "step": 527
    },
    {
      "epoch": 0.7,
      "grad_norm": 175.0,
      "learning_rate": 0.00013955145118733507,
      "loss": 6.9375,
      "step": 528
    },
    {
      "epoch": 0.7,
      "grad_norm": 145.0,
      "learning_rate": 0.00013953166226912927,
      "loss": 3.3281,
      "step": 529
    },
    {
      "epoch": 0.7,
      "grad_norm": 15.25,
      "learning_rate": 0.00013951187335092347,
      "loss": 0.2949,
      "step": 530
    },
    {
      "epoch": 0.7,
      "grad_norm": 94.0,
      "learning_rate": 0.00013949208443271767,
      "loss": 3.2188,
      "step": 531
    },
    {
      "epoch": 0.7,
      "grad_norm": 136.0,
      "learning_rate": 0.00013947229551451186,
      "loss": 3.1719,
      "step": 532
    },
    {
      "epoch": 0.7,
      "grad_norm": 98.0,
      "learning_rate": 0.00013945250659630606,
      "loss": 2.7031,
      "step": 533
    },
    {
      "epoch": 0.7,
      "grad_norm": 23.5,
      "learning_rate": 0.00013943271767810026,
      "loss": 0.4688,
      "step": 534
    },
    {
      "epoch": 0.71,
      "grad_norm": 19.25,
      "learning_rate": 0.00013941292875989443,
      "loss": 0.6133,
      "step": 535
    },
    {
      "epoch": 0.71,
      "grad_norm": 26.75,
      "learning_rate": 0.00013939313984168863,
      "loss": 0.3457,
      "step": 536
    },
    {
      "epoch": 0.71,
      "grad_norm": 205.0,
      "learning_rate": 0.00013937335092348283,
      "loss": 3.5156,
      "step": 537
    },
    {
      "epoch": 0.71,
      "grad_norm": 18.75,
      "learning_rate": 0.00013935356200527702,
      "loss": 0.5273,
      "step": 538
    },
    {
      "epoch": 0.71,
      "grad_norm": 86.0,
      "learning_rate": 0.00013933377308707122,
      "loss": 2.2031,
      "step": 539
    },
    {
      "epoch": 0.71,
      "grad_norm": 16.5,
      "learning_rate": 0.00013931398416886542,
      "loss": 0.6367,
      "step": 540
    },
    {
      "epoch": 0.71,
      "grad_norm": 148.0,
      "learning_rate": 0.00013929419525065962,
      "loss": 4.4688,
      "step": 541
    },
    {
      "epoch": 0.72,
      "grad_norm": 65.5,
      "learning_rate": 0.00013927440633245382,
      "loss": 1.8438,
      "step": 542
    },
    {
      "epoch": 0.72,
      "grad_norm": 114.0,
      "learning_rate": 0.00013925461741424802,
      "loss": 2.9531,
      "step": 543
    },
    {
      "epoch": 0.72,
      "grad_norm": 55.0,
      "learning_rate": 0.0001392348284960422,
      "loss": 1.0234,
      "step": 544
    },
    {
      "epoch": 0.72,
      "grad_norm": 48.0,
      "learning_rate": 0.0001392150395778364,
      "loss": 1.0938,
      "step": 545
    },
    {
      "epoch": 0.72,
      "grad_norm": 89.5,
      "learning_rate": 0.0001391952506596306,
      "loss": 2.3125,
      "step": 546
    },
    {
      "epoch": 0.72,
      "grad_norm": 38.5,
      "learning_rate": 0.00013917546174142478,
      "loss": 0.8125,
      "step": 547
    },
    {
      "epoch": 0.72,
      "grad_norm": 24.5,
      "learning_rate": 0.00013915567282321898,
      "loss": 0.7148,
      "step": 548
    },
    {
      "epoch": 0.72,
      "grad_norm": 87.5,
      "learning_rate": 0.00013913588390501318,
      "loss": 3.0,
      "step": 549
    },
    {
      "epoch": 0.73,
      "grad_norm": 53.5,
      "learning_rate": 0.00013911609498680737,
      "loss": 0.9102,
      "step": 550
    },
    {
      "epoch": 0.73,
      "grad_norm": 164.0,
      "learning_rate": 0.00013909630606860157,
      "loss": 5.0312,
      "step": 551
    },
    {
      "epoch": 0.73,
      "grad_norm": 21.0,
      "learning_rate": 0.00013907651715039577,
      "loss": 0.4824,
      "step": 552
    },
    {
      "epoch": 0.73,
      "grad_norm": 10.5625,
      "learning_rate": 0.00013905672823218997,
      "loss": 0.5234,
      "step": 553
    },
    {
      "epoch": 0.73,
      "grad_norm": 8.5,
      "learning_rate": 0.00013903693931398417,
      "loss": 0.4785,
      "step": 554
    },
    {
      "epoch": 0.73,
      "grad_norm": 14.6875,
      "learning_rate": 0.00013901715039577836,
      "loss": 0.4023,
      "step": 555
    },
    {
      "epoch": 0.73,
      "grad_norm": 33.5,
      "learning_rate": 0.00013899736147757256,
      "loss": 0.6094,
      "step": 556
    },
    {
      "epoch": 0.73,
      "grad_norm": 153.0,
      "learning_rate": 0.00013897757255936673,
      "loss": 6.625,
      "step": 557
    },
    {
      "epoch": 0.74,
      "grad_norm": 95.5,
      "learning_rate": 0.00013895778364116093,
      "loss": 3.5938,
      "step": 558
    },
    {
      "epoch": 0.74,
      "grad_norm": 82.5,
      "learning_rate": 0.00013893799472295513,
      "loss": 3.2344,
      "step": 559
    },
    {
      "epoch": 0.74,
      "grad_norm": 170.0,
      "learning_rate": 0.00013891820580474933,
      "loss": 7.9375,
      "step": 560
    },
    {
      "epoch": 0.74,
      "grad_norm": 48.0,
      "learning_rate": 0.00013889841688654353,
      "loss": 0.5977,
      "step": 561
    },
    {
      "epoch": 0.74,
      "grad_norm": 10.375,
      "learning_rate": 0.00013887862796833772,
      "loss": 0.3789,
      "step": 562
    },
    {
      "epoch": 0.74,
      "grad_norm": 52.75,
      "learning_rate": 0.00013885883905013192,
      "loss": 0.8555,
      "step": 563
    },
    {
      "epoch": 0.74,
      "grad_norm": 83.0,
      "learning_rate": 0.0001388390501319261,
      "loss": 2.2031,
      "step": 564
    },
    {
      "epoch": 0.75,
      "grad_norm": 31.25,
      "learning_rate": 0.0001388192612137203,
      "loss": 0.8008,
      "step": 565
    },
    {
      "epoch": 0.75,
      "grad_norm": 196.0,
      "learning_rate": 0.0001387994722955145,
      "loss": 4.875,
      "step": 566
    },
    {
      "epoch": 0.75,
      "grad_norm": 25.0,
      "learning_rate": 0.0001387796833773087,
      "loss": 0.3652,
      "step": 567
    },
    {
      "epoch": 0.75,
      "grad_norm": 1576.0,
      "learning_rate": 0.00013875989445910289,
      "loss": 4.875,
      "step": 568
    },
    {
      "epoch": 0.75,
      "grad_norm": 167.0,
      "learning_rate": 0.00013874010554089708,
      "loss": 1.0859,
      "step": 569
    },
    {
      "epoch": 0.75,
      "grad_norm": 203.0,
      "learning_rate": 0.00013872031662269128,
      "loss": 1.0469,
      "step": 570
    },
    {
      "epoch": 0.75,
      "grad_norm": 188.0,
      "learning_rate": 0.00013870052770448548,
      "loss": 0.8281,
      "step": 571
    },
    {
      "epoch": 0.75,
      "grad_norm": 576.0,
      "learning_rate": 0.00013868073878627968,
      "loss": 4.4375,
      "step": 572
    },
    {
      "epoch": 0.76,
      "grad_norm": 87.0,
      "learning_rate": 0.00013866094986807388,
      "loss": 0.6172,
      "step": 573
    },
    {
      "epoch": 0.76,
      "grad_norm": 32.5,
      "learning_rate": 0.00013864116094986807,
      "loss": 0.4258,
      "step": 574
    },
    {
      "epoch": 0.76,
      "grad_norm": 744.0,
      "learning_rate": 0.00013862137203166227,
      "loss": 5.625,
      "step": 575
    },
    {
      "epoch": 0.76,
      "grad_norm": 372.0,
      "learning_rate": 0.00013860158311345644,
      "loss": 3.0938,
      "step": 576
    },
    {
      "epoch": 0.76,
      "grad_norm": 390.0,
      "learning_rate": 0.00013858179419525064,
      "loss": 2.9844,
      "step": 577
    },
    {
      "epoch": 0.76,
      "grad_norm": 41.75,
      "learning_rate": 0.00013856200527704484,
      "loss": 0.4062,
      "step": 578
    },
    {
      "epoch": 0.76,
      "grad_norm": 59.75,
      "learning_rate": 0.00013854221635883904,
      "loss": 0.5078,
      "step": 579
    },
    {
      "epoch": 0.77,
      "grad_norm": 548.0,
      "learning_rate": 0.00013852242744063324,
      "loss": 6.9375,
      "step": 580
    },
    {
      "epoch": 0.77,
      "grad_norm": 688.0,
      "learning_rate": 0.00013850263852242743,
      "loss": 8.125,
      "step": 581
    },
    {
      "epoch": 0.77,
      "grad_norm": 110.0,
      "learning_rate": 0.00013848284960422163,
      "loss": 0.5742,
      "step": 582
    },
    {
      "epoch": 0.77,
      "grad_norm": 520.0,
      "learning_rate": 0.00013846306068601583,
      "loss": 4.5938,
      "step": 583
    },
    {
      "epoch": 0.77,
      "grad_norm": 92.0,
      "learning_rate": 0.00013844327176781003,
      "loss": 0.5859,
      "step": 584
    },
    {
      "epoch": 0.77,
      "grad_norm": 276.0,
      "learning_rate": 0.00013842348284960423,
      "loss": 1.9688,
      "step": 585
    },
    {
      "epoch": 0.77,
      "grad_norm": 144.0,
      "learning_rate": 0.00013840369393139842,
      "loss": 0.9805,
      "step": 586
    },
    {
      "epoch": 0.77,
      "grad_norm": 284.0,
      "learning_rate": 0.0001383839050131926,
      "loss": 1.5,
      "step": 587
    },
    {
      "epoch": 0.78,
      "grad_norm": 106.0,
      "learning_rate": 0.0001383641160949868,
      "loss": 0.6797,
      "step": 588
    },
    {
      "epoch": 0.78,
      "grad_norm": 282.0,
      "learning_rate": 0.000138344327176781,
      "loss": 1.8438,
      "step": 589
    },
    {
      "epoch": 0.78,
      "grad_norm": 308.0,
      "learning_rate": 0.0001383245382585752,
      "loss": 2.0312,
      "step": 590
    },
    {
      "epoch": 0.78,
      "grad_norm": 278.0,
      "learning_rate": 0.0001383047493403694,
      "loss": 1.6641,
      "step": 591
    },
    {
      "epoch": 0.78,
      "grad_norm": 196.0,
      "learning_rate": 0.00013828496042216356,
      "loss": 0.8203,
      "step": 592
    },
    {
      "epoch": 0.78,
      "grad_norm": 552.0,
      "learning_rate": 0.00013826517150395776,
      "loss": 6.9375,
      "step": 593
    },
    {
      "epoch": 0.78,
      "grad_norm": 189.0,
      "learning_rate": 0.00013824538258575195,
      "loss": 1.0469,
      "step": 594
    },
    {
      "epoch": 0.78,
      "grad_norm": 218.0,
      "learning_rate": 0.00013822559366754615,
      "loss": 1.1016,
      "step": 595
    },
    {
      "epoch": 0.79,
      "grad_norm": 148.0,
      "learning_rate": 0.00013820580474934035,
      "loss": 0.832,
      "step": 596
    },
    {
      "epoch": 0.79,
      "grad_norm": 628.0,
      "learning_rate": 0.00013818601583113455,
      "loss": 7.2188,
      "step": 597
    },
    {
      "epoch": 0.79,
      "grad_norm": 61.5,
      "learning_rate": 0.00013816622691292875,
      "loss": 0.5312,
      "step": 598
    },
    {
      "epoch": 0.79,
      "grad_norm": 680.0,
      "learning_rate": 0.00013814643799472294,
      "loss": 4.6875,
      "step": 599
    },
    {
      "epoch": 0.79,
      "grad_norm": 556.0,
      "learning_rate": 0.00013812664907651714,
      "loss": 5.3125,
      "step": 600
    },
    {
      "epoch": 0.79,
      "grad_norm": 51.5,
      "learning_rate": 0.00013810686015831134,
      "loss": 0.4258,
      "step": 601
    },
    {
      "epoch": 0.79,
      "grad_norm": 54.75,
      "learning_rate": 0.00013808707124010554,
      "loss": 0.5,
      "step": 602
    },
    {
      "epoch": 0.8,
      "grad_norm": 133.0,
      "learning_rate": 0.00013806728232189974,
      "loss": 0.3867,
      "step": 603
    },
    {
      "epoch": 0.8,
      "grad_norm": 338.0,
      "learning_rate": 0.0001380474934036939,
      "loss": 3.2188,
      "step": 604
    },
    {
      "epoch": 0.8,
      "grad_norm": 90.5,
      "learning_rate": 0.0001380277044854881,
      "loss": 0.5586,
      "step": 605
    },
    {
      "epoch": 0.8,
      "grad_norm": 93.0,
      "learning_rate": 0.0001380079155672823,
      "loss": 0.582,
      "step": 606
    },
    {
      "epoch": 0.8,
      "grad_norm": 680.0,
      "learning_rate": 0.0001379881266490765,
      "loss": 6.0312,
      "step": 607
    },
    {
      "epoch": 0.8,
      "grad_norm": 482.0,
      "learning_rate": 0.0001379683377308707,
      "loss": 3.0625,
      "step": 608
    },
    {
      "epoch": 0.8,
      "grad_norm": 330.0,
      "learning_rate": 0.0001379485488126649,
      "loss": 2.6406,
      "step": 609
    },
    {
      "epoch": 0.8,
      "grad_norm": 394.0,
      "learning_rate": 0.0001379287598944591,
      "loss": 2.3438,
      "step": 610
    },
    {
      "epoch": 0.81,
      "grad_norm": 128.0,
      "learning_rate": 0.0001379089709762533,
      "loss": 0.957,
      "step": 611
    },
    {
      "epoch": 0.81,
      "grad_norm": 159.0,
      "learning_rate": 0.0001378891820580475,
      "loss": 1.2188,
      "step": 612
    },
    {
      "epoch": 0.81,
      "grad_norm": 140.0,
      "learning_rate": 0.0001378693931398417,
      "loss": 1.0547,
      "step": 613
    },
    {
      "epoch": 0.81,
      "grad_norm": 147.0,
      "learning_rate": 0.0001378496042216359,
      "loss": 1.0391,
      "step": 614
    },
    {
      "epoch": 0.81,
      "grad_norm": 171.0,
      "learning_rate": 0.00013782981530343009,
      "loss": 0.7188,
      "step": 615
    },
    {
      "epoch": 0.81,
      "grad_norm": 512.0,
      "learning_rate": 0.00013781002638522428,
      "loss": 4.0,
      "step": 616
    },
    {
      "epoch": 0.81,
      "grad_norm": 214.0,
      "learning_rate": 0.00013779023746701845,
      "loss": 1.0,
      "step": 617
    },
    {
      "epoch": 0.82,
      "grad_norm": 434.0,
      "learning_rate": 0.00013777044854881265,
      "loss": 3.1406,
      "step": 618
    },
    {
      "epoch": 0.82,
      "grad_norm": 380.0,
      "learning_rate": 0.00013775065963060685,
      "loss": 2.8281,
      "step": 619
    },
    {
      "epoch": 0.82,
      "grad_norm": 196.0,
      "learning_rate": 0.00013773087071240105,
      "loss": 0.8398,
      "step": 620
    },
    {
      "epoch": 0.82,
      "grad_norm": 516.0,
      "learning_rate": 0.00013771108179419522,
      "loss": 4.0625,
      "step": 621
    },
    {
      "epoch": 0.82,
      "grad_norm": 652.0,
      "learning_rate": 0.00013769129287598942,
      "loss": 5.0625,
      "step": 622
    },
    {
      "epoch": 0.82,
      "grad_norm": 70.0,
      "learning_rate": 0.00013767150395778362,
      "loss": 0.5078,
      "step": 623
    },
    {
      "epoch": 0.82,
      "grad_norm": 222.0,
      "learning_rate": 0.00013765171503957781,
      "loss": 1.4062,
      "step": 624
    },
    {
      "epoch": 0.82,
      "grad_norm": 434.0,
      "learning_rate": 0.000137631926121372,
      "loss": 2.375,
      "step": 625
    },
    {
      "epoch": 0.83,
      "grad_norm": 384.0,
      "learning_rate": 0.0001376121372031662,
      "loss": 2.9531,
      "step": 626
    },
    {
      "epoch": 0.83,
      "grad_norm": 264.0,
      "learning_rate": 0.0001375923482849604,
      "loss": 1.8516,
      "step": 627
    },
    {
      "epoch": 0.83,
      "grad_norm": 196.0,
      "learning_rate": 0.0001375725593667546,
      "loss": 1.4922,
      "step": 628
    },
    {
      "epoch": 0.83,
      "grad_norm": 204.0,
      "learning_rate": 0.0001375527704485488,
      "loss": 1.4141,
      "step": 629
    },
    {
      "epoch": 0.83,
      "grad_norm": 195.0,
      "learning_rate": 0.000137532981530343,
      "loss": 1.25,
      "step": 630
    },
    {
      "epoch": 0.83,
      "grad_norm": 146.0,
      "learning_rate": 0.0001375131926121372,
      "loss": 0.9219,
      "step": 631
    },
    {
      "epoch": 0.83,
      "grad_norm": 75.0,
      "learning_rate": 0.0001374934036939314,
      "loss": 0.6562,
      "step": 632
    },
    {
      "epoch": 0.84,
      "grad_norm": 249.0,
      "learning_rate": 0.00013747361477572557,
      "loss": 1.6328,
      "step": 633
    },
    {
      "epoch": 0.84,
      "grad_norm": 260.0,
      "learning_rate": 0.00013745382585751977,
      "loss": 1.6719,
      "step": 634
    },
    {
      "epoch": 0.84,
      "grad_norm": 253.0,
      "learning_rate": 0.00013743403693931397,
      "loss": 1.3828,
      "step": 635
    },
    {
      "epoch": 0.84,
      "grad_norm": 129.0,
      "learning_rate": 0.00013741424802110816,
      "loss": 0.6367,
      "step": 636
    },
    {
      "epoch": 0.84,
      "grad_norm": 40.5,
      "learning_rate": 0.00013739445910290236,
      "loss": 0.4219,
      "step": 637
    },
    {
      "epoch": 0.84,
      "grad_norm": 147.0,
      "learning_rate": 0.00013737467018469656,
      "loss": 0.6719,
      "step": 638
    },
    {
      "epoch": 0.84,
      "grad_norm": 41.5,
      "learning_rate": 0.00013735488126649076,
      "loss": 0.3789,
      "step": 639
    },
    {
      "epoch": 0.84,
      "grad_norm": 49.5,
      "learning_rate": 0.00013733509234828496,
      "loss": 0.3887,
      "step": 640
    },
    {
      "epoch": 0.85,
      "grad_norm": 114.0,
      "learning_rate": 0.00013731530343007915,
      "loss": 0.6914,
      "step": 641
    },
    {
      "epoch": 0.85,
      "grad_norm": 99.5,
      "learning_rate": 0.00013729551451187335,
      "loss": 0.6016,
      "step": 642
    },
    {
      "epoch": 0.85,
      "grad_norm": 129.0,
      "learning_rate": 0.00013727572559366755,
      "loss": 0.5859,
      "step": 643
    },
    {
      "epoch": 0.85,
      "grad_norm": 352.0,
      "learning_rate": 0.00013725593667546175,
      "loss": 5.3125,
      "step": 644
    },
    {
      "epoch": 0.85,
      "grad_norm": 45.5,
      "learning_rate": 0.00013723614775725592,
      "loss": 0.377,
      "step": 645
    },
    {
      "epoch": 0.85,
      "grad_norm": 884.0,
      "learning_rate": 0.00013721635883905012,
      "loss": 20.25,
      "step": 646
    },
    {
      "epoch": 0.85,
      "grad_norm": 588.0,
      "learning_rate": 0.00013719656992084432,
      "loss": 14.0625,
      "step": 647
    },
    {
      "epoch": 0.85,
      "grad_norm": 660.0,
      "learning_rate": 0.0001371767810026385,
      "loss": 13.375,
      "step": 648
    },
    {
      "epoch": 0.86,
      "grad_norm": 99.5,
      "learning_rate": 0.0001371569920844327,
      "loss": 0.582,
      "step": 649
    },
    {
      "epoch": 0.86,
      "grad_norm": 22.25,
      "learning_rate": 0.00013713720316622688,
      "loss": 0.3945,
      "step": 650
    },
    {
      "epoch": 0.86,
      "grad_norm": 43.25,
      "learning_rate": 0.00013711741424802108,
      "loss": 0.3594,
      "step": 651
    },
    {
      "epoch": 0.86,
      "grad_norm": 90.5,
      "learning_rate": 0.00013709762532981528,
      "loss": 0.5078,
      "step": 652
    },
    {
      "epoch": 0.86,
      "grad_norm": 21.625,
      "learning_rate": 0.00013707783641160948,
      "loss": 0.4688,
      "step": 653
    },
    {
      "epoch": 0.86,
      "grad_norm": 247.0,
      "learning_rate": 0.00013705804749340367,
      "loss": 2.5156,
      "step": 654
    },
    {
      "epoch": 0.86,
      "grad_norm": 524.0,
      "learning_rate": 0.00013703825857519787,
      "loss": 5.8438,
      "step": 655
    },
    {
      "epoch": 0.87,
      "grad_norm": 68.5,
      "learning_rate": 0.00013701846965699207,
      "loss": 0.5195,
      "step": 656
    },
    {
      "epoch": 0.87,
      "grad_norm": 207.0,
      "learning_rate": 0.00013699868073878627,
      "loss": 2.1719,
      "step": 657
    },
    {
      "epoch": 0.87,
      "grad_norm": 316.0,
      "learning_rate": 0.00013697889182058047,
      "loss": 2.8906,
      "step": 658
    },
    {
      "epoch": 0.87,
      "grad_norm": 169.0,
      "learning_rate": 0.00013695910290237466,
      "loss": 1.8438,
      "step": 659
    },
    {
      "epoch": 0.87,
      "grad_norm": 109.0,
      "learning_rate": 0.00013693931398416886,
      "loss": 0.9141,
      "step": 660
    },
    {
      "epoch": 0.87,
      "grad_norm": 217.0,
      "learning_rate": 0.00013691952506596306,
      "loss": 2.1406,
      "step": 661
    },
    {
      "epoch": 0.87,
      "grad_norm": 143.0,
      "learning_rate": 0.00013689973614775723,
      "loss": 1.7344,
      "step": 662
    },
    {
      "epoch": 0.87,
      "grad_norm": 113.0,
      "learning_rate": 0.00013687994722955143,
      "loss": 0.9219,
      "step": 663
    },
    {
      "epoch": 0.88,
      "grad_norm": 93.5,
      "learning_rate": 0.00013686015831134563,
      "loss": 1.0938,
      "step": 664
    },
    {
      "epoch": 0.88,
      "grad_norm": 122.0,
      "learning_rate": 0.00013684036939313983,
      "loss": 1.4219,
      "step": 665
    },
    {
      "epoch": 0.88,
      "grad_norm": 241.0,
      "learning_rate": 0.00013682058047493402,
      "loss": 2.5781,
      "step": 666
    },
    {
      "epoch": 0.88,
      "grad_norm": 216.0,
      "learning_rate": 0.00013680079155672822,
      "loss": 3.4688,
      "step": 667
    },
    {
      "epoch": 0.88,
      "grad_norm": 181.0,
      "learning_rate": 0.00013678100263852242,
      "loss": 2.9531,
      "step": 668
    },
    {
      "epoch": 0.88,
      "grad_norm": 116.0,
      "learning_rate": 0.00013676121372031662,
      "loss": 1.2109,
      "step": 669
    },
    {
      "epoch": 0.88,
      "grad_norm": 88.5,
      "learning_rate": 0.00013674142480211082,
      "loss": 1.0781,
      "step": 670
    },
    {
      "epoch": 0.89,
      "grad_norm": 80.0,
      "learning_rate": 0.00013672163588390501,
      "loss": 0.918,
      "step": 671
    },
    {
      "epoch": 0.89,
      "grad_norm": 152.0,
      "learning_rate": 0.0001367018469656992,
      "loss": 2.9531,
      "step": 672
    },
    {
      "epoch": 0.89,
      "grad_norm": 172.0,
      "learning_rate": 0.0001366820580474934,
      "loss": 1.9062,
      "step": 673
    },
    {
      "epoch": 0.89,
      "grad_norm": 158.0,
      "learning_rate": 0.00013666226912928758,
      "loss": 2.125,
      "step": 674
    },
    {
      "epoch": 0.89,
      "grad_norm": 157.0,
      "learning_rate": 0.00013664248021108178,
      "loss": 2.1094,
      "step": 675
    },
    {
      "epoch": 0.89,
      "grad_norm": 123.5,
      "learning_rate": 0.00013662269129287598,
      "loss": 1.6953,
      "step": 676
    },
    {
      "epoch": 0.89,
      "grad_norm": 75.5,
      "learning_rate": 0.00013660290237467018,
      "loss": 0.8672,
      "step": 677
    },
    {
      "epoch": 0.89,
      "grad_norm": 158.0,
      "learning_rate": 0.00013658311345646437,
      "loss": 2.0938,
      "step": 678
    },
    {
      "epoch": 0.9,
      "grad_norm": 126.5,
      "learning_rate": 0.00013656332453825854,
      "loss": 1.7969,
      "step": 679
    },
    {
      "epoch": 0.9,
      "grad_norm": 154.0,
      "learning_rate": 0.00013654353562005274,
      "loss": 1.8906,
      "step": 680
    },
    {
      "epoch": 0.9,
      "grad_norm": 70.0,
      "learning_rate": 0.00013652374670184694,
      "loss": 0.9141,
      "step": 681
    },
    {
      "epoch": 0.9,
      "grad_norm": 91.0,
      "learning_rate": 0.00013650395778364114,
      "loss": 0.9531,
      "step": 682
    },
    {
      "epoch": 0.9,
      "grad_norm": 57.5,
      "learning_rate": 0.00013648416886543534,
      "loss": 0.6992,
      "step": 683
    },
    {
      "epoch": 0.9,
      "grad_norm": 48.5,
      "learning_rate": 0.00013646437994722954,
      "loss": 0.5977,
      "step": 684
    },
    {
      "epoch": 0.9,
      "grad_norm": 34.0,
      "learning_rate": 0.00013644459102902373,
      "loss": 0.5156,
      "step": 685
    },
    {
      "epoch": 0.91,
      "grad_norm": 18.625,
      "learning_rate": 0.00013642480211081793,
      "loss": 0.4297,
      "step": 686
    },
    {
      "epoch": 0.91,
      "grad_norm": 97.5,
      "learning_rate": 0.00013640501319261213,
      "loss": 0.7734,
      "step": 687
    },
    {
      "epoch": 0.91,
      "grad_norm": 352.0,
      "learning_rate": 0.00013638522427440633,
      "loss": 6.0625,
      "step": 688
    },
    {
      "epoch": 0.91,
      "grad_norm": 9.3125,
      "learning_rate": 0.00013636543535620053,
      "loss": 0.3613,
      "step": 689
    },
    {
      "epoch": 0.91,
      "grad_norm": 38.25,
      "learning_rate": 0.00013634564643799472,
      "loss": 0.4746,
      "step": 690
    },
    {
      "epoch": 0.91,
      "grad_norm": 187.0,
      "learning_rate": 0.0001363258575197889,
      "loss": 4.0938,
      "step": 691
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.0703125,
      "learning_rate": 0.0001363060686015831,
      "loss": 0.4062,
      "step": 692
    },
    {
      "epoch": 0.91,
      "grad_norm": 30.25,
      "learning_rate": 0.0001362862796833773,
      "loss": 0.3672,
      "step": 693
    },
    {
      "epoch": 0.92,
      "grad_norm": 63.25,
      "learning_rate": 0.0001362664907651715,
      "loss": 0.5586,
      "step": 694
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.296875,
      "learning_rate": 0.0001362467018469657,
      "loss": 0.3066,
      "step": 695
    },
    {
      "epoch": 0.92,
      "grad_norm": 77.0,
      "learning_rate": 0.00013622691292875988,
      "loss": 0.7383,
      "step": 696
    },
    {
      "epoch": 0.92,
      "grad_norm": 188.0,
      "learning_rate": 0.00013620712401055408,
      "loss": 5.875,
      "step": 697
    },
    {
      "epoch": 0.92,
      "grad_norm": 12.0,
      "learning_rate": 0.00013618733509234828,
      "loss": 0.3203,
      "step": 698
    },
    {
      "epoch": 0.92,
      "grad_norm": 73.5,
      "learning_rate": 0.00013616754617414248,
      "loss": 0.7109,
      "step": 699
    },
    {
      "epoch": 0.92,
      "grad_norm": 548.0,
      "learning_rate": 0.00013614775725593668,
      "loss": 20.0,
      "step": 700
    },
    {
      "epoch": 0.92,
      "grad_norm": 44.25,
      "learning_rate": 0.00013612796833773087,
      "loss": 0.4531,
      "step": 701
    },
    {
      "epoch": 0.93,
      "grad_norm": 51.25,
      "learning_rate": 0.00013610817941952507,
      "loss": 0.2412,
      "step": 702
    },
    {
      "epoch": 0.93,
      "grad_norm": 61.25,
      "learning_rate": 0.00013608839050131924,
      "loss": 0.5859,
      "step": 703
    },
    {
      "epoch": 0.93,
      "grad_norm": 464.0,
      "learning_rate": 0.00013606860158311344,
      "loss": 15.9375,
      "step": 704
    },
    {
      "epoch": 0.93,
      "grad_norm": 79.5,
      "learning_rate": 0.00013604881266490764,
      "loss": 0.8633,
      "step": 705
    },
    {
      "epoch": 0.93,
      "grad_norm": 33.0,
      "learning_rate": 0.00013602902374670184,
      "loss": 0.4199,
      "step": 706
    },
    {
      "epoch": 0.93,
      "grad_norm": 392.0,
      "learning_rate": 0.000136009234828496,
      "loss": 10.5,
      "step": 707
    },
    {
      "epoch": 0.93,
      "grad_norm": 29.5,
      "learning_rate": 0.0001359894459102902,
      "loss": 0.4238,
      "step": 708
    },
    {
      "epoch": 0.94,
      "grad_norm": 372.0,
      "learning_rate": 0.0001359696569920844,
      "loss": 12.4375,
      "step": 709
    },
    {
      "epoch": 0.94,
      "grad_norm": 166.0,
      "learning_rate": 0.0001359498680738786,
      "loss": 4.0938,
      "step": 710
    },
    {
      "epoch": 0.94,
      "grad_norm": 19.625,
      "learning_rate": 0.0001359300791556728,
      "loss": 0.3789,
      "step": 711
    },
    {
      "epoch": 0.94,
      "grad_norm": 155.0,
      "learning_rate": 0.000135910290237467,
      "loss": 3.0781,
      "step": 712
    },
    {
      "epoch": 0.94,
      "grad_norm": 7.0625,
      "learning_rate": 0.0001358905013192612,
      "loss": 0.4297,
      "step": 713
    },
    {
      "epoch": 0.94,
      "grad_norm": 22.25,
      "learning_rate": 0.0001358707124010554,
      "loss": 0.377,
      "step": 714
    },
    {
      "epoch": 0.94,
      "grad_norm": 23.375,
      "learning_rate": 0.0001358509234828496,
      "loss": 0.5117,
      "step": 715
    },
    {
      "epoch": 0.94,
      "grad_norm": 23.375,
      "learning_rate": 0.0001358311345646438,
      "loss": 0.4883,
      "step": 716
    },
    {
      "epoch": 0.95,
      "grad_norm": 51.0,
      "learning_rate": 0.000135811345646438,
      "loss": 0.5547,
      "step": 717
    },
    {
      "epoch": 0.95,
      "grad_norm": 40.75,
      "learning_rate": 0.0001357915567282322,
      "loss": 0.4961,
      "step": 718
    },
    {
      "epoch": 0.95,
      "grad_norm": 272.0,
      "learning_rate": 0.00013577176781002636,
      "loss": 4.0312,
      "step": 719
    },
    {
      "epoch": 0.95,
      "grad_norm": 63.25,
      "learning_rate": 0.00013575197889182056,
      "loss": 0.6328,
      "step": 720
    },
    {
      "epoch": 0.95,
      "grad_norm": 32.25,
      "learning_rate": 0.00013573218997361475,
      "loss": 0.1807,
      "step": 721
    },
    {
      "epoch": 0.95,
      "grad_norm": 176.0,
      "learning_rate": 0.00013571240105540895,
      "loss": 2.625,
      "step": 722
    },
    {
      "epoch": 0.95,
      "grad_norm": 258.0,
      "learning_rate": 0.00013569261213720315,
      "loss": 5.4375,
      "step": 723
    },
    {
      "epoch": 0.96,
      "grad_norm": 24.5,
      "learning_rate": 0.00013567282321899735,
      "loss": 0.4688,
      "step": 724
    },
    {
      "epoch": 0.96,
      "grad_norm": 188.0,
      "learning_rate": 0.00013565303430079155,
      "loss": 2.5469,
      "step": 725
    },
    {
      "epoch": 0.96,
      "grad_norm": 235.0,
      "learning_rate": 0.00013563324538258575,
      "loss": 4.9062,
      "step": 726
    },
    {
      "epoch": 0.96,
      "grad_norm": 129.0,
      "learning_rate": 0.00013561345646437994,
      "loss": 1.6875,
      "step": 727
    },
    {
      "epoch": 0.96,
      "grad_norm": 102.0,
      "learning_rate": 0.00013559366754617414,
      "loss": 1.4844,
      "step": 728
    },
    {
      "epoch": 0.96,
      "grad_norm": 233.0,
      "learning_rate": 0.00013557387862796834,
      "loss": 3.5938,
      "step": 729
    },
    {
      "epoch": 0.96,
      "grad_norm": 71.0,
      "learning_rate": 0.00013555408970976254,
      "loss": 0.8984,
      "step": 730
    },
    {
      "epoch": 0.96,
      "grad_norm": 77.0,
      "learning_rate": 0.0001355343007915567,
      "loss": 1.0469,
      "step": 731
    },
    {
      "epoch": 0.97,
      "grad_norm": 74.0,
      "learning_rate": 0.0001355145118733509,
      "loss": 1.0156,
      "step": 732
    },
    {
      "epoch": 0.97,
      "grad_norm": 154.0,
      "learning_rate": 0.0001354947229551451,
      "loss": 1.8047,
      "step": 733
    },
    {
      "epoch": 0.97,
      "grad_norm": 68.5,
      "learning_rate": 0.0001354749340369393,
      "loss": 1.0469,
      "step": 734
    },
    {
      "epoch": 0.97,
      "grad_norm": 91.5,
      "learning_rate": 0.0001354551451187335,
      "loss": 1.0234,
      "step": 735
    },
    {
      "epoch": 0.97,
      "grad_norm": 83.5,
      "learning_rate": 0.0001354353562005277,
      "loss": 1.4844,
      "step": 736
    },
    {
      "epoch": 0.97,
      "grad_norm": 197.0,
      "learning_rate": 0.00013541556728232187,
      "loss": 2.0938,
      "step": 737
    },
    {
      "epoch": 0.97,
      "grad_norm": 67.0,
      "learning_rate": 0.00013539577836411607,
      "loss": 0.8047,
      "step": 738
    },
    {
      "epoch": 0.97,
      "grad_norm": 71.0,
      "learning_rate": 0.00013537598944591027,
      "loss": 1.1719,
      "step": 739
    },
    {
      "epoch": 0.98,
      "grad_norm": 68.5,
      "learning_rate": 0.00013535620052770446,
      "loss": 0.8086,
      "step": 740
    },
    {
      "epoch": 0.98,
      "grad_norm": 63.5,
      "learning_rate": 0.00013533641160949866,
      "loss": 0.6797,
      "step": 741
    },
    {
      "epoch": 0.98,
      "grad_norm": 310.0,
      "learning_rate": 0.00013531662269129286,
      "loss": 4.7188,
      "step": 742
    },
    {
      "epoch": 0.98,
      "grad_norm": 44.0,
      "learning_rate": 0.00013529683377308706,
      "loss": 0.5469,
      "step": 743
    },
    {
      "epoch": 0.98,
      "grad_norm": 33.75,
      "learning_rate": 0.00013527704485488126,
      "loss": 0.5273,
      "step": 744
    },
    {
      "epoch": 0.98,
      "grad_norm": 19.625,
      "learning_rate": 0.00013525725593667545,
      "loss": 0.3477,
      "step": 745
    },
    {
      "epoch": 0.98,
      "grad_norm": 23.375,
      "learning_rate": 0.00013523746701846965,
      "loss": 0.4316,
      "step": 746
    },
    {
      "epoch": 0.99,
      "grad_norm": 35.5,
      "learning_rate": 0.00013521767810026385,
      "loss": 0.3848,
      "step": 747
    },
    {
      "epoch": 0.99,
      "grad_norm": 432.0,
      "learning_rate": 0.00013519788918205802,
      "loss": 8.5625,
      "step": 748
    },
    {
      "epoch": 0.99,
      "grad_norm": 192.0,
      "learning_rate": 0.00013517810026385222,
      "loss": 3.5,
      "step": 749
    },
    {
      "epoch": 0.99,
      "grad_norm": 196.0,
      "learning_rate": 0.00013515831134564642,
      "loss": 3.6719,
      "step": 750
    },
    {
      "epoch": 0.99,
      "grad_norm": 26.5,
      "learning_rate": 0.00013513852242744062,
      "loss": 0.3301,
      "step": 751
    },
    {
      "epoch": 0.99,
      "grad_norm": 54.0,
      "learning_rate": 0.0001351187335092348,
      "loss": 0.5195,
      "step": 752
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.90625,
      "learning_rate": 0.000135098944591029,
      "loss": 0.2871,
      "step": 753
    },
    {
      "epoch": 0.99,
      "grad_norm": 6.15625,
      "learning_rate": 0.0001350791556728232,
      "loss": 0.3086,
      "step": 754
    },
    {
      "epoch": 1.0,
      "grad_norm": 198.0,
      "learning_rate": 0.0001350593667546174,
      "loss": 4.25,
      "step": 755
    },
    {
      "epoch": 1.0,
      "grad_norm": 73.5,
      "learning_rate": 0.0001350395778364116,
      "loss": 0.7422,
      "step": 756
    },
    {
      "epoch": 1.0,
      "grad_norm": 107.5,
      "learning_rate": 0.0001350197889182058,
      "loss": 0.8789,
      "step": 757
    },
    {
      "epoch": 1.0,
      "grad_norm": 342.0,
      "learning_rate": 0.000135,
      "loss": 9.3125,
      "step": 758
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.74813175201416,
      "eval_runtime": 18.2774,
      "eval_samples_per_second": 42.785,
      "eval_steps_per_second": 10.724,
      "step": 758
    },
    {
      "epoch": 1.0,
      "grad_norm": 69.5,
      "learning_rate": 0.0001349802110817942,
      "loss": 0.3301,
      "step": 759
    },
    {
      "epoch": 1.0,
      "grad_norm": 58.5,
      "learning_rate": 0.00013496042216358837,
      "loss": 0.5547,
      "step": 760
    },
    {
      "epoch": 1.0,
      "grad_norm": 175.0,
      "learning_rate": 0.00013494063324538257,
      "loss": 3.5,
      "step": 761
    },
    {
      "epoch": 1.01,
      "grad_norm": 38.75,
      "learning_rate": 0.00013492084432717677,
      "loss": 0.3145,
      "step": 762
    },
    {
      "epoch": 1.01,
      "grad_norm": 43.0,
      "learning_rate": 0.00013490105540897096,
      "loss": 0.4551,
      "step": 763
    },
    {
      "epoch": 1.01,
      "grad_norm": 19.875,
      "learning_rate": 0.00013488126649076516,
      "loss": 0.3887,
      "step": 764
    },
    {
      "epoch": 1.01,
      "grad_norm": 185.0,
      "learning_rate": 0.00013486147757255936,
      "loss": 3.125,
      "step": 765
    },
    {
      "epoch": 1.01,
      "grad_norm": 13.625,
      "learning_rate": 0.00013484168865435356,
      "loss": 0.1768,
      "step": 766
    },
    {
      "epoch": 1.01,
      "grad_norm": 49.75,
      "learning_rate": 0.00013482189973614776,
      "loss": 0.4766,
      "step": 767
    },
    {
      "epoch": 1.01,
      "grad_norm": 14.0,
      "learning_rate": 0.00013480211081794193,
      "loss": 0.3008,
      "step": 768
    },
    {
      "epoch": 1.01,
      "grad_norm": 235.0,
      "learning_rate": 0.00013478232189973613,
      "loss": 5.0312,
      "step": 769
    },
    {
      "epoch": 1.02,
      "grad_norm": 131.0,
      "learning_rate": 0.00013476253298153032,
      "loss": 2.5312,
      "step": 770
    },
    {
      "epoch": 1.02,
      "grad_norm": 276.0,
      "learning_rate": 0.00013474274406332452,
      "loss": 4.9688,
      "step": 771
    },
    {
      "epoch": 1.02,
      "grad_norm": 114.5,
      "learning_rate": 0.00013472295514511872,
      "loss": 1.6562,
      "step": 772
    },
    {
      "epoch": 1.02,
      "grad_norm": 32.75,
      "learning_rate": 0.00013470316622691292,
      "loss": 0.5625,
      "step": 773
    },
    {
      "epoch": 1.02,
      "grad_norm": 77.5,
      "learning_rate": 0.00013468337730870712,
      "loss": 0.9258,
      "step": 774
    },
    {
      "epoch": 1.02,
      "grad_norm": 49.75,
      "learning_rate": 0.00013466358839050131,
      "loss": 0.832,
      "step": 775
    },
    {
      "epoch": 1.02,
      "grad_norm": 88.5,
      "learning_rate": 0.0001346437994722955,
      "loss": 1.3359,
      "step": 776
    },
    {
      "epoch": 1.03,
      "grad_norm": 38.75,
      "learning_rate": 0.00013462401055408968,
      "loss": 0.5508,
      "step": 777
    },
    {
      "epoch": 1.03,
      "grad_norm": 45.75,
      "learning_rate": 0.00013460422163588388,
      "loss": 0.7617,
      "step": 778
    },
    {
      "epoch": 1.03,
      "grad_norm": 286.0,
      "learning_rate": 0.00013458443271767808,
      "loss": 4.7812,
      "step": 779
    },
    {
      "epoch": 1.03,
      "grad_norm": 318.0,
      "learning_rate": 0.00013456464379947228,
      "loss": 3.4375,
      "step": 780
    },
    {
      "epoch": 1.03,
      "grad_norm": 43.5,
      "learning_rate": 0.00013454485488126648,
      "loss": 0.5938,
      "step": 781
    },
    {
      "epoch": 1.03,
      "grad_norm": 104.5,
      "learning_rate": 0.00013452506596306067,
      "loss": 0.7812,
      "step": 782
    },
    {
      "epoch": 1.03,
      "grad_norm": 18.875,
      "learning_rate": 0.00013450527704485487,
      "loss": 0.4004,
      "step": 783
    },
    {
      "epoch": 1.03,
      "grad_norm": 50.75,
      "learning_rate": 0.00013448548812664907,
      "loss": 0.459,
      "step": 784
    },
    {
      "epoch": 1.04,
      "grad_norm": 146.0,
      "learning_rate": 0.00013446569920844327,
      "loss": 2.3906,
      "step": 785
    },
    {
      "epoch": 1.04,
      "grad_norm": 164.0,
      "learning_rate": 0.00013444591029023747,
      "loss": 2.5625,
      "step": 786
    },
    {
      "epoch": 1.04,
      "grad_norm": 26.5,
      "learning_rate": 0.00013442612137203166,
      "loss": 0.4219,
      "step": 787
    },
    {
      "epoch": 1.04,
      "grad_norm": 17.75,
      "learning_rate": 0.00013440633245382586,
      "loss": 0.5312,
      "step": 788
    },
    {
      "epoch": 1.04,
      "grad_norm": 157.0,
      "learning_rate": 0.00013438654353562003,
      "loss": 2.375,
      "step": 789
    },
    {
      "epoch": 1.04,
      "grad_norm": 10.4375,
      "learning_rate": 0.00013436675461741423,
      "loss": 0.4434,
      "step": 790
    },
    {
      "epoch": 1.04,
      "grad_norm": 11.8125,
      "learning_rate": 0.00013434696569920843,
      "loss": 0.3789,
      "step": 791
    },
    {
      "epoch": 1.04,
      "grad_norm": 40.0,
      "learning_rate": 0.00013432717678100263,
      "loss": 0.1748,
      "step": 792
    },
    {
      "epoch": 1.05,
      "grad_norm": 350.0,
      "learning_rate": 0.00013430738786279683,
      "loss": 6.0312,
      "step": 793
    },
    {
      "epoch": 1.05,
      "grad_norm": 41.75,
      "learning_rate": 0.00013428759894459102,
      "loss": 0.498,
      "step": 794
    },
    {
      "epoch": 1.05,
      "grad_norm": 11.75,
      "learning_rate": 0.00013426781002638522,
      "loss": 0.043,
      "step": 795
    },
    {
      "epoch": 1.05,
      "grad_norm": 540.0,
      "learning_rate": 0.00013424802110817942,
      "loss": 9.9375,
      "step": 796
    },
    {
      "epoch": 1.05,
      "grad_norm": 448.0,
      "learning_rate": 0.00013422823218997362,
      "loss": 7.75,
      "step": 797
    },
    {
      "epoch": 1.05,
      "grad_norm": 51.75,
      "learning_rate": 0.0001342084432717678,
      "loss": 0.6367,
      "step": 798
    },
    {
      "epoch": 1.05,
      "grad_norm": 350.0,
      "learning_rate": 0.000134188654353562,
      "loss": 5.0938,
      "step": 799
    },
    {
      "epoch": 1.06,
      "grad_norm": 100.5,
      "learning_rate": 0.00013416886543535618,
      "loss": 1.0625,
      "step": 800
    },
    {
      "epoch": 1.06,
      "grad_norm": 218.0,
      "learning_rate": 0.00013414907651715038,
      "loss": 2.9688,
      "step": 801
    },
    {
      "epoch": 1.06,
      "grad_norm": 260.0,
      "learning_rate": 0.00013412928759894458,
      "loss": 3.4844,
      "step": 802
    },
    {
      "epoch": 1.06,
      "grad_norm": 322.0,
      "learning_rate": 0.00013410949868073878,
      "loss": 4.75,
      "step": 803
    },
    {
      "epoch": 1.06,
      "grad_norm": 294.0,
      "learning_rate": 0.00013408970976253298,
      "loss": 4.1562,
      "step": 804
    },
    {
      "epoch": 1.06,
      "grad_norm": 22.125,
      "learning_rate": 0.00013406992084432715,
      "loss": 0.4355,
      "step": 805
    },
    {
      "epoch": 1.06,
      "grad_norm": 304.0,
      "learning_rate": 0.00013405013192612135,
      "loss": 3.4375,
      "step": 806
    },
    {
      "epoch": 1.06,
      "grad_norm": 75.5,
      "learning_rate": 0.00013403034300791554,
      "loss": 0.5234,
      "step": 807
    },
    {
      "epoch": 1.07,
      "grad_norm": 48.25,
      "learning_rate": 0.00013401055408970974,
      "loss": 0.6172,
      "step": 808
    },
    {
      "epoch": 1.07,
      "grad_norm": 60.25,
      "learning_rate": 0.00013399076517150394,
      "loss": 0.6641,
      "step": 809
    },
    {
      "epoch": 1.07,
      "grad_norm": 54.75,
      "learning_rate": 0.00013397097625329814,
      "loss": 0.6094,
      "step": 810
    },
    {
      "epoch": 1.07,
      "grad_norm": 30.5,
      "learning_rate": 0.00013395118733509234,
      "loss": 0.5938,
      "step": 811
    },
    {
      "epoch": 1.07,
      "grad_norm": 137.0,
      "learning_rate": 0.00013393139841688653,
      "loss": 2.0781,
      "step": 812
    },
    {
      "epoch": 1.07,
      "grad_norm": 380.0,
      "learning_rate": 0.00013391160949868073,
      "loss": 6.4062,
      "step": 813
    },
    {
      "epoch": 1.07,
      "grad_norm": 22.75,
      "learning_rate": 0.00013389182058047493,
      "loss": 0.5508,
      "step": 814
    },
    {
      "epoch": 1.08,
      "grad_norm": 20.625,
      "learning_rate": 0.00013387203166226913,
      "loss": 0.5312,
      "step": 815
    },
    {
      "epoch": 1.08,
      "grad_norm": 40.25,
      "learning_rate": 0.00013385224274406333,
      "loss": 0.5469,
      "step": 816
    },
    {
      "epoch": 1.08,
      "grad_norm": 30.125,
      "learning_rate": 0.0001338324538258575,
      "loss": 0.4395,
      "step": 817
    },
    {
      "epoch": 1.08,
      "grad_norm": 25.25,
      "learning_rate": 0.0001338126649076517,
      "loss": 0.4941,
      "step": 818
    },
    {
      "epoch": 1.08,
      "grad_norm": 286.0,
      "learning_rate": 0.0001337928759894459,
      "loss": 7.7188,
      "step": 819
    },
    {
      "epoch": 1.08,
      "grad_norm": 136.0,
      "learning_rate": 0.0001337730870712401,
      "loss": 3.0156,
      "step": 820
    },
    {
      "epoch": 1.08,
      "grad_norm": 5.3125,
      "learning_rate": 0.0001337532981530343,
      "loss": 0.3359,
      "step": 821
    },
    {
      "epoch": 1.08,
      "grad_norm": 206.0,
      "learning_rate": 0.0001337335092348285,
      "loss": 5.2188,
      "step": 822
    },
    {
      "epoch": 1.09,
      "grad_norm": 32.25,
      "learning_rate": 0.00013371372031662269,
      "loss": 0.5039,
      "step": 823
    },
    {
      "epoch": 1.09,
      "grad_norm": 44.75,
      "learning_rate": 0.00013369393139841688,
      "loss": 0.3047,
      "step": 824
    },
    {
      "epoch": 1.09,
      "grad_norm": 16.375,
      "learning_rate": 0.00013367414248021108,
      "loss": 0.4395,
      "step": 825
    },
    {
      "epoch": 1.09,
      "grad_norm": 7.25,
      "learning_rate": 0.00013365435356200528,
      "loss": 0.4043,
      "step": 826
    },
    {
      "epoch": 1.09,
      "grad_norm": 136.0,
      "learning_rate": 0.00013363456464379948,
      "loss": 3.1406,
      "step": 827
    },
    {
      "epoch": 1.09,
      "grad_norm": 143.0,
      "learning_rate": 0.00013361477572559365,
      "loss": 3.125,
      "step": 828
    },
    {
      "epoch": 1.09,
      "grad_norm": 25.125,
      "learning_rate": 0.00013359498680738785,
      "loss": 0.4277,
      "step": 829
    },
    {
      "epoch": 1.09,
      "grad_norm": 310.0,
      "learning_rate": 0.00013357519788918205,
      "loss": 7.4062,
      "step": 830
    },
    {
      "epoch": 1.1,
      "grad_norm": 14.5,
      "learning_rate": 0.00013355540897097624,
      "loss": 0.4609,
      "step": 831
    },
    {
      "epoch": 1.1,
      "grad_norm": 15.5625,
      "learning_rate": 0.00013353562005277044,
      "loss": 0.3828,
      "step": 832
    },
    {
      "epoch": 1.1,
      "grad_norm": 216.0,
      "learning_rate": 0.00013351583113456464,
      "loss": 4.4375,
      "step": 833
    },
    {
      "epoch": 1.1,
      "grad_norm": 13.5625,
      "learning_rate": 0.0001334960422163588,
      "loss": 0.3379,
      "step": 834
    },
    {
      "epoch": 1.1,
      "grad_norm": 220.0,
      "learning_rate": 0.000133476253298153,
      "loss": 4.0625,
      "step": 835
    },
    {
      "epoch": 1.1,
      "grad_norm": 238.0,
      "learning_rate": 0.0001334564643799472,
      "loss": 3.8594,
      "step": 836
    },
    {
      "epoch": 1.1,
      "grad_norm": 61.25,
      "learning_rate": 0.0001334366754617414,
      "loss": 0.9453,
      "step": 837
    },
    {
      "epoch": 1.11,
      "grad_norm": 59.75,
      "learning_rate": 0.0001334168865435356,
      "loss": 0.8438,
      "step": 838
    },
    {
      "epoch": 1.11,
      "grad_norm": 145.0,
      "learning_rate": 0.0001333970976253298,
      "loss": 2.3594,
      "step": 839
    },
    {
      "epoch": 1.11,
      "grad_norm": 168.0,
      "learning_rate": 0.000133377308707124,
      "loss": 3.0469,
      "step": 840
    },
    {
      "epoch": 1.11,
      "grad_norm": 145.0,
      "learning_rate": 0.0001333575197889182,
      "loss": 2.3594,
      "step": 841
    },
    {
      "epoch": 1.11,
      "grad_norm": 140.0,
      "learning_rate": 0.0001333377308707124,
      "loss": 2.1875,
      "step": 842
    },
    {
      "epoch": 1.11,
      "grad_norm": 81.0,
      "learning_rate": 0.0001333179419525066,
      "loss": 0.8711,
      "step": 843
    },
    {
      "epoch": 1.11,
      "grad_norm": 422.0,
      "learning_rate": 0.0001332981530343008,
      "loss": 3.5156,
      "step": 844
    },
    {
      "epoch": 1.11,
      "grad_norm": 112.0,
      "learning_rate": 0.000133278364116095,
      "loss": 0.9531,
      "step": 845
    },
    {
      "epoch": 1.12,
      "grad_norm": 94.0,
      "learning_rate": 0.00013325857519788916,
      "loss": 1.0078,
      "step": 846
    },
    {
      "epoch": 1.12,
      "grad_norm": 85.5,
      "learning_rate": 0.00013323878627968336,
      "loss": 0.6641,
      "step": 847
    },
    {
      "epoch": 1.12,
      "grad_norm": 98.5,
      "learning_rate": 0.00013321899736147756,
      "loss": 1.0547,
      "step": 848
    },
    {
      "epoch": 1.12,
      "grad_norm": 145.0,
      "learning_rate": 0.00013319920844327175,
      "loss": 1.4766,
      "step": 849
    },
    {
      "epoch": 1.12,
      "grad_norm": 286.0,
      "learning_rate": 0.00013317941952506595,
      "loss": 2.5,
      "step": 850
    },
    {
      "epoch": 1.12,
      "grad_norm": 310.0,
      "learning_rate": 0.00013315963060686015,
      "loss": 2.9688,
      "step": 851
    },
    {
      "epoch": 1.12,
      "grad_norm": 270.0,
      "learning_rate": 0.00013313984168865435,
      "loss": 2.4688,
      "step": 852
    },
    {
      "epoch": 1.13,
      "grad_norm": 87.0,
      "learning_rate": 0.00013312005277044855,
      "loss": 0.7305,
      "step": 853
    },
    {
      "epoch": 1.13,
      "grad_norm": 113.0,
      "learning_rate": 0.00013310026385224274,
      "loss": 0.7578,
      "step": 854
    },
    {
      "epoch": 1.13,
      "grad_norm": 98.5,
      "learning_rate": 0.00013308047493403694,
      "loss": 0.582,
      "step": 855
    },
    {
      "epoch": 1.13,
      "grad_norm": 174.0,
      "learning_rate": 0.00013306068601583114,
      "loss": 1.8203,
      "step": 856
    },
    {
      "epoch": 1.13,
      "grad_norm": 51.75,
      "learning_rate": 0.00013304089709762534,
      "loss": 0.6328,
      "step": 857
    },
    {
      "epoch": 1.13,
      "grad_norm": 68.0,
      "learning_rate": 0.0001330211081794195,
      "loss": 0.2695,
      "step": 858
    },
    {
      "epoch": 1.13,
      "grad_norm": 466.0,
      "learning_rate": 0.0001330013192612137,
      "loss": 4.375,
      "step": 859
    },
    {
      "epoch": 1.13,
      "grad_norm": 390.0,
      "learning_rate": 0.0001329815303430079,
      "loss": 3.4844,
      "step": 860
    },
    {
      "epoch": 1.14,
      "grad_norm": 330.0,
      "learning_rate": 0.0001329617414248021,
      "loss": 3.6562,
      "step": 861
    },
    {
      "epoch": 1.14,
      "grad_norm": 42.25,
      "learning_rate": 0.0001329419525065963,
      "loss": 0.3867,
      "step": 862
    },
    {
      "epoch": 1.14,
      "grad_norm": 804.0,
      "learning_rate": 0.00013292216358839047,
      "loss": 7.5938,
      "step": 863
    },
    {
      "epoch": 1.14,
      "grad_norm": 324.0,
      "learning_rate": 0.00013290237467018467,
      "loss": 3.0625,
      "step": 864
    },
    {
      "epoch": 1.14,
      "grad_norm": 430.0,
      "learning_rate": 0.00013288258575197887,
      "loss": 5.2188,
      "step": 865
    },
    {
      "epoch": 1.14,
      "grad_norm": 45.5,
      "learning_rate": 0.00013286279683377307,
      "loss": 0.7031,
      "step": 866
    },
    {
      "epoch": 1.14,
      "grad_norm": 74.0,
      "learning_rate": 0.00013284300791556726,
      "loss": 1.1094,
      "step": 867
    },
    {
      "epoch": 1.15,
      "grad_norm": 152.0,
      "learning_rate": 0.00013282321899736146,
      "loss": 2.1094,
      "step": 868
    },
    {
      "epoch": 1.15,
      "grad_norm": 55.0,
      "learning_rate": 0.00013280343007915566,
      "loss": 0.5859,
      "step": 869
    },
    {
      "epoch": 1.15,
      "grad_norm": 117.5,
      "learning_rate": 0.00013278364116094986,
      "loss": 1.6562,
      "step": 870
    },
    {
      "epoch": 1.15,
      "grad_norm": 44.0,
      "learning_rate": 0.00013276385224274406,
      "loss": 0.75,
      "step": 871
    },
    {
      "epoch": 1.15,
      "grad_norm": 186.0,
      "learning_rate": 0.00013274406332453826,
      "loss": 2.6875,
      "step": 872
    },
    {
      "epoch": 1.15,
      "grad_norm": 46.0,
      "learning_rate": 0.00013272427440633245,
      "loss": 0.5391,
      "step": 873
    },
    {
      "epoch": 1.15,
      "grad_norm": 36.0,
      "learning_rate": 0.00013270448548812665,
      "loss": 0.6641,
      "step": 874
    },
    {
      "epoch": 1.15,
      "grad_norm": 27.375,
      "learning_rate": 0.00013268469656992082,
      "loss": 0.6055,
      "step": 875
    },
    {
      "epoch": 1.16,
      "grad_norm": 28.625,
      "learning_rate": 0.00013266490765171502,
      "loss": 0.3945,
      "step": 876
    },
    {
      "epoch": 1.16,
      "grad_norm": 234.0,
      "learning_rate": 0.00013264511873350922,
      "loss": 4.4062,
      "step": 877
    },
    {
      "epoch": 1.16,
      "grad_norm": 12.125,
      "learning_rate": 0.00013262532981530342,
      "loss": 0.2988,
      "step": 878
    },
    {
      "epoch": 1.16,
      "grad_norm": 59.5,
      "learning_rate": 0.00013260554089709761,
      "loss": 0.5234,
      "step": 879
    },
    {
      "epoch": 1.16,
      "grad_norm": 536.0,
      "learning_rate": 0.0001325857519788918,
      "loss": 11.625,
      "step": 880
    },
    {
      "epoch": 1.16,
      "grad_norm": 24.75,
      "learning_rate": 0.000132565963060686,
      "loss": 0.3477,
      "step": 881
    },
    {
      "epoch": 1.16,
      "grad_norm": 161.0,
      "learning_rate": 0.0001325461741424802,
      "loss": 3.6094,
      "step": 882
    },
    {
      "epoch": 1.16,
      "grad_norm": 12.25,
      "learning_rate": 0.0001325263852242744,
      "loss": 0.3574,
      "step": 883
    },
    {
      "epoch": 1.17,
      "grad_norm": 152.0,
      "learning_rate": 0.0001325065963060686,
      "loss": 3.4844,
      "step": 884
    },
    {
      "epoch": 1.17,
      "grad_norm": 5.6875,
      "learning_rate": 0.0001324868073878628,
      "loss": 0.3398,
      "step": 885
    },
    {
      "epoch": 1.17,
      "grad_norm": 310.0,
      "learning_rate": 0.000132467018469657,
      "loss": 5.5,
      "step": 886
    },
    {
      "epoch": 1.17,
      "grad_norm": 148.0,
      "learning_rate": 0.00013244722955145117,
      "loss": 3.2969,
      "step": 887
    },
    {
      "epoch": 1.17,
      "grad_norm": 27.125,
      "learning_rate": 0.00013242744063324537,
      "loss": 0.1455,
      "step": 888
    },
    {
      "epoch": 1.17,
      "grad_norm": 112.0,
      "learning_rate": 0.00013240765171503957,
      "loss": 0.9648,
      "step": 889
    },
    {
      "epoch": 1.17,
      "grad_norm": 17.375,
      "learning_rate": 0.00013238786279683377,
      "loss": 0.4883,
      "step": 890
    },
    {
      "epoch": 1.18,
      "grad_norm": 150.0,
      "learning_rate": 0.00013236807387862794,
      "loss": 2.8906,
      "step": 891
    },
    {
      "epoch": 1.18,
      "grad_norm": 153.0,
      "learning_rate": 0.00013234828496042214,
      "loss": 2.75,
      "step": 892
    },
    {
      "epoch": 1.18,
      "grad_norm": 217.0,
      "learning_rate": 0.00013232849604221633,
      "loss": 4.7812,
      "step": 893
    },
    {
      "epoch": 1.18,
      "grad_norm": 142.0,
      "learning_rate": 0.00013230870712401053,
      "loss": 2.8594,
      "step": 894
    },
    {
      "epoch": 1.18,
      "grad_norm": 45.5,
      "learning_rate": 0.00013228891820580473,
      "loss": 0.7188,
      "step": 895
    },
    {
      "epoch": 1.18,
      "grad_norm": 30.125,
      "learning_rate": 0.00013226912928759893,
      "loss": 0.3086,
      "step": 896
    },
    {
      "epoch": 1.18,
      "grad_norm": 38.75,
      "learning_rate": 0.00013224934036939313,
      "loss": 0.6367,
      "step": 897
    },
    {
      "epoch": 1.18,
      "grad_norm": 38.25,
      "learning_rate": 0.00013222955145118732,
      "loss": 0.4453,
      "step": 898
    },
    {
      "epoch": 1.19,
      "grad_norm": 79.5,
      "learning_rate": 0.00013220976253298152,
      "loss": 1.5156,
      "step": 899
    },
    {
      "epoch": 1.19,
      "grad_norm": 58.25,
      "learning_rate": 0.00013218997361477572,
      "loss": 0.6562,
      "step": 900
    },
    {
      "epoch": 1.19,
      "grad_norm": 41.25,
      "learning_rate": 0.00013217018469656992,
      "loss": 0.4062,
      "step": 901
    },
    {
      "epoch": 1.19,
      "grad_norm": 153.0,
      "learning_rate": 0.00013215039577836412,
      "loss": 2.125,
      "step": 902
    },
    {
      "epoch": 1.19,
      "grad_norm": 29.75,
      "learning_rate": 0.0001321306068601583,
      "loss": 0.5625,
      "step": 903
    },
    {
      "epoch": 1.19,
      "grad_norm": 39.0,
      "learning_rate": 0.00013211081794195248,
      "loss": 0.8555,
      "step": 904
    },
    {
      "epoch": 1.19,
      "grad_norm": 24.375,
      "learning_rate": 0.00013209102902374668,
      "loss": 0.2656,
      "step": 905
    },
    {
      "epoch": 1.2,
      "grad_norm": 24.25,
      "learning_rate": 0.00013207124010554088,
      "loss": 0.2891,
      "step": 906
    },
    {
      "epoch": 1.2,
      "grad_norm": 60.5,
      "learning_rate": 0.00013205145118733508,
      "loss": 0.8906,
      "step": 907
    },
    {
      "epoch": 1.2,
      "grad_norm": 9.375,
      "learning_rate": 0.00013203166226912928,
      "loss": 0.1484,
      "step": 908
    },
    {
      "epoch": 1.2,
      "grad_norm": 163.0,
      "learning_rate": 0.00013201187335092348,
      "loss": 3.0938,
      "step": 909
    },
    {
      "epoch": 1.2,
      "grad_norm": 336.0,
      "learning_rate": 0.00013199208443271767,
      "loss": 7.9688,
      "step": 910
    },
    {
      "epoch": 1.2,
      "grad_norm": 34.0,
      "learning_rate": 0.00013197229551451187,
      "loss": 0.4082,
      "step": 911
    },
    {
      "epoch": 1.2,
      "grad_norm": 28.5,
      "learning_rate": 0.00013195250659630607,
      "loss": 0.1436,
      "step": 912
    },
    {
      "epoch": 1.2,
      "grad_norm": 47.5,
      "learning_rate": 0.00013193271767810027,
      "loss": 0.5664,
      "step": 913
    },
    {
      "epoch": 1.21,
      "grad_norm": 294.0,
      "learning_rate": 0.00013191292875989447,
      "loss": 7.0312,
      "step": 914
    },
    {
      "epoch": 1.21,
      "grad_norm": 7.46875,
      "learning_rate": 0.00013189313984168864,
      "loss": 0.3066,
      "step": 915
    },
    {
      "epoch": 1.21,
      "grad_norm": 21.125,
      "learning_rate": 0.00013187335092348283,
      "loss": 0.2559,
      "step": 916
    },
    {
      "epoch": 1.21,
      "grad_norm": 207.0,
      "learning_rate": 0.00013185356200527703,
      "loss": 3.5156,
      "step": 917
    },
    {
      "epoch": 1.21,
      "grad_norm": 177.0,
      "learning_rate": 0.00013183377308707123,
      "loss": 3.3906,
      "step": 918
    },
    {
      "epoch": 1.21,
      "grad_norm": 264.0,
      "learning_rate": 0.00013181398416886543,
      "loss": 5.5,
      "step": 919
    },
    {
      "epoch": 1.21,
      "grad_norm": 69.5,
      "learning_rate": 0.0001317941952506596,
      "loss": 0.5938,
      "step": 920
    },
    {
      "epoch": 1.22,
      "grad_norm": 21.375,
      "learning_rate": 0.0001317744063324538,
      "loss": 0.459,
      "step": 921
    },
    {
      "epoch": 1.22,
      "grad_norm": 56.5,
      "learning_rate": 0.000131754617414248,
      "loss": 0.3477,
      "step": 922
    },
    {
      "epoch": 1.22,
      "grad_norm": 81.0,
      "learning_rate": 0.0001317348284960422,
      "loss": 0.6758,
      "step": 923
    },
    {
      "epoch": 1.22,
      "grad_norm": 270.0,
      "learning_rate": 0.0001317150395778364,
      "loss": 4.2812,
      "step": 924
    },
    {
      "epoch": 1.22,
      "grad_norm": 364.0,
      "learning_rate": 0.0001316952506596306,
      "loss": 6.5938,
      "step": 925
    },
    {
      "epoch": 1.22,
      "grad_norm": 186.0,
      "learning_rate": 0.0001316754617414248,
      "loss": 2.8906,
      "step": 926
    },
    {
      "epoch": 1.22,
      "grad_norm": 52.0,
      "learning_rate": 0.00013165567282321899,
      "loss": 0.6016,
      "step": 927
    },
    {
      "epoch": 1.22,
      "grad_norm": 30.25,
      "learning_rate": 0.00013163588390501318,
      "loss": 0.4609,
      "step": 928
    },
    {
      "epoch": 1.23,
      "grad_norm": 346.0,
      "learning_rate": 0.00013161609498680738,
      "loss": 4.2812,
      "step": 929
    },
    {
      "epoch": 1.23,
      "grad_norm": 42.75,
      "learning_rate": 0.00013159630606860158,
      "loss": 0.4141,
      "step": 930
    },
    {
      "epoch": 1.23,
      "grad_norm": 218.0,
      "learning_rate": 0.00013157651715039578,
      "loss": 2.5312,
      "step": 931
    },
    {
      "epoch": 1.23,
      "grad_norm": 35.5,
      "learning_rate": 0.00013155672823218995,
      "loss": 0.498,
      "step": 932
    },
    {
      "epoch": 1.23,
      "grad_norm": 225.0,
      "learning_rate": 0.00013153693931398415,
      "loss": 2.4219,
      "step": 933
    },
    {
      "epoch": 1.23,
      "grad_norm": 215.0,
      "learning_rate": 0.00013151715039577835,
      "loss": 1.9766,
      "step": 934
    },
    {
      "epoch": 1.23,
      "grad_norm": 50.75,
      "learning_rate": 0.00013149736147757254,
      "loss": 0.4883,
      "step": 935
    },
    {
      "epoch": 1.23,
      "grad_norm": 167.0,
      "learning_rate": 0.00013147757255936674,
      "loss": 1.7109,
      "step": 936
    },
    {
      "epoch": 1.24,
      "grad_norm": 354.0,
      "learning_rate": 0.00013145778364116094,
      "loss": 3.6562,
      "step": 937
    },
    {
      "epoch": 1.24,
      "grad_norm": 82.5,
      "learning_rate": 0.00013143799472295514,
      "loss": 0.6992,
      "step": 938
    },
    {
      "epoch": 1.24,
      "grad_norm": 95.5,
      "learning_rate": 0.00013141820580474934,
      "loss": 0.9453,
      "step": 939
    },
    {
      "epoch": 1.24,
      "grad_norm": 89.5,
      "learning_rate": 0.00013139841688654353,
      "loss": 0.7461,
      "step": 940
    },
    {
      "epoch": 1.24,
      "grad_norm": 181.0,
      "learning_rate": 0.00013137862796833773,
      "loss": 2.0781,
      "step": 941
    },
    {
      "epoch": 1.24,
      "grad_norm": 173.0,
      "learning_rate": 0.00013135883905013193,
      "loss": 2.0938,
      "step": 942
    },
    {
      "epoch": 1.24,
      "grad_norm": 314.0,
      "learning_rate": 0.00013133905013192613,
      "loss": 3.0,
      "step": 943
    },
    {
      "epoch": 1.25,
      "grad_norm": 139.0,
      "learning_rate": 0.0001313192612137203,
      "loss": 1.5625,
      "step": 944
    },
    {
      "epoch": 1.25,
      "grad_norm": 39.5,
      "learning_rate": 0.0001312994722955145,
      "loss": 0.3691,
      "step": 945
    },
    {
      "epoch": 1.25,
      "grad_norm": 72.0,
      "learning_rate": 0.0001312796833773087,
      "loss": 1.1953,
      "step": 946
    },
    {
      "epoch": 1.25,
      "grad_norm": 77.5,
      "learning_rate": 0.0001312598944591029,
      "loss": 0.8008,
      "step": 947
    },
    {
      "epoch": 1.25,
      "grad_norm": 61.5,
      "learning_rate": 0.0001312401055408971,
      "loss": 0.6797,
      "step": 948
    },
    {
      "epoch": 1.25,
      "grad_norm": 85.0,
      "learning_rate": 0.00013122031662269126,
      "loss": 0.9062,
      "step": 949
    },
    {
      "epoch": 1.25,
      "grad_norm": 78.0,
      "learning_rate": 0.00013120052770448546,
      "loss": 0.8828,
      "step": 950
    },
    {
      "epoch": 1.25,
      "grad_norm": 73.0,
      "learning_rate": 0.00013118073878627966,
      "loss": 1.2031,
      "step": 951
    },
    {
      "epoch": 1.26,
      "grad_norm": 65.0,
      "learning_rate": 0.00013116094986807386,
      "loss": 0.416,
      "step": 952
    },
    {
      "epoch": 1.26,
      "grad_norm": 53.0,
      "learning_rate": 0.00013114116094986805,
      "loss": 0.6641,
      "step": 953
    },
    {
      "epoch": 1.26,
      "grad_norm": 36.5,
      "learning_rate": 0.00013112137203166225,
      "loss": 0.25,
      "step": 954
    },
    {
      "epoch": 1.26,
      "grad_norm": 114.5,
      "learning_rate": 0.00013110158311345645,
      "loss": 1.7188,
      "step": 955
    },
    {
      "epoch": 1.26,
      "grad_norm": 117.0,
      "learning_rate": 0.00013108179419525065,
      "loss": 1.6875,
      "step": 956
    },
    {
      "epoch": 1.26,
      "grad_norm": 17.875,
      "learning_rate": 0.00013106200527704485,
      "loss": 0.4492,
      "step": 957
    },
    {
      "epoch": 1.26,
      "grad_norm": 122.0,
      "learning_rate": 0.00013104221635883904,
      "loss": 1.5781,
      "step": 958
    },
    {
      "epoch": 1.27,
      "grad_norm": 17.625,
      "learning_rate": 0.00013102242744063324,
      "loss": 0.4922,
      "step": 959
    },
    {
      "epoch": 1.27,
      "grad_norm": 116.0,
      "learning_rate": 0.00013100263852242744,
      "loss": 1.6719,
      "step": 960
    },
    {
      "epoch": 1.27,
      "grad_norm": 46.0,
      "learning_rate": 0.0001309828496042216,
      "loss": 0.5469,
      "step": 961
    },
    {
      "epoch": 1.27,
      "grad_norm": 29.25,
      "learning_rate": 0.0001309630606860158,
      "loss": 0.2002,
      "step": 962
    },
    {
      "epoch": 1.27,
      "grad_norm": 116.0,
      "learning_rate": 0.00013094327176781,
      "loss": 1.8203,
      "step": 963
    },
    {
      "epoch": 1.27,
      "grad_norm": 52.0,
      "learning_rate": 0.0001309234828496042,
      "loss": 1.3594,
      "step": 964
    },
    {
      "epoch": 1.27,
      "grad_norm": 40.25,
      "learning_rate": 0.0001309036939313984,
      "loss": 0.2871,
      "step": 965
    },
    {
      "epoch": 1.27,
      "grad_norm": 260.0,
      "learning_rate": 0.0001308839050131926,
      "loss": 8.4375,
      "step": 966
    },
    {
      "epoch": 1.28,
      "grad_norm": 109.0,
      "learning_rate": 0.0001308641160949868,
      "loss": 1.6562,
      "step": 967
    },
    {
      "epoch": 1.28,
      "grad_norm": 27.75,
      "learning_rate": 0.000130844327176781,
      "loss": 0.5508,
      "step": 968
    },
    {
      "epoch": 1.28,
      "grad_norm": 94.0,
      "learning_rate": 0.0001308245382585752,
      "loss": 1.5625,
      "step": 969
    },
    {
      "epoch": 1.28,
      "grad_norm": 194.0,
      "learning_rate": 0.0001308047493403694,
      "loss": 2.2812,
      "step": 970
    },
    {
      "epoch": 1.28,
      "grad_norm": 68.0,
      "learning_rate": 0.0001307849604221636,
      "loss": 0.6562,
      "step": 971
    },
    {
      "epoch": 1.28,
      "grad_norm": 70.5,
      "learning_rate": 0.0001307651715039578,
      "loss": 0.7031,
      "step": 972
    },
    {
      "epoch": 1.28,
      "grad_norm": 254.0,
      "learning_rate": 0.00013074538258575196,
      "loss": 7.3125,
      "step": 973
    },
    {
      "epoch": 1.28,
      "grad_norm": 55.5,
      "learning_rate": 0.00013072559366754616,
      "loss": 0.7305,
      "step": 974
    },
    {
      "epoch": 1.29,
      "grad_norm": 53.5,
      "learning_rate": 0.00013070580474934036,
      "loss": 0.7148,
      "step": 975
    },
    {
      "epoch": 1.29,
      "grad_norm": 50.25,
      "learning_rate": 0.00013068601583113456,
      "loss": 0.7383,
      "step": 976
    },
    {
      "epoch": 1.29,
      "grad_norm": 77.0,
      "learning_rate": 0.00013066622691292875,
      "loss": 1.1562,
      "step": 977
    },
    {
      "epoch": 1.29,
      "grad_norm": 201.0,
      "learning_rate": 0.00013064643799472292,
      "loss": 2.1094,
      "step": 978
    },
    {
      "epoch": 1.29,
      "grad_norm": 48.25,
      "learning_rate": 0.00013062664907651712,
      "loss": 0.7695,
      "step": 979
    },
    {
      "epoch": 1.29,
      "grad_norm": 111.5,
      "learning_rate": 0.00013060686015831132,
      "loss": 1.1797,
      "step": 980
    },
    {
      "epoch": 1.29,
      "grad_norm": 104.0,
      "learning_rate": 0.00013058707124010552,
      "loss": 1.6094,
      "step": 981
    },
    {
      "epoch": 1.3,
      "grad_norm": 36.75,
      "learning_rate": 0.00013056728232189972,
      "loss": 0.6445,
      "step": 982
    },
    {
      "epoch": 1.3,
      "grad_norm": 208.0,
      "learning_rate": 0.00013054749340369391,
      "loss": 5.5938,
      "step": 983
    },
    {
      "epoch": 1.3,
      "grad_norm": 23.75,
      "learning_rate": 0.0001305277044854881,
      "loss": 0.5469,
      "step": 984
    },
    {
      "epoch": 1.3,
      "grad_norm": 43.25,
      "learning_rate": 0.0001305079155672823,
      "loss": 0.6289,
      "step": 985
    },
    {
      "epoch": 1.3,
      "grad_norm": 198.0,
      "learning_rate": 0.0001304881266490765,
      "loss": 4.7188,
      "step": 986
    },
    {
      "epoch": 1.3,
      "grad_norm": 19.75,
      "learning_rate": 0.0001304683377308707,
      "loss": 0.5078,
      "step": 987
    },
    {
      "epoch": 1.3,
      "grad_norm": 42.0,
      "learning_rate": 0.0001304485488126649,
      "loss": 0.6016,
      "step": 988
    },
    {
      "epoch": 1.3,
      "grad_norm": 123.0,
      "learning_rate": 0.0001304287598944591,
      "loss": 2.6875,
      "step": 989
    },
    {
      "epoch": 1.31,
      "grad_norm": 120.0,
      "learning_rate": 0.00013040897097625327,
      "loss": 2.7188,
      "step": 990
    },
    {
      "epoch": 1.31,
      "grad_norm": 18.125,
      "learning_rate": 0.00013038918205804747,
      "loss": 0.4238,
      "step": 991
    },
    {
      "epoch": 1.31,
      "grad_norm": 33.25,
      "learning_rate": 0.00013036939313984167,
      "loss": 0.5742,
      "step": 992
    },
    {
      "epoch": 1.31,
      "grad_norm": 99.0,
      "learning_rate": 0.00013034960422163587,
      "loss": 0.9609,
      "step": 993
    },
    {
      "epoch": 1.31,
      "grad_norm": 131.0,
      "learning_rate": 0.00013032981530343007,
      "loss": 2.7188,
      "step": 994
    },
    {
      "epoch": 1.31,
      "grad_norm": 288.0,
      "learning_rate": 0.00013031002638522426,
      "loss": 5.9688,
      "step": 995
    },
    {
      "epoch": 1.31,
      "grad_norm": 94.5,
      "learning_rate": 0.00013029023746701846,
      "loss": 0.8789,
      "step": 996
    },
    {
      "epoch": 1.32,
      "grad_norm": 17.875,
      "learning_rate": 0.00013027044854881266,
      "loss": 0.4336,
      "step": 997
    },
    {
      "epoch": 1.32,
      "grad_norm": 49.25,
      "learning_rate": 0.00013025065963060686,
      "loss": 0.582,
      "step": 998
    },
    {
      "epoch": 1.32,
      "grad_norm": 26.875,
      "learning_rate": 0.00013023087071240106,
      "loss": 0.4844,
      "step": 999
    },
    {
      "epoch": 1.32,
      "grad_norm": 30.0,
      "learning_rate": 0.00013021108179419525,
      "loss": 0.4805,
      "step": 1000
    },
    {
      "epoch": 1.32,
      "grad_norm": 123.0,
      "learning_rate": 0.00013019129287598945,
      "loss": 2.3125,
      "step": 1001
    },
    {
      "epoch": 1.32,
      "grad_norm": 29.25,
      "learning_rate": 0.00013017150395778362,
      "loss": 0.4863,
      "step": 1002
    },
    {
      "epoch": 1.32,
      "grad_norm": 15.4375,
      "learning_rate": 0.00013015171503957782,
      "loss": 0.4648,
      "step": 1003
    },
    {
      "epoch": 1.32,
      "grad_norm": 19.375,
      "learning_rate": 0.00013013192612137202,
      "loss": 0.4844,
      "step": 1004
    },
    {
      "epoch": 1.33,
      "grad_norm": 22.0,
      "learning_rate": 0.00013011213720316622,
      "loss": 0.3945,
      "step": 1005
    },
    {
      "epoch": 1.33,
      "grad_norm": 18.75,
      "learning_rate": 0.00013009234828496042,
      "loss": 0.4902,
      "step": 1006
    },
    {
      "epoch": 1.33,
      "grad_norm": 19.5,
      "learning_rate": 0.00013007255936675461,
      "loss": 0.4668,
      "step": 1007
    },
    {
      "epoch": 1.33,
      "grad_norm": 252.0,
      "learning_rate": 0.00013005277044854878,
      "loss": 6.0,
      "step": 1008
    },
    {
      "epoch": 1.33,
      "grad_norm": 38.75,
      "learning_rate": 0.00013003298153034298,
      "loss": 0.4375,
      "step": 1009
    },
    {
      "epoch": 1.33,
      "grad_norm": 41.75,
      "learning_rate": 0.00013001319261213718,
      "loss": 0.4492,
      "step": 1010
    },
    {
      "epoch": 1.33,
      "grad_norm": 161.0,
      "learning_rate": 0.00012999340369393138,
      "loss": 3.2812,
      "step": 1011
    },
    {
      "epoch": 1.34,
      "grad_norm": 7.0625,
      "learning_rate": 0.00012997361477572558,
      "loss": 0.4023,
      "step": 1012
    },
    {
      "epoch": 1.34,
      "grad_norm": 350.0,
      "learning_rate": 0.00012995382585751978,
      "loss": 9.0625,
      "step": 1013
    },
    {
      "epoch": 1.34,
      "grad_norm": 169.0,
      "learning_rate": 0.00012993403693931397,
      "loss": 3.2969,
      "step": 1014
    },
    {
      "epoch": 1.34,
      "grad_norm": 26.625,
      "learning_rate": 0.00012991424802110817,
      "loss": 0.3867,
      "step": 1015
    },
    {
      "epoch": 1.34,
      "grad_norm": 8.9375,
      "learning_rate": 0.00012989445910290237,
      "loss": 0.4023,
      "step": 1016
    },
    {
      "epoch": 1.34,
      "grad_norm": 27.625,
      "learning_rate": 0.00012987467018469657,
      "loss": 0.3984,
      "step": 1017
    },
    {
      "epoch": 1.34,
      "grad_norm": 25.375,
      "learning_rate": 0.00012985488126649074,
      "loss": 0.3711,
      "step": 1018
    },
    {
      "epoch": 1.34,
      "grad_norm": 262.0,
      "learning_rate": 0.00012983509234828494,
      "loss": 6.0,
      "step": 1019
    },
    {
      "epoch": 1.35,
      "grad_norm": 262.0,
      "learning_rate": 0.00012981530343007913,
      "loss": 5.6875,
      "step": 1020
    },
    {
      "epoch": 1.35,
      "grad_norm": 272.0,
      "learning_rate": 0.00012979551451187333,
      "loss": 5.4688,
      "step": 1021
    },
    {
      "epoch": 1.35,
      "grad_norm": 198.0,
      "learning_rate": 0.00012977572559366753,
      "loss": 3.25,
      "step": 1022
    },
    {
      "epoch": 1.35,
      "grad_norm": 6.75,
      "learning_rate": 0.00012975593667546173,
      "loss": 0.3633,
      "step": 1023
    },
    {
      "epoch": 1.35,
      "grad_norm": 173.0,
      "learning_rate": 0.00012973614775725593,
      "loss": 2.9844,
      "step": 1024
    },
    {
      "epoch": 1.35,
      "grad_norm": 159.0,
      "learning_rate": 0.00012971635883905012,
      "loss": 2.7656,
      "step": 1025
    },
    {
      "epoch": 1.35,
      "grad_norm": 27.875,
      "learning_rate": 0.00012969656992084432,
      "loss": 0.5156,
      "step": 1026
    },
    {
      "epoch": 1.35,
      "grad_norm": 20.25,
      "learning_rate": 0.00012967678100263852,
      "loss": 0.5234,
      "step": 1027
    },
    {
      "epoch": 1.36,
      "grad_norm": 134.0,
      "learning_rate": 0.00012965699208443272,
      "loss": 2.2812,
      "step": 1028
    },
    {
      "epoch": 1.36,
      "grad_norm": 72.5,
      "learning_rate": 0.00012963720316622692,
      "loss": 0.6016,
      "step": 1029
    },
    {
      "epoch": 1.36,
      "grad_norm": 416.0,
      "learning_rate": 0.0001296174142480211,
      "loss": 5.7812,
      "step": 1030
    },
    {
      "epoch": 1.36,
      "grad_norm": 24.5,
      "learning_rate": 0.00012959762532981529,
      "loss": 0.5898,
      "step": 1031
    },
    {
      "epoch": 1.36,
      "grad_norm": 46.75,
      "learning_rate": 0.00012957783641160948,
      "loss": 0.5742,
      "step": 1032
    },
    {
      "epoch": 1.36,
      "grad_norm": 116.0,
      "learning_rate": 0.00012955804749340368,
      "loss": 1.9219,
      "step": 1033
    },
    {
      "epoch": 1.36,
      "grad_norm": 71.0,
      "learning_rate": 0.00012953825857519788,
      "loss": 0.6133,
      "step": 1034
    },
    {
      "epoch": 1.37,
      "grad_norm": 404.0,
      "learning_rate": 0.00012951846965699208,
      "loss": 5.4688,
      "step": 1035
    },
    {
      "epoch": 1.37,
      "grad_norm": 56.0,
      "learning_rate": 0.00012949868073878628,
      "loss": 0.6445,
      "step": 1036
    },
    {
      "epoch": 1.37,
      "grad_norm": 40.75,
      "learning_rate": 0.00012947889182058047,
      "loss": 0.6875,
      "step": 1037
    },
    {
      "epoch": 1.37,
      "grad_norm": 124.0,
      "learning_rate": 0.00012945910290237465,
      "loss": 1.9141,
      "step": 1038
    },
    {
      "epoch": 1.37,
      "grad_norm": 34.5,
      "learning_rate": 0.00012943931398416884,
      "loss": 0.5156,
      "step": 1039
    },
    {
      "epoch": 1.37,
      "grad_norm": 33.75,
      "learning_rate": 0.00012941952506596304,
      "loss": 0.4961,
      "step": 1040
    },
    {
      "epoch": 1.37,
      "grad_norm": 29.0,
      "learning_rate": 0.00012939973614775724,
      "loss": 0.543,
      "step": 1041
    },
    {
      "epoch": 1.37,
      "grad_norm": 22.0,
      "learning_rate": 0.00012937994722955144,
      "loss": 0.4258,
      "step": 1042
    },
    {
      "epoch": 1.38,
      "grad_norm": 68.5,
      "learning_rate": 0.00012936015831134564,
      "loss": 0.668,
      "step": 1043
    },
    {
      "epoch": 1.38,
      "grad_norm": 240.0,
      "learning_rate": 0.00012934036939313983,
      "loss": 4.3125,
      "step": 1044
    },
    {
      "epoch": 1.38,
      "grad_norm": 11.4375,
      "learning_rate": 0.00012932058047493403,
      "loss": 0.3125,
      "step": 1045
    },
    {
      "epoch": 1.38,
      "grad_norm": 248.0,
      "learning_rate": 0.00012930079155672823,
      "loss": 4.5312,
      "step": 1046
    },
    {
      "epoch": 1.38,
      "grad_norm": 5.65625,
      "learning_rate": 0.0001292810026385224,
      "loss": 0.3867,
      "step": 1047
    },
    {
      "epoch": 1.38,
      "grad_norm": 166.0,
      "learning_rate": 0.0001292612137203166,
      "loss": 3.3438,
      "step": 1048
    },
    {
      "epoch": 1.38,
      "grad_norm": 15.8125,
      "learning_rate": 0.0001292414248021108,
      "loss": 0.3789,
      "step": 1049
    },
    {
      "epoch": 1.39,
      "grad_norm": 6.125,
      "learning_rate": 0.000129221635883905,
      "loss": 0.4375,
      "step": 1050
    },
    {
      "epoch": 1.39,
      "grad_norm": 74.5,
      "learning_rate": 0.0001292018469656992,
      "loss": 0.6992,
      "step": 1051
    },
    {
      "epoch": 1.39,
      "grad_norm": 65.5,
      "learning_rate": 0.0001291820580474934,
      "loss": 0.5898,
      "step": 1052
    },
    {
      "epoch": 1.39,
      "grad_norm": 147.0,
      "learning_rate": 0.0001291622691292876,
      "loss": 3.8906,
      "step": 1053
    },
    {
      "epoch": 1.39,
      "grad_norm": 24.25,
      "learning_rate": 0.0001291424802110818,
      "loss": 0.4336,
      "step": 1054
    },
    {
      "epoch": 1.39,
      "grad_norm": 60.5,
      "learning_rate": 0.00012912269129287599,
      "loss": 0.375,
      "step": 1055
    },
    {
      "epoch": 1.39,
      "grad_norm": 147.0,
      "learning_rate": 0.00012910290237467018,
      "loss": 4.0938,
      "step": 1056
    },
    {
      "epoch": 1.39,
      "grad_norm": 2.828125,
      "learning_rate": 0.00012908311345646438,
      "loss": 0.252,
      "step": 1057
    },
    {
      "epoch": 1.4,
      "grad_norm": 164.0,
      "learning_rate": 0.00012906332453825858,
      "loss": 4.375,
      "step": 1058
    },
    {
      "epoch": 1.4,
      "grad_norm": 41.5,
      "learning_rate": 0.00012904353562005275,
      "loss": 0.4863,
      "step": 1059
    },
    {
      "epoch": 1.4,
      "grad_norm": 43.0,
      "learning_rate": 0.00012902374670184695,
      "loss": 0.459,
      "step": 1060
    },
    {
      "epoch": 1.4,
      "grad_norm": 61.5,
      "learning_rate": 0.00012900395778364115,
      "loss": 0.6016,
      "step": 1061
    },
    {
      "epoch": 1.4,
      "grad_norm": 78.5,
      "learning_rate": 0.00012898416886543534,
      "loss": 0.543,
      "step": 1062
    },
    {
      "epoch": 1.4,
      "grad_norm": 4.28125,
      "learning_rate": 0.00012896437994722954,
      "loss": 0.2852,
      "step": 1063
    },
    {
      "epoch": 1.4,
      "grad_norm": 28.25,
      "learning_rate": 0.00012894459102902374,
      "loss": 0.4297,
      "step": 1064
    },
    {
      "epoch": 1.41,
      "grad_norm": 32.75,
      "learning_rate": 0.00012892480211081794,
      "loss": 0.2891,
      "step": 1065
    },
    {
      "epoch": 1.41,
      "grad_norm": 49.5,
      "learning_rate": 0.00012890501319261214,
      "loss": 0.5469,
      "step": 1066
    },
    {
      "epoch": 1.41,
      "grad_norm": 13.1875,
      "learning_rate": 0.00012888522427440633,
      "loss": 0.293,
      "step": 1067
    },
    {
      "epoch": 1.41,
      "grad_norm": 25.75,
      "learning_rate": 0.0001288654353562005,
      "loss": 0.1973,
      "step": 1068
    },
    {
      "epoch": 1.41,
      "grad_norm": 158.0,
      "learning_rate": 0.0001288456464379947,
      "loss": 3.3594,
      "step": 1069
    },
    {
      "epoch": 1.41,
      "grad_norm": 163.0,
      "learning_rate": 0.0001288258575197889,
      "loss": 3.2656,
      "step": 1070
    },
    {
      "epoch": 1.41,
      "grad_norm": 17.625,
      "learning_rate": 0.0001288060686015831,
      "loss": 0.4531,
      "step": 1071
    },
    {
      "epoch": 1.41,
      "grad_norm": 163.0,
      "learning_rate": 0.0001287862796833773,
      "loss": 2.9844,
      "step": 1072
    },
    {
      "epoch": 1.42,
      "grad_norm": 15.5625,
      "learning_rate": 0.0001287664907651715,
      "loss": 0.332,
      "step": 1073
    },
    {
      "epoch": 1.42,
      "grad_norm": 76.0,
      "learning_rate": 0.0001287467018469657,
      "loss": 0.6055,
      "step": 1074
    },
    {
      "epoch": 1.42,
      "grad_norm": 258.0,
      "learning_rate": 0.0001287269129287599,
      "loss": 6.5938,
      "step": 1075
    },
    {
      "epoch": 1.42,
      "grad_norm": 13.4375,
      "learning_rate": 0.00012870712401055406,
      "loss": 0.3633,
      "step": 1076
    },
    {
      "epoch": 1.42,
      "grad_norm": 560.0,
      "learning_rate": 0.00012868733509234826,
      "loss": 12.75,
      "step": 1077
    },
    {
      "epoch": 1.42,
      "grad_norm": 15.4375,
      "learning_rate": 0.00012866754617414246,
      "loss": 0.416,
      "step": 1078
    },
    {
      "epoch": 1.42,
      "grad_norm": 52.25,
      "learning_rate": 0.00012864775725593666,
      "loss": 0.5234,
      "step": 1079
    },
    {
      "epoch": 1.42,
      "grad_norm": 29.625,
      "learning_rate": 0.00012862796833773086,
      "loss": 0.1621,
      "step": 1080
    },
    {
      "epoch": 1.43,
      "grad_norm": 140.0,
      "learning_rate": 0.00012860817941952505,
      "loss": 2.6719,
      "step": 1081
    },
    {
      "epoch": 1.43,
      "grad_norm": 131.0,
      "learning_rate": 0.00012858839050131925,
      "loss": 2.2656,
      "step": 1082
    },
    {
      "epoch": 1.43,
      "grad_norm": 127.0,
      "learning_rate": 0.00012856860158311345,
      "loss": 2.0781,
      "step": 1083
    },
    {
      "epoch": 1.43,
      "grad_norm": 43.5,
      "learning_rate": 0.00012854881266490765,
      "loss": 0.5703,
      "step": 1084
    },
    {
      "epoch": 1.43,
      "grad_norm": 113.0,
      "learning_rate": 0.00012852902374670185,
      "loss": 1.7422,
      "step": 1085
    },
    {
      "epoch": 1.43,
      "grad_norm": 108.0,
      "learning_rate": 0.00012850923482849604,
      "loss": 1.2578,
      "step": 1086
    },
    {
      "epoch": 1.43,
      "grad_norm": 22.625,
      "learning_rate": 0.00012848944591029024,
      "loss": 0.3652,
      "step": 1087
    },
    {
      "epoch": 1.44,
      "grad_norm": 33.5,
      "learning_rate": 0.0001284696569920844,
      "loss": 0.3242,
      "step": 1088
    },
    {
      "epoch": 1.44,
      "grad_norm": 40.75,
      "learning_rate": 0.0001284498680738786,
      "loss": 1.1641,
      "step": 1089
    },
    {
      "epoch": 1.44,
      "grad_norm": 61.25,
      "learning_rate": 0.0001284300791556728,
      "loss": 1.0469,
      "step": 1090
    },
    {
      "epoch": 1.44,
      "grad_norm": 20.625,
      "learning_rate": 0.000128410290237467,
      "loss": 1.0391,
      "step": 1091
    },
    {
      "epoch": 1.44,
      "grad_norm": 249.0,
      "learning_rate": 0.0001283905013192612,
      "loss": 5.125,
      "step": 1092
    },
    {
      "epoch": 1.44,
      "grad_norm": 57.5,
      "learning_rate": 0.0001283707124010554,
      "loss": 0.793,
      "step": 1093
    },
    {
      "epoch": 1.44,
      "grad_norm": 73.5,
      "learning_rate": 0.0001283509234828496,
      "loss": 1.1641,
      "step": 1094
    },
    {
      "epoch": 1.44,
      "grad_norm": 241.0,
      "learning_rate": 0.0001283311345646438,
      "loss": 5.3125,
      "step": 1095
    },
    {
      "epoch": 1.45,
      "grad_norm": 26.75,
      "learning_rate": 0.000128311345646438,
      "loss": 1.1719,
      "step": 1096
    },
    {
      "epoch": 1.45,
      "grad_norm": 85.5,
      "learning_rate": 0.0001282915567282322,
      "loss": 1.0078,
      "step": 1097
    },
    {
      "epoch": 1.45,
      "grad_norm": 258.0,
      "learning_rate": 0.00012827176781002637,
      "loss": 4.5,
      "step": 1098
    },
    {
      "epoch": 1.45,
      "grad_norm": 224.0,
      "learning_rate": 0.00012825197889182056,
      "loss": 4.4375,
      "step": 1099
    },
    {
      "epoch": 1.45,
      "grad_norm": 251.0,
      "learning_rate": 0.00012823218997361476,
      "loss": 3.7344,
      "step": 1100
    },
    {
      "epoch": 1.45,
      "grad_norm": 59.75,
      "learning_rate": 0.00012821240105540896,
      "loss": 0.7617,
      "step": 1101
    },
    {
      "epoch": 1.45,
      "grad_norm": 464.0,
      "learning_rate": 0.00012819261213720316,
      "loss": 1.8203,
      "step": 1102
    },
    {
      "epoch": 1.46,
      "grad_norm": 49.5,
      "learning_rate": 0.00012817282321899736,
      "loss": 0.707,
      "step": 1103
    },
    {
      "epoch": 1.46,
      "grad_norm": 163.0,
      "learning_rate": 0.00012815303430079153,
      "loss": 2.2969,
      "step": 1104
    },
    {
      "epoch": 1.46,
      "grad_norm": 100.5,
      "learning_rate": 0.00012813324538258573,
      "loss": 1.2266,
      "step": 1105
    },
    {
      "epoch": 1.46,
      "grad_norm": 115.5,
      "learning_rate": 0.00012811345646437992,
      "loss": 1.2031,
      "step": 1106
    },
    {
      "epoch": 1.46,
      "grad_norm": 99.0,
      "learning_rate": 0.00012809366754617412,
      "loss": 1.6719,
      "step": 1107
    },
    {
      "epoch": 1.46,
      "grad_norm": 64.0,
      "learning_rate": 0.00012807387862796832,
      "loss": 0.7852,
      "step": 1108
    },
    {
      "epoch": 1.46,
      "grad_norm": 506.0,
      "learning_rate": 0.00012805408970976252,
      "loss": 1.7969,
      "step": 1109
    },
    {
      "epoch": 1.46,
      "grad_norm": 165.0,
      "learning_rate": 0.00012803430079155672,
      "loss": 3.0469,
      "step": 1110
    },
    {
      "epoch": 1.47,
      "grad_norm": 174.0,
      "learning_rate": 0.00012801451187335091,
      "loss": 3.5,
      "step": 1111
    },
    {
      "epoch": 1.47,
      "grad_norm": 73.5,
      "learning_rate": 0.0001279947229551451,
      "loss": 0.7461,
      "step": 1112
    },
    {
      "epoch": 1.47,
      "grad_norm": 70.5,
      "learning_rate": 0.0001279749340369393,
      "loss": 0.8555,
      "step": 1113
    },
    {
      "epoch": 1.47,
      "grad_norm": 59.25,
      "learning_rate": 0.0001279551451187335,
      "loss": 0.4336,
      "step": 1114
    },
    {
      "epoch": 1.47,
      "grad_norm": 31.5,
      "learning_rate": 0.0001279353562005277,
      "loss": 0.3965,
      "step": 1115
    },
    {
      "epoch": 1.47,
      "grad_norm": 122.0,
      "learning_rate": 0.00012791556728232188,
      "loss": 2.8438,
      "step": 1116
    },
    {
      "epoch": 1.47,
      "grad_norm": 21.375,
      "learning_rate": 0.00012789577836411608,
      "loss": 0.2793,
      "step": 1117
    },
    {
      "epoch": 1.47,
      "grad_norm": 224.0,
      "learning_rate": 0.00012787598944591027,
      "loss": 1.0078,
      "step": 1118
    },
    {
      "epoch": 1.48,
      "grad_norm": 94.5,
      "learning_rate": 0.00012785620052770447,
      "loss": 1.7656,
      "step": 1119
    },
    {
      "epoch": 1.48,
      "grad_norm": 262.0,
      "learning_rate": 0.00012783641160949867,
      "loss": 3.7969,
      "step": 1120
    },
    {
      "epoch": 1.48,
      "grad_norm": 680.0,
      "learning_rate": 0.00012781662269129287,
      "loss": 5.5938,
      "step": 1121
    },
    {
      "epoch": 1.48,
      "grad_norm": 64.5,
      "learning_rate": 0.00012779683377308707,
      "loss": 1.1094,
      "step": 1122
    },
    {
      "epoch": 1.48,
      "grad_norm": 59.0,
      "learning_rate": 0.00012777704485488126,
      "loss": 1.1562,
      "step": 1123
    },
    {
      "epoch": 1.48,
      "grad_norm": 50.5,
      "learning_rate": 0.00012775725593667546,
      "loss": 1.4766,
      "step": 1124
    },
    {
      "epoch": 1.48,
      "grad_norm": 85.0,
      "learning_rate": 0.00012773746701846966,
      "loss": 1.0938,
      "step": 1125
    },
    {
      "epoch": 1.49,
      "grad_norm": 836.0,
      "learning_rate": 0.00012771767810026386,
      "loss": 1.7812,
      "step": 1126
    },
    {
      "epoch": 1.49,
      "grad_norm": 276.0,
      "learning_rate": 0.00012769788918205806,
      "loss": 2.9375,
      "step": 1127
    },
    {
      "epoch": 1.49,
      "grad_norm": 39.0,
      "learning_rate": 0.00012767810026385223,
      "loss": 1.0078,
      "step": 1128
    },
    {
      "epoch": 1.49,
      "grad_norm": 227.0,
      "learning_rate": 0.00012765831134564642,
      "loss": 6.125,
      "step": 1129
    },
    {
      "epoch": 1.49,
      "grad_norm": 51.5,
      "learning_rate": 0.00012763852242744062,
      "loss": 1.1328,
      "step": 1130
    },
    {
      "epoch": 1.49,
      "grad_norm": 46.25,
      "learning_rate": 0.00012761873350923482,
      "loss": 0.7109,
      "step": 1131
    },
    {
      "epoch": 1.49,
      "grad_norm": 138.0,
      "learning_rate": 0.00012759894459102902,
      "loss": 2.5781,
      "step": 1132
    },
    {
      "epoch": 1.49,
      "grad_norm": 46.0,
      "learning_rate": 0.0001275791556728232,
      "loss": 0.7031,
      "step": 1133
    },
    {
      "epoch": 1.5,
      "grad_norm": 216.0,
      "learning_rate": 0.0001275593667546174,
      "loss": 4.9375,
      "step": 1134
    },
    {
      "epoch": 1.5,
      "grad_norm": 496.0,
      "learning_rate": 0.00012753957783641159,
      "loss": 4.8438,
      "step": 1135
    },
    {
      "epoch": 1.5,
      "grad_norm": 1608.0,
      "learning_rate": 0.00012751978891820578,
      "loss": 5.6562,
      "step": 1136
    },
    {
      "epoch": 1.5,
      "grad_norm": 140.0,
      "learning_rate": 0.00012749999999999998,
      "loss": 0.582,
      "step": 1137
    },
    {
      "epoch": 1.5,
      "grad_norm": 43.75,
      "learning_rate": 0.00012748021108179418,
      "loss": 0.3496,
      "step": 1138
    },
    {
      "epoch": 1.5,
      "grad_norm": 424.0,
      "learning_rate": 0.00012746042216358838,
      "loss": 8.0,
      "step": 1139
    },
    {
      "epoch": 1.5,
      "grad_norm": 78.5,
      "learning_rate": 0.00012744063324538258,
      "loss": 0.3691,
      "step": 1140
    },
    {
      "epoch": 1.51,
      "grad_norm": 141.0,
      "learning_rate": 0.00012742084432717677,
      "loss": 4.0312,
      "step": 1141
    },
    {
      "epoch": 1.51,
      "grad_norm": 716.0,
      "learning_rate": 0.00012740105540897097,
      "loss": 11.5625,
      "step": 1142
    },
    {
      "epoch": 1.51,
      "grad_norm": 1616.0,
      "learning_rate": 0.00012738126649076517,
      "loss": 0.7812,
      "step": 1143
    },
    {
      "epoch": 1.51,
      "grad_norm": 182.0,
      "learning_rate": 0.00012736147757255937,
      "loss": 1.125,
      "step": 1144
    },
    {
      "epoch": 1.51,
      "grad_norm": 752.0,
      "learning_rate": 0.00012734168865435354,
      "loss": 4.9375,
      "step": 1145
    },
    {
      "epoch": 1.51,
      "grad_norm": 33.5,
      "learning_rate": 0.00012732189973614774,
      "loss": 0.1611,
      "step": 1146
    },
    {
      "epoch": 1.51,
      "grad_norm": 472.0,
      "learning_rate": 0.00012730211081794194,
      "loss": 7.7188,
      "step": 1147
    },
    {
      "epoch": 1.51,
      "grad_norm": 224.0,
      "learning_rate": 0.00012728232189973613,
      "loss": 4.0625,
      "step": 1148
    },
    {
      "epoch": 1.52,
      "grad_norm": 872.0,
      "learning_rate": 0.00012726253298153033,
      "loss": 13.625,
      "step": 1149
    },
    {
      "epoch": 1.52,
      "grad_norm": 63.75,
      "learning_rate": 0.00012724274406332453,
      "loss": 0.4258,
      "step": 1150
    },
    {
      "epoch": 1.52,
      "grad_norm": 32.75,
      "learning_rate": 0.00012722295514511873,
      "loss": 0.3027,
      "step": 1151
    },
    {
      "epoch": 1.52,
      "grad_norm": 736.0,
      "learning_rate": 0.00012720316622691293,
      "loss": 6.125,
      "step": 1152
    },
    {
      "epoch": 1.52,
      "grad_norm": 2288.0,
      "learning_rate": 0.00012718337730870712,
      "loss": 5.2188,
      "step": 1153
    },
    {
      "epoch": 1.52,
      "grad_norm": 476.0,
      "learning_rate": 0.00012716358839050132,
      "loss": 4.6562,
      "step": 1154
    },
    {
      "epoch": 1.52,
      "grad_norm": 93.0,
      "learning_rate": 0.00012714379947229552,
      "loss": 0.6562,
      "step": 1155
    },
    {
      "epoch": 1.53,
      "grad_norm": 79.0,
      "learning_rate": 0.00012712401055408972,
      "loss": 0.6406,
      "step": 1156
    },
    {
      "epoch": 1.53,
      "grad_norm": 102.0,
      "learning_rate": 0.0001271042216358839,
      "loss": 0.7383,
      "step": 1157
    },
    {
      "epoch": 1.53,
      "grad_norm": 318.0,
      "learning_rate": 0.0001270844327176781,
      "loss": 2.2656,
      "step": 1158
    },
    {
      "epoch": 1.53,
      "grad_norm": 93.0,
      "learning_rate": 0.00012706464379947229,
      "loss": 0.6406,
      "step": 1159
    },
    {
      "epoch": 1.53,
      "grad_norm": 121.5,
      "learning_rate": 0.00012704485488126648,
      "loss": 2.7656,
      "step": 1160
    },
    {
      "epoch": 1.53,
      "grad_norm": 199.0,
      "learning_rate": 0.00012702506596306068,
      "loss": 1.2969,
      "step": 1161
    },
    {
      "epoch": 1.53,
      "grad_norm": 154.0,
      "learning_rate": 0.00012700527704485485,
      "loss": 1.0703,
      "step": 1162
    },
    {
      "epoch": 1.53,
      "grad_norm": 620.0,
      "learning_rate": 0.00012698548812664905,
      "loss": 3.2969,
      "step": 1163
    },
    {
      "epoch": 1.54,
      "grad_norm": 612.0,
      "learning_rate": 0.00012696569920844325,
      "loss": 5.25,
      "step": 1164
    },
    {
      "epoch": 1.54,
      "grad_norm": 1240.0,
      "learning_rate": 0.00012694591029023745,
      "loss": 7.5,
      "step": 1165
    },
    {
      "epoch": 1.54,
      "grad_norm": 316.0,
      "learning_rate": 0.00012692612137203164,
      "loss": 1.3125,
      "step": 1166
    },
    {
      "epoch": 1.54,
      "grad_norm": 95.5,
      "learning_rate": 0.00012690633245382584,
      "loss": 0.5195,
      "step": 1167
    },
    {
      "epoch": 1.54,
      "grad_norm": 612.0,
      "learning_rate": 0.00012688654353562004,
      "loss": 5.4375,
      "step": 1168
    },
    {
      "epoch": 1.54,
      "grad_norm": 255.0,
      "learning_rate": 0.00012686675461741424,
      "loss": 1.5,
      "step": 1169
    },
    {
      "epoch": 1.54,
      "grad_norm": 136.0,
      "learning_rate": 0.00012684696569920844,
      "loss": 0.8008,
      "step": 1170
    },
    {
      "epoch": 1.54,
      "grad_norm": 196.0,
      "learning_rate": 0.00012682717678100263,
      "loss": 0.8594,
      "step": 1171
    },
    {
      "epoch": 1.55,
      "grad_norm": 224.0,
      "learning_rate": 0.00012680738786279683,
      "loss": 1.4766,
      "step": 1172
    },
    {
      "epoch": 1.55,
      "grad_norm": 94.0,
      "learning_rate": 0.00012678759894459103,
      "loss": 0.8359,
      "step": 1173
    },
    {
      "epoch": 1.55,
      "grad_norm": 274.0,
      "learning_rate": 0.0001267678100263852,
      "loss": 0.6172,
      "step": 1174
    },
    {
      "epoch": 1.55,
      "grad_norm": 358.0,
      "learning_rate": 0.0001267480211081794,
      "loss": 1.5625,
      "step": 1175
    },
    {
      "epoch": 1.55,
      "grad_norm": 106.5,
      "learning_rate": 0.0001267282321899736,
      "loss": 1.8359,
      "step": 1176
    },
    {
      "epoch": 1.55,
      "grad_norm": 82.5,
      "learning_rate": 0.0001267084432717678,
      "loss": 0.7227,
      "step": 1177
    },
    {
      "epoch": 1.55,
      "grad_norm": 144.0,
      "learning_rate": 0.000126688654353562,
      "loss": 0.6719,
      "step": 1178
    },
    {
      "epoch": 1.56,
      "grad_norm": 380.0,
      "learning_rate": 0.0001266688654353562,
      "loss": 4.9375,
      "step": 1179
    },
    {
      "epoch": 1.56,
      "grad_norm": 35.0,
      "learning_rate": 0.0001266490765171504,
      "loss": 0.6797,
      "step": 1180
    },
    {
      "epoch": 1.56,
      "grad_norm": 54.0,
      "learning_rate": 0.0001266292875989446,
      "loss": 0.7344,
      "step": 1181
    },
    {
      "epoch": 1.56,
      "grad_norm": 32.5,
      "learning_rate": 0.00012660949868073879,
      "loss": 0.7383,
      "step": 1182
    },
    {
      "epoch": 1.56,
      "grad_norm": 122.5,
      "learning_rate": 0.00012658970976253298,
      "loss": 0.7461,
      "step": 1183
    },
    {
      "epoch": 1.56,
      "grad_norm": 326.0,
      "learning_rate": 0.00012656992084432718,
      "loss": 3.4062,
      "step": 1184
    },
    {
      "epoch": 1.56,
      "grad_norm": 15.5625,
      "learning_rate": 0.00012655013192612138,
      "loss": 0.5742,
      "step": 1185
    },
    {
      "epoch": 1.56,
      "grad_norm": 21.375,
      "learning_rate": 0.00012653034300791555,
      "loss": 0.543,
      "step": 1186
    },
    {
      "epoch": 1.57,
      "grad_norm": 12.5,
      "learning_rate": 0.00012651055408970975,
      "loss": 0.3867,
      "step": 1187
    },
    {
      "epoch": 1.57,
      "grad_norm": 127.5,
      "learning_rate": 0.00012649076517150395,
      "loss": 4.375,
      "step": 1188
    },
    {
      "epoch": 1.57,
      "grad_norm": 1736.0,
      "learning_rate": 0.00012647097625329815,
      "loss": 4.75,
      "step": 1189
    },
    {
      "epoch": 1.57,
      "grad_norm": 27.0,
      "learning_rate": 0.00012645118733509232,
      "loss": 0.543,
      "step": 1190
    },
    {
      "epoch": 1.57,
      "grad_norm": 65.5,
      "learning_rate": 0.00012643139841688651,
      "loss": 1.8906,
      "step": 1191
    },
    {
      "epoch": 1.57,
      "grad_norm": 22.25,
      "learning_rate": 0.0001264116094986807,
      "loss": 0.3887,
      "step": 1192
    },
    {
      "epoch": 1.57,
      "grad_norm": 20.625,
      "learning_rate": 0.0001263918205804749,
      "loss": 0.4844,
      "step": 1193
    },
    {
      "epoch": 1.58,
      "grad_norm": 13.4375,
      "learning_rate": 0.0001263720316622691,
      "loss": 0.4805,
      "step": 1194
    },
    {
      "epoch": 1.58,
      "grad_norm": 72.0,
      "learning_rate": 0.0001263522427440633,
      "loss": 2.0781,
      "step": 1195
    },
    {
      "epoch": 1.58,
      "grad_norm": 26.875,
      "learning_rate": 0.0001263324538258575,
      "loss": 0.5273,
      "step": 1196
    },
    {
      "epoch": 1.58,
      "grad_norm": 150.0,
      "learning_rate": 0.0001263126649076517,
      "loss": 4.1562,
      "step": 1197
    },
    {
      "epoch": 1.58,
      "grad_norm": 27.25,
      "learning_rate": 0.0001262928759894459,
      "loss": 0.1543,
      "step": 1198
    },
    {
      "epoch": 1.58,
      "grad_norm": 44.0,
      "learning_rate": 0.0001262730870712401,
      "loss": 0.1758,
      "step": 1199
    },
    {
      "epoch": 1.58,
      "grad_norm": 200.0,
      "learning_rate": 0.0001262532981530343,
      "loss": 2.8594,
      "step": 1200
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.8125,
      "learning_rate": 0.0001262335092348285,
      "loss": 0.0063,
      "step": 1201
    },
    {
      "epoch": 1.59,
      "grad_norm": 424.0,
      "learning_rate": 0.00012621372031662267,
      "loss": 4.4375,
      "step": 1202
    },
    {
      "epoch": 1.59,
      "grad_norm": 195.0,
      "learning_rate": 0.00012619393139841686,
      "loss": 1.8594,
      "step": 1203
    },
    {
      "epoch": 1.59,
      "grad_norm": 4.21875,
      "learning_rate": 0.00012617414248021106,
      "loss": 0.0092,
      "step": 1204
    },
    {
      "epoch": 1.59,
      "grad_norm": 476.0,
      "learning_rate": 0.00012615435356200526,
      "loss": 4.7188,
      "step": 1205
    },
    {
      "epoch": 1.59,
      "grad_norm": 278.0,
      "learning_rate": 0.00012613456464379946,
      "loss": 1.8516,
      "step": 1206
    },
    {
      "epoch": 1.59,
      "grad_norm": 248.0,
      "learning_rate": 0.00012611477572559366,
      "loss": 1.1094,
      "step": 1207
    },
    {
      "epoch": 1.59,
      "grad_norm": 370.0,
      "learning_rate": 0.00012609498680738785,
      "loss": 2.6406,
      "step": 1208
    },
    {
      "epoch": 1.59,
      "grad_norm": 19.5,
      "learning_rate": 0.00012607519788918205,
      "loss": 0.2559,
      "step": 1209
    },
    {
      "epoch": 1.6,
      "grad_norm": 390.0,
      "learning_rate": 0.00012605540897097625,
      "loss": 0.8008,
      "step": 1210
    },
    {
      "epoch": 1.6,
      "grad_norm": 1264.0,
      "learning_rate": 0.00012603562005277045,
      "loss": 12.8125,
      "step": 1211
    },
    {
      "epoch": 1.6,
      "grad_norm": 57.75,
      "learning_rate": 0.00012601583113456465,
      "loss": 0.5156,
      "step": 1212
    },
    {
      "epoch": 1.6,
      "grad_norm": 128.0,
      "learning_rate": 0.00012599604221635884,
      "loss": 0.9062,
      "step": 1213
    },
    {
      "epoch": 1.6,
      "grad_norm": 185.0,
      "learning_rate": 0.00012597625329815302,
      "loss": 1.1641,
      "step": 1214
    },
    {
      "epoch": 1.6,
      "grad_norm": 92.5,
      "learning_rate": 0.00012595646437994721,
      "loss": 0.5547,
      "step": 1215
    },
    {
      "epoch": 1.6,
      "grad_norm": 81.5,
      "learning_rate": 0.0001259366754617414,
      "loss": 0.3555,
      "step": 1216
    },
    {
      "epoch": 1.61,
      "grad_norm": 60.5,
      "learning_rate": 0.0001259168865435356,
      "loss": 0.4883,
      "step": 1217
    },
    {
      "epoch": 1.61,
      "grad_norm": 450.0,
      "learning_rate": 0.0001258970976253298,
      "loss": 3.5156,
      "step": 1218
    },
    {
      "epoch": 1.61,
      "grad_norm": 648.0,
      "learning_rate": 0.00012587730870712398,
      "loss": 6.3125,
      "step": 1219
    },
    {
      "epoch": 1.61,
      "grad_norm": 768.0,
      "learning_rate": 0.00012585751978891818,
      "loss": 6.9375,
      "step": 1220
    },
    {
      "epoch": 1.61,
      "grad_norm": 11.75,
      "learning_rate": 0.00012583773087071238,
      "loss": 0.0261,
      "step": 1221
    },
    {
      "epoch": 1.61,
      "grad_norm": 680.0,
      "learning_rate": 0.00012581794195250657,
      "loss": 4.8438,
      "step": 1222
    },
    {
      "epoch": 1.61,
      "grad_norm": 394.0,
      "learning_rate": 0.00012579815303430077,
      "loss": 3.1406,
      "step": 1223
    },
    {
      "epoch": 1.61,
      "grad_norm": 79.5,
      "learning_rate": 0.00012577836411609497,
      "loss": 0.5664,
      "step": 1224
    },
    {
      "epoch": 1.62,
      "grad_norm": 157.0,
      "learning_rate": 0.00012575857519788917,
      "loss": 1.2031,
      "step": 1225
    },
    {
      "epoch": 1.62,
      "grad_norm": 100.5,
      "learning_rate": 0.00012573878627968337,
      "loss": 0.7539,
      "step": 1226
    },
    {
      "epoch": 1.62,
      "grad_norm": 136.0,
      "learning_rate": 0.00012571899736147756,
      "loss": 0.9453,
      "step": 1227
    },
    {
      "epoch": 1.62,
      "grad_norm": 442.0,
      "learning_rate": 0.00012569920844327176,
      "loss": 2.3125,
      "step": 1228
    },
    {
      "epoch": 1.62,
      "grad_norm": 45.25,
      "learning_rate": 0.00012567941952506596,
      "loss": 0.252,
      "step": 1229
    },
    {
      "epoch": 1.62,
      "grad_norm": 600.0,
      "learning_rate": 0.00012565963060686016,
      "loss": 3.625,
      "step": 1230
    },
    {
      "epoch": 1.62,
      "grad_norm": 1160.0,
      "learning_rate": 0.00012563984168865433,
      "loss": 6.2188,
      "step": 1231
    },
    {
      "epoch": 1.63,
      "grad_norm": 169.0,
      "learning_rate": 0.00012562005277044853,
      "loss": 0.8359,
      "step": 1232
    },
    {
      "epoch": 1.63,
      "grad_norm": 218.0,
      "learning_rate": 0.00012560026385224272,
      "loss": 1.0156,
      "step": 1233
    },
    {
      "epoch": 1.63,
      "grad_norm": 140.0,
      "learning_rate": 0.00012558047493403692,
      "loss": 0.7383,
      "step": 1234
    },
    {
      "epoch": 1.63,
      "grad_norm": 370.0,
      "learning_rate": 0.00012556068601583112,
      "loss": 3.1719,
      "step": 1235
    },
    {
      "epoch": 1.63,
      "grad_norm": 386.0,
      "learning_rate": 0.00012554089709762532,
      "loss": 3.0938,
      "step": 1236
    },
    {
      "epoch": 1.63,
      "grad_norm": 1012.0,
      "learning_rate": 0.00012552110817941952,
      "loss": 4.3438,
      "step": 1237
    },
    {
      "epoch": 1.63,
      "grad_norm": 308.0,
      "learning_rate": 0.00012550131926121372,
      "loss": 1.7812,
      "step": 1238
    },
    {
      "epoch": 1.63,
      "grad_norm": 458.0,
      "learning_rate": 0.0001254815303430079,
      "loss": 2.7344,
      "step": 1239
    },
    {
      "epoch": 1.64,
      "grad_norm": 149.0,
      "learning_rate": 0.0001254617414248021,
      "loss": 1.1719,
      "step": 1240
    },
    {
      "epoch": 1.64,
      "grad_norm": 168.0,
      "learning_rate": 0.0001254419525065963,
      "loss": 0.8633,
      "step": 1241
    },
    {
      "epoch": 1.64,
      "grad_norm": 288.0,
      "learning_rate": 0.0001254221635883905,
      "loss": 2.7812,
      "step": 1242
    },
    {
      "epoch": 1.64,
      "grad_norm": 184.0,
      "learning_rate": 0.00012540237467018468,
      "loss": 1.3359,
      "step": 1243
    },
    {
      "epoch": 1.64,
      "grad_norm": 155.0,
      "learning_rate": 0.00012538258575197888,
      "loss": 0.668,
      "step": 1244
    },
    {
      "epoch": 1.64,
      "grad_norm": 187.0,
      "learning_rate": 0.00012536279683377307,
      "loss": 1.2031,
      "step": 1245
    },
    {
      "epoch": 1.64,
      "grad_norm": 196.0,
      "learning_rate": 0.00012534300791556727,
      "loss": 1.375,
      "step": 1246
    },
    {
      "epoch": 1.65,
      "grad_norm": 173.0,
      "learning_rate": 0.00012532321899736147,
      "loss": 1.2891,
      "step": 1247
    },
    {
      "epoch": 1.65,
      "grad_norm": 134.0,
      "learning_rate": 0.00012530343007915567,
      "loss": 0.4023,
      "step": 1248
    },
    {
      "epoch": 1.65,
      "grad_norm": 192.0,
      "learning_rate": 0.00012528364116094984,
      "loss": 0.6094,
      "step": 1249
    },
    {
      "epoch": 1.65,
      "grad_norm": 223.0,
      "learning_rate": 0.00012526385224274404,
      "loss": 1.4688,
      "step": 1250
    },
    {
      "epoch": 1.65,
      "grad_norm": 171.0,
      "learning_rate": 0.00012524406332453824,
      "loss": 1.0859,
      "step": 1251
    },
    {
      "epoch": 1.65,
      "grad_norm": 150.0,
      "learning_rate": 0.00012522427440633243,
      "loss": 0.6523,
      "step": 1252
    },
    {
      "epoch": 1.65,
      "grad_norm": 131.0,
      "learning_rate": 0.00012520448548812663,
      "loss": 0.5312,
      "step": 1253
    },
    {
      "epoch": 1.65,
      "grad_norm": 580.0,
      "learning_rate": 0.00012518469656992083,
      "loss": 9.4375,
      "step": 1254
    },
    {
      "epoch": 1.66,
      "grad_norm": 476.0,
      "learning_rate": 0.00012516490765171503,
      "loss": 3.1094,
      "step": 1255
    },
    {
      "epoch": 1.66,
      "grad_norm": 78.0,
      "learning_rate": 0.00012514511873350923,
      "loss": 0.5391,
      "step": 1256
    },
    {
      "epoch": 1.66,
      "grad_norm": 60.0,
      "learning_rate": 0.00012512532981530342,
      "loss": 0.5781,
      "step": 1257
    },
    {
      "epoch": 1.66,
      "grad_norm": 390.0,
      "learning_rate": 0.00012510554089709762,
      "loss": 2.5625,
      "step": 1258
    },
    {
      "epoch": 1.66,
      "grad_norm": 41.0,
      "learning_rate": 0.00012508575197889182,
      "loss": 0.4062,
      "step": 1259
    },
    {
      "epoch": 1.66,
      "grad_norm": 45.75,
      "learning_rate": 0.000125065963060686,
      "loss": 0.3984,
      "step": 1260
    },
    {
      "epoch": 1.66,
      "grad_norm": 39.75,
      "learning_rate": 0.0001250461741424802,
      "loss": 0.3398,
      "step": 1261
    },
    {
      "epoch": 1.66,
      "grad_norm": 344.0,
      "learning_rate": 0.0001250263852242744,
      "loss": 2.5312,
      "step": 1262
    },
    {
      "epoch": 1.67,
      "grad_norm": 360.0,
      "learning_rate": 0.00012500659630606859,
      "loss": 2.7188,
      "step": 1263
    },
    {
      "epoch": 1.67,
      "grad_norm": 314.0,
      "learning_rate": 0.00012498680738786278,
      "loss": 2.0625,
      "step": 1264
    },
    {
      "epoch": 1.67,
      "grad_norm": 544.0,
      "learning_rate": 0.00012496701846965698,
      "loss": 8.875,
      "step": 1265
    },
    {
      "epoch": 1.67,
      "grad_norm": 141.0,
      "learning_rate": 0.00012494722955145118,
      "loss": 1.0078,
      "step": 1266
    },
    {
      "epoch": 1.67,
      "grad_norm": 616.0,
      "learning_rate": 0.00012492744063324538,
      "loss": 8.25,
      "step": 1267
    },
    {
      "epoch": 1.67,
      "grad_norm": 199.0,
      "learning_rate": 0.00012490765171503958,
      "loss": 1.1016,
      "step": 1268
    },
    {
      "epoch": 1.67,
      "grad_norm": 199.0,
      "learning_rate": 0.00012488786279683377,
      "loss": 1.7266,
      "step": 1269
    },
    {
      "epoch": 1.68,
      "grad_norm": 764.0,
      "learning_rate": 0.00012486807387862797,
      "loss": 6.875,
      "step": 1270
    },
    {
      "epoch": 1.68,
      "grad_norm": 244.0,
      "learning_rate": 0.00012484828496042217,
      "loss": 1.6484,
      "step": 1271
    },
    {
      "epoch": 1.68,
      "grad_norm": 155.0,
      "learning_rate": 0.00012482849604221634,
      "loss": 0.957,
      "step": 1272
    },
    {
      "epoch": 1.68,
      "grad_norm": 528.0,
      "learning_rate": 0.00012480870712401054,
      "loss": 2.3906,
      "step": 1273
    },
    {
      "epoch": 1.68,
      "grad_norm": 332.0,
      "learning_rate": 0.00012478891820580474,
      "loss": 2.1719,
      "step": 1274
    },
    {
      "epoch": 1.68,
      "grad_norm": 326.0,
      "learning_rate": 0.00012476912928759893,
      "loss": 1.9531,
      "step": 1275
    },
    {
      "epoch": 1.68,
      "grad_norm": 88.0,
      "learning_rate": 0.00012474934036939313,
      "loss": 0.3945,
      "step": 1276
    },
    {
      "epoch": 1.68,
      "grad_norm": 94.5,
      "learning_rate": 0.00012472955145118733,
      "loss": 0.3125,
      "step": 1277
    },
    {
      "epoch": 1.69,
      "grad_norm": 53.75,
      "learning_rate": 0.00012470976253298153,
      "loss": 0.4941,
      "step": 1278
    },
    {
      "epoch": 1.69,
      "grad_norm": 352.0,
      "learning_rate": 0.0001246899736147757,
      "loss": 2.1094,
      "step": 1279
    },
    {
      "epoch": 1.69,
      "grad_norm": 716.0,
      "learning_rate": 0.0001246701846965699,
      "loss": 6.5625,
      "step": 1280
    },
    {
      "epoch": 1.69,
      "grad_norm": 820.0,
      "learning_rate": 0.0001246503957783641,
      "loss": 9.0625,
      "step": 1281
    },
    {
      "epoch": 1.69,
      "grad_norm": 69.0,
      "learning_rate": 0.0001246306068601583,
      "loss": 0.4473,
      "step": 1282
    },
    {
      "epoch": 1.69,
      "grad_norm": 560.0,
      "learning_rate": 0.0001246108179419525,
      "loss": 6.2188,
      "step": 1283
    },
    {
      "epoch": 1.69,
      "grad_norm": 330.0,
      "learning_rate": 0.0001245910290237467,
      "loss": 2.0938,
      "step": 1284
    },
    {
      "epoch": 1.7,
      "grad_norm": 672.0,
      "learning_rate": 0.0001245712401055409,
      "loss": 8.125,
      "step": 1285
    },
    {
      "epoch": 1.7,
      "grad_norm": 152.0,
      "learning_rate": 0.00012455145118733509,
      "loss": 1.1328,
      "step": 1286
    },
    {
      "epoch": 1.7,
      "grad_norm": 278.0,
      "learning_rate": 0.00012453166226912928,
      "loss": 1.4766,
      "step": 1287
    },
    {
      "epoch": 1.7,
      "grad_norm": 203.0,
      "learning_rate": 0.00012451187335092348,
      "loss": 1.3281,
      "step": 1288
    },
    {
      "epoch": 1.7,
      "grad_norm": 159.0,
      "learning_rate": 0.00012449208443271765,
      "loss": 0.8906,
      "step": 1289
    },
    {
      "epoch": 1.7,
      "grad_norm": 200.0,
      "learning_rate": 0.00012447229551451185,
      "loss": 1.1875,
      "step": 1290
    },
    {
      "epoch": 1.7,
      "grad_norm": 109.0,
      "learning_rate": 0.00012445250659630605,
      "loss": 1.1016,
      "step": 1291
    },
    {
      "epoch": 1.7,
      "grad_norm": 548.0,
      "learning_rate": 0.00012443271767810025,
      "loss": 3.1875,
      "step": 1292
    },
    {
      "epoch": 1.71,
      "grad_norm": 506.0,
      "learning_rate": 0.00012441292875989445,
      "loss": 3.0625,
      "step": 1293
    },
    {
      "epoch": 1.71,
      "grad_norm": 109.5,
      "learning_rate": 0.00012439313984168864,
      "loss": 0.832,
      "step": 1294
    },
    {
      "epoch": 1.71,
      "grad_norm": 81.0,
      "learning_rate": 0.00012437335092348284,
      "loss": 0.4727,
      "step": 1295
    },
    {
      "epoch": 1.71,
      "grad_norm": 137.0,
      "learning_rate": 0.00012435356200527704,
      "loss": 0.7461,
      "step": 1296
    },
    {
      "epoch": 1.71,
      "grad_norm": 156.0,
      "learning_rate": 0.00012433377308707124,
      "loss": 1.1094,
      "step": 1297
    },
    {
      "epoch": 1.71,
      "grad_norm": 390.0,
      "learning_rate": 0.00012431398416886544,
      "loss": 4.25,
      "step": 1298
    },
    {
      "epoch": 1.71,
      "grad_norm": 23.375,
      "learning_rate": 0.00012429419525065963,
      "loss": 0.2129,
      "step": 1299
    },
    {
      "epoch": 1.72,
      "grad_norm": 47.5,
      "learning_rate": 0.00012427440633245383,
      "loss": 0.1992,
      "step": 1300
    },
    {
      "epoch": 1.72,
      "grad_norm": 6.0,
      "learning_rate": 0.000124254617414248,
      "loss": 0.3535,
      "step": 1301
    },
    {
      "epoch": 1.72,
      "grad_norm": 360.0,
      "learning_rate": 0.0001242348284960422,
      "loss": 4.75,
      "step": 1302
    },
    {
      "epoch": 1.72,
      "grad_norm": 564.0,
      "learning_rate": 0.0001242150395778364,
      "loss": 7.0625,
      "step": 1303
    },
    {
      "epoch": 1.72,
      "grad_norm": 576.0,
      "learning_rate": 0.0001241952506596306,
      "loss": 7.2812,
      "step": 1304
    },
    {
      "epoch": 1.72,
      "grad_norm": 362.0,
      "learning_rate": 0.0001241754617414248,
      "loss": 4.9375,
      "step": 1305
    },
    {
      "epoch": 1.72,
      "grad_norm": 65.0,
      "learning_rate": 0.000124155672823219,
      "loss": 0.3203,
      "step": 1306
    },
    {
      "epoch": 1.72,
      "grad_norm": 716.0,
      "learning_rate": 0.0001241358839050132,
      "loss": 10.375,
      "step": 1307
    },
    {
      "epoch": 1.73,
      "grad_norm": 27.75,
      "learning_rate": 0.0001241160949868074,
      "loss": 0.2949,
      "step": 1308
    },
    {
      "epoch": 1.73,
      "grad_norm": 25.125,
      "learning_rate": 0.00012409630606860156,
      "loss": 0.2539,
      "step": 1309
    },
    {
      "epoch": 1.73,
      "grad_norm": 516.0,
      "learning_rate": 0.00012407651715039576,
      "loss": 5.7188,
      "step": 1310
    },
    {
      "epoch": 1.73,
      "grad_norm": 508.0,
      "learning_rate": 0.00012405672823218996,
      "loss": 4.8438,
      "step": 1311
    },
    {
      "epoch": 1.73,
      "grad_norm": 604.0,
      "learning_rate": 0.00012403693931398415,
      "loss": 6.25,
      "step": 1312
    },
    {
      "epoch": 1.73,
      "grad_norm": 47.0,
      "learning_rate": 0.00012401715039577835,
      "loss": 0.5078,
      "step": 1313
    },
    {
      "epoch": 1.73,
      "grad_norm": 362.0,
      "learning_rate": 0.00012399736147757255,
      "loss": 3.4219,
      "step": 1314
    },
    {
      "epoch": 1.73,
      "grad_norm": 270.0,
      "learning_rate": 0.00012397757255936675,
      "loss": 2.0469,
      "step": 1315
    },
    {
      "epoch": 1.74,
      "grad_norm": 74.5,
      "learning_rate": 0.00012395778364116095,
      "loss": 0.6758,
      "step": 1316
    },
    {
      "epoch": 1.74,
      "grad_norm": 93.5,
      "learning_rate": 0.00012393799472295512,
      "loss": 0.7109,
      "step": 1317
    },
    {
      "epoch": 1.74,
      "grad_norm": 223.0,
      "learning_rate": 0.00012391820580474932,
      "loss": 2.3125,
      "step": 1318
    },
    {
      "epoch": 1.74,
      "grad_norm": 85.5,
      "learning_rate": 0.00012389841688654351,
      "loss": 0.9336,
      "step": 1319
    },
    {
      "epoch": 1.74,
      "grad_norm": 79.5,
      "learning_rate": 0.0001238786279683377,
      "loss": 0.5703,
      "step": 1320
    },
    {
      "epoch": 1.74,
      "grad_norm": 194.0,
      "learning_rate": 0.0001238588390501319,
      "loss": 2.9688,
      "step": 1321
    },
    {
      "epoch": 1.74,
      "grad_norm": 120.5,
      "learning_rate": 0.0001238390501319261,
      "loss": 1.0312,
      "step": 1322
    },
    {
      "epoch": 1.75,
      "grad_norm": 62.5,
      "learning_rate": 0.0001238192612137203,
      "loss": 0.7305,
      "step": 1323
    },
    {
      "epoch": 1.75,
      "grad_norm": 268.0,
      "learning_rate": 0.0001237994722955145,
      "loss": 3.0312,
      "step": 1324
    },
    {
      "epoch": 1.75,
      "grad_norm": 75.5,
      "learning_rate": 0.0001237796833773087,
      "loss": 0.7656,
      "step": 1325
    },
    {
      "epoch": 1.75,
      "grad_norm": 116.0,
      "learning_rate": 0.0001237598944591029,
      "loss": 1.3281,
      "step": 1326
    },
    {
      "epoch": 1.75,
      "grad_norm": 36.0,
      "learning_rate": 0.0001237401055408971,
      "loss": 0.6719,
      "step": 1327
    },
    {
      "epoch": 1.75,
      "grad_norm": 242.0,
      "learning_rate": 0.0001237203166226913,
      "loss": 3.5938,
      "step": 1328
    },
    {
      "epoch": 1.75,
      "grad_norm": 33.0,
      "learning_rate": 0.00012370052770448547,
      "loss": 0.3691,
      "step": 1329
    },
    {
      "epoch": 1.75,
      "grad_norm": 54.5,
      "learning_rate": 0.00012368073878627967,
      "loss": 0.6836,
      "step": 1330
    },
    {
      "epoch": 1.76,
      "grad_norm": 75.5,
      "learning_rate": 0.00012366094986807386,
      "loss": 0.5938,
      "step": 1331
    },
    {
      "epoch": 1.76,
      "grad_norm": 240.0,
      "learning_rate": 0.00012364116094986806,
      "loss": 3.9062,
      "step": 1332
    },
    {
      "epoch": 1.76,
      "grad_norm": 132.0,
      "learning_rate": 0.00012362137203166226,
      "loss": 1.8438,
      "step": 1333
    },
    {
      "epoch": 1.76,
      "grad_norm": 21.5,
      "learning_rate": 0.00012360158311345646,
      "loss": 0.4141,
      "step": 1334
    },
    {
      "epoch": 1.76,
      "grad_norm": 57.5,
      "learning_rate": 0.00012358179419525066,
      "loss": 0.3789,
      "step": 1335
    },
    {
      "epoch": 1.76,
      "grad_norm": 59.75,
      "learning_rate": 0.00012356200527704485,
      "loss": 0.5859,
      "step": 1336
    },
    {
      "epoch": 1.76,
      "grad_norm": 17.125,
      "learning_rate": 0.00012354221635883905,
      "loss": 0.5,
      "step": 1337
    },
    {
      "epoch": 1.77,
      "grad_norm": 168.0,
      "learning_rate": 0.00012352242744063325,
      "loss": 2.4062,
      "step": 1338
    },
    {
      "epoch": 1.77,
      "grad_norm": 20.75,
      "learning_rate": 0.00012350263852242742,
      "loss": 0.2109,
      "step": 1339
    },
    {
      "epoch": 1.77,
      "grad_norm": 350.0,
      "learning_rate": 0.00012348284960422162,
      "loss": 6.4375,
      "step": 1340
    },
    {
      "epoch": 1.77,
      "grad_norm": 177.0,
      "learning_rate": 0.00012346306068601582,
      "loss": 2.6406,
      "step": 1341
    },
    {
      "epoch": 1.77,
      "grad_norm": 8.1875,
      "learning_rate": 0.00012344327176781002,
      "loss": 0.1973,
      "step": 1342
    },
    {
      "epoch": 1.77,
      "grad_norm": 35.25,
      "learning_rate": 0.0001234234828496042,
      "loss": 0.4531,
      "step": 1343
    },
    {
      "epoch": 1.77,
      "grad_norm": 50.25,
      "learning_rate": 0.0001234036939313984,
      "loss": 0.5781,
      "step": 1344
    },
    {
      "epoch": 1.77,
      "grad_norm": 31.125,
      "learning_rate": 0.0001233839050131926,
      "loss": 0.1816,
      "step": 1345
    },
    {
      "epoch": 1.78,
      "grad_norm": 177.0,
      "learning_rate": 0.00012336411609498678,
      "loss": 2.5625,
      "step": 1346
    },
    {
      "epoch": 1.78,
      "grad_norm": 366.0,
      "learning_rate": 0.00012334432717678098,
      "loss": 7.0,
      "step": 1347
    },
    {
      "epoch": 1.78,
      "grad_norm": 175.0,
      "learning_rate": 0.00012332453825857518,
      "loss": 2.3906,
      "step": 1348
    },
    {
      "epoch": 1.78,
      "grad_norm": 30.625,
      "learning_rate": 0.00012330474934036937,
      "loss": 0.1602,
      "step": 1349
    },
    {
      "epoch": 1.78,
      "grad_norm": 16.125,
      "learning_rate": 0.00012328496042216357,
      "loss": 0.2168,
      "step": 1350
    },
    {
      "epoch": 1.78,
      "grad_norm": 568.0,
      "learning_rate": 0.00012326517150395777,
      "loss": 7.5625,
      "step": 1351
    },
    {
      "epoch": 1.78,
      "grad_norm": 47.0,
      "learning_rate": 0.00012324538258575197,
      "loss": 0.543,
      "step": 1352
    },
    {
      "epoch": 1.78,
      "grad_norm": 51.0,
      "learning_rate": 0.00012322559366754617,
      "loss": 0.8633,
      "step": 1353
    },
    {
      "epoch": 1.79,
      "grad_norm": 36.75,
      "learning_rate": 0.00012320580474934036,
      "loss": 0.2012,
      "step": 1354
    },
    {
      "epoch": 1.79,
      "grad_norm": 55.5,
      "learning_rate": 0.00012318601583113456,
      "loss": 0.4668,
      "step": 1355
    },
    {
      "epoch": 1.79,
      "grad_norm": 356.0,
      "learning_rate": 0.00012316622691292876,
      "loss": 5.2812,
      "step": 1356
    },
    {
      "epoch": 1.79,
      "grad_norm": 170.0,
      "learning_rate": 0.00012314643799472296,
      "loss": 2.0312,
      "step": 1357
    },
    {
      "epoch": 1.79,
      "grad_norm": 42.0,
      "learning_rate": 0.00012312664907651713,
      "loss": 0.2168,
      "step": 1358
    },
    {
      "epoch": 1.79,
      "grad_norm": 46.75,
      "learning_rate": 0.00012310686015831133,
      "loss": 0.9922,
      "step": 1359
    },
    {
      "epoch": 1.79,
      "grad_norm": 166.0,
      "learning_rate": 0.00012308707124010553,
      "loss": 1.9062,
      "step": 1360
    },
    {
      "epoch": 1.8,
      "grad_norm": 362.0,
      "learning_rate": 0.00012306728232189972,
      "loss": 4.0312,
      "step": 1361
    },
    {
      "epoch": 1.8,
      "grad_norm": 44.5,
      "learning_rate": 0.00012304749340369392,
      "loss": 0.2412,
      "step": 1362
    },
    {
      "epoch": 1.8,
      "grad_norm": 36.25,
      "learning_rate": 0.00012302770448548812,
      "loss": 0.5742,
      "step": 1363
    },
    {
      "epoch": 1.8,
      "grad_norm": 35.5,
      "learning_rate": 0.00012300791556728232,
      "loss": 0.5742,
      "step": 1364
    },
    {
      "epoch": 1.8,
      "grad_norm": 149.0,
      "learning_rate": 0.00012298812664907652,
      "loss": 1.5781,
      "step": 1365
    },
    {
      "epoch": 1.8,
      "grad_norm": 258.0,
      "learning_rate": 0.00012296833773087071,
      "loss": 3.6875,
      "step": 1366
    },
    {
      "epoch": 1.8,
      "grad_norm": 89.0,
      "learning_rate": 0.0001229485488126649,
      "loss": 0.8711,
      "step": 1367
    },
    {
      "epoch": 1.8,
      "grad_norm": 41.5,
      "learning_rate": 0.0001229287598944591,
      "loss": 0.5078,
      "step": 1368
    },
    {
      "epoch": 1.81,
      "grad_norm": 72.5,
      "learning_rate": 0.00012290897097625328,
      "loss": 0.6562,
      "step": 1369
    },
    {
      "epoch": 1.81,
      "grad_norm": 26.125,
      "learning_rate": 0.00012288918205804748,
      "loss": 0.4316,
      "step": 1370
    },
    {
      "epoch": 1.81,
      "grad_norm": 318.0,
      "learning_rate": 0.00012286939313984168,
      "loss": 3.6094,
      "step": 1371
    },
    {
      "epoch": 1.81,
      "grad_norm": 314.0,
      "learning_rate": 0.00012284960422163588,
      "loss": 3.3281,
      "step": 1372
    },
    {
      "epoch": 1.81,
      "grad_norm": 264.0,
      "learning_rate": 0.00012282981530343007,
      "loss": 4.0625,
      "step": 1373
    },
    {
      "epoch": 1.81,
      "grad_norm": 342.0,
      "learning_rate": 0.00012281002638522427,
      "loss": 5.3438,
      "step": 1374
    },
    {
      "epoch": 1.81,
      "grad_norm": 180.0,
      "learning_rate": 0.00012279023746701844,
      "loss": 2.1094,
      "step": 1375
    },
    {
      "epoch": 1.82,
      "grad_norm": 29.125,
      "learning_rate": 0.00012277044854881264,
      "loss": 0.5781,
      "step": 1376
    },
    {
      "epoch": 1.82,
      "grad_norm": 282.0,
      "learning_rate": 0.00012275065963060684,
      "loss": 3.5938,
      "step": 1377
    },
    {
      "epoch": 1.82,
      "grad_norm": 34.25,
      "learning_rate": 0.00012273087071240104,
      "loss": 0.4414,
      "step": 1378
    },
    {
      "epoch": 1.82,
      "grad_norm": 294.0,
      "learning_rate": 0.00012271108179419523,
      "loss": 4.125,
      "step": 1379
    },
    {
      "epoch": 1.82,
      "grad_norm": 141.0,
      "learning_rate": 0.00012269129287598943,
      "loss": 1.6172,
      "step": 1380
    },
    {
      "epoch": 1.82,
      "grad_norm": 332.0,
      "learning_rate": 0.00012267150395778363,
      "loss": 4.25,
      "step": 1381
    },
    {
      "epoch": 1.82,
      "grad_norm": 143.0,
      "learning_rate": 0.00012265171503957783,
      "loss": 1.7578,
      "step": 1382
    },
    {
      "epoch": 1.82,
      "grad_norm": 73.5,
      "learning_rate": 0.00012263192612137203,
      "loss": 0.5742,
      "step": 1383
    },
    {
      "epoch": 1.83,
      "grad_norm": 69.5,
      "learning_rate": 0.00012261213720316623,
      "loss": 0.8086,
      "step": 1384
    },
    {
      "epoch": 1.83,
      "grad_norm": 70.0,
      "learning_rate": 0.00012259234828496042,
      "loss": 0.8086,
      "step": 1385
    },
    {
      "epoch": 1.83,
      "grad_norm": 310.0,
      "learning_rate": 0.00012257255936675462,
      "loss": 4.3438,
      "step": 1386
    },
    {
      "epoch": 1.83,
      "grad_norm": 57.25,
      "learning_rate": 0.0001225527704485488,
      "loss": 0.498,
      "step": 1387
    },
    {
      "epoch": 1.83,
      "grad_norm": 62.25,
      "learning_rate": 0.000122532981530343,
      "loss": 0.4746,
      "step": 1388
    },
    {
      "epoch": 1.83,
      "grad_norm": 235.0,
      "learning_rate": 0.0001225131926121372,
      "loss": 2.5625,
      "step": 1389
    },
    {
      "epoch": 1.83,
      "grad_norm": 112.0,
      "learning_rate": 0.00012249340369393139,
      "loss": 1.5703,
      "step": 1390
    },
    {
      "epoch": 1.84,
      "grad_norm": 87.0,
      "learning_rate": 0.00012247361477572558,
      "loss": 0.9883,
      "step": 1391
    },
    {
      "epoch": 1.84,
      "grad_norm": 74.5,
      "learning_rate": 0.00012245382585751978,
      "loss": 0.5039,
      "step": 1392
    },
    {
      "epoch": 1.84,
      "grad_norm": 46.5,
      "learning_rate": 0.00012243403693931398,
      "loss": 0.7656,
      "step": 1393
    },
    {
      "epoch": 1.84,
      "grad_norm": 160.0,
      "learning_rate": 0.00012241424802110818,
      "loss": 1.8516,
      "step": 1394
    },
    {
      "epoch": 1.84,
      "grad_norm": 227.0,
      "learning_rate": 0.00012239445910290238,
      "loss": 2.8906,
      "step": 1395
    },
    {
      "epoch": 1.84,
      "grad_norm": 59.75,
      "learning_rate": 0.00012237467018469657,
      "loss": 0.8203,
      "step": 1396
    },
    {
      "epoch": 1.84,
      "grad_norm": 39.5,
      "learning_rate": 0.00012235488126649077,
      "loss": 0.3203,
      "step": 1397
    },
    {
      "epoch": 1.84,
      "grad_norm": 136.0,
      "learning_rate": 0.00012233509234828497,
      "loss": 1.7969,
      "step": 1398
    },
    {
      "epoch": 1.85,
      "grad_norm": 24.125,
      "learning_rate": 0.00012231530343007914,
      "loss": 0.6406,
      "step": 1399
    },
    {
      "epoch": 1.85,
      "grad_norm": 35.25,
      "learning_rate": 0.00012229551451187334,
      "loss": 0.2734,
      "step": 1400
    },
    {
      "epoch": 1.85,
      "grad_norm": 227.0,
      "learning_rate": 0.00012227572559366754,
      "loss": 3.6875,
      "step": 1401
    },
    {
      "epoch": 1.85,
      "grad_norm": 230.0,
      "learning_rate": 0.00012225593667546174,
      "loss": 3.5625,
      "step": 1402
    },
    {
      "epoch": 1.85,
      "grad_norm": 18.625,
      "learning_rate": 0.0001222361477572559,
      "loss": 0.4219,
      "step": 1403
    },
    {
      "epoch": 1.85,
      "grad_norm": 56.5,
      "learning_rate": 0.0001222163588390501,
      "loss": 0.3496,
      "step": 1404
    },
    {
      "epoch": 1.85,
      "grad_norm": 280.0,
      "learning_rate": 0.0001221965699208443,
      "loss": 4.7812,
      "step": 1405
    },
    {
      "epoch": 1.85,
      "grad_norm": 16.875,
      "learning_rate": 0.0001221767810026385,
      "loss": 0.4238,
      "step": 1406
    },
    {
      "epoch": 1.86,
      "grad_norm": 46.25,
      "learning_rate": 0.0001221569920844327,
      "loss": 0.2578,
      "step": 1407
    },
    {
      "epoch": 1.86,
      "grad_norm": 11.5625,
      "learning_rate": 0.0001221372031662269,
      "loss": 0.3809,
      "step": 1408
    },
    {
      "epoch": 1.86,
      "grad_norm": 340.0,
      "learning_rate": 0.0001221174142480211,
      "loss": 6.375,
      "step": 1409
    },
    {
      "epoch": 1.86,
      "grad_norm": 180.0,
      "learning_rate": 0.0001220976253298153,
      "loss": 3.75,
      "step": 1410
    },
    {
      "epoch": 1.86,
      "grad_norm": 94.5,
      "learning_rate": 0.0001220778364116095,
      "loss": 0.9102,
      "step": 1411
    },
    {
      "epoch": 1.86,
      "grad_norm": 19.5,
      "learning_rate": 0.00012205804749340368,
      "loss": 0.4727,
      "step": 1412
    },
    {
      "epoch": 1.86,
      "grad_norm": 32.75,
      "learning_rate": 0.00012203825857519787,
      "loss": 0.4238,
      "step": 1413
    },
    {
      "epoch": 1.87,
      "grad_norm": 5.875,
      "learning_rate": 0.00012201846965699207,
      "loss": 0.1416,
      "step": 1414
    },
    {
      "epoch": 1.87,
      "grad_norm": 167.0,
      "learning_rate": 0.00012199868073878627,
      "loss": 3.5781,
      "step": 1415
    },
    {
      "epoch": 1.87,
      "grad_norm": 236.0,
      "learning_rate": 0.00012197889182058047,
      "loss": 4.375,
      "step": 1416
    },
    {
      "epoch": 1.87,
      "grad_norm": 49.75,
      "learning_rate": 0.00012195910290237467,
      "loss": 0.2852,
      "step": 1417
    },
    {
      "epoch": 1.87,
      "grad_norm": 150.0,
      "learning_rate": 0.00012193931398416885,
      "loss": 3.125,
      "step": 1418
    },
    {
      "epoch": 1.87,
      "grad_norm": 5.375,
      "learning_rate": 0.00012191952506596305,
      "loss": 0.332,
      "step": 1419
    },
    {
      "epoch": 1.87,
      "grad_norm": 150.0,
      "learning_rate": 0.00012189973614775725,
      "loss": 2.9062,
      "step": 1420
    },
    {
      "epoch": 1.87,
      "grad_norm": 226.0,
      "learning_rate": 0.00012187994722955144,
      "loss": 4.3125,
      "step": 1421
    },
    {
      "epoch": 1.88,
      "grad_norm": 454.0,
      "learning_rate": 0.00012186015831134564,
      "loss": 8.5625,
      "step": 1422
    },
    {
      "epoch": 1.88,
      "grad_norm": 47.75,
      "learning_rate": 0.00012184036939313984,
      "loss": 0.582,
      "step": 1423
    },
    {
      "epoch": 1.88,
      "grad_norm": 135.0,
      "learning_rate": 0.00012182058047493403,
      "loss": 2.2344,
      "step": 1424
    },
    {
      "epoch": 1.88,
      "grad_norm": 132.0,
      "learning_rate": 0.00012180079155672822,
      "loss": 1.7344,
      "step": 1425
    },
    {
      "epoch": 1.88,
      "grad_norm": 53.5,
      "learning_rate": 0.00012178100263852242,
      "loss": 0.6797,
      "step": 1426
    },
    {
      "epoch": 1.88,
      "grad_norm": 98.0,
      "learning_rate": 0.00012176121372031662,
      "loss": 1.5391,
      "step": 1427
    },
    {
      "epoch": 1.88,
      "grad_norm": 28.875,
      "learning_rate": 0.00012174142480211082,
      "loss": 0.5742,
      "step": 1428
    },
    {
      "epoch": 1.89,
      "grad_norm": 65.5,
      "learning_rate": 0.00012172163588390499,
      "loss": 0.5742,
      "step": 1429
    },
    {
      "epoch": 1.89,
      "grad_norm": 58.25,
      "learning_rate": 0.00012170184696569919,
      "loss": 0.8359,
      "step": 1430
    },
    {
      "epoch": 1.89,
      "grad_norm": 32.0,
      "learning_rate": 0.00012168205804749338,
      "loss": 1.1719,
      "step": 1431
    },
    {
      "epoch": 1.89,
      "grad_norm": 61.0,
      "learning_rate": 0.00012166226912928758,
      "loss": 0.8516,
      "step": 1432
    },
    {
      "epoch": 1.89,
      "grad_norm": 41.75,
      "learning_rate": 0.00012164248021108178,
      "loss": 1.0078,
      "step": 1433
    },
    {
      "epoch": 1.89,
      "grad_norm": 218.0,
      "learning_rate": 0.00012162269129287598,
      "loss": 3.9531,
      "step": 1434
    },
    {
      "epoch": 1.89,
      "grad_norm": 61.5,
      "learning_rate": 0.00012160290237467016,
      "loss": 0.8594,
      "step": 1435
    },
    {
      "epoch": 1.89,
      "grad_norm": 410.0,
      "learning_rate": 0.00012158311345646436,
      "loss": 6.7812,
      "step": 1436
    },
    {
      "epoch": 1.9,
      "grad_norm": 80.5,
      "learning_rate": 0.00012156332453825856,
      "loss": 0.9883,
      "step": 1437
    },
    {
      "epoch": 1.9,
      "grad_norm": 47.25,
      "learning_rate": 0.00012154353562005276,
      "loss": 0.6758,
      "step": 1438
    },
    {
      "epoch": 1.9,
      "grad_norm": 60.0,
      "learning_rate": 0.00012152374670184696,
      "loss": 0.4688,
      "step": 1439
    },
    {
      "epoch": 1.9,
      "grad_norm": 204.0,
      "learning_rate": 0.00012150395778364115,
      "loss": 2.9688,
      "step": 1440
    },
    {
      "epoch": 1.9,
      "grad_norm": 49.5,
      "learning_rate": 0.00012148416886543534,
      "loss": 0.3203,
      "step": 1441
    },
    {
      "epoch": 1.9,
      "grad_norm": 300.0,
      "learning_rate": 0.00012146437994722954,
      "loss": 4.6562,
      "step": 1442
    },
    {
      "epoch": 1.9,
      "grad_norm": 42.25,
      "learning_rate": 0.00012144459102902373,
      "loss": 0.2373,
      "step": 1443
    },
    {
      "epoch": 1.91,
      "grad_norm": 176.0,
      "learning_rate": 0.00012142480211081793,
      "loss": 2.875,
      "step": 1444
    },
    {
      "epoch": 1.91,
      "grad_norm": 516.0,
      "learning_rate": 0.00012140501319261213,
      "loss": 4.8125,
      "step": 1445
    },
    {
      "epoch": 1.91,
      "grad_norm": 207.0,
      "learning_rate": 0.00012138522427440633,
      "loss": 3.25,
      "step": 1446
    },
    {
      "epoch": 1.91,
      "grad_norm": 65.5,
      "learning_rate": 0.00012136543535620051,
      "loss": 0.6602,
      "step": 1447
    },
    {
      "epoch": 1.91,
      "grad_norm": 114.5,
      "learning_rate": 0.00012134564643799471,
      "loss": 1.1484,
      "step": 1448
    },
    {
      "epoch": 1.91,
      "grad_norm": 49.5,
      "learning_rate": 0.00012132585751978891,
      "loss": 0.2461,
      "step": 1449
    },
    {
      "epoch": 1.91,
      "grad_norm": 90.0,
      "learning_rate": 0.00012130606860158311,
      "loss": 0.8164,
      "step": 1450
    },
    {
      "epoch": 1.91,
      "grad_norm": 37.0,
      "learning_rate": 0.0001212862796833773,
      "loss": 0.2324,
      "step": 1451
    },
    {
      "epoch": 1.92,
      "grad_norm": 194.0,
      "learning_rate": 0.0001212664907651715,
      "loss": 2.9688,
      "step": 1452
    },
    {
      "epoch": 1.92,
      "grad_norm": 27.625,
      "learning_rate": 0.00012124670184696569,
      "loss": 0.418,
      "step": 1453
    },
    {
      "epoch": 1.92,
      "grad_norm": 109.0,
      "learning_rate": 0.00012122691292875989,
      "loss": 0.7266,
      "step": 1454
    },
    {
      "epoch": 1.92,
      "grad_norm": 182.0,
      "learning_rate": 0.00012120712401055408,
      "loss": 2.6875,
      "step": 1455
    },
    {
      "epoch": 1.92,
      "grad_norm": 39.0,
      "learning_rate": 0.00012118733509234828,
      "loss": 0.3945,
      "step": 1456
    },
    {
      "epoch": 1.92,
      "grad_norm": 286.0,
      "learning_rate": 0.00012116754617414248,
      "loss": 3.3281,
      "step": 1457
    },
    {
      "epoch": 1.92,
      "grad_norm": 59.75,
      "learning_rate": 0.00012114775725593668,
      "loss": 0.5352,
      "step": 1458
    },
    {
      "epoch": 1.92,
      "grad_norm": 39.0,
      "learning_rate": 0.00012112796833773085,
      "loss": 0.4062,
      "step": 1459
    },
    {
      "epoch": 1.93,
      "grad_norm": 324.0,
      "learning_rate": 0.00012110817941952505,
      "loss": 3.8438,
      "step": 1460
    },
    {
      "epoch": 1.93,
      "grad_norm": 22.25,
      "learning_rate": 0.00012108839050131925,
      "loss": 0.4727,
      "step": 1461
    },
    {
      "epoch": 1.93,
      "grad_norm": 222.0,
      "learning_rate": 0.00012106860158311344,
      "loss": 2.9531,
      "step": 1462
    },
    {
      "epoch": 1.93,
      "grad_norm": 592.0,
      "learning_rate": 0.00012104881266490764,
      "loss": 7.0938,
      "step": 1463
    },
    {
      "epoch": 1.93,
      "grad_norm": 286.0,
      "learning_rate": 0.00012102902374670183,
      "loss": 3.4219,
      "step": 1464
    },
    {
      "epoch": 1.93,
      "grad_norm": 177.0,
      "learning_rate": 0.00012100923482849602,
      "loss": 2.5625,
      "step": 1465
    },
    {
      "epoch": 1.93,
      "grad_norm": 14.125,
      "learning_rate": 0.00012098944591029022,
      "loss": 0.2432,
      "step": 1466
    },
    {
      "epoch": 1.94,
      "grad_norm": 253.0,
      "learning_rate": 0.00012096965699208442,
      "loss": 3.1719,
      "step": 1467
    },
    {
      "epoch": 1.94,
      "grad_norm": 260.0,
      "learning_rate": 0.00012094986807387862,
      "loss": 2.9844,
      "step": 1468
    },
    {
      "epoch": 1.94,
      "grad_norm": 173.0,
      "learning_rate": 0.00012093007915567282,
      "loss": 2.3438,
      "step": 1469
    },
    {
      "epoch": 1.94,
      "grad_norm": 164.0,
      "learning_rate": 0.000120910290237467,
      "loss": 2.1562,
      "step": 1470
    },
    {
      "epoch": 1.94,
      "grad_norm": 156.0,
      "learning_rate": 0.0001208905013192612,
      "loss": 2.0156,
      "step": 1471
    },
    {
      "epoch": 1.94,
      "grad_norm": 217.0,
      "learning_rate": 0.0001208707124010554,
      "loss": 1.9141,
      "step": 1472
    },
    {
      "epoch": 1.94,
      "grad_norm": 150.0,
      "learning_rate": 0.0001208509234828496,
      "loss": 1.4453,
      "step": 1473
    },
    {
      "epoch": 1.94,
      "grad_norm": 125.5,
      "learning_rate": 0.00012083113456464379,
      "loss": 1.5859,
      "step": 1474
    },
    {
      "epoch": 1.95,
      "grad_norm": 104.5,
      "learning_rate": 0.00012081134564643799,
      "loss": 1.2031,
      "step": 1475
    },
    {
      "epoch": 1.95,
      "grad_norm": 302.0,
      "learning_rate": 0.00012079155672823218,
      "loss": 2.7812,
      "step": 1476
    },
    {
      "epoch": 1.95,
      "grad_norm": 118.5,
      "learning_rate": 0.00012077176781002637,
      "loss": 1.2266,
      "step": 1477
    },
    {
      "epoch": 1.95,
      "grad_norm": 83.5,
      "learning_rate": 0.00012075197889182057,
      "loss": 1.3828,
      "step": 1478
    },
    {
      "epoch": 1.95,
      "grad_norm": 104.5,
      "learning_rate": 0.00012073218997361477,
      "loss": 2.1562,
      "step": 1479
    },
    {
      "epoch": 1.95,
      "grad_norm": 68.5,
      "learning_rate": 0.00012071240105540897,
      "loss": 1.3438,
      "step": 1480
    },
    {
      "epoch": 1.95,
      "grad_norm": 76.5,
      "learning_rate": 0.00012069261213720317,
      "loss": 1.1328,
      "step": 1481
    },
    {
      "epoch": 1.96,
      "grad_norm": 132.0,
      "learning_rate": 0.00012067282321899735,
      "loss": 1.2969,
      "step": 1482
    },
    {
      "epoch": 1.96,
      "grad_norm": 89.5,
      "learning_rate": 0.00012065303430079155,
      "loss": 0.9844,
      "step": 1483
    },
    {
      "epoch": 1.96,
      "grad_norm": 87.5,
      "learning_rate": 0.00012063324538258575,
      "loss": 1.0781,
      "step": 1484
    },
    {
      "epoch": 1.96,
      "grad_norm": 75.5,
      "learning_rate": 0.00012061345646437994,
      "loss": 0.9141,
      "step": 1485
    },
    {
      "epoch": 1.96,
      "grad_norm": 258.0,
      "learning_rate": 0.00012059366754617414,
      "loss": 4.5312,
      "step": 1486
    },
    {
      "epoch": 1.96,
      "grad_norm": 53.75,
      "learning_rate": 0.00012057387862796834,
      "loss": 0.6602,
      "step": 1487
    },
    {
      "epoch": 1.96,
      "grad_norm": 462.0,
      "learning_rate": 0.00012055408970976253,
      "loss": 7.0625,
      "step": 1488
    },
    {
      "epoch": 1.96,
      "grad_norm": 260.0,
      "learning_rate": 0.00012053430079155671,
      "loss": 4.9062,
      "step": 1489
    },
    {
      "epoch": 1.97,
      "grad_norm": 24.25,
      "learning_rate": 0.00012051451187335091,
      "loss": 0.2617,
      "step": 1490
    },
    {
      "epoch": 1.97,
      "grad_norm": 26.625,
      "learning_rate": 0.0001204947229551451,
      "loss": 0.4902,
      "step": 1491
    },
    {
      "epoch": 1.97,
      "grad_norm": 123.5,
      "learning_rate": 0.00012047493403693929,
      "loss": 2.2188,
      "step": 1492
    },
    {
      "epoch": 1.97,
      "grad_norm": 11.1875,
      "learning_rate": 0.00012045514511873349,
      "loss": 0.3594,
      "step": 1493
    },
    {
      "epoch": 1.97,
      "grad_norm": 19.75,
      "learning_rate": 0.00012043535620052769,
      "loss": 0.5586,
      "step": 1494
    },
    {
      "epoch": 1.97,
      "grad_norm": 125.5,
      "learning_rate": 0.00012041556728232188,
      "loss": 2.5625,
      "step": 1495
    },
    {
      "epoch": 1.97,
      "grad_norm": 131.0,
      "learning_rate": 0.00012039577836411608,
      "loss": 2.5312,
      "step": 1496
    },
    {
      "epoch": 1.97,
      "grad_norm": 121.0,
      "learning_rate": 0.00012037598944591028,
      "loss": 2.4062,
      "step": 1497
    },
    {
      "epoch": 1.98,
      "grad_norm": 120.0,
      "learning_rate": 0.00012035620052770447,
      "loss": 2.25,
      "step": 1498
    },
    {
      "epoch": 1.98,
      "grad_norm": 17.375,
      "learning_rate": 0.00012033641160949866,
      "loss": 0.5156,
      "step": 1499
    },
    {
      "epoch": 1.98,
      "grad_norm": 250.0,
      "learning_rate": 0.00012031662269129286,
      "loss": 5.5312,
      "step": 1500
    },
    {
      "epoch": 1.98,
      "grad_norm": 229.0,
      "learning_rate": 0.00012029683377308706,
      "loss": 2.8594,
      "step": 1501
    },
    {
      "epoch": 1.98,
      "grad_norm": 29.875,
      "learning_rate": 0.00012027704485488126,
      "loss": 0.2168,
      "step": 1502
    },
    {
      "epoch": 1.98,
      "grad_norm": 37.75,
      "learning_rate": 0.00012025725593667546,
      "loss": 0.6641,
      "step": 1503
    },
    {
      "epoch": 1.98,
      "grad_norm": 35.0,
      "learning_rate": 0.00012023746701846964,
      "loss": 0.668,
      "step": 1504
    },
    {
      "epoch": 1.99,
      "grad_norm": 57.75,
      "learning_rate": 0.00012021767810026384,
      "loss": 0.6328,
      "step": 1505
    },
    {
      "epoch": 1.99,
      "grad_norm": 34.25,
      "learning_rate": 0.00012019788918205804,
      "loss": 0.543,
      "step": 1506
    },
    {
      "epoch": 1.99,
      "grad_norm": 229.0,
      "learning_rate": 0.00012017810026385223,
      "loss": 5.3125,
      "step": 1507
    },
    {
      "epoch": 1.99,
      "grad_norm": 53.75,
      "learning_rate": 0.00012015831134564643,
      "loss": 0.5,
      "step": 1508
    },
    {
      "epoch": 1.99,
      "grad_norm": 244.0,
      "learning_rate": 0.00012013852242744063,
      "loss": 5.4062,
      "step": 1509
    },
    {
      "epoch": 1.99,
      "grad_norm": 44.25,
      "learning_rate": 0.00012011873350923481,
      "loss": 0.377,
      "step": 1510
    },
    {
      "epoch": 1.99,
      "grad_norm": 25.25,
      "learning_rate": 0.00012009894459102901,
      "loss": 0.2852,
      "step": 1511
    },
    {
      "epoch": 1.99,
      "grad_norm": 18.0,
      "learning_rate": 0.00012007915567282321,
      "loss": 0.2373,
      "step": 1512
    },
    {
      "epoch": 2.0,
      "grad_norm": 20.875,
      "learning_rate": 0.00012005936675461741,
      "loss": 0.4863,
      "step": 1513
    },
    {
      "epoch": 2.0,
      "grad_norm": 146.0,
      "learning_rate": 0.00012003957783641161,
      "loss": 2.0625,
      "step": 1514
    },
    {
      "epoch": 2.0,
      "grad_norm": 226.0,
      "learning_rate": 0.0001200197889182058,
      "loss": 5.875,
      "step": 1515
    },
    {
      "epoch": 2.0,
      "grad_norm": 94.5,
      "learning_rate": 0.00011999999999999999,
      "loss": 1.2578,
      "step": 1516
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.0686841011047363,
      "eval_runtime": 18.3197,
      "eval_samples_per_second": 42.686,
      "eval_steps_per_second": 10.699,
      "step": 1516
    },
    {
      "epoch": 2.0,
      "grad_norm": 358.0,
      "learning_rate": 0.00011998021108179419,
      "loss": 5.5938,
      "step": 1517
    },
    {
      "epoch": 2.0,
      "grad_norm": 5.1875,
      "learning_rate": 0.00011996042216358839,
      "loss": 0.208,
      "step": 1518
    },
    {
      "epoch": 2.0,
      "grad_norm": 28.125,
      "learning_rate": 0.00011994063324538258,
      "loss": 0.3867,
      "step": 1519
    },
    {
      "epoch": 2.01,
      "grad_norm": 5.71875,
      "learning_rate": 0.00011992084432717677,
      "loss": 0.0879,
      "step": 1520
    },
    {
      "epoch": 2.01,
      "grad_norm": 60.5,
      "learning_rate": 0.00011990105540897095,
      "loss": 0.5898,
      "step": 1521
    },
    {
      "epoch": 2.01,
      "grad_norm": 32.0,
      "learning_rate": 0.00011988126649076515,
      "loss": 0.4336,
      "step": 1522
    },
    {
      "epoch": 2.01,
      "grad_norm": 226.0,
      "learning_rate": 0.00011986147757255935,
      "loss": 4.0938,
      "step": 1523
    },
    {
      "epoch": 2.01,
      "grad_norm": 11.4375,
      "learning_rate": 0.00011984168865435355,
      "loss": 0.0913,
      "step": 1524
    },
    {
      "epoch": 2.01,
      "grad_norm": 6.3125,
      "learning_rate": 0.00011982189973614774,
      "loss": 0.0325,
      "step": 1525
    },
    {
      "epoch": 2.01,
      "grad_norm": 12.25,
      "learning_rate": 0.00011980211081794194,
      "loss": 0.0762,
      "step": 1526
    },
    {
      "epoch": 2.01,
      "grad_norm": 80.5,
      "learning_rate": 0.00011978232189973613,
      "loss": 1.4219,
      "step": 1527
    },
    {
      "epoch": 2.02,
      "grad_norm": 241.0,
      "learning_rate": 0.00011976253298153033,
      "loss": 5.875,
      "step": 1528
    },
    {
      "epoch": 2.02,
      "grad_norm": 3.734375,
      "learning_rate": 0.00011974274406332452,
      "loss": 0.0188,
      "step": 1529
    },
    {
      "epoch": 2.02,
      "grad_norm": 5.125,
      "learning_rate": 0.00011972295514511872,
      "loss": 0.0571,
      "step": 1530
    },
    {
      "epoch": 2.02,
      "grad_norm": 286.0,
      "learning_rate": 0.00011970316622691292,
      "loss": 6.0,
      "step": 1531
    },
    {
      "epoch": 2.02,
      "grad_norm": 40.25,
      "learning_rate": 0.00011968337730870712,
      "loss": 0.8516,
      "step": 1532
    },
    {
      "epoch": 2.02,
      "grad_norm": 36.75,
      "learning_rate": 0.0001196635883905013,
      "loss": 0.3555,
      "step": 1533
    },
    {
      "epoch": 2.02,
      "grad_norm": 41.75,
      "learning_rate": 0.0001196437994722955,
      "loss": 0.8438,
      "step": 1534
    },
    {
      "epoch": 2.03,
      "grad_norm": 334.0,
      "learning_rate": 0.0001196240105540897,
      "loss": 7.25,
      "step": 1535
    },
    {
      "epoch": 2.03,
      "grad_norm": 28.125,
      "learning_rate": 0.0001196042216358839,
      "loss": 0.8945,
      "step": 1536
    },
    {
      "epoch": 2.03,
      "grad_norm": 428.0,
      "learning_rate": 0.0001195844327176781,
      "loss": 8.9375,
      "step": 1537
    },
    {
      "epoch": 2.03,
      "grad_norm": 46.0,
      "learning_rate": 0.00011956464379947229,
      "loss": 0.582,
      "step": 1538
    },
    {
      "epoch": 2.03,
      "grad_norm": 26.875,
      "learning_rate": 0.00011954485488126648,
      "loss": 0.4512,
      "step": 1539
    },
    {
      "epoch": 2.03,
      "grad_norm": 14.0,
      "learning_rate": 0.00011952506596306068,
      "loss": 0.0898,
      "step": 1540
    },
    {
      "epoch": 2.03,
      "grad_norm": 51.25,
      "learning_rate": 0.00011950527704485487,
      "loss": 0.4824,
      "step": 1541
    },
    {
      "epoch": 2.03,
      "grad_norm": 38.0,
      "learning_rate": 0.00011948548812664907,
      "loss": 0.4102,
      "step": 1542
    },
    {
      "epoch": 2.04,
      "grad_norm": 346.0,
      "learning_rate": 0.00011946569920844327,
      "loss": 6.125,
      "step": 1543
    },
    {
      "epoch": 2.04,
      "grad_norm": 262.0,
      "learning_rate": 0.00011944591029023747,
      "loss": 3.5469,
      "step": 1544
    },
    {
      "epoch": 2.04,
      "grad_norm": 33.5,
      "learning_rate": 0.00011942612137203165,
      "loss": 0.418,
      "step": 1545
    },
    {
      "epoch": 2.04,
      "grad_norm": 342.0,
      "learning_rate": 0.00011940633245382585,
      "loss": 5.4688,
      "step": 1546
    },
    {
      "epoch": 2.04,
      "grad_norm": 32.75,
      "learning_rate": 0.00011938654353562005,
      "loss": 0.4727,
      "step": 1547
    },
    {
      "epoch": 2.04,
      "grad_norm": 568.0,
      "learning_rate": 0.00011936675461741425,
      "loss": 7.5,
      "step": 1548
    },
    {
      "epoch": 2.04,
      "grad_norm": 310.0,
      "learning_rate": 0.00011934696569920844,
      "loss": 4.3125,
      "step": 1549
    },
    {
      "epoch": 2.04,
      "grad_norm": 83.0,
      "learning_rate": 0.00011932717678100262,
      "loss": 0.625,
      "step": 1550
    },
    {
      "epoch": 2.05,
      "grad_norm": 72.5,
      "learning_rate": 0.00011930738786279681,
      "loss": 0.5352,
      "step": 1551
    },
    {
      "epoch": 2.05,
      "grad_norm": 146.0,
      "learning_rate": 0.00011928759894459101,
      "loss": 2.5781,
      "step": 1552
    },
    {
      "epoch": 2.05,
      "grad_norm": 38.0,
      "learning_rate": 0.00011926781002638521,
      "loss": 0.5625,
      "step": 1553
    },
    {
      "epoch": 2.05,
      "grad_norm": 45.5,
      "learning_rate": 0.00011924802110817941,
      "loss": 0.5781,
      "step": 1554
    },
    {
      "epoch": 2.05,
      "grad_norm": 33.5,
      "learning_rate": 0.0001192282321899736,
      "loss": 0.3438,
      "step": 1555
    },
    {
      "epoch": 2.05,
      "grad_norm": 157.0,
      "learning_rate": 0.00011920844327176779,
      "loss": 2.5469,
      "step": 1556
    },
    {
      "epoch": 2.05,
      "grad_norm": 21.875,
      "learning_rate": 0.00011918865435356199,
      "loss": 0.4062,
      "step": 1557
    },
    {
      "epoch": 2.06,
      "grad_norm": 53.75,
      "learning_rate": 0.00011916886543535619,
      "loss": 0.6641,
      "step": 1558
    },
    {
      "epoch": 2.06,
      "grad_norm": 14.6875,
      "learning_rate": 0.00011914907651715038,
      "loss": 0.2207,
      "step": 1559
    },
    {
      "epoch": 2.06,
      "grad_norm": 205.0,
      "learning_rate": 0.00011912928759894458,
      "loss": 2.6719,
      "step": 1560
    },
    {
      "epoch": 2.06,
      "grad_norm": 175.0,
      "learning_rate": 0.00011910949868073878,
      "loss": 2.4375,
      "step": 1561
    },
    {
      "epoch": 2.06,
      "grad_norm": 264.0,
      "learning_rate": 0.00011908970976253296,
      "loss": 4.3125,
      "step": 1562
    },
    {
      "epoch": 2.06,
      "grad_norm": 58.75,
      "learning_rate": 0.00011906992084432716,
      "loss": 0.6797,
      "step": 1563
    },
    {
      "epoch": 2.06,
      "grad_norm": 264.0,
      "learning_rate": 0.00011905013192612136,
      "loss": 4.5625,
      "step": 1564
    },
    {
      "epoch": 2.06,
      "grad_norm": 17.875,
      "learning_rate": 0.00011903034300791556,
      "loss": 0.4922,
      "step": 1565
    },
    {
      "epoch": 2.07,
      "grad_norm": 10.8125,
      "learning_rate": 0.00011901055408970976,
      "loss": 0.0835,
      "step": 1566
    },
    {
      "epoch": 2.07,
      "grad_norm": 56.5,
      "learning_rate": 0.00011899076517150395,
      "loss": 0.3301,
      "step": 1567
    },
    {
      "epoch": 2.07,
      "grad_norm": 46.25,
      "learning_rate": 0.00011897097625329814,
      "loss": 0.4883,
      "step": 1568
    },
    {
      "epoch": 2.07,
      "grad_norm": 42.75,
      "learning_rate": 0.00011895118733509234,
      "loss": 0.2236,
      "step": 1569
    },
    {
      "epoch": 2.07,
      "grad_norm": 162.0,
      "learning_rate": 0.00011893139841688654,
      "loss": 2.0156,
      "step": 1570
    },
    {
      "epoch": 2.07,
      "grad_norm": 199.0,
      "learning_rate": 0.00011891160949868073,
      "loss": 2.5625,
      "step": 1571
    },
    {
      "epoch": 2.07,
      "grad_norm": 12.8125,
      "learning_rate": 0.00011889182058047493,
      "loss": 0.5586,
      "step": 1572
    },
    {
      "epoch": 2.08,
      "grad_norm": 298.0,
      "learning_rate": 0.00011887203166226913,
      "loss": 5.1562,
      "step": 1573
    },
    {
      "epoch": 2.08,
      "grad_norm": 22.5,
      "learning_rate": 0.00011885224274406331,
      "loss": 0.4336,
      "step": 1574
    },
    {
      "epoch": 2.08,
      "grad_norm": 42.0,
      "learning_rate": 0.00011883245382585751,
      "loss": 0.4883,
      "step": 1575
    },
    {
      "epoch": 2.08,
      "grad_norm": 404.0,
      "learning_rate": 0.00011881266490765171,
      "loss": 7.25,
      "step": 1576
    },
    {
      "epoch": 2.08,
      "grad_norm": 157.0,
      "learning_rate": 0.00011879287598944591,
      "loss": 1.9375,
      "step": 1577
    },
    {
      "epoch": 2.08,
      "grad_norm": 69.5,
      "learning_rate": 0.0001187730870712401,
      "loss": 0.4531,
      "step": 1578
    },
    {
      "epoch": 2.08,
      "grad_norm": 14.25,
      "learning_rate": 0.0001187532981530343,
      "loss": 0.3535,
      "step": 1579
    },
    {
      "epoch": 2.08,
      "grad_norm": 143.0,
      "learning_rate": 0.00011873350923482848,
      "loss": 1.7969,
      "step": 1580
    },
    {
      "epoch": 2.09,
      "grad_norm": 36.5,
      "learning_rate": 0.00011871372031662267,
      "loss": 0.4922,
      "step": 1581
    },
    {
      "epoch": 2.09,
      "grad_norm": 294.0,
      "learning_rate": 0.00011869393139841687,
      "loss": 6.4688,
      "step": 1582
    },
    {
      "epoch": 2.09,
      "grad_norm": 18.0,
      "learning_rate": 0.00011867414248021107,
      "loss": 0.416,
      "step": 1583
    },
    {
      "epoch": 2.09,
      "grad_norm": 330.0,
      "learning_rate": 0.00011865435356200525,
      "loss": 5.9375,
      "step": 1584
    },
    {
      "epoch": 2.09,
      "grad_norm": 246.0,
      "learning_rate": 0.00011863456464379945,
      "loss": 4.0625,
      "step": 1585
    },
    {
      "epoch": 2.09,
      "grad_norm": 72.5,
      "learning_rate": 0.00011861477572559365,
      "loss": 0.5117,
      "step": 1586
    },
    {
      "epoch": 2.09,
      "grad_norm": 30.5,
      "learning_rate": 0.00011859498680738785,
      "loss": 0.2695,
      "step": 1587
    },
    {
      "epoch": 2.09,
      "grad_norm": 23.5,
      "learning_rate": 0.00011857519788918205,
      "loss": 0.4805,
      "step": 1588
    },
    {
      "epoch": 2.1,
      "grad_norm": 32.25,
      "learning_rate": 0.00011855540897097624,
      "loss": 0.3965,
      "step": 1589
    },
    {
      "epoch": 2.1,
      "grad_norm": 227.0,
      "learning_rate": 0.00011853562005277044,
      "loss": 3.1562,
      "step": 1590
    },
    {
      "epoch": 2.1,
      "grad_norm": 16.875,
      "learning_rate": 0.00011851583113456463,
      "loss": 0.4004,
      "step": 1591
    },
    {
      "epoch": 2.1,
      "grad_norm": 26.875,
      "learning_rate": 0.00011849604221635883,
      "loss": 0.5586,
      "step": 1592
    },
    {
      "epoch": 2.1,
      "grad_norm": 286.0,
      "learning_rate": 0.00011847625329815302,
      "loss": 5.0938,
      "step": 1593
    },
    {
      "epoch": 2.1,
      "grad_norm": 144.0,
      "learning_rate": 0.00011845646437994722,
      "loss": 2.3594,
      "step": 1594
    },
    {
      "epoch": 2.1,
      "grad_norm": 20.375,
      "learning_rate": 0.00011843667546174142,
      "loss": 0.3105,
      "step": 1595
    },
    {
      "epoch": 2.11,
      "grad_norm": 468.0,
      "learning_rate": 0.00011841688654353562,
      "loss": 5.875,
      "step": 1596
    },
    {
      "epoch": 2.11,
      "grad_norm": 157.0,
      "learning_rate": 0.0001183970976253298,
      "loss": 2.2812,
      "step": 1597
    },
    {
      "epoch": 2.11,
      "grad_norm": 13.625,
      "learning_rate": 0.000118377308707124,
      "loss": 0.1621,
      "step": 1598
    },
    {
      "epoch": 2.11,
      "grad_norm": 148.0,
      "learning_rate": 0.0001183575197889182,
      "loss": 2.2812,
      "step": 1599
    },
    {
      "epoch": 2.11,
      "grad_norm": 17.5,
      "learning_rate": 0.0001183377308707124,
      "loss": 0.4414,
      "step": 1600
    },
    {
      "epoch": 2.11,
      "grad_norm": 47.5,
      "learning_rate": 0.0001183179419525066,
      "loss": 0.6641,
      "step": 1601
    },
    {
      "epoch": 2.11,
      "grad_norm": 149.0,
      "learning_rate": 0.00011829815303430079,
      "loss": 2.4062,
      "step": 1602
    },
    {
      "epoch": 2.11,
      "grad_norm": 233.0,
      "learning_rate": 0.00011827836411609498,
      "loss": 3.25,
      "step": 1603
    },
    {
      "epoch": 2.12,
      "grad_norm": 39.0,
      "learning_rate": 0.00011825857519788917,
      "loss": 0.25,
      "step": 1604
    },
    {
      "epoch": 2.12,
      "grad_norm": 152.0,
      "learning_rate": 0.00011823878627968337,
      "loss": 2.1094,
      "step": 1605
    },
    {
      "epoch": 2.12,
      "grad_norm": 448.0,
      "learning_rate": 0.00011821899736147757,
      "loss": 5.6875,
      "step": 1606
    },
    {
      "epoch": 2.12,
      "grad_norm": 215.0,
      "learning_rate": 0.00011819920844327177,
      "loss": 2.9688,
      "step": 1607
    },
    {
      "epoch": 2.12,
      "grad_norm": 31.375,
      "learning_rate": 0.00011817941952506597,
      "loss": 0.5312,
      "step": 1608
    },
    {
      "epoch": 2.12,
      "grad_norm": 10.125,
      "learning_rate": 0.00011815963060686015,
      "loss": 0.0525,
      "step": 1609
    },
    {
      "epoch": 2.12,
      "grad_norm": 28.875,
      "learning_rate": 0.00011813984168865434,
      "loss": 0.2246,
      "step": 1610
    },
    {
      "epoch": 2.13,
      "grad_norm": 60.0,
      "learning_rate": 0.00011812005277044853,
      "loss": 0.4141,
      "step": 1611
    },
    {
      "epoch": 2.13,
      "grad_norm": 42.0,
      "learning_rate": 0.00011810026385224273,
      "loss": 0.2793,
      "step": 1612
    },
    {
      "epoch": 2.13,
      "grad_norm": 139.0,
      "learning_rate": 0.00011808047493403692,
      "loss": 2.9062,
      "step": 1613
    },
    {
      "epoch": 2.13,
      "grad_norm": 25.375,
      "learning_rate": 0.00011806068601583111,
      "loss": 0.4883,
      "step": 1614
    },
    {
      "epoch": 2.13,
      "grad_norm": 149.0,
      "learning_rate": 0.00011804089709762531,
      "loss": 2.0312,
      "step": 1615
    },
    {
      "epoch": 2.13,
      "grad_norm": 38.0,
      "learning_rate": 0.00011802110817941951,
      "loss": 0.2139,
      "step": 1616
    },
    {
      "epoch": 2.13,
      "grad_norm": 247.0,
      "learning_rate": 0.00011800131926121371,
      "loss": 3.1094,
      "step": 1617
    },
    {
      "epoch": 2.13,
      "grad_norm": 165.0,
      "learning_rate": 0.00011798153034300791,
      "loss": 2.0,
      "step": 1618
    },
    {
      "epoch": 2.14,
      "grad_norm": 62.5,
      "learning_rate": 0.00011796174142480209,
      "loss": 0.3203,
      "step": 1619
    },
    {
      "epoch": 2.14,
      "grad_norm": 36.0,
      "learning_rate": 0.00011794195250659629,
      "loss": 0.1953,
      "step": 1620
    },
    {
      "epoch": 2.14,
      "grad_norm": 326.0,
      "learning_rate": 0.00011792216358839049,
      "loss": 9.375,
      "step": 1621
    },
    {
      "epoch": 2.14,
      "grad_norm": 32.25,
      "learning_rate": 0.00011790237467018469,
      "loss": 0.5,
      "step": 1622
    },
    {
      "epoch": 2.14,
      "grad_norm": 336.0,
      "learning_rate": 0.00011788258575197888,
      "loss": 3.6562,
      "step": 1623
    },
    {
      "epoch": 2.14,
      "grad_norm": 144.0,
      "learning_rate": 0.00011786279683377308,
      "loss": 1.8906,
      "step": 1624
    },
    {
      "epoch": 2.14,
      "grad_norm": 67.0,
      "learning_rate": 0.00011784300791556727,
      "loss": 0.9297,
      "step": 1625
    },
    {
      "epoch": 2.15,
      "grad_norm": 141.0,
      "learning_rate": 0.00011782321899736146,
      "loss": 1.5,
      "step": 1626
    },
    {
      "epoch": 2.15,
      "grad_norm": 59.75,
      "learning_rate": 0.00011780343007915566,
      "loss": 0.9492,
      "step": 1627
    },
    {
      "epoch": 2.15,
      "grad_norm": 117.0,
      "learning_rate": 0.00011778364116094986,
      "loss": 1.2656,
      "step": 1628
    },
    {
      "epoch": 2.15,
      "grad_norm": 41.25,
      "learning_rate": 0.00011776385224274406,
      "loss": 0.2734,
      "step": 1629
    },
    {
      "epoch": 2.15,
      "grad_norm": 472.0,
      "learning_rate": 0.00011774406332453826,
      "loss": 6.5312,
      "step": 1630
    },
    {
      "epoch": 2.15,
      "grad_norm": 191.0,
      "learning_rate": 0.00011772427440633244,
      "loss": 1.7578,
      "step": 1631
    },
    {
      "epoch": 2.15,
      "grad_norm": 77.5,
      "learning_rate": 0.00011770448548812664,
      "loss": 0.8633,
      "step": 1632
    },
    {
      "epoch": 2.15,
      "grad_norm": 61.5,
      "learning_rate": 0.00011768469656992084,
      "loss": 0.5078,
      "step": 1633
    },
    {
      "epoch": 2.16,
      "grad_norm": 258.0,
      "learning_rate": 0.00011766490765171504,
      "loss": 3.7969,
      "step": 1634
    },
    {
      "epoch": 2.16,
      "grad_norm": 82.0,
      "learning_rate": 0.00011764511873350923,
      "loss": 1.0781,
      "step": 1635
    },
    {
      "epoch": 2.16,
      "grad_norm": 215.0,
      "learning_rate": 0.00011762532981530343,
      "loss": 4.3125,
      "step": 1636
    },
    {
      "epoch": 2.16,
      "grad_norm": 82.0,
      "learning_rate": 0.00011760554089709762,
      "loss": 1.0703,
      "step": 1637
    },
    {
      "epoch": 2.16,
      "grad_norm": 74.5,
      "learning_rate": 0.00011758575197889181,
      "loss": 0.8984,
      "step": 1638
    },
    {
      "epoch": 2.16,
      "grad_norm": 43.0,
      "learning_rate": 0.00011756596306068601,
      "loss": 0.4531,
      "step": 1639
    },
    {
      "epoch": 2.16,
      "grad_norm": 67.5,
      "learning_rate": 0.0001175461741424802,
      "loss": 1.1719,
      "step": 1640
    },
    {
      "epoch": 2.16,
      "grad_norm": 34.25,
      "learning_rate": 0.0001175263852242744,
      "loss": 0.459,
      "step": 1641
    },
    {
      "epoch": 2.17,
      "grad_norm": 35.25,
      "learning_rate": 0.00011750659630606858,
      "loss": 0.4551,
      "step": 1642
    },
    {
      "epoch": 2.17,
      "grad_norm": 214.0,
      "learning_rate": 0.00011748680738786278,
      "loss": 2.4688,
      "step": 1643
    },
    {
      "epoch": 2.17,
      "grad_norm": 104.0,
      "learning_rate": 0.00011746701846965698,
      "loss": 1.6172,
      "step": 1644
    },
    {
      "epoch": 2.17,
      "grad_norm": 48.75,
      "learning_rate": 0.00011744722955145117,
      "loss": 0.6758,
      "step": 1645
    },
    {
      "epoch": 2.17,
      "grad_norm": 56.75,
      "learning_rate": 0.00011742744063324537,
      "loss": 0.5234,
      "step": 1646
    },
    {
      "epoch": 2.17,
      "grad_norm": 47.25,
      "learning_rate": 0.00011740765171503957,
      "loss": 0.9023,
      "step": 1647
    },
    {
      "epoch": 2.17,
      "grad_norm": 15.625,
      "learning_rate": 0.00011738786279683375,
      "loss": 0.3047,
      "step": 1648
    },
    {
      "epoch": 2.18,
      "grad_norm": 25.5,
      "learning_rate": 0.00011736807387862795,
      "loss": 0.543,
      "step": 1649
    },
    {
      "epoch": 2.18,
      "grad_norm": 39.0,
      "learning_rate": 0.00011734828496042215,
      "loss": 0.2715,
      "step": 1650
    },
    {
      "epoch": 2.18,
      "grad_norm": 33.0,
      "learning_rate": 0.00011732849604221635,
      "loss": 0.2178,
      "step": 1651
    },
    {
      "epoch": 2.18,
      "grad_norm": 12.0625,
      "learning_rate": 0.00011730870712401055,
      "loss": 0.123,
      "step": 1652
    },
    {
      "epoch": 2.18,
      "grad_norm": 41.25,
      "learning_rate": 0.00011728891820580474,
      "loss": 0.4277,
      "step": 1653
    },
    {
      "epoch": 2.18,
      "grad_norm": 57.5,
      "learning_rate": 0.00011726912928759893,
      "loss": 0.7148,
      "step": 1654
    },
    {
      "epoch": 2.18,
      "grad_norm": 10.0,
      "learning_rate": 0.00011724934036939313,
      "loss": 0.0977,
      "step": 1655
    },
    {
      "epoch": 2.18,
      "grad_norm": 157.0,
      "learning_rate": 0.00011722955145118732,
      "loss": 3.6562,
      "step": 1656
    },
    {
      "epoch": 2.19,
      "grad_norm": 6.9375,
      "learning_rate": 0.00011720976253298152,
      "loss": 0.0615,
      "step": 1657
    },
    {
      "epoch": 2.19,
      "grad_norm": 280.0,
      "learning_rate": 0.00011718997361477572,
      "loss": 7.1562,
      "step": 1658
    },
    {
      "epoch": 2.19,
      "grad_norm": 4.9375,
      "learning_rate": 0.00011717018469656992,
      "loss": 0.0391,
      "step": 1659
    },
    {
      "epoch": 2.19,
      "grad_norm": 8.4375,
      "learning_rate": 0.0001171503957783641,
      "loss": 0.0718,
      "step": 1660
    },
    {
      "epoch": 2.19,
      "grad_norm": 272.0,
      "learning_rate": 0.0001171306068601583,
      "loss": 7.1562,
      "step": 1661
    },
    {
      "epoch": 2.19,
      "grad_norm": 52.25,
      "learning_rate": 0.0001171108179419525,
      "loss": 0.6133,
      "step": 1662
    },
    {
      "epoch": 2.19,
      "grad_norm": 228.0,
      "learning_rate": 0.0001170910290237467,
      "loss": 5.2188,
      "step": 1663
    },
    {
      "epoch": 2.2,
      "grad_norm": 55.75,
      "learning_rate": 0.0001170712401055409,
      "loss": 0.3125,
      "step": 1664
    },
    {
      "epoch": 2.2,
      "grad_norm": 177.0,
      "learning_rate": 0.0001170514511873351,
      "loss": 4.0625,
      "step": 1665
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.265625,
      "learning_rate": 0.00011703166226912928,
      "loss": 0.0156,
      "step": 1666
    },
    {
      "epoch": 2.2,
      "grad_norm": 4.03125,
      "learning_rate": 0.00011701187335092348,
      "loss": 0.0189,
      "step": 1667
    },
    {
      "epoch": 2.2,
      "grad_norm": 184.0,
      "learning_rate": 0.00011699208443271767,
      "loss": 3.9062,
      "step": 1668
    },
    {
      "epoch": 2.2,
      "grad_norm": 284.0,
      "learning_rate": 0.00011697229551451187,
      "loss": 7.0938,
      "step": 1669
    },
    {
      "epoch": 2.2,
      "grad_norm": 320.0,
      "learning_rate": 0.00011695250659630606,
      "loss": 7.4375,
      "step": 1670
    },
    {
      "epoch": 2.2,
      "grad_norm": 182.0,
      "learning_rate": 0.00011693271767810024,
      "loss": 3.8906,
      "step": 1671
    },
    {
      "epoch": 2.21,
      "grad_norm": 286.0,
      "learning_rate": 0.00011691292875989444,
      "loss": 5.0938,
      "step": 1672
    },
    {
      "epoch": 2.21,
      "grad_norm": 250.0,
      "learning_rate": 0.00011689313984168864,
      "loss": 3.9844,
      "step": 1673
    },
    {
      "epoch": 2.21,
      "grad_norm": 6.21875,
      "learning_rate": 0.00011687335092348284,
      "loss": 0.0295,
      "step": 1674
    },
    {
      "epoch": 2.21,
      "grad_norm": 11.875,
      "learning_rate": 0.00011685356200527703,
      "loss": 0.0547,
      "step": 1675
    },
    {
      "epoch": 2.21,
      "grad_norm": 37.75,
      "learning_rate": 0.00011683377308707123,
      "loss": 0.7305,
      "step": 1676
    },
    {
      "epoch": 2.21,
      "grad_norm": 26.75,
      "learning_rate": 0.00011681398416886542,
      "loss": 0.1777,
      "step": 1677
    },
    {
      "epoch": 2.21,
      "grad_norm": 40.75,
      "learning_rate": 0.00011679419525065961,
      "loss": 0.6016,
      "step": 1678
    },
    {
      "epoch": 2.22,
      "grad_norm": 205.0,
      "learning_rate": 0.00011677440633245381,
      "loss": 2.8125,
      "step": 1679
    },
    {
      "epoch": 2.22,
      "grad_norm": 235.0,
      "learning_rate": 0.00011675461741424801,
      "loss": 3.0469,
      "step": 1680
    },
    {
      "epoch": 2.22,
      "grad_norm": 16.75,
      "learning_rate": 0.00011673482849604221,
      "loss": 0.083,
      "step": 1681
    },
    {
      "epoch": 2.22,
      "grad_norm": 24.375,
      "learning_rate": 0.0001167150395778364,
      "loss": 0.8438,
      "step": 1682
    },
    {
      "epoch": 2.22,
      "grad_norm": 37.5,
      "learning_rate": 0.00011669525065963059,
      "loss": 0.6328,
      "step": 1683
    },
    {
      "epoch": 2.22,
      "grad_norm": 628.0,
      "learning_rate": 0.00011667546174142479,
      "loss": 8.9375,
      "step": 1684
    },
    {
      "epoch": 2.22,
      "grad_norm": 404.0,
      "learning_rate": 0.00011665567282321899,
      "loss": 6.0312,
      "step": 1685
    },
    {
      "epoch": 2.22,
      "grad_norm": 14.8125,
      "learning_rate": 0.00011663588390501319,
      "loss": 0.2471,
      "step": 1686
    },
    {
      "epoch": 2.23,
      "grad_norm": 338.0,
      "learning_rate": 0.00011661609498680738,
      "loss": 3.1094,
      "step": 1687
    },
    {
      "epoch": 2.23,
      "grad_norm": 69.5,
      "learning_rate": 0.00011659630606860158,
      "loss": 0.8867,
      "step": 1688
    },
    {
      "epoch": 2.23,
      "grad_norm": 286.0,
      "learning_rate": 0.00011657651715039577,
      "loss": 2.6406,
      "step": 1689
    },
    {
      "epoch": 2.23,
      "grad_norm": 302.0,
      "learning_rate": 0.00011655672823218996,
      "loss": 4.6562,
      "step": 1690
    },
    {
      "epoch": 2.23,
      "grad_norm": 123.5,
      "learning_rate": 0.00011653693931398416,
      "loss": 1.6172,
      "step": 1691
    },
    {
      "epoch": 2.23,
      "grad_norm": 55.5,
      "learning_rate": 0.00011651715039577836,
      "loss": 0.6406,
      "step": 1692
    },
    {
      "epoch": 2.23,
      "grad_norm": 61.75,
      "learning_rate": 0.00011649736147757256,
      "loss": 0.4844,
      "step": 1693
    },
    {
      "epoch": 2.23,
      "grad_norm": 40.75,
      "learning_rate": 0.00011647757255936676,
      "loss": 0.416,
      "step": 1694
    },
    {
      "epoch": 2.24,
      "grad_norm": 252.0,
      "learning_rate": 0.00011645778364116094,
      "loss": 3.0,
      "step": 1695
    },
    {
      "epoch": 2.24,
      "grad_norm": 88.0,
      "learning_rate": 0.00011643799472295514,
      "loss": 1.4062,
      "step": 1696
    },
    {
      "epoch": 2.24,
      "grad_norm": 492.0,
      "learning_rate": 0.00011641820580474934,
      "loss": 6.4062,
      "step": 1697
    },
    {
      "epoch": 2.24,
      "grad_norm": 85.5,
      "learning_rate": 0.00011639841688654353,
      "loss": 1.4062,
      "step": 1698
    },
    {
      "epoch": 2.24,
      "grad_norm": 66.5,
      "learning_rate": 0.00011637862796833773,
      "loss": 0.7617,
      "step": 1699
    },
    {
      "epoch": 2.24,
      "grad_norm": 92.0,
      "learning_rate": 0.0001163588390501319,
      "loss": 0.6992,
      "step": 1700
    },
    {
      "epoch": 2.24,
      "grad_norm": 44.0,
      "learning_rate": 0.0001163390501319261,
      "loss": 0.4023,
      "step": 1701
    },
    {
      "epoch": 2.25,
      "grad_norm": 89.5,
      "learning_rate": 0.0001163192612137203,
      "loss": 0.668,
      "step": 1702
    },
    {
      "epoch": 2.25,
      "grad_norm": 42.5,
      "learning_rate": 0.0001162994722955145,
      "loss": 0.5469,
      "step": 1703
    },
    {
      "epoch": 2.25,
      "grad_norm": 231.0,
      "learning_rate": 0.0001162796833773087,
      "loss": 2.8438,
      "step": 1704
    },
    {
      "epoch": 2.25,
      "grad_norm": 54.0,
      "learning_rate": 0.00011625989445910288,
      "loss": 0.4062,
      "step": 1705
    },
    {
      "epoch": 2.25,
      "grad_norm": 31.125,
      "learning_rate": 0.00011624010554089708,
      "loss": 0.5039,
      "step": 1706
    },
    {
      "epoch": 2.25,
      "grad_norm": 26.5,
      "learning_rate": 0.00011622031662269128,
      "loss": 0.2773,
      "step": 1707
    },
    {
      "epoch": 2.25,
      "grad_norm": 150.0,
      "learning_rate": 0.00011620052770448547,
      "loss": 2.0938,
      "step": 1708
    },
    {
      "epoch": 2.25,
      "grad_norm": 338.0,
      "learning_rate": 0.00011618073878627967,
      "loss": 4.3438,
      "step": 1709
    },
    {
      "epoch": 2.26,
      "grad_norm": 57.0,
      "learning_rate": 0.00011616094986807387,
      "loss": 0.6797,
      "step": 1710
    },
    {
      "epoch": 2.26,
      "grad_norm": 12.0,
      "learning_rate": 0.00011614116094986806,
      "loss": 0.1504,
      "step": 1711
    },
    {
      "epoch": 2.26,
      "grad_norm": 45.25,
      "learning_rate": 0.00011612137203166225,
      "loss": 0.4766,
      "step": 1712
    },
    {
      "epoch": 2.26,
      "grad_norm": 504.0,
      "learning_rate": 0.00011610158311345645,
      "loss": 8.5,
      "step": 1713
    },
    {
      "epoch": 2.26,
      "grad_norm": 366.0,
      "learning_rate": 0.00011608179419525065,
      "loss": 6.2188,
      "step": 1714
    },
    {
      "epoch": 2.26,
      "grad_norm": 13.8125,
      "learning_rate": 0.00011606200527704485,
      "loss": 0.1602,
      "step": 1715
    },
    {
      "epoch": 2.26,
      "grad_norm": 57.5,
      "learning_rate": 0.00011604221635883905,
      "loss": 0.7148,
      "step": 1716
    },
    {
      "epoch": 2.27,
      "grad_norm": 29.75,
      "learning_rate": 0.00011602242744063323,
      "loss": 0.3477,
      "step": 1717
    },
    {
      "epoch": 2.27,
      "grad_norm": 152.0,
      "learning_rate": 0.00011600263852242743,
      "loss": 2.9688,
      "step": 1718
    },
    {
      "epoch": 2.27,
      "grad_norm": 24.25,
      "learning_rate": 0.00011598284960422163,
      "loss": 0.1514,
      "step": 1719
    },
    {
      "epoch": 2.27,
      "grad_norm": 29.875,
      "learning_rate": 0.00011596306068601582,
      "loss": 0.2734,
      "step": 1720
    },
    {
      "epoch": 2.27,
      "grad_norm": 26.0,
      "learning_rate": 0.00011594327176781002,
      "loss": 0.1855,
      "step": 1721
    },
    {
      "epoch": 2.27,
      "grad_norm": 22.0,
      "learning_rate": 0.00011592348284960422,
      "loss": 0.1514,
      "step": 1722
    },
    {
      "epoch": 2.27,
      "grad_norm": 35.75,
      "learning_rate": 0.0001159036939313984,
      "loss": 0.2324,
      "step": 1723
    },
    {
      "epoch": 2.27,
      "grad_norm": 245.0,
      "learning_rate": 0.0001158839050131926,
      "loss": 3.9375,
      "step": 1724
    },
    {
      "epoch": 2.28,
      "grad_norm": 252.0,
      "learning_rate": 0.0001158641160949868,
      "loss": 7.0625,
      "step": 1725
    },
    {
      "epoch": 2.28,
      "grad_norm": 53.75,
      "learning_rate": 0.000115844327176781,
      "loss": 0.5352,
      "step": 1726
    },
    {
      "epoch": 2.28,
      "grad_norm": 27.375,
      "learning_rate": 0.0001158245382585752,
      "loss": 0.4062,
      "step": 1727
    },
    {
      "epoch": 2.28,
      "grad_norm": 172.0,
      "learning_rate": 0.0001158047493403694,
      "loss": 2.7344,
      "step": 1728
    },
    {
      "epoch": 2.28,
      "grad_norm": 320.0,
      "learning_rate": 0.00011578496042216358,
      "loss": 4.6875,
      "step": 1729
    },
    {
      "epoch": 2.28,
      "grad_norm": 156.0,
      "learning_rate": 0.00011576517150395776,
      "loss": 2.4219,
      "step": 1730
    },
    {
      "epoch": 2.28,
      "grad_norm": 18.375,
      "learning_rate": 0.00011574538258575196,
      "loss": 0.4121,
      "step": 1731
    },
    {
      "epoch": 2.28,
      "grad_norm": 137.0,
      "learning_rate": 0.00011572559366754616,
      "loss": 1.9141,
      "step": 1732
    },
    {
      "epoch": 2.29,
      "grad_norm": 132.0,
      "learning_rate": 0.00011570580474934036,
      "loss": 1.7578,
      "step": 1733
    },
    {
      "epoch": 2.29,
      "grad_norm": 23.75,
      "learning_rate": 0.00011568601583113454,
      "loss": 0.3438,
      "step": 1734
    },
    {
      "epoch": 2.29,
      "grad_norm": 29.0,
      "learning_rate": 0.00011566622691292874,
      "loss": 0.25,
      "step": 1735
    },
    {
      "epoch": 2.29,
      "grad_norm": 51.0,
      "learning_rate": 0.00011564643799472294,
      "loss": 0.4082,
      "step": 1736
    },
    {
      "epoch": 2.29,
      "grad_norm": 244.0,
      "learning_rate": 0.00011562664907651714,
      "loss": 5.6562,
      "step": 1737
    },
    {
      "epoch": 2.29,
      "grad_norm": 220.0,
      "learning_rate": 0.00011560686015831134,
      "loss": 3.375,
      "step": 1738
    },
    {
      "epoch": 2.29,
      "grad_norm": 56.75,
      "learning_rate": 0.00011558707124010553,
      "loss": 0.5117,
      "step": 1739
    },
    {
      "epoch": 2.3,
      "grad_norm": 36.25,
      "learning_rate": 0.00011556728232189972,
      "loss": 0.5625,
      "step": 1740
    },
    {
      "epoch": 2.3,
      "grad_norm": 35.75,
      "learning_rate": 0.00011554749340369392,
      "loss": 0.3418,
      "step": 1741
    },
    {
      "epoch": 2.3,
      "grad_norm": 209.0,
      "learning_rate": 0.00011552770448548811,
      "loss": 2.8281,
      "step": 1742
    },
    {
      "epoch": 2.3,
      "grad_norm": 52.75,
      "learning_rate": 0.00011550791556728231,
      "loss": 0.459,
      "step": 1743
    },
    {
      "epoch": 2.3,
      "grad_norm": 31.125,
      "learning_rate": 0.00011548812664907651,
      "loss": 0.5078,
      "step": 1744
    },
    {
      "epoch": 2.3,
      "grad_norm": 32.75,
      "learning_rate": 0.00011546833773087071,
      "loss": 0.5547,
      "step": 1745
    },
    {
      "epoch": 2.3,
      "grad_norm": 128.0,
      "learning_rate": 0.00011544854881266489,
      "loss": 1.7578,
      "step": 1746
    },
    {
      "epoch": 2.3,
      "grad_norm": 134.0,
      "learning_rate": 0.00011542875989445909,
      "loss": 2.1094,
      "step": 1747
    },
    {
      "epoch": 2.31,
      "grad_norm": 229.0,
      "learning_rate": 0.00011540897097625329,
      "loss": 3.2188,
      "step": 1748
    },
    {
      "epoch": 2.31,
      "grad_norm": 40.75,
      "learning_rate": 0.00011538918205804749,
      "loss": 0.2559,
      "step": 1749
    },
    {
      "epoch": 2.31,
      "grad_norm": 17.75,
      "learning_rate": 0.00011536939313984168,
      "loss": 0.6953,
      "step": 1750
    },
    {
      "epoch": 2.31,
      "grad_norm": 25.125,
      "learning_rate": 0.00011534960422163588,
      "loss": 0.4199,
      "step": 1751
    },
    {
      "epoch": 2.31,
      "grad_norm": 16.875,
      "learning_rate": 0.00011532981530343007,
      "loss": 0.1426,
      "step": 1752
    },
    {
      "epoch": 2.31,
      "grad_norm": 26.5,
      "learning_rate": 0.00011531002638522427,
      "loss": 0.4395,
      "step": 1753
    },
    {
      "epoch": 2.31,
      "grad_norm": 17.625,
      "learning_rate": 0.00011529023746701846,
      "loss": 0.124,
      "step": 1754
    },
    {
      "epoch": 2.32,
      "grad_norm": 170.0,
      "learning_rate": 0.00011527044854881266,
      "loss": 2.7812,
      "step": 1755
    },
    {
      "epoch": 2.32,
      "grad_norm": 8.5625,
      "learning_rate": 0.00011525065963060686,
      "loss": 0.1309,
      "step": 1756
    },
    {
      "epoch": 2.32,
      "grad_norm": 65.5,
      "learning_rate": 0.00011523087071240106,
      "loss": 0.8398,
      "step": 1757
    },
    {
      "epoch": 2.32,
      "grad_norm": 200.0,
      "learning_rate": 0.00011521108179419524,
      "loss": 3.1562,
      "step": 1758
    },
    {
      "epoch": 2.32,
      "grad_norm": 9.3125,
      "learning_rate": 0.00011519129287598944,
      "loss": 0.1025,
      "step": 1759
    },
    {
      "epoch": 2.32,
      "grad_norm": 23.375,
      "learning_rate": 0.00011517150395778362,
      "loss": 0.1187,
      "step": 1760
    },
    {
      "epoch": 2.32,
      "grad_norm": 62.25,
      "learning_rate": 0.00011515171503957782,
      "loss": 0.7227,
      "step": 1761
    },
    {
      "epoch": 2.32,
      "grad_norm": 262.0,
      "learning_rate": 0.00011513192612137202,
      "loss": 5.3125,
      "step": 1762
    },
    {
      "epoch": 2.33,
      "grad_norm": 6.4375,
      "learning_rate": 0.0001151121372031662,
      "loss": 0.0605,
      "step": 1763
    },
    {
      "epoch": 2.33,
      "grad_norm": 18.625,
      "learning_rate": 0.0001150923482849604,
      "loss": 0.0923,
      "step": 1764
    },
    {
      "epoch": 2.33,
      "grad_norm": 26.0,
      "learning_rate": 0.0001150725593667546,
      "loss": 0.4414,
      "step": 1765
    },
    {
      "epoch": 2.33,
      "grad_norm": 166.0,
      "learning_rate": 0.0001150527704485488,
      "loss": 2.875,
      "step": 1766
    },
    {
      "epoch": 2.33,
      "grad_norm": 181.0,
      "learning_rate": 0.000115032981530343,
      "loss": 3.1719,
      "step": 1767
    },
    {
      "epoch": 2.33,
      "grad_norm": 22.75,
      "learning_rate": 0.0001150131926121372,
      "loss": 0.3965,
      "step": 1768
    },
    {
      "epoch": 2.33,
      "grad_norm": 258.0,
      "learning_rate": 0.00011499340369393138,
      "loss": 5.375,
      "step": 1769
    },
    {
      "epoch": 2.34,
      "grad_norm": 15.875,
      "learning_rate": 0.00011497361477572558,
      "loss": 0.4922,
      "step": 1770
    },
    {
      "epoch": 2.34,
      "grad_norm": 166.0,
      "learning_rate": 0.00011495382585751978,
      "loss": 2.7188,
      "step": 1771
    },
    {
      "epoch": 2.34,
      "grad_norm": 6.71875,
      "learning_rate": 0.00011493403693931397,
      "loss": 0.373,
      "step": 1772
    },
    {
      "epoch": 2.34,
      "grad_norm": 47.0,
      "learning_rate": 0.00011491424802110817,
      "loss": 0.2637,
      "step": 1773
    },
    {
      "epoch": 2.34,
      "grad_norm": 6.6875,
      "learning_rate": 0.00011489445910290237,
      "loss": 0.3203,
      "step": 1774
    },
    {
      "epoch": 2.34,
      "grad_norm": 24.25,
      "learning_rate": 0.00011487467018469656,
      "loss": 0.1602,
      "step": 1775
    },
    {
      "epoch": 2.34,
      "grad_norm": 256.0,
      "learning_rate": 0.00011485488126649075,
      "loss": 5.0,
      "step": 1776
    },
    {
      "epoch": 2.34,
      "grad_norm": 29.75,
      "learning_rate": 0.00011483509234828495,
      "loss": 0.4453,
      "step": 1777
    },
    {
      "epoch": 2.35,
      "grad_norm": 306.0,
      "learning_rate": 0.00011481530343007915,
      "loss": 4.4688,
      "step": 1778
    },
    {
      "epoch": 2.35,
      "grad_norm": 246.0,
      "learning_rate": 0.00011479551451187335,
      "loss": 5.0312,
      "step": 1779
    },
    {
      "epoch": 2.35,
      "grad_norm": 27.5,
      "learning_rate": 0.00011477572559366755,
      "loss": 0.1699,
      "step": 1780
    },
    {
      "epoch": 2.35,
      "grad_norm": 59.0,
      "learning_rate": 0.00011475593667546173,
      "loss": 0.3555,
      "step": 1781
    },
    {
      "epoch": 2.35,
      "grad_norm": 146.0,
      "learning_rate": 0.00011473614775725593,
      "loss": 2.5781,
      "step": 1782
    },
    {
      "epoch": 2.35,
      "grad_norm": 9.9375,
      "learning_rate": 0.00011471635883905013,
      "loss": 0.4531,
      "step": 1783
    },
    {
      "epoch": 2.35,
      "grad_norm": 26.375,
      "learning_rate": 0.00011469656992084432,
      "loss": 0.3652,
      "step": 1784
    },
    {
      "epoch": 2.35,
      "grad_norm": 75.5,
      "learning_rate": 0.00011467678100263852,
      "loss": 0.5234,
      "step": 1785
    },
    {
      "epoch": 2.36,
      "grad_norm": 237.0,
      "learning_rate": 0.00011465699208443272,
      "loss": 4.1875,
      "step": 1786
    },
    {
      "epoch": 2.36,
      "grad_norm": 241.0,
      "learning_rate": 0.0001146372031662269,
      "loss": 4.0312,
      "step": 1787
    },
    {
      "epoch": 2.36,
      "grad_norm": 12.4375,
      "learning_rate": 0.0001146174142480211,
      "loss": 0.4609,
      "step": 1788
    },
    {
      "epoch": 2.36,
      "grad_norm": 18.25,
      "learning_rate": 0.0001145976253298153,
      "loss": 0.3574,
      "step": 1789
    },
    {
      "epoch": 2.36,
      "grad_norm": 194.0,
      "learning_rate": 0.00011457783641160949,
      "loss": 6.4375,
      "step": 1790
    },
    {
      "epoch": 2.36,
      "grad_norm": 304.0,
      "learning_rate": 0.00011455804749340367,
      "loss": 5.625,
      "step": 1791
    },
    {
      "epoch": 2.36,
      "grad_norm": 36.0,
      "learning_rate": 0.00011453825857519787,
      "loss": 0.2695,
      "step": 1792
    },
    {
      "epoch": 2.37,
      "grad_norm": 20.75,
      "learning_rate": 0.00011451846965699207,
      "loss": 0.4023,
      "step": 1793
    },
    {
      "epoch": 2.37,
      "grad_norm": 27.625,
      "learning_rate": 0.00011449868073878626,
      "loss": 0.3906,
      "step": 1794
    },
    {
      "epoch": 2.37,
      "grad_norm": 59.75,
      "learning_rate": 0.00011447889182058046,
      "loss": 0.3984,
      "step": 1795
    },
    {
      "epoch": 2.37,
      "grad_norm": 139.0,
      "learning_rate": 0.00011445910290237466,
      "loss": 2.3906,
      "step": 1796
    },
    {
      "epoch": 2.37,
      "grad_norm": 145.0,
      "learning_rate": 0.00011443931398416884,
      "loss": 2.4062,
      "step": 1797
    },
    {
      "epoch": 2.37,
      "grad_norm": 25.375,
      "learning_rate": 0.00011441952506596304,
      "loss": 0.3223,
      "step": 1798
    },
    {
      "epoch": 2.37,
      "grad_norm": 14.1875,
      "learning_rate": 0.00011439973614775724,
      "loss": 0.3477,
      "step": 1799
    },
    {
      "epoch": 2.37,
      "grad_norm": 142.0,
      "learning_rate": 0.00011437994722955144,
      "loss": 2.0781,
      "step": 1800
    },
    {
      "epoch": 2.38,
      "grad_norm": 33.5,
      "learning_rate": 0.00011436015831134564,
      "loss": 0.2197,
      "step": 1801
    },
    {
      "epoch": 2.38,
      "grad_norm": 256.0,
      "learning_rate": 0.00011434036939313983,
      "loss": 5.2188,
      "step": 1802
    },
    {
      "epoch": 2.38,
      "grad_norm": 32.25,
      "learning_rate": 0.00011432058047493402,
      "loss": 0.21,
      "step": 1803
    },
    {
      "epoch": 2.38,
      "grad_norm": 29.375,
      "learning_rate": 0.00011430079155672822,
      "loss": 0.1973,
      "step": 1804
    },
    {
      "epoch": 2.38,
      "grad_norm": 146.0,
      "learning_rate": 0.00011428100263852242,
      "loss": 2.2812,
      "step": 1805
    },
    {
      "epoch": 2.38,
      "grad_norm": 237.0,
      "learning_rate": 0.00011426121372031661,
      "loss": 3.5156,
      "step": 1806
    },
    {
      "epoch": 2.38,
      "grad_norm": 258.0,
      "learning_rate": 0.00011424142480211081,
      "loss": 3.6719,
      "step": 1807
    },
    {
      "epoch": 2.39,
      "grad_norm": 568.0,
      "learning_rate": 0.00011422163588390501,
      "loss": 8.125,
      "step": 1808
    },
    {
      "epoch": 2.39,
      "grad_norm": 32.5,
      "learning_rate": 0.0001142018469656992,
      "loss": 0.5195,
      "step": 1809
    },
    {
      "epoch": 2.39,
      "grad_norm": 31.875,
      "learning_rate": 0.00011418205804749339,
      "loss": 0.1816,
      "step": 1810
    },
    {
      "epoch": 2.39,
      "grad_norm": 62.0,
      "learning_rate": 0.00011416226912928759,
      "loss": 0.9453,
      "step": 1811
    },
    {
      "epoch": 2.39,
      "grad_norm": 152.0,
      "learning_rate": 0.00011414248021108179,
      "loss": 2.1562,
      "step": 1812
    },
    {
      "epoch": 2.39,
      "grad_norm": 171.0,
      "learning_rate": 0.00011412269129287599,
      "loss": 2.1406,
      "step": 1813
    },
    {
      "epoch": 2.39,
      "grad_norm": 65.5,
      "learning_rate": 0.00011410290237467018,
      "loss": 0.8359,
      "step": 1814
    },
    {
      "epoch": 2.39,
      "grad_norm": 31.375,
      "learning_rate": 0.00011408311345646437,
      "loss": 0.5469,
      "step": 1815
    },
    {
      "epoch": 2.4,
      "grad_norm": 221.0,
      "learning_rate": 0.00011406332453825857,
      "loss": 2.9688,
      "step": 1816
    },
    {
      "epoch": 2.4,
      "grad_norm": 125.0,
      "learning_rate": 0.00011404353562005277,
      "loss": 1.8203,
      "step": 1817
    },
    {
      "epoch": 2.4,
      "grad_norm": 219.0,
      "learning_rate": 0.00011402374670184696,
      "loss": 4.1562,
      "step": 1818
    },
    {
      "epoch": 2.4,
      "grad_norm": 65.5,
      "learning_rate": 0.00011400395778364116,
      "loss": 0.7266,
      "step": 1819
    },
    {
      "epoch": 2.4,
      "grad_norm": 33.0,
      "learning_rate": 0.00011398416886543533,
      "loss": 0.5703,
      "step": 1820
    },
    {
      "epoch": 2.4,
      "grad_norm": 184.0,
      "learning_rate": 0.00011396437994722953,
      "loss": 2.5625,
      "step": 1821
    },
    {
      "epoch": 2.4,
      "grad_norm": 23.75,
      "learning_rate": 0.00011394459102902373,
      "loss": 0.3691,
      "step": 1822
    },
    {
      "epoch": 2.41,
      "grad_norm": 35.25,
      "learning_rate": 0.00011392480211081793,
      "loss": 0.5469,
      "step": 1823
    },
    {
      "epoch": 2.41,
      "grad_norm": 57.25,
      "learning_rate": 0.00011390501319261212,
      "loss": 1.1172,
      "step": 1824
    },
    {
      "epoch": 2.41,
      "grad_norm": 188.0,
      "learning_rate": 0.00011388522427440632,
      "loss": 2.2031,
      "step": 1825
    },
    {
      "epoch": 2.41,
      "grad_norm": 396.0,
      "learning_rate": 0.00011386543535620051,
      "loss": 4.4375,
      "step": 1826
    },
    {
      "epoch": 2.41,
      "grad_norm": 150.0,
      "learning_rate": 0.0001138456464379947,
      "loss": 2.2969,
      "step": 1827
    },
    {
      "epoch": 2.41,
      "grad_norm": 213.0,
      "learning_rate": 0.0001138258575197889,
      "loss": 3.125,
      "step": 1828
    },
    {
      "epoch": 2.41,
      "grad_norm": 55.25,
      "learning_rate": 0.0001138060686015831,
      "loss": 0.5312,
      "step": 1829
    },
    {
      "epoch": 2.41,
      "grad_norm": 38.5,
      "learning_rate": 0.0001137862796833773,
      "loss": 0.4629,
      "step": 1830
    },
    {
      "epoch": 2.42,
      "grad_norm": 50.0,
      "learning_rate": 0.0001137664907651715,
      "loss": 0.4414,
      "step": 1831
    },
    {
      "epoch": 2.42,
      "grad_norm": 147.0,
      "learning_rate": 0.00011374670184696568,
      "loss": 2.5156,
      "step": 1832
    },
    {
      "epoch": 2.42,
      "grad_norm": 129.0,
      "learning_rate": 0.00011372691292875988,
      "loss": 2.0781,
      "step": 1833
    },
    {
      "epoch": 2.42,
      "grad_norm": 215.0,
      "learning_rate": 0.00011370712401055408,
      "loss": 3.9531,
      "step": 1834
    },
    {
      "epoch": 2.42,
      "grad_norm": 34.5,
      "learning_rate": 0.00011368733509234828,
      "loss": 0.5391,
      "step": 1835
    },
    {
      "epoch": 2.42,
      "grad_norm": 78.5,
      "learning_rate": 0.00011366754617414247,
      "loss": 0.918,
      "step": 1836
    },
    {
      "epoch": 2.42,
      "grad_norm": 72.5,
      "learning_rate": 0.00011364775725593667,
      "loss": 0.8594,
      "step": 1837
    },
    {
      "epoch": 2.42,
      "grad_norm": 42.0,
      "learning_rate": 0.00011362796833773086,
      "loss": 0.6562,
      "step": 1838
    },
    {
      "epoch": 2.43,
      "grad_norm": 40.25,
      "learning_rate": 0.00011360817941952505,
      "loss": 0.3281,
      "step": 1839
    },
    {
      "epoch": 2.43,
      "grad_norm": 128.0,
      "learning_rate": 0.00011358839050131925,
      "loss": 1.7109,
      "step": 1840
    },
    {
      "epoch": 2.43,
      "grad_norm": 35.75,
      "learning_rate": 0.00011356860158311345,
      "loss": 0.6758,
      "step": 1841
    },
    {
      "epoch": 2.43,
      "grad_norm": 219.0,
      "learning_rate": 0.00011354881266490765,
      "loss": 3.5,
      "step": 1842
    },
    {
      "epoch": 2.43,
      "grad_norm": 125.0,
      "learning_rate": 0.00011352902374670185,
      "loss": 1.8203,
      "step": 1843
    },
    {
      "epoch": 2.43,
      "grad_norm": 270.0,
      "learning_rate": 0.00011350923482849603,
      "loss": 5.3125,
      "step": 1844
    },
    {
      "epoch": 2.43,
      "grad_norm": 59.0,
      "learning_rate": 0.00011348944591029023,
      "loss": 0.4668,
      "step": 1845
    },
    {
      "epoch": 2.44,
      "grad_norm": 124.5,
      "learning_rate": 0.00011346965699208443,
      "loss": 1.7578,
      "step": 1846
    },
    {
      "epoch": 2.44,
      "grad_norm": 33.5,
      "learning_rate": 0.00011344986807387863,
      "loss": 0.5273,
      "step": 1847
    },
    {
      "epoch": 2.44,
      "grad_norm": 204.0,
      "learning_rate": 0.00011343007915567282,
      "loss": 4.0,
      "step": 1848
    },
    {
      "epoch": 2.44,
      "grad_norm": 29.125,
      "learning_rate": 0.00011341029023746702,
      "loss": 0.5234,
      "step": 1849
    },
    {
      "epoch": 2.44,
      "grad_norm": 45.5,
      "learning_rate": 0.00011339050131926119,
      "loss": 0.291,
      "step": 1850
    },
    {
      "epoch": 2.44,
      "grad_norm": 37.0,
      "learning_rate": 0.00011337071240105539,
      "loss": 0.5625,
      "step": 1851
    },
    {
      "epoch": 2.44,
      "grad_norm": 232.0,
      "learning_rate": 0.00011335092348284959,
      "loss": 3.7969,
      "step": 1852
    },
    {
      "epoch": 2.44,
      "grad_norm": 188.0,
      "learning_rate": 0.00011333113456464379,
      "loss": 3.2656,
      "step": 1853
    },
    {
      "epoch": 2.45,
      "grad_norm": 147.0,
      "learning_rate": 0.00011331134564643798,
      "loss": 1.875,
      "step": 1854
    },
    {
      "epoch": 2.45,
      "grad_norm": 35.25,
      "learning_rate": 0.00011329155672823217,
      "loss": 0.2129,
      "step": 1855
    },
    {
      "epoch": 2.45,
      "grad_norm": 236.0,
      "learning_rate": 0.00011327176781002637,
      "loss": 3.3438,
      "step": 1856
    },
    {
      "epoch": 2.45,
      "grad_norm": 25.5,
      "learning_rate": 0.00011325197889182057,
      "loss": 0.2617,
      "step": 1857
    },
    {
      "epoch": 2.45,
      "grad_norm": 143.0,
      "learning_rate": 0.00011323218997361476,
      "loss": 2.0469,
      "step": 1858
    },
    {
      "epoch": 2.45,
      "grad_norm": 155.0,
      "learning_rate": 0.00011321240105540896,
      "loss": 2.3281,
      "step": 1859
    },
    {
      "epoch": 2.45,
      "grad_norm": 58.0,
      "learning_rate": 0.00011319261213720316,
      "loss": 0.9297,
      "step": 1860
    },
    {
      "epoch": 2.46,
      "grad_norm": 264.0,
      "learning_rate": 0.00011317282321899734,
      "loss": 2.9219,
      "step": 1861
    },
    {
      "epoch": 2.46,
      "grad_norm": 195.0,
      "learning_rate": 0.00011315303430079154,
      "loss": 2.5,
      "step": 1862
    },
    {
      "epoch": 2.46,
      "grad_norm": 51.5,
      "learning_rate": 0.00011313324538258574,
      "loss": 0.3594,
      "step": 1863
    },
    {
      "epoch": 2.46,
      "grad_norm": 112.0,
      "learning_rate": 0.00011311345646437994,
      "loss": 1.4609,
      "step": 1864
    },
    {
      "epoch": 2.46,
      "grad_norm": 83.0,
      "learning_rate": 0.00011309366754617414,
      "loss": 0.8164,
      "step": 1865
    },
    {
      "epoch": 2.46,
      "grad_norm": 40.0,
      "learning_rate": 0.00011307387862796833,
      "loss": 0.6406,
      "step": 1866
    },
    {
      "epoch": 2.46,
      "grad_norm": 53.75,
      "learning_rate": 0.00011305408970976252,
      "loss": 0.8945,
      "step": 1867
    },
    {
      "epoch": 2.46,
      "grad_norm": 39.25,
      "learning_rate": 0.00011303430079155672,
      "loss": 0.6367,
      "step": 1868
    },
    {
      "epoch": 2.47,
      "grad_norm": 129.0,
      "learning_rate": 0.00011301451187335092,
      "loss": 1.7422,
      "step": 1869
    },
    {
      "epoch": 2.47,
      "grad_norm": 29.5,
      "learning_rate": 0.00011299472295514511,
      "loss": 0.3379,
      "step": 1870
    },
    {
      "epoch": 2.47,
      "grad_norm": 212.0,
      "learning_rate": 0.00011297493403693931,
      "loss": 3.1719,
      "step": 1871
    },
    {
      "epoch": 2.47,
      "grad_norm": 43.75,
      "learning_rate": 0.00011295514511873351,
      "loss": 0.4902,
      "step": 1872
    },
    {
      "epoch": 2.47,
      "grad_norm": 25.5,
      "learning_rate": 0.0001129353562005277,
      "loss": 0.5703,
      "step": 1873
    },
    {
      "epoch": 2.47,
      "grad_norm": 175.0,
      "learning_rate": 0.00011291556728232189,
      "loss": 2.5312,
      "step": 1874
    },
    {
      "epoch": 2.47,
      "grad_norm": 54.25,
      "learning_rate": 0.00011289577836411609,
      "loss": 0.3281,
      "step": 1875
    },
    {
      "epoch": 2.47,
      "grad_norm": 40.0,
      "learning_rate": 0.00011287598944591029,
      "loss": 0.377,
      "step": 1876
    },
    {
      "epoch": 2.48,
      "grad_norm": 64.5,
      "learning_rate": 0.00011285620052770449,
      "loss": 0.5391,
      "step": 1877
    },
    {
      "epoch": 2.48,
      "grad_norm": 40.25,
      "learning_rate": 0.00011283641160949868,
      "loss": 0.3828,
      "step": 1878
    },
    {
      "epoch": 2.48,
      "grad_norm": 16.875,
      "learning_rate": 0.00011281662269129287,
      "loss": 0.1699,
      "step": 1879
    },
    {
      "epoch": 2.48,
      "grad_norm": 83.0,
      "learning_rate": 0.00011279683377308705,
      "loss": 0.7305,
      "step": 1880
    },
    {
      "epoch": 2.48,
      "grad_norm": 45.75,
      "learning_rate": 0.00011277704485488125,
      "loss": 0.2988,
      "step": 1881
    },
    {
      "epoch": 2.48,
      "grad_norm": 242.0,
      "learning_rate": 0.00011275725593667545,
      "loss": 4.7812,
      "step": 1882
    },
    {
      "epoch": 2.48,
      "grad_norm": 159.0,
      "learning_rate": 0.00011273746701846963,
      "loss": 2.5938,
      "step": 1883
    },
    {
      "epoch": 2.49,
      "grad_norm": 68.5,
      "learning_rate": 0.00011271767810026383,
      "loss": 0.6445,
      "step": 1884
    },
    {
      "epoch": 2.49,
      "grad_norm": 59.25,
      "learning_rate": 0.00011269788918205803,
      "loss": 0.707,
      "step": 1885
    },
    {
      "epoch": 2.49,
      "grad_norm": 17.0,
      "learning_rate": 0.00011267810026385223,
      "loss": 0.3789,
      "step": 1886
    },
    {
      "epoch": 2.49,
      "grad_norm": 206.0,
      "learning_rate": 0.00011265831134564643,
      "loss": 3.0469,
      "step": 1887
    },
    {
      "epoch": 2.49,
      "grad_norm": 34.25,
      "learning_rate": 0.00011263852242744062,
      "loss": 0.3477,
      "step": 1888
    },
    {
      "epoch": 2.49,
      "grad_norm": 163.0,
      "learning_rate": 0.00011261873350923481,
      "loss": 2.6406,
      "step": 1889
    },
    {
      "epoch": 2.49,
      "grad_norm": 308.0,
      "learning_rate": 0.000112598944591029,
      "loss": 4.4688,
      "step": 1890
    },
    {
      "epoch": 2.49,
      "grad_norm": 9.0,
      "learning_rate": 0.0001125791556728232,
      "loss": 0.3125,
      "step": 1891
    },
    {
      "epoch": 2.5,
      "grad_norm": 52.25,
      "learning_rate": 0.0001125593667546174,
      "loss": 0.459,
      "step": 1892
    },
    {
      "epoch": 2.5,
      "grad_norm": 45.0,
      "learning_rate": 0.0001125395778364116,
      "loss": 0.291,
      "step": 1893
    },
    {
      "epoch": 2.5,
      "grad_norm": 148.0,
      "learning_rate": 0.0001125197889182058,
      "loss": 2.1406,
      "step": 1894
    },
    {
      "epoch": 2.5,
      "grad_norm": 11.3125,
      "learning_rate": 0.0001125,
      "loss": 0.3496,
      "step": 1895
    },
    {
      "epoch": 2.5,
      "grad_norm": 248.0,
      "learning_rate": 0.00011248021108179418,
      "loss": 4.8125,
      "step": 1896
    },
    {
      "epoch": 2.5,
      "grad_norm": 247.0,
      "learning_rate": 0.00011246042216358838,
      "loss": 4.625,
      "step": 1897
    },
    {
      "epoch": 2.5,
      "grad_norm": 15.125,
      "learning_rate": 0.00011244063324538258,
      "loss": 0.2168,
      "step": 1898
    },
    {
      "epoch": 2.51,
      "grad_norm": 26.125,
      "learning_rate": 0.00011242084432717678,
      "loss": 0.4336,
      "step": 1899
    },
    {
      "epoch": 2.51,
      "grad_norm": 11.375,
      "learning_rate": 0.00011240105540897097,
      "loss": 0.3398,
      "step": 1900
    },
    {
      "epoch": 2.51,
      "grad_norm": 147.0,
      "learning_rate": 0.00011238126649076517,
      "loss": 2.0,
      "step": 1901
    },
    {
      "epoch": 2.51,
      "grad_norm": 27.25,
      "learning_rate": 0.00011236147757255936,
      "loss": 0.3398,
      "step": 1902
    },
    {
      "epoch": 2.51,
      "grad_norm": 27.875,
      "learning_rate": 0.00011234168865435355,
      "loss": 0.2969,
      "step": 1903
    },
    {
      "epoch": 2.51,
      "grad_norm": 568.0,
      "learning_rate": 0.00011232189973614775,
      "loss": 10.5,
      "step": 1904
    },
    {
      "epoch": 2.51,
      "grad_norm": 11.3125,
      "learning_rate": 0.00011230211081794195,
      "loss": 0.4023,
      "step": 1905
    },
    {
      "epoch": 2.51,
      "grad_norm": 12.8125,
      "learning_rate": 0.00011228232189973615,
      "loss": 0.4512,
      "step": 1906
    },
    {
      "epoch": 2.52,
      "grad_norm": 229.0,
      "learning_rate": 0.00011226253298153035,
      "loss": 4.75,
      "step": 1907
    },
    {
      "epoch": 2.52,
      "grad_norm": 260.0,
      "learning_rate": 0.00011224274406332453,
      "loss": 4.5312,
      "step": 1908
    },
    {
      "epoch": 2.52,
      "grad_norm": 151.0,
      "learning_rate": 0.00011222295514511873,
      "loss": 2.8125,
      "step": 1909
    },
    {
      "epoch": 2.52,
      "grad_norm": 11.25,
      "learning_rate": 0.00011220316622691293,
      "loss": 0.3984,
      "step": 1910
    },
    {
      "epoch": 2.52,
      "grad_norm": 155.0,
      "learning_rate": 0.00011218337730870711,
      "loss": 2.4688,
      "step": 1911
    },
    {
      "epoch": 2.52,
      "grad_norm": 334.0,
      "learning_rate": 0.0001121635883905013,
      "loss": 4.9375,
      "step": 1912
    },
    {
      "epoch": 2.52,
      "grad_norm": 164.0,
      "learning_rate": 0.0001121437994722955,
      "loss": 2.5625,
      "step": 1913
    },
    {
      "epoch": 2.53,
      "grad_norm": 46.0,
      "learning_rate": 0.00011212401055408969,
      "loss": 0.5859,
      "step": 1914
    },
    {
      "epoch": 2.53,
      "grad_norm": 39.75,
      "learning_rate": 0.00011210422163588389,
      "loss": 0.2295,
      "step": 1915
    },
    {
      "epoch": 2.53,
      "grad_norm": 294.0,
      "learning_rate": 0.00011208443271767809,
      "loss": 5.2188,
      "step": 1916
    },
    {
      "epoch": 2.53,
      "grad_norm": 11.875,
      "learning_rate": 0.00011206464379947229,
      "loss": 0.1699,
      "step": 1917
    },
    {
      "epoch": 2.53,
      "grad_norm": 18.5,
      "learning_rate": 0.00011204485488126647,
      "loss": 0.3809,
      "step": 1918
    },
    {
      "epoch": 2.53,
      "grad_norm": 23.0,
      "learning_rate": 0.00011202506596306067,
      "loss": 0.3984,
      "step": 1919
    },
    {
      "epoch": 2.53,
      "grad_norm": 143.0,
      "learning_rate": 0.00011200527704485487,
      "loss": 1.9688,
      "step": 1920
    },
    {
      "epoch": 2.53,
      "grad_norm": 18.0,
      "learning_rate": 0.00011198548812664907,
      "loss": 0.4121,
      "step": 1921
    },
    {
      "epoch": 2.54,
      "grad_norm": 142.0,
      "learning_rate": 0.00011196569920844326,
      "loss": 2.0,
      "step": 1922
    },
    {
      "epoch": 2.54,
      "grad_norm": 145.0,
      "learning_rate": 0.00011194591029023746,
      "loss": 1.875,
      "step": 1923
    },
    {
      "epoch": 2.54,
      "grad_norm": 232.0,
      "learning_rate": 0.00011192612137203165,
      "loss": 3.75,
      "step": 1924
    },
    {
      "epoch": 2.54,
      "grad_norm": 228.0,
      "learning_rate": 0.00011190633245382584,
      "loss": 3.6406,
      "step": 1925
    },
    {
      "epoch": 2.54,
      "grad_norm": 20.0,
      "learning_rate": 0.00011188654353562004,
      "loss": 0.252,
      "step": 1926
    },
    {
      "epoch": 2.54,
      "grad_norm": 66.0,
      "learning_rate": 0.00011186675461741424,
      "loss": 0.582,
      "step": 1927
    },
    {
      "epoch": 2.54,
      "grad_norm": 274.0,
      "learning_rate": 0.00011184696569920844,
      "loss": 5.1875,
      "step": 1928
    },
    {
      "epoch": 2.54,
      "grad_norm": 63.25,
      "learning_rate": 0.00011182717678100264,
      "loss": 0.4395,
      "step": 1929
    },
    {
      "epoch": 2.55,
      "grad_norm": 34.0,
      "learning_rate": 0.00011180738786279682,
      "loss": 0.6328,
      "step": 1930
    },
    {
      "epoch": 2.55,
      "grad_norm": 34.5,
      "learning_rate": 0.00011178759894459102,
      "loss": 0.5508,
      "step": 1931
    },
    {
      "epoch": 2.55,
      "grad_norm": 274.0,
      "learning_rate": 0.00011176781002638522,
      "loss": 5.0312,
      "step": 1932
    },
    {
      "epoch": 2.55,
      "grad_norm": 24.125,
      "learning_rate": 0.00011174802110817941,
      "loss": 0.5156,
      "step": 1933
    },
    {
      "epoch": 2.55,
      "grad_norm": 251.0,
      "learning_rate": 0.00011172823218997361,
      "loss": 3.6875,
      "step": 1934
    },
    {
      "epoch": 2.55,
      "grad_norm": 310.0,
      "learning_rate": 0.00011170844327176781,
      "loss": 4.9375,
      "step": 1935
    },
    {
      "epoch": 2.55,
      "grad_norm": 33.0,
      "learning_rate": 0.000111688654353562,
      "loss": 0.2188,
      "step": 1936
    },
    {
      "epoch": 2.56,
      "grad_norm": 139.0,
      "learning_rate": 0.0001116688654353562,
      "loss": 1.75,
      "step": 1937
    },
    {
      "epoch": 2.56,
      "grad_norm": 284.0,
      "learning_rate": 0.00011164907651715039,
      "loss": 2.9844,
      "step": 1938
    },
    {
      "epoch": 2.56,
      "grad_norm": 28.75,
      "learning_rate": 0.00011162928759894459,
      "loss": 0.4707,
      "step": 1939
    },
    {
      "epoch": 2.56,
      "grad_norm": 264.0,
      "learning_rate": 0.00011160949868073879,
      "loss": 3.5156,
      "step": 1940
    },
    {
      "epoch": 2.56,
      "grad_norm": 66.5,
      "learning_rate": 0.00011158970976253296,
      "loss": 0.8164,
      "step": 1941
    },
    {
      "epoch": 2.56,
      "grad_norm": 250.0,
      "learning_rate": 0.00011156992084432716,
      "loss": 3.8438,
      "step": 1942
    },
    {
      "epoch": 2.56,
      "grad_norm": 221.0,
      "learning_rate": 0.00011155013192612135,
      "loss": 2.6875,
      "step": 1943
    },
    {
      "epoch": 2.56,
      "grad_norm": 64.0,
      "learning_rate": 0.00011153034300791555,
      "loss": 0.4688,
      "step": 1944
    },
    {
      "epoch": 2.57,
      "grad_norm": 45.5,
      "learning_rate": 0.00011151055408970975,
      "loss": 0.707,
      "step": 1945
    },
    {
      "epoch": 2.57,
      "grad_norm": 127.0,
      "learning_rate": 0.00011149076517150395,
      "loss": 1.8281,
      "step": 1946
    },
    {
      "epoch": 2.57,
      "grad_norm": 49.5,
      "learning_rate": 0.00011147097625329813,
      "loss": 0.7227,
      "step": 1947
    },
    {
      "epoch": 2.57,
      "grad_norm": 50.75,
      "learning_rate": 0.00011145118733509233,
      "loss": 0.7695,
      "step": 1948
    },
    {
      "epoch": 2.57,
      "grad_norm": 199.0,
      "learning_rate": 0.00011143139841688653,
      "loss": 3.4688,
      "step": 1949
    },
    {
      "epoch": 2.57,
      "grad_norm": 196.0,
      "learning_rate": 0.00011141160949868073,
      "loss": 3.4531,
      "step": 1950
    },
    {
      "epoch": 2.57,
      "grad_norm": 47.5,
      "learning_rate": 0.00011139182058047493,
      "loss": 0.6719,
      "step": 1951
    },
    {
      "epoch": 2.58,
      "grad_norm": 124.0,
      "learning_rate": 0.00011137203166226912,
      "loss": 1.6172,
      "step": 1952
    },
    {
      "epoch": 2.58,
      "grad_norm": 196.0,
      "learning_rate": 0.00011135224274406331,
      "loss": 3.1719,
      "step": 1953
    },
    {
      "epoch": 2.58,
      "grad_norm": 46.5,
      "learning_rate": 0.0001113324538258575,
      "loss": 0.7383,
      "step": 1954
    },
    {
      "epoch": 2.58,
      "grad_norm": 68.5,
      "learning_rate": 0.0001113126649076517,
      "loss": 0.7344,
      "step": 1955
    },
    {
      "epoch": 2.58,
      "grad_norm": 126.5,
      "learning_rate": 0.0001112928759894459,
      "loss": 2.0625,
      "step": 1956
    },
    {
      "epoch": 2.58,
      "grad_norm": 51.75,
      "learning_rate": 0.0001112730870712401,
      "loss": 0.459,
      "step": 1957
    },
    {
      "epoch": 2.58,
      "grad_norm": 38.25,
      "learning_rate": 0.0001112532981530343,
      "loss": 0.5859,
      "step": 1958
    },
    {
      "epoch": 2.58,
      "grad_norm": 456.0,
      "learning_rate": 0.00011123350923482848,
      "loss": 5.5,
      "step": 1959
    },
    {
      "epoch": 2.59,
      "grad_norm": 41.5,
      "learning_rate": 0.00011121372031662268,
      "loss": 0.7344,
      "step": 1960
    },
    {
      "epoch": 2.59,
      "grad_norm": 199.0,
      "learning_rate": 0.00011119393139841688,
      "loss": 2.7969,
      "step": 1961
    },
    {
      "epoch": 2.59,
      "grad_norm": 109.5,
      "learning_rate": 0.00011117414248021108,
      "loss": 1.6797,
      "step": 1962
    },
    {
      "epoch": 2.59,
      "grad_norm": 32.5,
      "learning_rate": 0.00011115435356200528,
      "loss": 0.2412,
      "step": 1963
    },
    {
      "epoch": 2.59,
      "grad_norm": 50.25,
      "learning_rate": 0.00011113456464379947,
      "loss": 0.3926,
      "step": 1964
    },
    {
      "epoch": 2.59,
      "grad_norm": 216.0,
      "learning_rate": 0.00011111477572559366,
      "loss": 2.8438,
      "step": 1965
    },
    {
      "epoch": 2.59,
      "grad_norm": 48.5,
      "learning_rate": 0.00011109498680738786,
      "loss": 0.3828,
      "step": 1966
    },
    {
      "epoch": 2.59,
      "grad_norm": 51.25,
      "learning_rate": 0.00011107519788918205,
      "loss": 0.5156,
      "step": 1967
    },
    {
      "epoch": 2.6,
      "grad_norm": 422.0,
      "learning_rate": 0.00011105540897097625,
      "loss": 5.125,
      "step": 1968
    },
    {
      "epoch": 2.6,
      "grad_norm": 209.0,
      "learning_rate": 0.00011103562005277045,
      "loss": 2.7344,
      "step": 1969
    },
    {
      "epoch": 2.6,
      "grad_norm": 118.5,
      "learning_rate": 0.00011101583113456465,
      "loss": 1.8438,
      "step": 1970
    },
    {
      "epoch": 2.6,
      "grad_norm": 200.0,
      "learning_rate": 0.00011099604221635882,
      "loss": 2.5625,
      "step": 1971
    },
    {
      "epoch": 2.6,
      "grad_norm": 48.75,
      "learning_rate": 0.00011097625329815302,
      "loss": 0.3848,
      "step": 1972
    },
    {
      "epoch": 2.6,
      "grad_norm": 39.75,
      "learning_rate": 0.00011095646437994722,
      "loss": 0.6016,
      "step": 1973
    },
    {
      "epoch": 2.6,
      "grad_norm": 212.0,
      "learning_rate": 0.00011093667546174141,
      "loss": 3.4844,
      "step": 1974
    },
    {
      "epoch": 2.61,
      "grad_norm": 39.0,
      "learning_rate": 0.00011091688654353561,
      "loss": 0.5781,
      "step": 1975
    },
    {
      "epoch": 2.61,
      "grad_norm": 51.0,
      "learning_rate": 0.0001108970976253298,
      "loss": 0.7695,
      "step": 1976
    },
    {
      "epoch": 2.61,
      "grad_norm": 146.0,
      "learning_rate": 0.000110877308707124,
      "loss": 1.9844,
      "step": 1977
    },
    {
      "epoch": 2.61,
      "grad_norm": 57.0,
      "learning_rate": 0.00011085751978891819,
      "loss": 0.3945,
      "step": 1978
    },
    {
      "epoch": 2.61,
      "grad_norm": 30.0,
      "learning_rate": 0.00011083773087071239,
      "loss": 0.4727,
      "step": 1979
    },
    {
      "epoch": 2.61,
      "grad_norm": 45.0,
      "learning_rate": 0.00011081794195250659,
      "loss": 0.7031,
      "step": 1980
    },
    {
      "epoch": 2.61,
      "grad_norm": 41.5,
      "learning_rate": 0.00011079815303430079,
      "loss": 0.6016,
      "step": 1981
    },
    {
      "epoch": 2.61,
      "grad_norm": 40.75,
      "learning_rate": 0.00011077836411609497,
      "loss": 0.2891,
      "step": 1982
    },
    {
      "epoch": 2.62,
      "grad_norm": 21.25,
      "learning_rate": 0.00011075857519788917,
      "loss": 0.1768,
      "step": 1983
    },
    {
      "epoch": 2.62,
      "grad_norm": 28.375,
      "learning_rate": 0.00011073878627968337,
      "loss": 0.1738,
      "step": 1984
    },
    {
      "epoch": 2.62,
      "grad_norm": 332.0,
      "learning_rate": 0.00011071899736147756,
      "loss": 4.6875,
      "step": 1985
    },
    {
      "epoch": 2.62,
      "grad_norm": 20.625,
      "learning_rate": 0.00011069920844327176,
      "loss": 0.3438,
      "step": 1986
    },
    {
      "epoch": 2.62,
      "grad_norm": 338.0,
      "learning_rate": 0.00011067941952506596,
      "loss": 6.6562,
      "step": 1987
    },
    {
      "epoch": 2.62,
      "grad_norm": 17.0,
      "learning_rate": 0.00011065963060686015,
      "loss": 0.1074,
      "step": 1988
    },
    {
      "epoch": 2.62,
      "grad_norm": 165.0,
      "learning_rate": 0.00011063984168865434,
      "loss": 2.5938,
      "step": 1989
    },
    {
      "epoch": 2.63,
      "grad_norm": 153.0,
      "learning_rate": 0.00011062005277044854,
      "loss": 2.3594,
      "step": 1990
    },
    {
      "epoch": 2.63,
      "grad_norm": 184.0,
      "learning_rate": 0.00011060026385224274,
      "loss": 2.7969,
      "step": 1991
    },
    {
      "epoch": 2.63,
      "grad_norm": 162.0,
      "learning_rate": 0.00011058047493403694,
      "loss": 2.3438,
      "step": 1992
    },
    {
      "epoch": 2.63,
      "grad_norm": 175.0,
      "learning_rate": 0.00011056068601583114,
      "loss": 2.1719,
      "step": 1993
    },
    {
      "epoch": 2.63,
      "grad_norm": 147.0,
      "learning_rate": 0.00011054089709762532,
      "loss": 1.875,
      "step": 1994
    },
    {
      "epoch": 2.63,
      "grad_norm": 23.375,
      "learning_rate": 0.00011052110817941952,
      "loss": 0.2734,
      "step": 1995
    },
    {
      "epoch": 2.63,
      "grad_norm": 45.5,
      "learning_rate": 0.00011050131926121372,
      "loss": 0.4746,
      "step": 1996
    },
    {
      "epoch": 2.63,
      "grad_norm": 68.0,
      "learning_rate": 0.00011048153034300791,
      "loss": 0.498,
      "step": 1997
    },
    {
      "epoch": 2.64,
      "grad_norm": 306.0,
      "learning_rate": 0.00011046174142480211,
      "loss": 6.3125,
      "step": 1998
    },
    {
      "epoch": 2.64,
      "grad_norm": 55.25,
      "learning_rate": 0.00011044195250659631,
      "loss": 0.7148,
      "step": 1999
    },
    {
      "epoch": 2.64,
      "grad_norm": 117.0,
      "learning_rate": 0.0001104221635883905,
      "loss": 1.8828,
      "step": 2000
    },
    {
      "epoch": 2.64,
      "grad_norm": 79.5,
      "learning_rate": 0.00011040237467018468,
      "loss": 1.3594,
      "step": 2001
    },
    {
      "epoch": 2.64,
      "grad_norm": 82.5,
      "learning_rate": 0.00011038258575197888,
      "loss": 0.7148,
      "step": 2002
    },
    {
      "epoch": 2.64,
      "grad_norm": 237.0,
      "learning_rate": 0.00011036279683377308,
      "loss": 5.7188,
      "step": 2003
    },
    {
      "epoch": 2.64,
      "grad_norm": 248.0,
      "learning_rate": 0.00011034300791556726,
      "loss": 4.8438,
      "step": 2004
    },
    {
      "epoch": 2.65,
      "grad_norm": 30.625,
      "learning_rate": 0.00011032321899736146,
      "loss": 1.1172,
      "step": 2005
    },
    {
      "epoch": 2.65,
      "grad_norm": 27.375,
      "learning_rate": 0.00011030343007915566,
      "loss": 0.8516,
      "step": 2006
    },
    {
      "epoch": 2.65,
      "grad_norm": 280.0,
      "learning_rate": 0.00011028364116094985,
      "loss": 5.2188,
      "step": 2007
    },
    {
      "epoch": 2.65,
      "grad_norm": 31.5,
      "learning_rate": 0.00011026385224274405,
      "loss": 0.957,
      "step": 2008
    },
    {
      "epoch": 2.65,
      "grad_norm": 95.5,
      "learning_rate": 0.00011024406332453825,
      "loss": 1.3203,
      "step": 2009
    },
    {
      "epoch": 2.65,
      "grad_norm": 89.5,
      "learning_rate": 0.00011022427440633243,
      "loss": 1.1328,
      "step": 2010
    },
    {
      "epoch": 2.65,
      "grad_norm": 49.25,
      "learning_rate": 0.00011020448548812663,
      "loss": 0.6406,
      "step": 2011
    },
    {
      "epoch": 2.65,
      "grad_norm": 44.75,
      "learning_rate": 0.00011018469656992083,
      "loss": 0.3906,
      "step": 2012
    },
    {
      "epoch": 2.66,
      "grad_norm": 51.75,
      "learning_rate": 0.00011016490765171503,
      "loss": 0.5742,
      "step": 2013
    },
    {
      "epoch": 2.66,
      "grad_norm": 26.625,
      "learning_rate": 0.00011014511873350923,
      "loss": 1.1875,
      "step": 2014
    },
    {
      "epoch": 2.66,
      "grad_norm": 50.25,
      "learning_rate": 0.00011012532981530343,
      "loss": 1.0391,
      "step": 2015
    },
    {
      "epoch": 2.66,
      "grad_norm": 75.0,
      "learning_rate": 0.00011010554089709761,
      "loss": 0.9023,
      "step": 2016
    },
    {
      "epoch": 2.66,
      "grad_norm": 68.5,
      "learning_rate": 0.00011008575197889181,
      "loss": 0.7344,
      "step": 2017
    },
    {
      "epoch": 2.66,
      "grad_norm": 42.25,
      "learning_rate": 0.000110065963060686,
      "loss": 0.5273,
      "step": 2018
    },
    {
      "epoch": 2.66,
      "grad_norm": 60.25,
      "learning_rate": 0.0001100461741424802,
      "loss": 0.5117,
      "step": 2019
    },
    {
      "epoch": 2.66,
      "grad_norm": 59.75,
      "learning_rate": 0.0001100263852242744,
      "loss": 1.2109,
      "step": 2020
    },
    {
      "epoch": 2.67,
      "grad_norm": 93.0,
      "learning_rate": 0.0001100065963060686,
      "loss": 1.5859,
      "step": 2021
    },
    {
      "epoch": 2.67,
      "grad_norm": 82.5,
      "learning_rate": 0.00010998680738786278,
      "loss": 1.1797,
      "step": 2022
    },
    {
      "epoch": 2.67,
      "grad_norm": 56.0,
      "learning_rate": 0.00010996701846965698,
      "loss": 0.6172,
      "step": 2023
    },
    {
      "epoch": 2.67,
      "grad_norm": 74.0,
      "learning_rate": 0.00010994722955145118,
      "loss": 0.5938,
      "step": 2024
    },
    {
      "epoch": 2.67,
      "grad_norm": 82.0,
      "learning_rate": 0.00010992744063324538,
      "loss": 1.0547,
      "step": 2025
    },
    {
      "epoch": 2.67,
      "grad_norm": 233.0,
      "learning_rate": 0.00010990765171503958,
      "loss": 3.9844,
      "step": 2026
    },
    {
      "epoch": 2.67,
      "grad_norm": 46.0,
      "learning_rate": 0.00010988786279683377,
      "loss": 0.3828,
      "step": 2027
    },
    {
      "epoch": 2.68,
      "grad_norm": 41.0,
      "learning_rate": 0.00010986807387862796,
      "loss": 0.6875,
      "step": 2028
    },
    {
      "epoch": 2.68,
      "grad_norm": 244.0,
      "learning_rate": 0.00010984828496042216,
      "loss": 4.625,
      "step": 2029
    },
    {
      "epoch": 2.68,
      "grad_norm": 234.0,
      "learning_rate": 0.00010982849604221636,
      "loss": 3.8906,
      "step": 2030
    },
    {
      "epoch": 2.68,
      "grad_norm": 27.375,
      "learning_rate": 0.00010980870712401054,
      "loss": 0.4199,
      "step": 2031
    },
    {
      "epoch": 2.68,
      "grad_norm": 61.25,
      "learning_rate": 0.00010978891820580474,
      "loss": 0.6602,
      "step": 2032
    },
    {
      "epoch": 2.68,
      "grad_norm": 288.0,
      "learning_rate": 0.00010976912928759892,
      "loss": 3.0312,
      "step": 2033
    },
    {
      "epoch": 2.68,
      "grad_norm": 19.625,
      "learning_rate": 0.00010974934036939312,
      "loss": 0.5391,
      "step": 2034
    },
    {
      "epoch": 2.68,
      "grad_norm": 46.0,
      "learning_rate": 0.00010972955145118732,
      "loss": 0.4863,
      "step": 2035
    },
    {
      "epoch": 2.69,
      "grad_norm": 20.875,
      "learning_rate": 0.00010970976253298152,
      "loss": 0.2832,
      "step": 2036
    },
    {
      "epoch": 2.69,
      "grad_norm": 23.375,
      "learning_rate": 0.00010968997361477571,
      "loss": 0.4883,
      "step": 2037
    },
    {
      "epoch": 2.69,
      "grad_norm": 40.25,
      "learning_rate": 0.00010967018469656991,
      "loss": 0.3848,
      "step": 2038
    },
    {
      "epoch": 2.69,
      "grad_norm": 83.5,
      "learning_rate": 0.0001096503957783641,
      "loss": 0.6172,
      "step": 2039
    },
    {
      "epoch": 2.69,
      "grad_norm": 239.0,
      "learning_rate": 0.0001096306068601583,
      "loss": 4.0,
      "step": 2040
    },
    {
      "epoch": 2.69,
      "grad_norm": 176.0,
      "learning_rate": 0.0001096108179419525,
      "loss": 3.8594,
      "step": 2041
    },
    {
      "epoch": 2.69,
      "grad_norm": 15.3125,
      "learning_rate": 0.00010959102902374669,
      "loss": 0.3066,
      "step": 2042
    },
    {
      "epoch": 2.7,
      "grad_norm": 43.75,
      "learning_rate": 0.00010957124010554089,
      "loss": 0.4883,
      "step": 2043
    },
    {
      "epoch": 2.7,
      "grad_norm": 448.0,
      "learning_rate": 0.00010955145118733509,
      "loss": 9.5,
      "step": 2044
    },
    {
      "epoch": 2.7,
      "grad_norm": 152.0,
      "learning_rate": 0.00010953166226912927,
      "loss": 3.1406,
      "step": 2045
    },
    {
      "epoch": 2.7,
      "grad_norm": 7.21875,
      "learning_rate": 0.00010951187335092347,
      "loss": 0.2852,
      "step": 2046
    },
    {
      "epoch": 2.7,
      "grad_norm": 22.625,
      "learning_rate": 0.00010949208443271767,
      "loss": 0.3418,
      "step": 2047
    },
    {
      "epoch": 2.7,
      "grad_norm": 7.625,
      "learning_rate": 0.00010947229551451187,
      "loss": 0.4043,
      "step": 2048
    },
    {
      "epoch": 2.7,
      "grad_norm": 20.25,
      "learning_rate": 0.00010945250659630606,
      "loss": 0.2812,
      "step": 2049
    },
    {
      "epoch": 2.7,
      "grad_norm": 266.0,
      "learning_rate": 0.00010943271767810026,
      "loss": 4.4375,
      "step": 2050
    },
    {
      "epoch": 2.71,
      "grad_norm": 268.0,
      "learning_rate": 0.00010941292875989445,
      "loss": 4.5,
      "step": 2051
    },
    {
      "epoch": 2.71,
      "grad_norm": 35.5,
      "learning_rate": 0.00010939313984168865,
      "loss": 0.1797,
      "step": 2052
    },
    {
      "epoch": 2.71,
      "grad_norm": 162.0,
      "learning_rate": 0.00010937335092348284,
      "loss": 2.9375,
      "step": 2053
    },
    {
      "epoch": 2.71,
      "grad_norm": 157.0,
      "learning_rate": 0.00010935356200527704,
      "loss": 3.0156,
      "step": 2054
    },
    {
      "epoch": 2.71,
      "grad_norm": 53.25,
      "learning_rate": 0.00010933377308707124,
      "loss": 0.4883,
      "step": 2055
    },
    {
      "epoch": 2.71,
      "grad_norm": 320.0,
      "learning_rate": 0.00010931398416886544,
      "loss": 6.3438,
      "step": 2056
    },
    {
      "epoch": 2.71,
      "grad_norm": 9.25,
      "learning_rate": 0.00010929419525065962,
      "loss": 0.4141,
      "step": 2057
    },
    {
      "epoch": 2.72,
      "grad_norm": 23.125,
      "learning_rate": 0.00010927440633245382,
      "loss": 0.5,
      "step": 2058
    },
    {
      "epoch": 2.72,
      "grad_norm": 53.75,
      "learning_rate": 0.00010925461741424802,
      "loss": 0.5859,
      "step": 2059
    },
    {
      "epoch": 2.72,
      "grad_norm": 36.25,
      "learning_rate": 0.00010923482849604222,
      "loss": 0.498,
      "step": 2060
    },
    {
      "epoch": 2.72,
      "grad_norm": 294.0,
      "learning_rate": 0.0001092150395778364,
      "loss": 5.75,
      "step": 2061
    },
    {
      "epoch": 2.72,
      "grad_norm": 230.0,
      "learning_rate": 0.00010919525065963058,
      "loss": 3.6094,
      "step": 2062
    },
    {
      "epoch": 2.72,
      "grad_norm": 237.0,
      "learning_rate": 0.00010917546174142478,
      "loss": 3.7031,
      "step": 2063
    },
    {
      "epoch": 2.72,
      "grad_norm": 23.125,
      "learning_rate": 0.00010915567282321898,
      "loss": 0.3477,
      "step": 2064
    },
    {
      "epoch": 2.72,
      "grad_norm": 161.0,
      "learning_rate": 0.00010913588390501318,
      "loss": 2.7188,
      "step": 2065
    },
    {
      "epoch": 2.73,
      "grad_norm": 65.0,
      "learning_rate": 0.00010911609498680738,
      "loss": 0.4844,
      "step": 2066
    },
    {
      "epoch": 2.73,
      "grad_norm": 20.25,
      "learning_rate": 0.00010909630606860158,
      "loss": 0.5547,
      "step": 2067
    },
    {
      "epoch": 2.73,
      "grad_norm": 364.0,
      "learning_rate": 0.00010907651715039576,
      "loss": 6.5625,
      "step": 2068
    },
    {
      "epoch": 2.73,
      "grad_norm": 29.875,
      "learning_rate": 0.00010905672823218996,
      "loss": 0.4961,
      "step": 2069
    },
    {
      "epoch": 2.73,
      "grad_norm": 201.0,
      "learning_rate": 0.00010903693931398416,
      "loss": 2.3906,
      "step": 2070
    },
    {
      "epoch": 2.73,
      "grad_norm": 40.0,
      "learning_rate": 0.00010901715039577835,
      "loss": 0.2949,
      "step": 2071
    },
    {
      "epoch": 2.73,
      "grad_norm": 34.0,
      "learning_rate": 0.00010899736147757255,
      "loss": 0.3262,
      "step": 2072
    },
    {
      "epoch": 2.73,
      "grad_norm": 131.0,
      "learning_rate": 0.00010897757255936675,
      "loss": 2.1875,
      "step": 2073
    },
    {
      "epoch": 2.74,
      "grad_norm": 131.0,
      "learning_rate": 0.00010895778364116093,
      "loss": 1.9766,
      "step": 2074
    },
    {
      "epoch": 2.74,
      "grad_norm": 56.25,
      "learning_rate": 0.00010893799472295513,
      "loss": 0.7305,
      "step": 2075
    },
    {
      "epoch": 2.74,
      "grad_norm": 124.5,
      "learning_rate": 0.00010891820580474933,
      "loss": 1.8906,
      "step": 2076
    },
    {
      "epoch": 2.74,
      "grad_norm": 125.5,
      "learning_rate": 0.00010889841688654353,
      "loss": 1.8516,
      "step": 2077
    },
    {
      "epoch": 2.74,
      "grad_norm": 46.5,
      "learning_rate": 0.00010887862796833773,
      "loss": 0.3125,
      "step": 2078
    },
    {
      "epoch": 2.74,
      "grad_norm": 24.125,
      "learning_rate": 0.00010885883905013192,
      "loss": 0.2119,
      "step": 2079
    },
    {
      "epoch": 2.74,
      "grad_norm": 104.0,
      "learning_rate": 0.00010883905013192611,
      "loss": 1.2344,
      "step": 2080
    },
    {
      "epoch": 2.75,
      "grad_norm": 38.0,
      "learning_rate": 0.00010881926121372031,
      "loss": 0.6133,
      "step": 2081
    },
    {
      "epoch": 2.75,
      "grad_norm": 39.25,
      "learning_rate": 0.0001087994722955145,
      "loss": 0.6602,
      "step": 2082
    },
    {
      "epoch": 2.75,
      "grad_norm": 37.0,
      "learning_rate": 0.0001087796833773087,
      "loss": 0.2344,
      "step": 2083
    },
    {
      "epoch": 2.75,
      "grad_norm": 58.5,
      "learning_rate": 0.0001087598944591029,
      "loss": 0.8125,
      "step": 2084
    },
    {
      "epoch": 2.75,
      "grad_norm": 33.5,
      "learning_rate": 0.0001087401055408971,
      "loss": 0.5078,
      "step": 2085
    },
    {
      "epoch": 2.75,
      "grad_norm": 23.375,
      "learning_rate": 0.00010872031662269128,
      "loss": 0.1553,
      "step": 2086
    },
    {
      "epoch": 2.75,
      "grad_norm": 117.0,
      "learning_rate": 0.00010870052770448548,
      "loss": 1.3594,
      "step": 2087
    },
    {
      "epoch": 2.75,
      "grad_norm": 238.0,
      "learning_rate": 0.00010868073878627968,
      "loss": 4.1875,
      "step": 2088
    },
    {
      "epoch": 2.76,
      "grad_norm": 25.25,
      "learning_rate": 0.00010866094986807388,
      "loss": 0.7148,
      "step": 2089
    },
    {
      "epoch": 2.76,
      "grad_norm": 23.5,
      "learning_rate": 0.00010864116094986808,
      "loss": 0.5039,
      "step": 2090
    },
    {
      "epoch": 2.76,
      "grad_norm": 54.5,
      "learning_rate": 0.00010862137203166225,
      "loss": 0.6641,
      "step": 2091
    },
    {
      "epoch": 2.76,
      "grad_norm": 234.0,
      "learning_rate": 0.00010860158311345645,
      "loss": 6.375,
      "step": 2092
    },
    {
      "epoch": 2.76,
      "grad_norm": 14.1875,
      "learning_rate": 0.00010858179419525064,
      "loss": 0.3906,
      "step": 2093
    },
    {
      "epoch": 2.76,
      "grad_norm": 142.0,
      "learning_rate": 0.00010856200527704484,
      "loss": 2.1719,
      "step": 2094
    },
    {
      "epoch": 2.76,
      "grad_norm": 247.0,
      "learning_rate": 0.00010854221635883904,
      "loss": 5.9688,
      "step": 2095
    },
    {
      "epoch": 2.77,
      "grad_norm": 73.0,
      "learning_rate": 0.00010852242744063322,
      "loss": 0.5,
      "step": 2096
    },
    {
      "epoch": 2.77,
      "grad_norm": 510.0,
      "learning_rate": 0.00010850263852242742,
      "loss": 10.0625,
      "step": 2097
    },
    {
      "epoch": 2.77,
      "grad_norm": 231.0,
      "learning_rate": 0.00010848284960422162,
      "loss": 4.1562,
      "step": 2098
    },
    {
      "epoch": 2.77,
      "grad_norm": 30.375,
      "learning_rate": 0.00010846306068601582,
      "loss": 0.4453,
      "step": 2099
    },
    {
      "epoch": 2.77,
      "grad_norm": 142.0,
      "learning_rate": 0.00010844327176781002,
      "loss": 2.375,
      "step": 2100
    },
    {
      "epoch": 2.77,
      "grad_norm": 211.0,
      "learning_rate": 0.00010842348284960421,
      "loss": 3.0312,
      "step": 2101
    },
    {
      "epoch": 2.77,
      "grad_norm": 258.0,
      "learning_rate": 0.0001084036939313984,
      "loss": 5.0,
      "step": 2102
    },
    {
      "epoch": 2.77,
      "grad_norm": 16.25,
      "learning_rate": 0.0001083839050131926,
      "loss": 0.2061,
      "step": 2103
    },
    {
      "epoch": 2.78,
      "grad_norm": 23.875,
      "learning_rate": 0.0001083641160949868,
      "loss": 0.1426,
      "step": 2104
    },
    {
      "epoch": 2.78,
      "grad_norm": 67.0,
      "learning_rate": 0.00010834432717678099,
      "loss": 0.8672,
      "step": 2105
    },
    {
      "epoch": 2.78,
      "grad_norm": 151.0,
      "learning_rate": 0.00010832453825857519,
      "loss": 3.6562,
      "step": 2106
    },
    {
      "epoch": 2.78,
      "grad_norm": 24.125,
      "learning_rate": 0.00010830474934036939,
      "loss": 0.3594,
      "step": 2107
    },
    {
      "epoch": 2.78,
      "grad_norm": 217.0,
      "learning_rate": 0.00010828496042216357,
      "loss": 4.1562,
      "step": 2108
    },
    {
      "epoch": 2.78,
      "grad_norm": 127.5,
      "learning_rate": 0.00010826517150395777,
      "loss": 2.2031,
      "step": 2109
    },
    {
      "epoch": 2.78,
      "grad_norm": 124.0,
      "learning_rate": 0.00010824538258575197,
      "loss": 2.1406,
      "step": 2110
    },
    {
      "epoch": 2.78,
      "grad_norm": 31.0,
      "learning_rate": 0.00010822559366754617,
      "loss": 0.543,
      "step": 2111
    },
    {
      "epoch": 2.79,
      "grad_norm": 200.0,
      "learning_rate": 0.00010820580474934037,
      "loss": 3.6562,
      "step": 2112
    },
    {
      "epoch": 2.79,
      "grad_norm": 103.5,
      "learning_rate": 0.00010818601583113456,
      "loss": 1.5078,
      "step": 2113
    },
    {
      "epoch": 2.79,
      "grad_norm": 112.5,
      "learning_rate": 0.00010816622691292875,
      "loss": 1.7734,
      "step": 2114
    },
    {
      "epoch": 2.79,
      "grad_norm": 43.75,
      "learning_rate": 0.00010814643799472295,
      "loss": 0.7812,
      "step": 2115
    },
    {
      "epoch": 2.79,
      "grad_norm": 30.875,
      "learning_rate": 0.00010812664907651714,
      "loss": 0.3555,
      "step": 2116
    },
    {
      "epoch": 2.79,
      "grad_norm": 61.0,
      "learning_rate": 0.00010810686015831134,
      "loss": 0.7852,
      "step": 2117
    },
    {
      "epoch": 2.79,
      "grad_norm": 34.75,
      "learning_rate": 0.00010808707124010554,
      "loss": 0.3691,
      "step": 2118
    },
    {
      "epoch": 2.8,
      "grad_norm": 42.0,
      "learning_rate": 0.00010806728232189974,
      "loss": 1.1797,
      "step": 2119
    },
    {
      "epoch": 2.8,
      "grad_norm": 52.0,
      "learning_rate": 0.00010804749340369392,
      "loss": 1.0156,
      "step": 2120
    },
    {
      "epoch": 2.8,
      "grad_norm": 35.5,
      "learning_rate": 0.00010802770448548811,
      "loss": 0.3594,
      "step": 2121
    },
    {
      "epoch": 2.8,
      "grad_norm": 45.25,
      "learning_rate": 0.0001080079155672823,
      "loss": 1.2812,
      "step": 2122
    },
    {
      "epoch": 2.8,
      "grad_norm": 50.0,
      "learning_rate": 0.0001079881266490765,
      "loss": 0.6719,
      "step": 2123
    },
    {
      "epoch": 2.8,
      "grad_norm": 44.5,
      "learning_rate": 0.0001079683377308707,
      "loss": 1.2031,
      "step": 2124
    },
    {
      "epoch": 2.8,
      "grad_norm": 60.25,
      "learning_rate": 0.00010794854881266489,
      "loss": 1.0703,
      "step": 2125
    },
    {
      "epoch": 2.8,
      "grad_norm": 217.0,
      "learning_rate": 0.00010792875989445908,
      "loss": 5.5,
      "step": 2126
    },
    {
      "epoch": 2.81,
      "grad_norm": 47.0,
      "learning_rate": 0.00010790897097625328,
      "loss": 0.4258,
      "step": 2127
    },
    {
      "epoch": 2.81,
      "grad_norm": 29.625,
      "learning_rate": 0.00010788918205804748,
      "loss": 0.2363,
      "step": 2128
    },
    {
      "epoch": 2.81,
      "grad_norm": 50.0,
      "learning_rate": 0.00010786939313984168,
      "loss": 0.5898,
      "step": 2129
    },
    {
      "epoch": 2.81,
      "grad_norm": 52.25,
      "learning_rate": 0.00010784960422163588,
      "loss": 0.3535,
      "step": 2130
    },
    {
      "epoch": 2.81,
      "grad_norm": 30.125,
      "learning_rate": 0.00010782981530343006,
      "loss": 0.3789,
      "step": 2131
    },
    {
      "epoch": 2.81,
      "grad_norm": 31.125,
      "learning_rate": 0.00010781002638522426,
      "loss": 0.4336,
      "step": 2132
    },
    {
      "epoch": 2.81,
      "grad_norm": 139.0,
      "learning_rate": 0.00010779023746701846,
      "loss": 1.6094,
      "step": 2133
    },
    {
      "epoch": 2.82,
      "grad_norm": 18.25,
      "learning_rate": 0.00010777044854881266,
      "loss": 0.4609,
      "step": 2134
    },
    {
      "epoch": 2.82,
      "grad_norm": 15.875,
      "learning_rate": 0.00010775065963060685,
      "loss": 0.4121,
      "step": 2135
    },
    {
      "epoch": 2.82,
      "grad_norm": 320.0,
      "learning_rate": 0.00010773087071240105,
      "loss": 7.2188,
      "step": 2136
    },
    {
      "epoch": 2.82,
      "grad_norm": 57.75,
      "learning_rate": 0.00010771108179419524,
      "loss": 0.5312,
      "step": 2137
    },
    {
      "epoch": 2.82,
      "grad_norm": 8.75,
      "learning_rate": 0.00010769129287598943,
      "loss": 0.3242,
      "step": 2138
    },
    {
      "epoch": 2.82,
      "grad_norm": 239.0,
      "learning_rate": 0.00010767150395778363,
      "loss": 5.5625,
      "step": 2139
    },
    {
      "epoch": 2.82,
      "grad_norm": 13.6875,
      "learning_rate": 0.00010765171503957783,
      "loss": 0.1758,
      "step": 2140
    },
    {
      "epoch": 2.82,
      "grad_norm": 18.0,
      "learning_rate": 0.00010763192612137203,
      "loss": 0.334,
      "step": 2141
    },
    {
      "epoch": 2.83,
      "grad_norm": 158.0,
      "learning_rate": 0.00010761213720316623,
      "loss": 3.1094,
      "step": 2142
    },
    {
      "epoch": 2.83,
      "grad_norm": 45.5,
      "learning_rate": 0.00010759234828496041,
      "loss": 0.4746,
      "step": 2143
    },
    {
      "epoch": 2.83,
      "grad_norm": 32.5,
      "learning_rate": 0.00010757255936675461,
      "loss": 0.4805,
      "step": 2144
    },
    {
      "epoch": 2.83,
      "grad_norm": 8.875,
      "learning_rate": 0.00010755277044854881,
      "loss": 0.4297,
      "step": 2145
    },
    {
      "epoch": 2.83,
      "grad_norm": 36.0,
      "learning_rate": 0.000107532981530343,
      "loss": 0.4395,
      "step": 2146
    },
    {
      "epoch": 2.83,
      "grad_norm": 7.34375,
      "learning_rate": 0.0001075131926121372,
      "loss": 0.293,
      "step": 2147
    },
    {
      "epoch": 2.83,
      "grad_norm": 12.8125,
      "learning_rate": 0.0001074934036939314,
      "loss": 0.2676,
      "step": 2148
    },
    {
      "epoch": 2.84,
      "grad_norm": 4.53125,
      "learning_rate": 0.00010747361477572559,
      "loss": 0.2617,
      "step": 2149
    },
    {
      "epoch": 2.84,
      "grad_norm": 14.8125,
      "learning_rate": 0.00010745382585751978,
      "loss": 0.3555,
      "step": 2150
    },
    {
      "epoch": 2.84,
      "grad_norm": 55.25,
      "learning_rate": 0.00010743403693931397,
      "loss": 0.5508,
      "step": 2151
    },
    {
      "epoch": 2.84,
      "grad_norm": 188.0,
      "learning_rate": 0.00010741424802110817,
      "loss": 3.7969,
      "step": 2152
    },
    {
      "epoch": 2.84,
      "grad_norm": 8.375,
      "learning_rate": 0.00010739445910290236,
      "loss": 0.2734,
      "step": 2153
    },
    {
      "epoch": 2.84,
      "grad_norm": 154.0,
      "learning_rate": 0.00010737467018469655,
      "loss": 3.5938,
      "step": 2154
    },
    {
      "epoch": 2.84,
      "grad_norm": 8.625,
      "learning_rate": 0.00010735488126649075,
      "loss": 0.0496,
      "step": 2155
    },
    {
      "epoch": 2.84,
      "grad_norm": 560.0,
      "learning_rate": 0.00010733509234828495,
      "loss": 15.6875,
      "step": 2156
    },
    {
      "epoch": 2.85,
      "grad_norm": 25.75,
      "learning_rate": 0.00010731530343007914,
      "loss": 0.4707,
      "step": 2157
    },
    {
      "epoch": 2.85,
      "grad_norm": 13.125,
      "learning_rate": 0.00010729551451187334,
      "loss": 0.377,
      "step": 2158
    },
    {
      "epoch": 2.85,
      "grad_norm": 161.0,
      "learning_rate": 0.00010727572559366754,
      "loss": 3.4062,
      "step": 2159
    },
    {
      "epoch": 2.85,
      "grad_norm": 31.875,
      "learning_rate": 0.00010725593667546172,
      "loss": 1.1016,
      "step": 2160
    },
    {
      "epoch": 2.85,
      "grad_norm": 42.0,
      "learning_rate": 0.00010723614775725592,
      "loss": 0.2197,
      "step": 2161
    },
    {
      "epoch": 2.85,
      "grad_norm": 170.0,
      "learning_rate": 0.00010721635883905012,
      "loss": 3.625,
      "step": 2162
    },
    {
      "epoch": 2.85,
      "grad_norm": 159.0,
      "learning_rate": 0.00010719656992084432,
      "loss": 3.3281,
      "step": 2163
    },
    {
      "epoch": 2.85,
      "grad_norm": 336.0,
      "learning_rate": 0.00010717678100263852,
      "loss": 6.7188,
      "step": 2164
    },
    {
      "epoch": 2.86,
      "grad_norm": 226.0,
      "learning_rate": 0.00010715699208443271,
      "loss": 3.2969,
      "step": 2165
    },
    {
      "epoch": 2.86,
      "grad_norm": 207.0,
      "learning_rate": 0.0001071372031662269,
      "loss": 2.6562,
      "step": 2166
    },
    {
      "epoch": 2.86,
      "grad_norm": 35.0,
      "learning_rate": 0.0001071174142480211,
      "loss": 0.5391,
      "step": 2167
    },
    {
      "epoch": 2.86,
      "grad_norm": 146.0,
      "learning_rate": 0.0001070976253298153,
      "loss": 1.8438,
      "step": 2168
    },
    {
      "epoch": 2.86,
      "grad_norm": 53.0,
      "learning_rate": 0.00010707783641160949,
      "loss": 0.5273,
      "step": 2169
    },
    {
      "epoch": 2.86,
      "grad_norm": 66.5,
      "learning_rate": 0.00010705804749340369,
      "loss": 0.7148,
      "step": 2170
    },
    {
      "epoch": 2.86,
      "grad_norm": 13.25,
      "learning_rate": 0.00010703825857519789,
      "loss": 0.1865,
      "step": 2171
    },
    {
      "epoch": 2.87,
      "grad_norm": 48.25,
      "learning_rate": 0.00010701846965699207,
      "loss": 0.377,
      "step": 2172
    },
    {
      "epoch": 2.87,
      "grad_norm": 43.75,
      "learning_rate": 0.00010699868073878627,
      "loss": 0.6094,
      "step": 2173
    },
    {
      "epoch": 2.87,
      "grad_norm": 34.75,
      "learning_rate": 0.00010697889182058047,
      "loss": 0.3691,
      "step": 2174
    },
    {
      "epoch": 2.87,
      "grad_norm": 224.0,
      "learning_rate": 0.00010695910290237467,
      "loss": 2.125,
      "step": 2175
    },
    {
      "epoch": 2.87,
      "grad_norm": 98.5,
      "learning_rate": 0.00010693931398416887,
      "loss": 1.5703,
      "step": 2176
    },
    {
      "epoch": 2.87,
      "grad_norm": 45.5,
      "learning_rate": 0.00010691952506596306,
      "loss": 0.5547,
      "step": 2177
    },
    {
      "epoch": 2.87,
      "grad_norm": 53.5,
      "learning_rate": 0.00010689973614775725,
      "loss": 0.4434,
      "step": 2178
    },
    {
      "epoch": 2.87,
      "grad_norm": 34.0,
      "learning_rate": 0.00010687994722955145,
      "loss": 0.2559,
      "step": 2179
    },
    {
      "epoch": 2.88,
      "grad_norm": 30.375,
      "learning_rate": 0.00010686015831134564,
      "loss": 0.4688,
      "step": 2180
    },
    {
      "epoch": 2.88,
      "grad_norm": 27.25,
      "learning_rate": 0.00010684036939313983,
      "loss": 0.4336,
      "step": 2181
    },
    {
      "epoch": 2.88,
      "grad_norm": 46.25,
      "learning_rate": 0.00010682058047493401,
      "loss": 0.3418,
      "step": 2182
    },
    {
      "epoch": 2.88,
      "grad_norm": 118.0,
      "learning_rate": 0.00010680079155672821,
      "loss": 1.5391,
      "step": 2183
    },
    {
      "epoch": 2.88,
      "grad_norm": 282.0,
      "learning_rate": 0.00010678100263852241,
      "loss": 6.0938,
      "step": 2184
    },
    {
      "epoch": 2.88,
      "grad_norm": 224.0,
      "learning_rate": 0.00010676121372031661,
      "loss": 5.7812,
      "step": 2185
    },
    {
      "epoch": 2.88,
      "grad_norm": 123.5,
      "learning_rate": 0.0001067414248021108,
      "loss": 1.7109,
      "step": 2186
    },
    {
      "epoch": 2.89,
      "grad_norm": 256.0,
      "learning_rate": 0.000106721635883905,
      "loss": 4.9688,
      "step": 2187
    },
    {
      "epoch": 2.89,
      "grad_norm": 258.0,
      "learning_rate": 0.00010670184696569919,
      "loss": 4.7812,
      "step": 2188
    },
    {
      "epoch": 2.89,
      "grad_norm": 23.375,
      "learning_rate": 0.00010668205804749339,
      "loss": 0.4492,
      "step": 2189
    },
    {
      "epoch": 2.89,
      "grad_norm": 36.25,
      "learning_rate": 0.00010666226912928758,
      "loss": 0.5781,
      "step": 2190
    },
    {
      "epoch": 2.89,
      "grad_norm": 18.625,
      "learning_rate": 0.00010664248021108178,
      "loss": 0.3633,
      "step": 2191
    },
    {
      "epoch": 2.89,
      "grad_norm": 130.0,
      "learning_rate": 0.00010662269129287598,
      "loss": 1.8828,
      "step": 2192
    },
    {
      "epoch": 2.89,
      "grad_norm": 62.5,
      "learning_rate": 0.00010660290237467018,
      "loss": 0.4648,
      "step": 2193
    },
    {
      "epoch": 2.89,
      "grad_norm": 129.0,
      "learning_rate": 0.00010658311345646436,
      "loss": 1.9844,
      "step": 2194
    },
    {
      "epoch": 2.9,
      "grad_norm": 15.8125,
      "learning_rate": 0.00010656332453825856,
      "loss": 0.3887,
      "step": 2195
    },
    {
      "epoch": 2.9,
      "grad_norm": 20.0,
      "learning_rate": 0.00010654353562005276,
      "loss": 0.3262,
      "step": 2196
    },
    {
      "epoch": 2.9,
      "grad_norm": 21.375,
      "learning_rate": 0.00010652374670184696,
      "loss": 0.2188,
      "step": 2197
    },
    {
      "epoch": 2.9,
      "grad_norm": 134.0,
      "learning_rate": 0.00010650395778364116,
      "loss": 2.0156,
      "step": 2198
    },
    {
      "epoch": 2.9,
      "grad_norm": 33.5,
      "learning_rate": 0.00010648416886543535,
      "loss": 0.3926,
      "step": 2199
    },
    {
      "epoch": 2.9,
      "grad_norm": 53.0,
      "learning_rate": 0.00010646437994722954,
      "loss": 0.5586,
      "step": 2200
    },
    {
      "epoch": 2.9,
      "grad_norm": 458.0,
      "learning_rate": 0.00010644459102902374,
      "loss": 6.8125,
      "step": 2201
    },
    {
      "epoch": 2.91,
      "grad_norm": 135.0,
      "learning_rate": 0.00010642480211081793,
      "loss": 1.9766,
      "step": 2202
    },
    {
      "epoch": 2.91,
      "grad_norm": 136.0,
      "learning_rate": 0.00010640501319261213,
      "loss": 1.9297,
      "step": 2203
    },
    {
      "epoch": 2.91,
      "grad_norm": 137.0,
      "learning_rate": 0.00010638522427440633,
      "loss": 1.9062,
      "step": 2204
    },
    {
      "epoch": 2.91,
      "grad_norm": 219.0,
      "learning_rate": 0.00010636543535620053,
      "loss": 3.6094,
      "step": 2205
    },
    {
      "epoch": 2.91,
      "grad_norm": 117.5,
      "learning_rate": 0.00010634564643799473,
      "loss": 1.7109,
      "step": 2206
    },
    {
      "epoch": 2.91,
      "grad_norm": 38.75,
      "learning_rate": 0.00010632585751978891,
      "loss": 0.9414,
      "step": 2207
    },
    {
      "epoch": 2.91,
      "grad_norm": 113.5,
      "learning_rate": 0.00010630606860158311,
      "loss": 1.6328,
      "step": 2208
    },
    {
      "epoch": 2.91,
      "grad_norm": 34.5,
      "learning_rate": 0.0001062862796833773,
      "loss": 0.5234,
      "step": 2209
    },
    {
      "epoch": 2.92,
      "grad_norm": 209.0,
      "learning_rate": 0.0001062664907651715,
      "loss": 1.7578,
      "step": 2210
    },
    {
      "epoch": 2.92,
      "grad_norm": 222.0,
      "learning_rate": 0.00010624670184696568,
      "loss": 3.5469,
      "step": 2211
    },
    {
      "epoch": 2.92,
      "grad_norm": 72.0,
      "learning_rate": 0.00010622691292875987,
      "loss": 0.9297,
      "step": 2212
    },
    {
      "epoch": 2.92,
      "grad_norm": 50.5,
      "learning_rate": 0.00010620712401055407,
      "loss": 0.9766,
      "step": 2213
    },
    {
      "epoch": 2.92,
      "grad_norm": 264.0,
      "learning_rate": 0.00010618733509234827,
      "loss": 4.0,
      "step": 2214
    },
    {
      "epoch": 2.92,
      "grad_norm": 30.25,
      "learning_rate": 0.00010616754617414247,
      "loss": 0.7969,
      "step": 2215
    },
    {
      "epoch": 2.92,
      "grad_norm": 151.0,
      "learning_rate": 0.00010614775725593667,
      "loss": 2.375,
      "step": 2216
    },
    {
      "epoch": 2.92,
      "grad_norm": 103.0,
      "learning_rate": 0.00010612796833773085,
      "loss": 1.2656,
      "step": 2217
    },
    {
      "epoch": 2.93,
      "grad_norm": 216.0,
      "learning_rate": 0.00010610817941952505,
      "loss": 3.8125,
      "step": 2218
    },
    {
      "epoch": 2.93,
      "grad_norm": 28.125,
      "learning_rate": 0.00010608839050131925,
      "loss": 0.6211,
      "step": 2219
    },
    {
      "epoch": 2.93,
      "grad_norm": 90.0,
      "learning_rate": 0.00010606860158311344,
      "loss": 1.1406,
      "step": 2220
    },
    {
      "epoch": 2.93,
      "grad_norm": 107.5,
      "learning_rate": 0.00010604881266490764,
      "loss": 1.2578,
      "step": 2221
    },
    {
      "epoch": 2.93,
      "grad_norm": 34.5,
      "learning_rate": 0.00010602902374670184,
      "loss": 1.2422,
      "step": 2222
    },
    {
      "epoch": 2.93,
      "grad_norm": 80.5,
      "learning_rate": 0.00010600923482849603,
      "loss": 0.9453,
      "step": 2223
    },
    {
      "epoch": 2.93,
      "grad_norm": 78.0,
      "learning_rate": 0.00010598944591029022,
      "loss": 0.8555,
      "step": 2224
    },
    {
      "epoch": 2.94,
      "grad_norm": 93.0,
      "learning_rate": 0.00010596965699208442,
      "loss": 0.7383,
      "step": 2225
    },
    {
      "epoch": 2.94,
      "grad_norm": 41.0,
      "learning_rate": 0.00010594986807387862,
      "loss": 0.9102,
      "step": 2226
    },
    {
      "epoch": 2.94,
      "grad_norm": 62.0,
      "learning_rate": 0.00010593007915567282,
      "loss": 0.7031,
      "step": 2227
    },
    {
      "epoch": 2.94,
      "grad_norm": 71.0,
      "learning_rate": 0.00010591029023746702,
      "loss": 1.0312,
      "step": 2228
    },
    {
      "epoch": 2.94,
      "grad_norm": 47.75,
      "learning_rate": 0.0001058905013192612,
      "loss": 0.5977,
      "step": 2229
    },
    {
      "epoch": 2.94,
      "grad_norm": 230.0,
      "learning_rate": 0.0001058707124010554,
      "loss": 4.0,
      "step": 2230
    },
    {
      "epoch": 2.94,
      "grad_norm": 109.5,
      "learning_rate": 0.0001058509234828496,
      "loss": 1.5156,
      "step": 2231
    },
    {
      "epoch": 2.94,
      "grad_norm": 139.0,
      "learning_rate": 0.0001058311345646438,
      "loss": 1.8203,
      "step": 2232
    },
    {
      "epoch": 2.95,
      "grad_norm": 266.0,
      "learning_rate": 0.00010581134564643799,
      "loss": 4.4375,
      "step": 2233
    },
    {
      "epoch": 2.95,
      "grad_norm": 53.5,
      "learning_rate": 0.00010579155672823219,
      "loss": 0.7734,
      "step": 2234
    },
    {
      "epoch": 2.95,
      "grad_norm": 117.0,
      "learning_rate": 0.00010577176781002637,
      "loss": 1.4453,
      "step": 2235
    },
    {
      "epoch": 2.95,
      "grad_norm": 44.75,
      "learning_rate": 0.00010575197889182057,
      "loss": 0.9375,
      "step": 2236
    },
    {
      "epoch": 2.95,
      "grad_norm": 36.25,
      "learning_rate": 0.00010573218997361477,
      "loss": 0.6172,
      "step": 2237
    },
    {
      "epoch": 2.95,
      "grad_norm": 110.5,
      "learning_rate": 0.00010571240105540897,
      "loss": 1.5391,
      "step": 2238
    },
    {
      "epoch": 2.95,
      "grad_norm": 246.0,
      "learning_rate": 0.00010569261213720317,
      "loss": 3.625,
      "step": 2239
    },
    {
      "epoch": 2.96,
      "grad_norm": 106.0,
      "learning_rate": 0.00010567282321899737,
      "loss": 1.2422,
      "step": 2240
    },
    {
      "epoch": 2.96,
      "grad_norm": 103.5,
      "learning_rate": 0.00010565303430079154,
      "loss": 1.6953,
      "step": 2241
    },
    {
      "epoch": 2.96,
      "grad_norm": 57.25,
      "learning_rate": 0.00010563324538258573,
      "loss": 0.6445,
      "step": 2242
    },
    {
      "epoch": 2.96,
      "grad_norm": 35.75,
      "learning_rate": 0.00010561345646437993,
      "loss": 0.4707,
      "step": 2243
    },
    {
      "epoch": 2.96,
      "grad_norm": 39.75,
      "learning_rate": 0.00010559366754617413,
      "loss": 0.5586,
      "step": 2244
    },
    {
      "epoch": 2.96,
      "grad_norm": 77.0,
      "learning_rate": 0.00010557387862796833,
      "loss": 0.8125,
      "step": 2245
    },
    {
      "epoch": 2.96,
      "grad_norm": 62.0,
      "learning_rate": 0.00010555408970976251,
      "loss": 1.1094,
      "step": 2246
    },
    {
      "epoch": 2.96,
      "grad_norm": 41.5,
      "learning_rate": 0.00010553430079155671,
      "loss": 0.543,
      "step": 2247
    },
    {
      "epoch": 2.97,
      "grad_norm": 38.5,
      "learning_rate": 0.00010551451187335091,
      "loss": 0.5703,
      "step": 2248
    },
    {
      "epoch": 2.97,
      "grad_norm": 220.0,
      "learning_rate": 0.00010549472295514511,
      "loss": 4.375,
      "step": 2249
    },
    {
      "epoch": 2.97,
      "grad_norm": 33.75,
      "learning_rate": 0.0001054749340369393,
      "loss": 0.3691,
      "step": 2250
    },
    {
      "epoch": 2.97,
      "grad_norm": 292.0,
      "learning_rate": 0.0001054551451187335,
      "loss": 5.75,
      "step": 2251
    },
    {
      "epoch": 2.97,
      "grad_norm": 100.5,
      "learning_rate": 0.00010543535620052769,
      "loss": 1.3281,
      "step": 2252
    },
    {
      "epoch": 2.97,
      "grad_norm": 29.125,
      "learning_rate": 0.00010541556728232189,
      "loss": 0.2832,
      "step": 2253
    },
    {
      "epoch": 2.97,
      "grad_norm": 33.25,
      "learning_rate": 0.00010539577836411608,
      "loss": 0.4863,
      "step": 2254
    },
    {
      "epoch": 2.97,
      "grad_norm": 21.5,
      "learning_rate": 0.00010537598944591028,
      "loss": 0.4238,
      "step": 2255
    },
    {
      "epoch": 2.98,
      "grad_norm": 23.25,
      "learning_rate": 0.00010535620052770448,
      "loss": 0.6641,
      "step": 2256
    },
    {
      "epoch": 2.98,
      "grad_norm": 228.0,
      "learning_rate": 0.00010533641160949868,
      "loss": 4.1562,
      "step": 2257
    },
    {
      "epoch": 2.98,
      "grad_norm": 308.0,
      "learning_rate": 0.00010531662269129286,
      "loss": 6.1875,
      "step": 2258
    },
    {
      "epoch": 2.98,
      "grad_norm": 13.625,
      "learning_rate": 0.00010529683377308706,
      "loss": 0.1836,
      "step": 2259
    },
    {
      "epoch": 2.98,
      "grad_norm": 264.0,
      "learning_rate": 0.00010527704485488126,
      "loss": 4.6562,
      "step": 2260
    },
    {
      "epoch": 2.98,
      "grad_norm": 11.625,
      "learning_rate": 0.00010525725593667546,
      "loss": 0.2197,
      "step": 2261
    },
    {
      "epoch": 2.98,
      "grad_norm": 40.75,
      "learning_rate": 0.00010523746701846965,
      "loss": 0.5547,
      "step": 2262
    },
    {
      "epoch": 2.99,
      "grad_norm": 24.75,
      "learning_rate": 0.00010521767810026385,
      "loss": 0.4531,
      "step": 2263
    },
    {
      "epoch": 2.99,
      "grad_norm": 166.0,
      "learning_rate": 0.00010519788918205804,
      "loss": 2.875,
      "step": 2264
    },
    {
      "epoch": 2.99,
      "grad_norm": 7.3125,
      "learning_rate": 0.00010517810026385224,
      "loss": 0.1504,
      "step": 2265
    },
    {
      "epoch": 2.99,
      "grad_norm": 8.0625,
      "learning_rate": 0.00010515831134564643,
      "loss": 0.1621,
      "step": 2266
    },
    {
      "epoch": 2.99,
      "grad_norm": 21.875,
      "learning_rate": 0.00010513852242744063,
      "loss": 0.4102,
      "step": 2267
    },
    {
      "epoch": 2.99,
      "grad_norm": 54.0,
      "learning_rate": 0.00010511873350923483,
      "loss": 0.6094,
      "step": 2268
    },
    {
      "epoch": 2.99,
      "grad_norm": 46.0,
      "learning_rate": 0.00010509894459102903,
      "loss": 0.6055,
      "step": 2269
    },
    {
      "epoch": 2.99,
      "grad_norm": 243.0,
      "learning_rate": 0.00010507915567282321,
      "loss": 3.9844,
      "step": 2270
    },
    {
      "epoch": 3.0,
      "grad_norm": 23.0,
      "learning_rate": 0.0001050593667546174,
      "loss": 0.2754,
      "step": 2271
    },
    {
      "epoch": 3.0,
      "grad_norm": 246.0,
      "learning_rate": 0.0001050395778364116,
      "loss": 4.0,
      "step": 2272
    },
    {
      "epoch": 3.0,
      "grad_norm": 56.25,
      "learning_rate": 0.00010501978891820579,
      "loss": 1.1953,
      "step": 2273
    },
    {
      "epoch": 3.0,
      "grad_norm": 350.0,
      "learning_rate": 0.00010499999999999999,
      "loss": 5.2812,
      "step": 2274
    },
    {
      "epoch": 3.0,
      "eval_loss": 2.426910161972046,
      "eval_runtime": 18.3348,
      "eval_samples_per_second": 42.651,
      "eval_steps_per_second": 10.69,
      "step": 2274
    },
    {
      "epoch": 3.0,
      "grad_norm": 300.0,
      "learning_rate": 0.00010498021108179418,
      "loss": 6.625,
      "step": 2275
    },
    {
      "epoch": 3.0,
      "grad_norm": 88.0,
      "learning_rate": 0.00010496042216358837,
      "loss": 0.6562,
      "step": 2276
    },
    {
      "epoch": 3.0,
      "grad_norm": 11.0625,
      "learning_rate": 0.00010494063324538257,
      "loss": 0.2715,
      "step": 2277
    },
    {
      "epoch": 3.01,
      "grad_norm": 169.0,
      "learning_rate": 0.00010492084432717677,
      "loss": 3.4375,
      "step": 2278
    },
    {
      "epoch": 3.01,
      "grad_norm": 254.0,
      "learning_rate": 0.00010490105540897097,
      "loss": 3.0,
      "step": 2279
    },
    {
      "epoch": 3.01,
      "grad_norm": 68.0,
      "learning_rate": 0.00010488126649076517,
      "loss": 0.5078,
      "step": 2280
    },
    {
      "epoch": 3.01,
      "grad_norm": 63.0,
      "learning_rate": 0.00010486147757255935,
      "loss": 0.4512,
      "step": 2281
    },
    {
      "epoch": 3.01,
      "grad_norm": 212.0,
      "learning_rate": 0.00010484168865435355,
      "loss": 3.9688,
      "step": 2282
    },
    {
      "epoch": 3.01,
      "grad_norm": 55.0,
      "learning_rate": 0.00010482189973614775,
      "loss": 0.3223,
      "step": 2283
    },
    {
      "epoch": 3.01,
      "grad_norm": 466.0,
      "learning_rate": 0.00010480211081794194,
      "loss": 6.3125,
      "step": 2284
    },
    {
      "epoch": 3.01,
      "grad_norm": 25.5,
      "learning_rate": 0.00010478232189973614,
      "loss": 0.1533,
      "step": 2285
    },
    {
      "epoch": 3.02,
      "grad_norm": 72.0,
      "learning_rate": 0.00010476253298153034,
      "loss": 0.9531,
      "step": 2286
    },
    {
      "epoch": 3.02,
      "grad_norm": 314.0,
      "learning_rate": 0.00010474274406332452,
      "loss": 3.5312,
      "step": 2287
    },
    {
      "epoch": 3.02,
      "grad_norm": 20.125,
      "learning_rate": 0.00010472295514511872,
      "loss": 0.0928,
      "step": 2288
    },
    {
      "epoch": 3.02,
      "grad_norm": 16.875,
      "learning_rate": 0.00010470316622691292,
      "loss": 0.0762,
      "step": 2289
    },
    {
      "epoch": 3.02,
      "grad_norm": 38.75,
      "learning_rate": 0.00010468337730870712,
      "loss": 0.6992,
      "step": 2290
    },
    {
      "epoch": 3.02,
      "grad_norm": 304.0,
      "learning_rate": 0.00010466358839050132,
      "loss": 3.6719,
      "step": 2291
    },
    {
      "epoch": 3.02,
      "grad_norm": 210.0,
      "learning_rate": 0.00010464379947229552,
      "loss": 3.625,
      "step": 2292
    },
    {
      "epoch": 3.03,
      "grad_norm": 185.0,
      "learning_rate": 0.0001046240105540897,
      "loss": 2.9844,
      "step": 2293
    },
    {
      "epoch": 3.03,
      "grad_norm": 500.0,
      "learning_rate": 0.0001046042216358839,
      "loss": 4.6875,
      "step": 2294
    },
    {
      "epoch": 3.03,
      "grad_norm": 233.0,
      "learning_rate": 0.0001045844327176781,
      "loss": 3.9531,
      "step": 2295
    },
    {
      "epoch": 3.03,
      "grad_norm": 280.0,
      "learning_rate": 0.0001045646437994723,
      "loss": 3.2344,
      "step": 2296
    },
    {
      "epoch": 3.03,
      "grad_norm": 54.0,
      "learning_rate": 0.00010454485488126649,
      "loss": 0.7422,
      "step": 2297
    },
    {
      "epoch": 3.03,
      "grad_norm": 74.0,
      "learning_rate": 0.00010452506596306069,
      "loss": 1.1328,
      "step": 2298
    },
    {
      "epoch": 3.03,
      "grad_norm": 37.5,
      "learning_rate": 0.00010450527704485487,
      "loss": 0.375,
      "step": 2299
    },
    {
      "epoch": 3.03,
      "grad_norm": 42.0,
      "learning_rate": 0.00010448548812664907,
      "loss": 0.373,
      "step": 2300
    },
    {
      "epoch": 3.04,
      "grad_norm": 266.0,
      "learning_rate": 0.00010446569920844327,
      "loss": 3.7969,
      "step": 2301
    },
    {
      "epoch": 3.04,
      "grad_norm": 32.25,
      "learning_rate": 0.00010444591029023746,
      "loss": 0.2578,
      "step": 2302
    },
    {
      "epoch": 3.04,
      "grad_norm": 414.0,
      "learning_rate": 0.00010442612137203164,
      "loss": 3.6875,
      "step": 2303
    },
    {
      "epoch": 3.04,
      "grad_norm": 33.5,
      "learning_rate": 0.00010440633245382584,
      "loss": 0.3672,
      "step": 2304
    },
    {
      "epoch": 3.04,
      "grad_norm": 183.0,
      "learning_rate": 0.00010438654353562004,
      "loss": 2.2344,
      "step": 2305
    },
    {
      "epoch": 3.04,
      "grad_norm": 43.5,
      "learning_rate": 0.00010436675461741423,
      "loss": 0.6758,
      "step": 2306
    },
    {
      "epoch": 3.04,
      "grad_norm": 164.0,
      "learning_rate": 0.00010434696569920843,
      "loss": 2.0938,
      "step": 2307
    },
    {
      "epoch": 3.04,
      "grad_norm": 37.5,
      "learning_rate": 0.00010432717678100263,
      "loss": 0.6328,
      "step": 2308
    },
    {
      "epoch": 3.05,
      "grad_norm": 38.0,
      "learning_rate": 0.00010430738786279681,
      "loss": 0.377,
      "step": 2309
    },
    {
      "epoch": 3.05,
      "grad_norm": 63.25,
      "learning_rate": 0.00010428759894459101,
      "loss": 0.6094,
      "step": 2310
    },
    {
      "epoch": 3.05,
      "grad_norm": 147.0,
      "learning_rate": 0.00010426781002638521,
      "loss": 2.2188,
      "step": 2311
    },
    {
      "epoch": 3.05,
      "grad_norm": 48.75,
      "learning_rate": 0.00010424802110817941,
      "loss": 0.6289,
      "step": 2312
    },
    {
      "epoch": 3.05,
      "grad_norm": 31.25,
      "learning_rate": 0.0001042282321899736,
      "loss": 1.0078,
      "step": 2313
    },
    {
      "epoch": 3.05,
      "grad_norm": 52.75,
      "learning_rate": 0.0001042084432717678,
      "loss": 0.5312,
      "step": 2314
    },
    {
      "epoch": 3.05,
      "grad_norm": 31.875,
      "learning_rate": 0.00010418865435356199,
      "loss": 0.2656,
      "step": 2315
    },
    {
      "epoch": 3.06,
      "grad_norm": 131.0,
      "learning_rate": 0.00010416886543535619,
      "loss": 2.2812,
      "step": 2316
    },
    {
      "epoch": 3.06,
      "grad_norm": 205.0,
      "learning_rate": 0.00010414907651715039,
      "loss": 3.125,
      "step": 2317
    },
    {
      "epoch": 3.06,
      "grad_norm": 33.0,
      "learning_rate": 0.00010412928759894458,
      "loss": 0.2129,
      "step": 2318
    },
    {
      "epoch": 3.06,
      "grad_norm": 214.0,
      "learning_rate": 0.00010410949868073878,
      "loss": 5.1875,
      "step": 2319
    },
    {
      "epoch": 3.06,
      "grad_norm": 22.125,
      "learning_rate": 0.00010408970976253298,
      "loss": 0.4863,
      "step": 2320
    },
    {
      "epoch": 3.06,
      "grad_norm": 222.0,
      "learning_rate": 0.00010406992084432716,
      "loss": 3.625,
      "step": 2321
    },
    {
      "epoch": 3.06,
      "grad_norm": 219.0,
      "learning_rate": 0.00010405013192612136,
      "loss": 3.7031,
      "step": 2322
    },
    {
      "epoch": 3.06,
      "grad_norm": 152.0,
      "learning_rate": 0.00010403034300791556,
      "loss": 2.3281,
      "step": 2323
    },
    {
      "epoch": 3.07,
      "grad_norm": 12.9375,
      "learning_rate": 0.00010401055408970976,
      "loss": 0.1113,
      "step": 2324
    },
    {
      "epoch": 3.07,
      "grad_norm": 258.0,
      "learning_rate": 0.00010399076517150396,
      "loss": 4.7188,
      "step": 2325
    },
    {
      "epoch": 3.07,
      "grad_norm": 26.0,
      "learning_rate": 0.00010397097625329815,
      "loss": 0.5508,
      "step": 2326
    },
    {
      "epoch": 3.07,
      "grad_norm": 288.0,
      "learning_rate": 0.00010395118733509234,
      "loss": 4.2812,
      "step": 2327
    },
    {
      "epoch": 3.07,
      "grad_norm": 21.75,
      "learning_rate": 0.00010393139841688654,
      "loss": 0.582,
      "step": 2328
    },
    {
      "epoch": 3.07,
      "grad_norm": 34.25,
      "learning_rate": 0.00010391160949868073,
      "loss": 0.3789,
      "step": 2329
    },
    {
      "epoch": 3.07,
      "grad_norm": 24.25,
      "learning_rate": 0.00010389182058047493,
      "loss": 0.6562,
      "step": 2330
    },
    {
      "epoch": 3.08,
      "grad_norm": 134.0,
      "learning_rate": 0.00010387203166226913,
      "loss": 1.9453,
      "step": 2331
    },
    {
      "epoch": 3.08,
      "grad_norm": 26.375,
      "learning_rate": 0.0001038522427440633,
      "loss": 0.4258,
      "step": 2332
    },
    {
      "epoch": 3.08,
      "grad_norm": 19.375,
      "learning_rate": 0.0001038324538258575,
      "loss": 0.291,
      "step": 2333
    },
    {
      "epoch": 3.08,
      "grad_norm": 120.0,
      "learning_rate": 0.0001038126649076517,
      "loss": 2.0,
      "step": 2334
    },
    {
      "epoch": 3.08,
      "grad_norm": 135.0,
      "learning_rate": 0.0001037928759894459,
      "loss": 2.0156,
      "step": 2335
    },
    {
      "epoch": 3.08,
      "grad_norm": 64.5,
      "learning_rate": 0.0001037730870712401,
      "loss": 0.8086,
      "step": 2336
    },
    {
      "epoch": 3.08,
      "grad_norm": 219.0,
      "learning_rate": 0.00010375329815303429,
      "loss": 3.7969,
      "step": 2337
    },
    {
      "epoch": 3.08,
      "grad_norm": 21.75,
      "learning_rate": 0.00010373350923482848,
      "loss": 0.2871,
      "step": 2338
    },
    {
      "epoch": 3.09,
      "grad_norm": 222.0,
      "learning_rate": 0.00010371372031662267,
      "loss": 3.8125,
      "step": 2339
    },
    {
      "epoch": 3.09,
      "grad_norm": 39.75,
      "learning_rate": 0.00010369393139841687,
      "loss": 0.4707,
      "step": 2340
    },
    {
      "epoch": 3.09,
      "grad_norm": 49.5,
      "learning_rate": 0.00010367414248021107,
      "loss": 0.416,
      "step": 2341
    },
    {
      "epoch": 3.09,
      "grad_norm": 262.0,
      "learning_rate": 0.00010365435356200527,
      "loss": 4.625,
      "step": 2342
    },
    {
      "epoch": 3.09,
      "grad_norm": 247.0,
      "learning_rate": 0.00010363456464379947,
      "loss": 2.9219,
      "step": 2343
    },
    {
      "epoch": 3.09,
      "grad_norm": 112.5,
      "learning_rate": 0.00010361477572559365,
      "loss": 1.7344,
      "step": 2344
    },
    {
      "epoch": 3.09,
      "grad_norm": 61.5,
      "learning_rate": 0.00010359498680738785,
      "loss": 0.4336,
      "step": 2345
    },
    {
      "epoch": 3.09,
      "grad_norm": 53.5,
      "learning_rate": 0.00010357519788918205,
      "loss": 0.5312,
      "step": 2346
    },
    {
      "epoch": 3.1,
      "grad_norm": 219.0,
      "learning_rate": 0.00010355540897097625,
      "loss": 3.5938,
      "step": 2347
    },
    {
      "epoch": 3.1,
      "grad_norm": 44.0,
      "learning_rate": 0.00010353562005277044,
      "loss": 0.3066,
      "step": 2348
    },
    {
      "epoch": 3.1,
      "grad_norm": 25.125,
      "learning_rate": 0.00010351583113456464,
      "loss": 0.7305,
      "step": 2349
    },
    {
      "epoch": 3.1,
      "grad_norm": 110.0,
      "learning_rate": 0.00010349604221635883,
      "loss": 1.2812,
      "step": 2350
    },
    {
      "epoch": 3.1,
      "grad_norm": 111.0,
      "learning_rate": 0.00010347625329815302,
      "loss": 1.5312,
      "step": 2351
    },
    {
      "epoch": 3.1,
      "grad_norm": 249.0,
      "learning_rate": 0.00010345646437994722,
      "loss": 3.6562,
      "step": 2352
    },
    {
      "epoch": 3.1,
      "grad_norm": 260.0,
      "learning_rate": 0.00010343667546174142,
      "loss": 4.125,
      "step": 2353
    },
    {
      "epoch": 3.11,
      "grad_norm": 59.75,
      "learning_rate": 0.00010341688654353562,
      "loss": 0.75,
      "step": 2354
    },
    {
      "epoch": 3.11,
      "grad_norm": 34.0,
      "learning_rate": 0.00010339709762532982,
      "loss": 0.4023,
      "step": 2355
    },
    {
      "epoch": 3.11,
      "grad_norm": 73.0,
      "learning_rate": 0.000103377308707124,
      "loss": 0.7344,
      "step": 2356
    },
    {
      "epoch": 3.11,
      "grad_norm": 108.0,
      "learning_rate": 0.0001033575197889182,
      "loss": 1.375,
      "step": 2357
    },
    {
      "epoch": 3.11,
      "grad_norm": 231.0,
      "learning_rate": 0.0001033377308707124,
      "loss": 3.5781,
      "step": 2358
    },
    {
      "epoch": 3.11,
      "grad_norm": 44.75,
      "learning_rate": 0.0001033179419525066,
      "loss": 0.4297,
      "step": 2359
    },
    {
      "epoch": 3.11,
      "grad_norm": 40.5,
      "learning_rate": 0.0001032981530343008,
      "loss": 0.5898,
      "step": 2360
    },
    {
      "epoch": 3.11,
      "grad_norm": 189.0,
      "learning_rate": 0.00010327836411609499,
      "loss": 2.8438,
      "step": 2361
    },
    {
      "epoch": 3.12,
      "grad_norm": 124.5,
      "learning_rate": 0.00010325857519788916,
      "loss": 1.6172,
      "step": 2362
    },
    {
      "epoch": 3.12,
      "grad_norm": 103.0,
      "learning_rate": 0.00010323878627968336,
      "loss": 1.4219,
      "step": 2363
    },
    {
      "epoch": 3.12,
      "grad_norm": 31.5,
      "learning_rate": 0.00010321899736147756,
      "loss": 0.3145,
      "step": 2364
    },
    {
      "epoch": 3.12,
      "grad_norm": 56.0,
      "learning_rate": 0.00010319920844327176,
      "loss": 0.5508,
      "step": 2365
    },
    {
      "epoch": 3.12,
      "grad_norm": 40.25,
      "learning_rate": 0.00010317941952506595,
      "loss": 0.6055,
      "step": 2366
    },
    {
      "epoch": 3.12,
      "grad_norm": 104.5,
      "learning_rate": 0.00010315963060686014,
      "loss": 1.3672,
      "step": 2367
    },
    {
      "epoch": 3.12,
      "grad_norm": 37.0,
      "learning_rate": 0.00010313984168865434,
      "loss": 0.4434,
      "step": 2368
    },
    {
      "epoch": 3.13,
      "grad_norm": 24.875,
      "learning_rate": 0.00010312005277044854,
      "loss": 0.2598,
      "step": 2369
    },
    {
      "epoch": 3.13,
      "grad_norm": 42.0,
      "learning_rate": 0.00010310026385224273,
      "loss": 0.2305,
      "step": 2370
    },
    {
      "epoch": 3.13,
      "grad_norm": 132.0,
      "learning_rate": 0.00010308047493403693,
      "loss": 1.4844,
      "step": 2371
    },
    {
      "epoch": 3.13,
      "grad_norm": 312.0,
      "learning_rate": 0.00010306068601583113,
      "loss": 2.9531,
      "step": 2372
    },
    {
      "epoch": 3.13,
      "grad_norm": 254.0,
      "learning_rate": 0.00010304089709762531,
      "loss": 3.7656,
      "step": 2373
    },
    {
      "epoch": 3.13,
      "grad_norm": 68.0,
      "learning_rate": 0.00010302110817941951,
      "loss": 0.8867,
      "step": 2374
    },
    {
      "epoch": 3.13,
      "grad_norm": 16.125,
      "learning_rate": 0.00010300131926121371,
      "loss": 0.1689,
      "step": 2375
    },
    {
      "epoch": 3.13,
      "grad_norm": 29.375,
      "learning_rate": 0.00010298153034300791,
      "loss": 0.1533,
      "step": 2376
    },
    {
      "epoch": 3.14,
      "grad_norm": 26.5,
      "learning_rate": 0.0001029617414248021,
      "loss": 0.1309,
      "step": 2377
    },
    {
      "epoch": 3.14,
      "grad_norm": 18.5,
      "learning_rate": 0.0001029419525065963,
      "loss": 0.1553,
      "step": 2378
    },
    {
      "epoch": 3.14,
      "grad_norm": 114.5,
      "learning_rate": 0.00010292216358839049,
      "loss": 1.2578,
      "step": 2379
    },
    {
      "epoch": 3.14,
      "grad_norm": 290.0,
      "learning_rate": 0.00010290237467018469,
      "loss": 5.0,
      "step": 2380
    },
    {
      "epoch": 3.14,
      "grad_norm": 220.0,
      "learning_rate": 0.00010288258575197889,
      "loss": 2.8594,
      "step": 2381
    },
    {
      "epoch": 3.14,
      "grad_norm": 235.0,
      "learning_rate": 0.00010286279683377308,
      "loss": 3.0,
      "step": 2382
    },
    {
      "epoch": 3.14,
      "grad_norm": 290.0,
      "learning_rate": 0.00010284300791556728,
      "loss": 4.5,
      "step": 2383
    },
    {
      "epoch": 3.15,
      "grad_norm": 36.75,
      "learning_rate": 0.00010282321899736148,
      "loss": 0.3828,
      "step": 2384
    },
    {
      "epoch": 3.15,
      "grad_norm": 26.75,
      "learning_rate": 0.00010280343007915566,
      "loss": 0.3789,
      "step": 2385
    },
    {
      "epoch": 3.15,
      "grad_norm": 27.875,
      "learning_rate": 0.00010278364116094986,
      "loss": 0.3184,
      "step": 2386
    },
    {
      "epoch": 3.15,
      "grad_norm": 150.0,
      "learning_rate": 0.00010276385224274406,
      "loss": 2.1562,
      "step": 2387
    },
    {
      "epoch": 3.15,
      "grad_norm": 29.75,
      "learning_rate": 0.00010274406332453826,
      "loss": 0.4238,
      "step": 2388
    },
    {
      "epoch": 3.15,
      "grad_norm": 27.875,
      "learning_rate": 0.00010272427440633246,
      "loss": 0.252,
      "step": 2389
    },
    {
      "epoch": 3.15,
      "grad_norm": 292.0,
      "learning_rate": 0.00010270448548812665,
      "loss": 4.6562,
      "step": 2390
    },
    {
      "epoch": 3.15,
      "grad_norm": 16.125,
      "learning_rate": 0.00010268469656992084,
      "loss": 0.1875,
      "step": 2391
    },
    {
      "epoch": 3.16,
      "grad_norm": 155.0,
      "learning_rate": 0.00010266490765171502,
      "loss": 2.625,
      "step": 2392
    },
    {
      "epoch": 3.16,
      "grad_norm": 58.25,
      "learning_rate": 0.00010264511873350922,
      "loss": 0.5078,
      "step": 2393
    },
    {
      "epoch": 3.16,
      "grad_norm": 41.0,
      "learning_rate": 0.00010262532981530342,
      "loss": 0.252,
      "step": 2394
    },
    {
      "epoch": 3.16,
      "grad_norm": 138.0,
      "learning_rate": 0.0001026055408970976,
      "loss": 1.7266,
      "step": 2395
    },
    {
      "epoch": 3.16,
      "grad_norm": 33.25,
      "learning_rate": 0.0001025857519788918,
      "loss": 0.4727,
      "step": 2396
    },
    {
      "epoch": 3.16,
      "grad_norm": 135.0,
      "learning_rate": 0.000102565963060686,
      "loss": 2.0625,
      "step": 2397
    },
    {
      "epoch": 3.16,
      "grad_norm": 336.0,
      "learning_rate": 0.0001025461741424802,
      "loss": 6.5,
      "step": 2398
    },
    {
      "epoch": 3.16,
      "grad_norm": 288.0,
      "learning_rate": 0.0001025263852242744,
      "loss": 4.375,
      "step": 2399
    },
    {
      "epoch": 3.17,
      "grad_norm": 45.0,
      "learning_rate": 0.0001025065963060686,
      "loss": 0.4551,
      "step": 2400
    },
    {
      "epoch": 3.17,
      "grad_norm": 260.0,
      "learning_rate": 0.00010248680738786278,
      "loss": 2.4219,
      "step": 2401
    },
    {
      "epoch": 3.17,
      "grad_norm": 36.5,
      "learning_rate": 0.00010246701846965698,
      "loss": 0.5391,
      "step": 2402
    },
    {
      "epoch": 3.17,
      "grad_norm": 149.0,
      "learning_rate": 0.00010244722955145117,
      "loss": 1.125,
      "step": 2403
    },
    {
      "epoch": 3.17,
      "grad_norm": 36.0,
      "learning_rate": 0.00010242744063324537,
      "loss": 0.5703,
      "step": 2404
    },
    {
      "epoch": 3.17,
      "grad_norm": 270.0,
      "learning_rate": 0.00010240765171503957,
      "loss": 4.0625,
      "step": 2405
    },
    {
      "epoch": 3.17,
      "grad_norm": 59.75,
      "learning_rate": 0.00010238786279683377,
      "loss": 0.4062,
      "step": 2406
    },
    {
      "epoch": 3.18,
      "grad_norm": 36.75,
      "learning_rate": 0.00010236807387862795,
      "loss": 0.2168,
      "step": 2407
    },
    {
      "epoch": 3.18,
      "grad_norm": 64.0,
      "learning_rate": 0.00010234828496042215,
      "loss": 1.0469,
      "step": 2408
    },
    {
      "epoch": 3.18,
      "grad_norm": 39.25,
      "learning_rate": 0.00010232849604221635,
      "loss": 0.2715,
      "step": 2409
    },
    {
      "epoch": 3.18,
      "grad_norm": 48.25,
      "learning_rate": 0.00010230870712401055,
      "loss": 0.2949,
      "step": 2410
    },
    {
      "epoch": 3.18,
      "grad_norm": 131.0,
      "learning_rate": 0.00010228891820580475,
      "loss": 1.6953,
      "step": 2411
    },
    {
      "epoch": 3.18,
      "grad_norm": 124.0,
      "learning_rate": 0.00010226912928759894,
      "loss": 1.9531,
      "step": 2412
    },
    {
      "epoch": 3.18,
      "grad_norm": 183.0,
      "learning_rate": 0.00010224934036939313,
      "loss": 1.8828,
      "step": 2413
    },
    {
      "epoch": 3.18,
      "grad_norm": 262.0,
      "learning_rate": 0.00010222955145118733,
      "loss": 4.0625,
      "step": 2414
    },
    {
      "epoch": 3.19,
      "grad_norm": 27.0,
      "learning_rate": 0.00010220976253298152,
      "loss": 0.375,
      "step": 2415
    },
    {
      "epoch": 3.19,
      "grad_norm": 119.0,
      "learning_rate": 0.00010218997361477572,
      "loss": 1.3281,
      "step": 2416
    },
    {
      "epoch": 3.19,
      "grad_norm": 55.25,
      "learning_rate": 0.00010217018469656992,
      "loss": 0.3867,
      "step": 2417
    },
    {
      "epoch": 3.19,
      "grad_norm": 19.0,
      "learning_rate": 0.00010215039577836412,
      "loss": 0.1924,
      "step": 2418
    },
    {
      "epoch": 3.19,
      "grad_norm": 28.5,
      "learning_rate": 0.0001021306068601583,
      "loss": 0.1523,
      "step": 2419
    },
    {
      "epoch": 3.19,
      "grad_norm": 20.0,
      "learning_rate": 0.0001021108179419525,
      "loss": 0.4609,
      "step": 2420
    },
    {
      "epoch": 3.19,
      "grad_norm": 276.0,
      "learning_rate": 0.0001020910290237467,
      "loss": 4.0312,
      "step": 2421
    },
    {
      "epoch": 3.2,
      "grad_norm": 26.125,
      "learning_rate": 0.00010207124010554088,
      "loss": 0.4062,
      "step": 2422
    },
    {
      "epoch": 3.2,
      "grad_norm": 26.5,
      "learning_rate": 0.00010205145118733508,
      "loss": 0.1553,
      "step": 2423
    },
    {
      "epoch": 3.2,
      "grad_norm": 288.0,
      "learning_rate": 0.00010203166226912927,
      "loss": 3.7188,
      "step": 2424
    },
    {
      "epoch": 3.2,
      "grad_norm": 56.0,
      "learning_rate": 0.00010201187335092346,
      "loss": 0.6055,
      "step": 2425
    },
    {
      "epoch": 3.2,
      "grad_norm": 137.0,
      "learning_rate": 0.00010199208443271766,
      "loss": 1.8906,
      "step": 2426
    },
    {
      "epoch": 3.2,
      "grad_norm": 241.0,
      "learning_rate": 0.00010197229551451186,
      "loss": 5.1562,
      "step": 2427
    },
    {
      "epoch": 3.2,
      "grad_norm": 141.0,
      "learning_rate": 0.00010195250659630606,
      "loss": 2.0469,
      "step": 2428
    },
    {
      "epoch": 3.2,
      "grad_norm": 280.0,
      "learning_rate": 0.00010193271767810026,
      "loss": 3.875,
      "step": 2429
    },
    {
      "epoch": 3.21,
      "grad_norm": 32.5,
      "learning_rate": 0.00010191292875989444,
      "loss": 0.3633,
      "step": 2430
    },
    {
      "epoch": 3.21,
      "grad_norm": 39.0,
      "learning_rate": 0.00010189313984168864,
      "loss": 0.6641,
      "step": 2431
    },
    {
      "epoch": 3.21,
      "grad_norm": 217.0,
      "learning_rate": 0.00010187335092348284,
      "loss": 3.2656,
      "step": 2432
    },
    {
      "epoch": 3.21,
      "grad_norm": 202.0,
      "learning_rate": 0.00010185356200527704,
      "loss": 2.9688,
      "step": 2433
    },
    {
      "epoch": 3.21,
      "grad_norm": 42.5,
      "learning_rate": 0.00010183377308707123,
      "loss": 0.3711,
      "step": 2434
    },
    {
      "epoch": 3.21,
      "grad_norm": 264.0,
      "learning_rate": 0.00010181398416886543,
      "loss": 3.1094,
      "step": 2435
    },
    {
      "epoch": 3.21,
      "grad_norm": 180.0,
      "learning_rate": 0.00010179419525065962,
      "loss": 2.9062,
      "step": 2436
    },
    {
      "epoch": 3.22,
      "grad_norm": 404.0,
      "learning_rate": 0.00010177440633245381,
      "loss": 4.4688,
      "step": 2437
    },
    {
      "epoch": 3.22,
      "grad_norm": 338.0,
      "learning_rate": 0.00010175461741424801,
      "loss": 3.6875,
      "step": 2438
    },
    {
      "epoch": 3.22,
      "grad_norm": 31.5,
      "learning_rate": 0.00010173482849604221,
      "loss": 0.3848,
      "step": 2439
    },
    {
      "epoch": 3.22,
      "grad_norm": 79.5,
      "learning_rate": 0.00010171503957783641,
      "loss": 0.8125,
      "step": 2440
    },
    {
      "epoch": 3.22,
      "grad_norm": 59.75,
      "learning_rate": 0.0001016952506596306,
      "loss": 0.5938,
      "step": 2441
    },
    {
      "epoch": 3.22,
      "grad_norm": 92.0,
      "learning_rate": 0.00010167546174142479,
      "loss": 0.7812,
      "step": 2442
    },
    {
      "epoch": 3.22,
      "grad_norm": 86.0,
      "learning_rate": 0.00010165567282321899,
      "loss": 1.5469,
      "step": 2443
    },
    {
      "epoch": 3.22,
      "grad_norm": 42.0,
      "learning_rate": 0.00010163588390501319,
      "loss": 0.4941,
      "step": 2444
    },
    {
      "epoch": 3.23,
      "grad_norm": 63.25,
      "learning_rate": 0.00010161609498680738,
      "loss": 0.7188,
      "step": 2445
    },
    {
      "epoch": 3.23,
      "grad_norm": 47.5,
      "learning_rate": 0.00010159630606860158,
      "loss": 0.9805,
      "step": 2446
    },
    {
      "epoch": 3.23,
      "grad_norm": 88.5,
      "learning_rate": 0.00010157651715039578,
      "loss": 0.8438,
      "step": 2447
    },
    {
      "epoch": 3.23,
      "grad_norm": 38.75,
      "learning_rate": 0.00010155672823218997,
      "loss": 0.3145,
      "step": 2448
    },
    {
      "epoch": 3.23,
      "grad_norm": 36.0,
      "learning_rate": 0.00010153693931398416,
      "loss": 0.3164,
      "step": 2449
    },
    {
      "epoch": 3.23,
      "grad_norm": 135.0,
      "learning_rate": 0.00010151715039577836,
      "loss": 2.25,
      "step": 2450
    },
    {
      "epoch": 3.23,
      "grad_norm": 60.25,
      "learning_rate": 0.00010149736147757256,
      "loss": 0.4668,
      "step": 2451
    },
    {
      "epoch": 3.23,
      "grad_norm": 19.75,
      "learning_rate": 0.00010147757255936674,
      "loss": 0.377,
      "step": 2452
    },
    {
      "epoch": 3.24,
      "grad_norm": 18.625,
      "learning_rate": 0.00010145778364116093,
      "loss": 0.4844,
      "step": 2453
    },
    {
      "epoch": 3.24,
      "grad_norm": 10.6875,
      "learning_rate": 0.00010143799472295513,
      "loss": 0.2812,
      "step": 2454
    },
    {
      "epoch": 3.24,
      "grad_norm": 9.9375,
      "learning_rate": 0.00010141820580474932,
      "loss": 0.3594,
      "step": 2455
    },
    {
      "epoch": 3.24,
      "grad_norm": 155.0,
      "learning_rate": 0.00010139841688654352,
      "loss": 2.4531,
      "step": 2456
    },
    {
      "epoch": 3.24,
      "grad_norm": 141.0,
      "learning_rate": 0.00010137862796833772,
      "loss": 2.5625,
      "step": 2457
    },
    {
      "epoch": 3.24,
      "grad_norm": 306.0,
      "learning_rate": 0.00010135883905013192,
      "loss": 7.4375,
      "step": 2458
    },
    {
      "epoch": 3.24,
      "grad_norm": 227.0,
      "learning_rate": 0.0001013390501319261,
      "loss": 5.3125,
      "step": 2459
    },
    {
      "epoch": 3.25,
      "grad_norm": 224.0,
      "learning_rate": 0.0001013192612137203,
      "loss": 5.4688,
      "step": 2460
    },
    {
      "epoch": 3.25,
      "grad_norm": 31.5,
      "learning_rate": 0.0001012994722955145,
      "loss": 0.4004,
      "step": 2461
    },
    {
      "epoch": 3.25,
      "grad_norm": 55.25,
      "learning_rate": 0.0001012796833773087,
      "loss": 0.6602,
      "step": 2462
    },
    {
      "epoch": 3.25,
      "grad_norm": 226.0,
      "learning_rate": 0.0001012598944591029,
      "loss": 5.4062,
      "step": 2463
    },
    {
      "epoch": 3.25,
      "grad_norm": 10.6875,
      "learning_rate": 0.0001012401055408971,
      "loss": 0.1787,
      "step": 2464
    },
    {
      "epoch": 3.25,
      "grad_norm": 8.75,
      "learning_rate": 0.00010122031662269128,
      "loss": 0.293,
      "step": 2465
    },
    {
      "epoch": 3.25,
      "grad_norm": 16.125,
      "learning_rate": 0.00010120052770448548,
      "loss": 0.7656,
      "step": 2466
    },
    {
      "epoch": 3.25,
      "grad_norm": 9.5,
      "learning_rate": 0.00010118073878627967,
      "loss": 0.3379,
      "step": 2467
    },
    {
      "epoch": 3.26,
      "grad_norm": 146.0,
      "learning_rate": 0.00010116094986807387,
      "loss": 2.7344,
      "step": 2468
    },
    {
      "epoch": 3.26,
      "grad_norm": 251.0,
      "learning_rate": 0.00010114116094986807,
      "loss": 7.0,
      "step": 2469
    },
    {
      "epoch": 3.26,
      "grad_norm": 12.4375,
      "learning_rate": 0.00010112137203166227,
      "loss": 0.2695,
      "step": 2470
    },
    {
      "epoch": 3.26,
      "grad_norm": 135.0,
      "learning_rate": 0.00010110158311345645,
      "loss": 2.5781,
      "step": 2471
    },
    {
      "epoch": 3.26,
      "grad_norm": 209.0,
      "learning_rate": 0.00010108179419525065,
      "loss": 5.5312,
      "step": 2472
    },
    {
      "epoch": 3.26,
      "grad_norm": 22.875,
      "learning_rate": 0.00010106200527704485,
      "loss": 0.3223,
      "step": 2473
    },
    {
      "epoch": 3.26,
      "grad_norm": 31.375,
      "learning_rate": 0.00010104221635883905,
      "loss": 0.3945,
      "step": 2474
    },
    {
      "epoch": 3.27,
      "grad_norm": 220.0,
      "learning_rate": 0.00010102242744063325,
      "loss": 4.6562,
      "step": 2475
    },
    {
      "epoch": 3.27,
      "grad_norm": 270.0,
      "learning_rate": 0.00010100263852242744,
      "loss": 6.25,
      "step": 2476
    },
    {
      "epoch": 3.27,
      "grad_norm": 34.75,
      "learning_rate": 0.00010098284960422163,
      "loss": 0.3652,
      "step": 2477
    },
    {
      "epoch": 3.27,
      "grad_norm": 292.0,
      "learning_rate": 0.00010096306068601583,
      "loss": 5.625,
      "step": 2478
    },
    {
      "epoch": 3.27,
      "grad_norm": 11.3125,
      "learning_rate": 0.00010094327176781002,
      "loss": 0.1934,
      "step": 2479
    },
    {
      "epoch": 3.27,
      "grad_norm": 242.0,
      "learning_rate": 0.00010092348284960422,
      "loss": 5.1875,
      "step": 2480
    },
    {
      "epoch": 3.27,
      "grad_norm": 198.0,
      "learning_rate": 0.00010090369393139842,
      "loss": 2.7812,
      "step": 2481
    },
    {
      "epoch": 3.27,
      "grad_norm": 237.0,
      "learning_rate": 0.00010088390501319259,
      "loss": 2.9375,
      "step": 2482
    },
    {
      "epoch": 3.28,
      "grad_norm": 32.75,
      "learning_rate": 0.00010086411609498679,
      "loss": 0.625,
      "step": 2483
    },
    {
      "epoch": 3.28,
      "grad_norm": 37.0,
      "learning_rate": 0.00010084432717678099,
      "loss": 0.6641,
      "step": 2484
    },
    {
      "epoch": 3.28,
      "grad_norm": 118.5,
      "learning_rate": 0.00010082453825857519,
      "loss": 2.6562,
      "step": 2485
    },
    {
      "epoch": 3.28,
      "grad_norm": 133.0,
      "learning_rate": 0.00010080474934036938,
      "loss": 2.1406,
      "step": 2486
    },
    {
      "epoch": 3.28,
      "grad_norm": 106.5,
      "learning_rate": 0.00010078496042216357,
      "loss": 1.7812,
      "step": 2487
    },
    {
      "epoch": 3.28,
      "grad_norm": 228.0,
      "learning_rate": 0.00010076517150395777,
      "loss": 2.5625,
      "step": 2488
    },
    {
      "epoch": 3.28,
      "grad_norm": 118.0,
      "learning_rate": 0.00010074538258575196,
      "loss": 2.125,
      "step": 2489
    },
    {
      "epoch": 3.28,
      "grad_norm": 128.0,
      "learning_rate": 0.00010072559366754616,
      "loss": 1.7891,
      "step": 2490
    },
    {
      "epoch": 3.29,
      "grad_norm": 53.75,
      "learning_rate": 0.00010070580474934036,
      "loss": 0.7969,
      "step": 2491
    },
    {
      "epoch": 3.29,
      "grad_norm": 107.0,
      "learning_rate": 0.00010068601583113456,
      "loss": 1.6875,
      "step": 2492
    },
    {
      "epoch": 3.29,
      "grad_norm": 47.75,
      "learning_rate": 0.00010066622691292874,
      "loss": 0.7852,
      "step": 2493
    },
    {
      "epoch": 3.29,
      "grad_norm": 140.0,
      "learning_rate": 0.00010064643799472294,
      "loss": 2.0625,
      "step": 2494
    },
    {
      "epoch": 3.29,
      "grad_norm": 70.5,
      "learning_rate": 0.00010062664907651714,
      "loss": 1.0859,
      "step": 2495
    },
    {
      "epoch": 3.29,
      "grad_norm": 70.5,
      "learning_rate": 0.00010060686015831134,
      "loss": 1.2422,
      "step": 2496
    },
    {
      "epoch": 3.29,
      "grad_norm": 53.25,
      "learning_rate": 0.00010058707124010553,
      "loss": 0.9531,
      "step": 2497
    },
    {
      "epoch": 3.3,
      "grad_norm": 40.0,
      "learning_rate": 0.00010056728232189973,
      "loss": 0.9453,
      "step": 2498
    },
    {
      "epoch": 3.3,
      "grad_norm": 164.0,
      "learning_rate": 0.00010054749340369392,
      "loss": 3.4844,
      "step": 2499
    },
    {
      "epoch": 3.3,
      "grad_norm": 237.0,
      "learning_rate": 0.00010052770448548812,
      "loss": 3.875,
      "step": 2500
    },
    {
      "epoch": 3.3,
      "grad_norm": 74.5,
      "learning_rate": 0.00010050791556728231,
      "loss": 1.1641,
      "step": 2501
    },
    {
      "epoch": 3.3,
      "grad_norm": 57.0,
      "learning_rate": 0.00010048812664907651,
      "loss": 1.2734,
      "step": 2502
    },
    {
      "epoch": 3.3,
      "grad_norm": 35.75,
      "learning_rate": 0.00010046833773087071,
      "loss": 1.3359,
      "step": 2503
    },
    {
      "epoch": 3.3,
      "grad_norm": 35.5,
      "learning_rate": 0.00010044854881266491,
      "loss": 0.5039,
      "step": 2504
    },
    {
      "epoch": 3.3,
      "grad_norm": 223.0,
      "learning_rate": 0.00010042875989445909,
      "loss": 3.8438,
      "step": 2505
    },
    {
      "epoch": 3.31,
      "grad_norm": 46.5,
      "learning_rate": 0.00010040897097625329,
      "loss": 0.5703,
      "step": 2506
    },
    {
      "epoch": 3.31,
      "grad_norm": 33.25,
      "learning_rate": 0.00010038918205804749,
      "loss": 0.4453,
      "step": 2507
    },
    {
      "epoch": 3.31,
      "grad_norm": 28.375,
      "learning_rate": 0.00010036939313984169,
      "loss": 0.2617,
      "step": 2508
    },
    {
      "epoch": 3.31,
      "grad_norm": 18.875,
      "learning_rate": 0.00010034960422163588,
      "loss": 0.2734,
      "step": 2509
    },
    {
      "epoch": 3.31,
      "grad_norm": 43.0,
      "learning_rate": 0.00010032981530343008,
      "loss": 0.2168,
      "step": 2510
    },
    {
      "epoch": 3.31,
      "grad_norm": 264.0,
      "learning_rate": 0.00010031002638522428,
      "loss": 3.0625,
      "step": 2511
    },
    {
      "epoch": 3.31,
      "grad_norm": 25.25,
      "learning_rate": 0.00010029023746701845,
      "loss": 0.0962,
      "step": 2512
    },
    {
      "epoch": 3.32,
      "grad_norm": 108.0,
      "learning_rate": 0.00010027044854881265,
      "loss": 0.8828,
      "step": 2513
    },
    {
      "epoch": 3.32,
      "grad_norm": 51.0,
      "learning_rate": 0.00010025065963060685,
      "loss": 0.5938,
      "step": 2514
    },
    {
      "epoch": 3.32,
      "grad_norm": 51.0,
      "learning_rate": 0.00010023087071240105,
      "loss": 0.1406,
      "step": 2515
    },
    {
      "epoch": 3.32,
      "grad_norm": 280.0,
      "learning_rate": 0.00010021108179419523,
      "loss": 3.75,
      "step": 2516
    },
    {
      "epoch": 3.32,
      "grad_norm": 596.0,
      "learning_rate": 0.00010019129287598943,
      "loss": 7.8438,
      "step": 2517
    },
    {
      "epoch": 3.32,
      "grad_norm": 302.0,
      "learning_rate": 0.00010017150395778363,
      "loss": 4.0625,
      "step": 2518
    },
    {
      "epoch": 3.32,
      "grad_norm": 82.0,
      "learning_rate": 0.00010015171503957782,
      "loss": 0.5781,
      "step": 2519
    },
    {
      "epoch": 3.32,
      "grad_norm": 225.0,
      "learning_rate": 0.00010013192612137202,
      "loss": 3.8594,
      "step": 2520
    },
    {
      "epoch": 3.33,
      "grad_norm": 22.375,
      "learning_rate": 0.00010011213720316622,
      "loss": 0.2734,
      "step": 2521
    },
    {
      "epoch": 3.33,
      "grad_norm": 66.5,
      "learning_rate": 0.0001000923482849604,
      "loss": 0.9141,
      "step": 2522
    },
    {
      "epoch": 3.33,
      "grad_norm": 242.0,
      "learning_rate": 0.0001000725593667546,
      "loss": 3.25,
      "step": 2523
    },
    {
      "epoch": 3.33,
      "grad_norm": 242.0,
      "learning_rate": 0.0001000527704485488,
      "loss": 4.1562,
      "step": 2524
    },
    {
      "epoch": 3.33,
      "grad_norm": 224.0,
      "learning_rate": 0.000100032981530343,
      "loss": 3.0625,
      "step": 2525
    },
    {
      "epoch": 3.33,
      "grad_norm": 31.125,
      "learning_rate": 0.0001000131926121372,
      "loss": 0.1235,
      "step": 2526
    },
    {
      "epoch": 3.33,
      "grad_norm": 45.5,
      "learning_rate": 9.99934036939314e-05,
      "loss": 0.2715,
      "step": 2527
    },
    {
      "epoch": 3.34,
      "grad_norm": 103.5,
      "learning_rate": 9.997361477572558e-05,
      "loss": 0.582,
      "step": 2528
    },
    {
      "epoch": 3.34,
      "grad_norm": 105.5,
      "learning_rate": 9.995382585751978e-05,
      "loss": 0.6211,
      "step": 2529
    },
    {
      "epoch": 3.34,
      "grad_norm": 48.0,
      "learning_rate": 9.993403693931398e-05,
      "loss": 0.2617,
      "step": 2530
    },
    {
      "epoch": 3.34,
      "grad_norm": 334.0,
      "learning_rate": 9.991424802110817e-05,
      "loss": 4.625,
      "step": 2531
    },
    {
      "epoch": 3.34,
      "grad_norm": 32.5,
      "learning_rate": 9.989445910290237e-05,
      "loss": 0.2812,
      "step": 2532
    },
    {
      "epoch": 3.34,
      "grad_norm": 14.375,
      "learning_rate": 9.987467018469657e-05,
      "loss": 0.2578,
      "step": 2533
    },
    {
      "epoch": 3.34,
      "grad_norm": 25.5,
      "learning_rate": 9.985488126649075e-05,
      "loss": 0.2598,
      "step": 2534
    },
    {
      "epoch": 3.34,
      "grad_norm": 191.0,
      "learning_rate": 9.983509234828495e-05,
      "loss": 2.4219,
      "step": 2535
    },
    {
      "epoch": 3.35,
      "grad_norm": 34.75,
      "learning_rate": 9.981530343007915e-05,
      "loss": 0.3711,
      "step": 2536
    },
    {
      "epoch": 3.35,
      "grad_norm": 384.0,
      "learning_rate": 9.979551451187335e-05,
      "loss": 4.375,
      "step": 2537
    },
    {
      "epoch": 3.35,
      "grad_norm": 62.25,
      "learning_rate": 9.977572559366755e-05,
      "loss": 0.5547,
      "step": 2538
    },
    {
      "epoch": 3.35,
      "grad_norm": 90.5,
      "learning_rate": 9.975593667546174e-05,
      "loss": 0.8047,
      "step": 2539
    },
    {
      "epoch": 3.35,
      "grad_norm": 11.125,
      "learning_rate": 9.973614775725593e-05,
      "loss": 0.0557,
      "step": 2540
    },
    {
      "epoch": 3.35,
      "grad_norm": 55.25,
      "learning_rate": 9.971635883905013e-05,
      "loss": 0.6016,
      "step": 2541
    },
    {
      "epoch": 3.35,
      "grad_norm": 218.0,
      "learning_rate": 9.969656992084431e-05,
      "loss": 2.2812,
      "step": 2542
    },
    {
      "epoch": 3.35,
      "grad_norm": 7.78125,
      "learning_rate": 9.967678100263851e-05,
      "loss": 0.064,
      "step": 2543
    },
    {
      "epoch": 3.36,
      "grad_norm": 164.0,
      "learning_rate": 9.965699208443271e-05,
      "loss": 3.7969,
      "step": 2544
    },
    {
      "epoch": 3.36,
      "grad_norm": 83.0,
      "learning_rate": 9.963720316622689e-05,
      "loss": 0.8516,
      "step": 2545
    },
    {
      "epoch": 3.36,
      "grad_norm": 12.125,
      "learning_rate": 9.961741424802109e-05,
      "loss": 0.0625,
      "step": 2546
    },
    {
      "epoch": 3.36,
      "grad_norm": 316.0,
      "learning_rate": 9.959762532981529e-05,
      "loss": 4.6562,
      "step": 2547
    },
    {
      "epoch": 3.36,
      "grad_norm": 21.125,
      "learning_rate": 9.957783641160949e-05,
      "loss": 0.1924,
      "step": 2548
    },
    {
      "epoch": 3.36,
      "grad_norm": 402.0,
      "learning_rate": 9.955804749340368e-05,
      "loss": 4.8125,
      "step": 2549
    },
    {
      "epoch": 3.36,
      "grad_norm": 38.0,
      "learning_rate": 9.953825857519788e-05,
      "loss": 0.2275,
      "step": 2550
    },
    {
      "epoch": 3.37,
      "grad_norm": 49.0,
      "learning_rate": 9.951846965699207e-05,
      "loss": 0.4551,
      "step": 2551
    },
    {
      "epoch": 3.37,
      "grad_norm": 350.0,
      "learning_rate": 9.949868073878627e-05,
      "loss": 4.5,
      "step": 2552
    },
    {
      "epoch": 3.37,
      "grad_norm": 54.0,
      "learning_rate": 9.947889182058046e-05,
      "loss": 0.6445,
      "step": 2553
    },
    {
      "epoch": 3.37,
      "grad_norm": 30.0,
      "learning_rate": 9.945910290237466e-05,
      "loss": 0.1865,
      "step": 2554
    },
    {
      "epoch": 3.37,
      "grad_norm": 338.0,
      "learning_rate": 9.943931398416886e-05,
      "loss": 4.3438,
      "step": 2555
    },
    {
      "epoch": 3.37,
      "grad_norm": 104.0,
      "learning_rate": 9.941952506596306e-05,
      "loss": 0.8906,
      "step": 2556
    },
    {
      "epoch": 3.37,
      "grad_norm": 19.125,
      "learning_rate": 9.939973614775724e-05,
      "loss": 0.1299,
      "step": 2557
    },
    {
      "epoch": 3.37,
      "grad_norm": 44.5,
      "learning_rate": 9.937994722955144e-05,
      "loss": 0.5039,
      "step": 2558
    },
    {
      "epoch": 3.38,
      "grad_norm": 332.0,
      "learning_rate": 9.936015831134564e-05,
      "loss": 4.25,
      "step": 2559
    },
    {
      "epoch": 3.38,
      "grad_norm": 17.75,
      "learning_rate": 9.934036939313984e-05,
      "loss": 0.0952,
      "step": 2560
    },
    {
      "epoch": 3.38,
      "grad_norm": 33.5,
      "learning_rate": 9.932058047493403e-05,
      "loss": 0.2559,
      "step": 2561
    },
    {
      "epoch": 3.38,
      "grad_norm": 173.0,
      "learning_rate": 9.930079155672823e-05,
      "loss": 2.1875,
      "step": 2562
    },
    {
      "epoch": 3.38,
      "grad_norm": 284.0,
      "learning_rate": 9.928100263852242e-05,
      "loss": 3.9688,
      "step": 2563
    },
    {
      "epoch": 3.38,
      "grad_norm": 258.0,
      "learning_rate": 9.926121372031661e-05,
      "loss": 5.0312,
      "step": 2564
    },
    {
      "epoch": 3.38,
      "grad_norm": 284.0,
      "learning_rate": 9.924142480211081e-05,
      "loss": 3.4531,
      "step": 2565
    },
    {
      "epoch": 3.39,
      "grad_norm": 22.875,
      "learning_rate": 9.922163588390501e-05,
      "loss": 0.3691,
      "step": 2566
    },
    {
      "epoch": 3.39,
      "grad_norm": 29.0,
      "learning_rate": 9.920184696569921e-05,
      "loss": 0.3477,
      "step": 2567
    },
    {
      "epoch": 3.39,
      "grad_norm": 28.125,
      "learning_rate": 9.918205804749341e-05,
      "loss": 0.4668,
      "step": 2568
    },
    {
      "epoch": 3.39,
      "grad_norm": 21.375,
      "learning_rate": 9.916226912928759e-05,
      "loss": 0.2354,
      "step": 2569
    },
    {
      "epoch": 3.39,
      "grad_norm": 32.0,
      "learning_rate": 9.914248021108179e-05,
      "loss": 0.5352,
      "step": 2570
    },
    {
      "epoch": 3.39,
      "grad_norm": 171.0,
      "learning_rate": 9.912269129287599e-05,
      "loss": 2.625,
      "step": 2571
    },
    {
      "epoch": 3.39,
      "grad_norm": 348.0,
      "learning_rate": 9.910290237467017e-05,
      "loss": 4.7188,
      "step": 2572
    },
    {
      "epoch": 3.39,
      "grad_norm": 163.0,
      "learning_rate": 9.908311345646437e-05,
      "loss": 2.0938,
      "step": 2573
    },
    {
      "epoch": 3.4,
      "grad_norm": 34.0,
      "learning_rate": 9.906332453825855e-05,
      "loss": 0.208,
      "step": 2574
    },
    {
      "epoch": 3.4,
      "grad_norm": 42.75,
      "learning_rate": 9.904353562005275e-05,
      "loss": 0.2412,
      "step": 2575
    },
    {
      "epoch": 3.4,
      "grad_norm": 37.5,
      "learning_rate": 9.902374670184695e-05,
      "loss": 0.3965,
      "step": 2576
    },
    {
      "epoch": 3.4,
      "grad_norm": 17.125,
      "learning_rate": 9.900395778364115e-05,
      "loss": 0.4668,
      "step": 2577
    },
    {
      "epoch": 3.4,
      "grad_norm": 21.875,
      "learning_rate": 9.898416886543535e-05,
      "loss": 0.1211,
      "step": 2578
    },
    {
      "epoch": 3.4,
      "grad_norm": 23.5,
      "learning_rate": 9.896437994722955e-05,
      "loss": 0.4316,
      "step": 2579
    },
    {
      "epoch": 3.4,
      "grad_norm": 44.75,
      "learning_rate": 9.894459102902373e-05,
      "loss": 0.2969,
      "step": 2580
    },
    {
      "epoch": 3.41,
      "grad_norm": 177.0,
      "learning_rate": 9.892480211081793e-05,
      "loss": 2.5312,
      "step": 2581
    },
    {
      "epoch": 3.41,
      "grad_norm": 32.5,
      "learning_rate": 9.890501319261213e-05,
      "loss": 0.2988,
      "step": 2582
    },
    {
      "epoch": 3.41,
      "grad_norm": 27.375,
      "learning_rate": 9.888522427440632e-05,
      "loss": 0.1309,
      "step": 2583
    },
    {
      "epoch": 3.41,
      "grad_norm": 159.0,
      "learning_rate": 9.886543535620052e-05,
      "loss": 2.4531,
      "step": 2584
    },
    {
      "epoch": 3.41,
      "grad_norm": 34.5,
      "learning_rate": 9.884564643799472e-05,
      "loss": 0.4746,
      "step": 2585
    },
    {
      "epoch": 3.41,
      "grad_norm": 154.0,
      "learning_rate": 9.88258575197889e-05,
      "loss": 2.7812,
      "step": 2586
    },
    {
      "epoch": 3.41,
      "grad_norm": 208.0,
      "learning_rate": 9.88060686015831e-05,
      "loss": 2.5938,
      "step": 2587
    },
    {
      "epoch": 3.41,
      "grad_norm": 27.875,
      "learning_rate": 9.87862796833773e-05,
      "loss": 0.1748,
      "step": 2588
    },
    {
      "epoch": 3.42,
      "grad_norm": 172.0,
      "learning_rate": 9.87664907651715e-05,
      "loss": 2.2656,
      "step": 2589
    },
    {
      "epoch": 3.42,
      "grad_norm": 7.78125,
      "learning_rate": 9.87467018469657e-05,
      "loss": 0.1543,
      "step": 2590
    },
    {
      "epoch": 3.42,
      "grad_norm": 304.0,
      "learning_rate": 9.87269129287599e-05,
      "loss": 4.1562,
      "step": 2591
    },
    {
      "epoch": 3.42,
      "grad_norm": 282.0,
      "learning_rate": 9.870712401055408e-05,
      "loss": 4.625,
      "step": 2592
    },
    {
      "epoch": 3.42,
      "grad_norm": 65.0,
      "learning_rate": 9.868733509234828e-05,
      "loss": 0.582,
      "step": 2593
    },
    {
      "epoch": 3.42,
      "grad_norm": 17.875,
      "learning_rate": 9.866754617414248e-05,
      "loss": 0.085,
      "step": 2594
    },
    {
      "epoch": 3.42,
      "grad_norm": 255.0,
      "learning_rate": 9.864775725593667e-05,
      "loss": 4.3125,
      "step": 2595
    },
    {
      "epoch": 3.42,
      "grad_norm": 32.75,
      "learning_rate": 9.862796833773087e-05,
      "loss": 0.3828,
      "step": 2596
    },
    {
      "epoch": 3.43,
      "grad_norm": 66.0,
      "learning_rate": 9.860817941952507e-05,
      "loss": 0.7539,
      "step": 2597
    },
    {
      "epoch": 3.43,
      "grad_norm": 276.0,
      "learning_rate": 9.858839050131925e-05,
      "loss": 4.4375,
      "step": 2598
    },
    {
      "epoch": 3.43,
      "grad_norm": 27.25,
      "learning_rate": 9.856860158311345e-05,
      "loss": 0.1641,
      "step": 2599
    },
    {
      "epoch": 3.43,
      "grad_norm": 25.0,
      "learning_rate": 9.854881266490765e-05,
      "loss": 0.4316,
      "step": 2600
    },
    {
      "epoch": 3.43,
      "grad_norm": 253.0,
      "learning_rate": 9.852902374670185e-05,
      "loss": 5.7812,
      "step": 2601
    },
    {
      "epoch": 3.43,
      "grad_norm": 21.75,
      "learning_rate": 9.850923482849602e-05,
      "loss": 0.1484,
      "step": 2602
    },
    {
      "epoch": 3.43,
      "grad_norm": 129.0,
      "learning_rate": 9.848944591029022e-05,
      "loss": 1.7031,
      "step": 2603
    },
    {
      "epoch": 3.44,
      "grad_norm": 20.125,
      "learning_rate": 9.846965699208442e-05,
      "loss": 0.1206,
      "step": 2604
    },
    {
      "epoch": 3.44,
      "grad_norm": 237.0,
      "learning_rate": 9.844986807387861e-05,
      "loss": 3.7031,
      "step": 2605
    },
    {
      "epoch": 3.44,
      "grad_norm": 158.0,
      "learning_rate": 9.843007915567281e-05,
      "loss": 1.7969,
      "step": 2606
    },
    {
      "epoch": 3.44,
      "grad_norm": 143.0,
      "learning_rate": 9.841029023746701e-05,
      "loss": 1.7344,
      "step": 2607
    },
    {
      "epoch": 3.44,
      "grad_norm": 492.0,
      "learning_rate": 9.83905013192612e-05,
      "loss": 6.9688,
      "step": 2608
    },
    {
      "epoch": 3.44,
      "grad_norm": 141.0,
      "learning_rate": 9.837071240105539e-05,
      "loss": 1.6094,
      "step": 2609
    },
    {
      "epoch": 3.44,
      "grad_norm": 30.75,
      "learning_rate": 9.835092348284959e-05,
      "loss": 0.291,
      "step": 2610
    },
    {
      "epoch": 3.44,
      "grad_norm": 33.5,
      "learning_rate": 9.833113456464379e-05,
      "loss": 0.1914,
      "step": 2611
    },
    {
      "epoch": 3.45,
      "grad_norm": 242.0,
      "learning_rate": 9.831134564643799e-05,
      "loss": 2.9062,
      "step": 2612
    },
    {
      "epoch": 3.45,
      "grad_norm": 169.0,
      "learning_rate": 9.829155672823218e-05,
      "loss": 2.3281,
      "step": 2613
    },
    {
      "epoch": 3.45,
      "grad_norm": 35.75,
      "learning_rate": 9.827176781002637e-05,
      "loss": 0.5742,
      "step": 2614
    },
    {
      "epoch": 3.45,
      "grad_norm": 131.0,
      "learning_rate": 9.825197889182057e-05,
      "loss": 1.3125,
      "step": 2615
    },
    {
      "epoch": 3.45,
      "grad_norm": 250.0,
      "learning_rate": 9.823218997361476e-05,
      "loss": 2.8281,
      "step": 2616
    },
    {
      "epoch": 3.45,
      "grad_norm": 30.375,
      "learning_rate": 9.821240105540896e-05,
      "loss": 0.2031,
      "step": 2617
    },
    {
      "epoch": 3.45,
      "grad_norm": 154.0,
      "learning_rate": 9.819261213720316e-05,
      "loss": 1.6875,
      "step": 2618
    },
    {
      "epoch": 3.46,
      "grad_norm": 41.75,
      "learning_rate": 9.817282321899736e-05,
      "loss": 0.5781,
      "step": 2619
    },
    {
      "epoch": 3.46,
      "grad_norm": 119.0,
      "learning_rate": 9.815303430079154e-05,
      "loss": 1.5234,
      "step": 2620
    },
    {
      "epoch": 3.46,
      "grad_norm": 139.0,
      "learning_rate": 9.813324538258574e-05,
      "loss": 1.4844,
      "step": 2621
    },
    {
      "epoch": 3.46,
      "grad_norm": 33.25,
      "learning_rate": 9.811345646437994e-05,
      "loss": 0.25,
      "step": 2622
    },
    {
      "epoch": 3.46,
      "grad_norm": 199.0,
      "learning_rate": 9.809366754617414e-05,
      "loss": 2.7188,
      "step": 2623
    },
    {
      "epoch": 3.46,
      "grad_norm": 50.75,
      "learning_rate": 9.807387862796834e-05,
      "loss": 0.4473,
      "step": 2624
    },
    {
      "epoch": 3.46,
      "grad_norm": 66.0,
      "learning_rate": 9.805408970976253e-05,
      "loss": 0.3984,
      "step": 2625
    },
    {
      "epoch": 3.46,
      "grad_norm": 113.0,
      "learning_rate": 9.803430079155672e-05,
      "loss": 1.2344,
      "step": 2626
    },
    {
      "epoch": 3.47,
      "grad_norm": 82.0,
      "learning_rate": 9.801451187335092e-05,
      "loss": 0.8594,
      "step": 2627
    },
    {
      "epoch": 3.47,
      "grad_norm": 52.5,
      "learning_rate": 9.799472295514511e-05,
      "loss": 0.5977,
      "step": 2628
    },
    {
      "epoch": 3.47,
      "grad_norm": 106.0,
      "learning_rate": 9.797493403693931e-05,
      "loss": 1.3438,
      "step": 2629
    },
    {
      "epoch": 3.47,
      "grad_norm": 65.0,
      "learning_rate": 9.795514511873351e-05,
      "loss": 0.7461,
      "step": 2630
    },
    {
      "epoch": 3.47,
      "grad_norm": 64.5,
      "learning_rate": 9.793535620052771e-05,
      "loss": 0.4102,
      "step": 2631
    },
    {
      "epoch": 3.47,
      "grad_norm": 225.0,
      "learning_rate": 9.791556728232188e-05,
      "loss": 3.0469,
      "step": 2632
    },
    {
      "epoch": 3.47,
      "grad_norm": 47.5,
      "learning_rate": 9.789577836411608e-05,
      "loss": 0.4785,
      "step": 2633
    },
    {
      "epoch": 3.47,
      "grad_norm": 39.75,
      "learning_rate": 9.787598944591028e-05,
      "loss": 0.2471,
      "step": 2634
    },
    {
      "epoch": 3.48,
      "grad_norm": 198.0,
      "learning_rate": 9.785620052770447e-05,
      "loss": 3.3438,
      "step": 2635
    },
    {
      "epoch": 3.48,
      "grad_norm": 122.0,
      "learning_rate": 9.783641160949867e-05,
      "loss": 1.3594,
      "step": 2636
    },
    {
      "epoch": 3.48,
      "grad_norm": 25.75,
      "learning_rate": 9.781662269129286e-05,
      "loss": 0.3223,
      "step": 2637
    },
    {
      "epoch": 3.48,
      "grad_norm": 47.5,
      "learning_rate": 9.779683377308705e-05,
      "loss": 0.2676,
      "step": 2638
    },
    {
      "epoch": 3.48,
      "grad_norm": 29.375,
      "learning_rate": 9.777704485488125e-05,
      "loss": 0.3594,
      "step": 2639
    },
    {
      "epoch": 3.48,
      "grad_norm": 45.5,
      "learning_rate": 9.775725593667545e-05,
      "loss": 0.9414,
      "step": 2640
    },
    {
      "epoch": 3.48,
      "grad_norm": 35.0,
      "learning_rate": 9.773746701846965e-05,
      "loss": 0.2178,
      "step": 2641
    },
    {
      "epoch": 3.49,
      "grad_norm": 29.625,
      "learning_rate": 9.771767810026385e-05,
      "loss": 0.4473,
      "step": 2642
    },
    {
      "epoch": 3.49,
      "grad_norm": 175.0,
      "learning_rate": 9.769788918205803e-05,
      "loss": 1.9766,
      "step": 2643
    },
    {
      "epoch": 3.49,
      "grad_norm": 376.0,
      "learning_rate": 9.767810026385223e-05,
      "loss": 5.5312,
      "step": 2644
    },
    {
      "epoch": 3.49,
      "grad_norm": 36.0,
      "learning_rate": 9.765831134564643e-05,
      "loss": 0.4707,
      "step": 2645
    },
    {
      "epoch": 3.49,
      "grad_norm": 168.0,
      "learning_rate": 9.763852242744063e-05,
      "loss": 2.1562,
      "step": 2646
    },
    {
      "epoch": 3.49,
      "grad_norm": 157.0,
      "learning_rate": 9.761873350923482e-05,
      "loss": 2.0312,
      "step": 2647
    },
    {
      "epoch": 3.49,
      "grad_norm": 16.25,
      "learning_rate": 9.759894459102902e-05,
      "loss": 0.3613,
      "step": 2648
    },
    {
      "epoch": 3.49,
      "grad_norm": 19.75,
      "learning_rate": 9.75791556728232e-05,
      "loss": 0.127,
      "step": 2649
    },
    {
      "epoch": 3.5,
      "grad_norm": 133.0,
      "learning_rate": 9.75593667546174e-05,
      "loss": 2.3281,
      "step": 2650
    },
    {
      "epoch": 3.5,
      "grad_norm": 14.0625,
      "learning_rate": 9.75395778364116e-05,
      "loss": 0.3242,
      "step": 2651
    },
    {
      "epoch": 3.5,
      "grad_norm": 264.0,
      "learning_rate": 9.75197889182058e-05,
      "loss": 3.8906,
      "step": 2652
    },
    {
      "epoch": 3.5,
      "grad_norm": 60.75,
      "learning_rate": 9.75e-05,
      "loss": 0.6836,
      "step": 2653
    },
    {
      "epoch": 3.5,
      "grad_norm": 17.75,
      "learning_rate": 9.74802110817942e-05,
      "loss": 0.2715,
      "step": 2654
    },
    {
      "epoch": 3.5,
      "grad_norm": 434.0,
      "learning_rate": 9.746042216358838e-05,
      "loss": 8.4375,
      "step": 2655
    },
    {
      "epoch": 3.5,
      "grad_norm": 162.0,
      "learning_rate": 9.744063324538258e-05,
      "loss": 2.0781,
      "step": 2656
    },
    {
      "epoch": 3.51,
      "grad_norm": 29.125,
      "learning_rate": 9.742084432717678e-05,
      "loss": 0.4238,
      "step": 2657
    },
    {
      "epoch": 3.51,
      "grad_norm": 262.0,
      "learning_rate": 9.740105540897097e-05,
      "loss": 3.5781,
      "step": 2658
    },
    {
      "epoch": 3.51,
      "grad_norm": 15.125,
      "learning_rate": 9.738126649076517e-05,
      "loss": 0.1387,
      "step": 2659
    },
    {
      "epoch": 3.51,
      "grad_norm": 31.25,
      "learning_rate": 9.736147757255937e-05,
      "loss": 0.5312,
      "step": 2660
    },
    {
      "epoch": 3.51,
      "grad_norm": 117.5,
      "learning_rate": 9.734168865435356e-05,
      "loss": 1.7578,
      "step": 2661
    },
    {
      "epoch": 3.51,
      "grad_norm": 38.25,
      "learning_rate": 9.732189973614775e-05,
      "loss": 0.3809,
      "step": 2662
    },
    {
      "epoch": 3.51,
      "grad_norm": 208.0,
      "learning_rate": 9.730211081794194e-05,
      "loss": 3.5938,
      "step": 2663
    },
    {
      "epoch": 3.51,
      "grad_norm": 28.25,
      "learning_rate": 9.728232189973614e-05,
      "loss": 0.668,
      "step": 2664
    },
    {
      "epoch": 3.52,
      "grad_norm": 35.5,
      "learning_rate": 9.726253298153033e-05,
      "loss": 0.8516,
      "step": 2665
    },
    {
      "epoch": 3.52,
      "grad_norm": 118.0,
      "learning_rate": 9.724274406332452e-05,
      "loss": 1.8359,
      "step": 2666
    },
    {
      "epoch": 3.52,
      "grad_norm": 19.625,
      "learning_rate": 9.722295514511872e-05,
      "loss": 0.3574,
      "step": 2667
    },
    {
      "epoch": 3.52,
      "grad_norm": 35.0,
      "learning_rate": 9.720316622691291e-05,
      "loss": 0.3418,
      "step": 2668
    },
    {
      "epoch": 3.52,
      "grad_norm": 44.0,
      "learning_rate": 9.718337730870711e-05,
      "loss": 0.3926,
      "step": 2669
    },
    {
      "epoch": 3.52,
      "grad_norm": 210.0,
      "learning_rate": 9.716358839050131e-05,
      "loss": 4.7188,
      "step": 2670
    },
    {
      "epoch": 3.52,
      "grad_norm": 360.0,
      "learning_rate": 9.714379947229551e-05,
      "loss": 4.5625,
      "step": 2671
    },
    {
      "epoch": 3.53,
      "grad_norm": 356.0,
      "learning_rate": 9.71240105540897e-05,
      "loss": 4.7188,
      "step": 2672
    },
    {
      "epoch": 3.53,
      "grad_norm": 194.0,
      "learning_rate": 9.710422163588389e-05,
      "loss": 3.6719,
      "step": 2673
    },
    {
      "epoch": 3.53,
      "grad_norm": 42.0,
      "learning_rate": 9.708443271767809e-05,
      "loss": 0.3594,
      "step": 2674
    },
    {
      "epoch": 3.53,
      "grad_norm": 97.5,
      "learning_rate": 9.706464379947229e-05,
      "loss": 1.6719,
      "step": 2675
    },
    {
      "epoch": 3.53,
      "grad_norm": 26.75,
      "learning_rate": 9.704485488126649e-05,
      "loss": 0.6016,
      "step": 2676
    },
    {
      "epoch": 3.53,
      "grad_norm": 97.5,
      "learning_rate": 9.702506596306068e-05,
      "loss": 1.3047,
      "step": 2677
    },
    {
      "epoch": 3.53,
      "grad_norm": 31.875,
      "learning_rate": 9.700527704485487e-05,
      "loss": 0.4844,
      "step": 2678
    },
    {
      "epoch": 3.53,
      "grad_norm": 22.875,
      "learning_rate": 9.698548812664907e-05,
      "loss": 0.2734,
      "step": 2679
    },
    {
      "epoch": 3.54,
      "grad_norm": 22.5,
      "learning_rate": 9.696569920844326e-05,
      "loss": 0.1963,
      "step": 2680
    },
    {
      "epoch": 3.54,
      "grad_norm": 109.0,
      "learning_rate": 9.694591029023746e-05,
      "loss": 1.7969,
      "step": 2681
    },
    {
      "epoch": 3.54,
      "grad_norm": 103.5,
      "learning_rate": 9.692612137203166e-05,
      "loss": 1.2656,
      "step": 2682
    },
    {
      "epoch": 3.54,
      "grad_norm": 33.0,
      "learning_rate": 9.690633245382586e-05,
      "loss": 0.2676,
      "step": 2683
    },
    {
      "epoch": 3.54,
      "grad_norm": 31.5,
      "learning_rate": 9.688654353562004e-05,
      "loss": 0.4199,
      "step": 2684
    },
    {
      "epoch": 3.54,
      "grad_norm": 223.0,
      "learning_rate": 9.686675461741424e-05,
      "loss": 3.7656,
      "step": 2685
    },
    {
      "epoch": 3.54,
      "grad_norm": 53.75,
      "learning_rate": 9.684696569920844e-05,
      "loss": 0.7344,
      "step": 2686
    },
    {
      "epoch": 3.54,
      "grad_norm": 29.0,
      "learning_rate": 9.682717678100264e-05,
      "loss": 0.5742,
      "step": 2687
    },
    {
      "epoch": 3.55,
      "grad_norm": 201.0,
      "learning_rate": 9.680738786279684e-05,
      "loss": 3.4688,
      "step": 2688
    },
    {
      "epoch": 3.55,
      "grad_norm": 217.0,
      "learning_rate": 9.678759894459103e-05,
      "loss": 3.6875,
      "step": 2689
    },
    {
      "epoch": 3.55,
      "grad_norm": 43.0,
      "learning_rate": 9.676781002638522e-05,
      "loss": 0.6523,
      "step": 2690
    },
    {
      "epoch": 3.55,
      "grad_norm": 108.5,
      "learning_rate": 9.674802110817942e-05,
      "loss": 1.5703,
      "step": 2691
    },
    {
      "epoch": 3.55,
      "grad_norm": 23.0,
      "learning_rate": 9.672823218997361e-05,
      "loss": 0.5273,
      "step": 2692
    },
    {
      "epoch": 3.55,
      "grad_norm": 37.5,
      "learning_rate": 9.67084432717678e-05,
      "loss": 0.4043,
      "step": 2693
    },
    {
      "epoch": 3.55,
      "grad_norm": 29.375,
      "learning_rate": 9.668865435356198e-05,
      "loss": 0.5547,
      "step": 2694
    },
    {
      "epoch": 3.56,
      "grad_norm": 11.6875,
      "learning_rate": 9.666886543535618e-05,
      "loss": 0.2051,
      "step": 2695
    },
    {
      "epoch": 3.56,
      "grad_norm": 66.5,
      "learning_rate": 9.664907651715038e-05,
      "loss": 0.5547,
      "step": 2696
    },
    {
      "epoch": 3.56,
      "grad_norm": 36.0,
      "learning_rate": 9.662928759894458e-05,
      "loss": 0.3379,
      "step": 2697
    },
    {
      "epoch": 3.56,
      "grad_norm": 141.0,
      "learning_rate": 9.660949868073878e-05,
      "loss": 2.7031,
      "step": 2698
    },
    {
      "epoch": 3.56,
      "grad_norm": 139.0,
      "learning_rate": 9.658970976253297e-05,
      "loss": 2.5469,
      "step": 2699
    },
    {
      "epoch": 3.56,
      "grad_norm": 48.25,
      "learning_rate": 9.656992084432716e-05,
      "loss": 0.5117,
      "step": 2700
    },
    {
      "epoch": 3.56,
      "grad_norm": 188.0,
      "learning_rate": 9.655013192612136e-05,
      "loss": 5.5,
      "step": 2701
    },
    {
      "epoch": 3.56,
      "grad_norm": 138.0,
      "learning_rate": 9.653034300791555e-05,
      "loss": 2.4531,
      "step": 2702
    },
    {
      "epoch": 3.57,
      "grad_norm": 43.75,
      "learning_rate": 9.651055408970975e-05,
      "loss": 0.3145,
      "step": 2703
    },
    {
      "epoch": 3.57,
      "grad_norm": 40.75,
      "learning_rate": 9.649076517150395e-05,
      "loss": 0.2871,
      "step": 2704
    },
    {
      "epoch": 3.57,
      "grad_norm": 207.0,
      "learning_rate": 9.647097625329815e-05,
      "loss": 3.75,
      "step": 2705
    },
    {
      "epoch": 3.57,
      "grad_norm": 244.0,
      "learning_rate": 9.645118733509233e-05,
      "loss": 5.0625,
      "step": 2706
    },
    {
      "epoch": 3.57,
      "grad_norm": 24.25,
      "learning_rate": 9.643139841688653e-05,
      "loss": 0.1611,
      "step": 2707
    },
    {
      "epoch": 3.57,
      "grad_norm": 26.75,
      "learning_rate": 9.641160949868073e-05,
      "loss": 0.5547,
      "step": 2708
    },
    {
      "epoch": 3.57,
      "grad_norm": 7.9375,
      "learning_rate": 9.639182058047493e-05,
      "loss": 0.082,
      "step": 2709
    },
    {
      "epoch": 3.58,
      "grad_norm": 168.0,
      "learning_rate": 9.637203166226912e-05,
      "loss": 2.2969,
      "step": 2710
    },
    {
      "epoch": 3.58,
      "grad_norm": 8.8125,
      "learning_rate": 9.635224274406332e-05,
      "loss": 0.0918,
      "step": 2711
    },
    {
      "epoch": 3.58,
      "grad_norm": 9.625,
      "learning_rate": 9.633245382585751e-05,
      "loss": 0.1279,
      "step": 2712
    },
    {
      "epoch": 3.58,
      "grad_norm": 94.5,
      "learning_rate": 9.63126649076517e-05,
      "loss": 1.1953,
      "step": 2713
    },
    {
      "epoch": 3.58,
      "grad_norm": 33.25,
      "learning_rate": 9.62928759894459e-05,
      "loss": 0.5078,
      "step": 2714
    },
    {
      "epoch": 3.58,
      "grad_norm": 200.0,
      "learning_rate": 9.62730870712401e-05,
      "loss": 3.1094,
      "step": 2715
    },
    {
      "epoch": 3.58,
      "grad_norm": 182.0,
      "learning_rate": 9.62532981530343e-05,
      "loss": 2.5156,
      "step": 2716
    },
    {
      "epoch": 3.58,
      "grad_norm": 326.0,
      "learning_rate": 9.62335092348285e-05,
      "loss": 5.3125,
      "step": 2717
    },
    {
      "epoch": 3.59,
      "grad_norm": 150.0,
      "learning_rate": 9.621372031662268e-05,
      "loss": 4.3125,
      "step": 2718
    },
    {
      "epoch": 3.59,
      "grad_norm": 188.0,
      "learning_rate": 9.619393139841688e-05,
      "loss": 2.625,
      "step": 2719
    },
    {
      "epoch": 3.59,
      "grad_norm": 27.875,
      "learning_rate": 9.617414248021108e-05,
      "loss": 0.3066,
      "step": 2720
    },
    {
      "epoch": 3.59,
      "grad_norm": 62.75,
      "learning_rate": 9.615435356200528e-05,
      "loss": 0.7109,
      "step": 2721
    },
    {
      "epoch": 3.59,
      "grad_norm": 20.0,
      "learning_rate": 9.613456464379947e-05,
      "loss": 0.3867,
      "step": 2722
    },
    {
      "epoch": 3.59,
      "grad_norm": 145.0,
      "learning_rate": 9.611477572559365e-05,
      "loss": 1.8984,
      "step": 2723
    },
    {
      "epoch": 3.59,
      "grad_norm": 131.0,
      "learning_rate": 9.609498680738784e-05,
      "loss": 1.6016,
      "step": 2724
    },
    {
      "epoch": 3.59,
      "grad_norm": 25.125,
      "learning_rate": 9.607519788918204e-05,
      "loss": 0.1699,
      "step": 2725
    },
    {
      "epoch": 3.6,
      "grad_norm": 42.0,
      "learning_rate": 9.605540897097624e-05,
      "loss": 0.4766,
      "step": 2726
    },
    {
      "epoch": 3.6,
      "grad_norm": 142.0,
      "learning_rate": 9.603562005277044e-05,
      "loss": 1.8828,
      "step": 2727
    },
    {
      "epoch": 3.6,
      "grad_norm": 34.0,
      "learning_rate": 9.601583113456464e-05,
      "loss": 0.2832,
      "step": 2728
    },
    {
      "epoch": 3.6,
      "grad_norm": 32.5,
      "learning_rate": 9.599604221635882e-05,
      "loss": 0.2559,
      "step": 2729
    },
    {
      "epoch": 3.6,
      "grad_norm": 149.0,
      "learning_rate": 9.597625329815302e-05,
      "loss": 2.0938,
      "step": 2730
    },
    {
      "epoch": 3.6,
      "grad_norm": 25.875,
      "learning_rate": 9.595646437994722e-05,
      "loss": 0.1699,
      "step": 2731
    },
    {
      "epoch": 3.6,
      "grad_norm": 250.0,
      "learning_rate": 9.593667546174141e-05,
      "loss": 4.9062,
      "step": 2732
    },
    {
      "epoch": 3.61,
      "grad_norm": 108.5,
      "learning_rate": 9.591688654353561e-05,
      "loss": 1.6797,
      "step": 2733
    },
    {
      "epoch": 3.61,
      "grad_norm": 95.0,
      "learning_rate": 9.589709762532981e-05,
      "loss": 1.3047,
      "step": 2734
    },
    {
      "epoch": 3.61,
      "grad_norm": 45.25,
      "learning_rate": 9.5877308707124e-05,
      "loss": 0.334,
      "step": 2735
    },
    {
      "epoch": 3.61,
      "grad_norm": 77.0,
      "learning_rate": 9.585751978891819e-05,
      "loss": 1.1094,
      "step": 2736
    },
    {
      "epoch": 3.61,
      "grad_norm": 131.0,
      "learning_rate": 9.583773087071239e-05,
      "loss": 1.6328,
      "step": 2737
    },
    {
      "epoch": 3.61,
      "grad_norm": 42.75,
      "learning_rate": 9.581794195250659e-05,
      "loss": 0.4473,
      "step": 2738
    },
    {
      "epoch": 3.61,
      "grad_norm": 92.0,
      "learning_rate": 9.579815303430079e-05,
      "loss": 1.3359,
      "step": 2739
    },
    {
      "epoch": 3.61,
      "grad_norm": 73.0,
      "learning_rate": 9.577836411609499e-05,
      "loss": 0.5234,
      "step": 2740
    },
    {
      "epoch": 3.62,
      "grad_norm": 296.0,
      "learning_rate": 9.575857519788917e-05,
      "loss": 5.125,
      "step": 2741
    },
    {
      "epoch": 3.62,
      "grad_norm": 37.75,
      "learning_rate": 9.573878627968337e-05,
      "loss": 0.793,
      "step": 2742
    },
    {
      "epoch": 3.62,
      "grad_norm": 135.0,
      "learning_rate": 9.571899736147757e-05,
      "loss": 1.375,
      "step": 2743
    },
    {
      "epoch": 3.62,
      "grad_norm": 49.5,
      "learning_rate": 9.569920844327176e-05,
      "loss": 0.6641,
      "step": 2744
    },
    {
      "epoch": 3.62,
      "grad_norm": 24.125,
      "learning_rate": 9.567941952506596e-05,
      "loss": 0.8477,
      "step": 2745
    },
    {
      "epoch": 3.62,
      "grad_norm": 73.0,
      "learning_rate": 9.565963060686016e-05,
      "loss": 0.5195,
      "step": 2746
    },
    {
      "epoch": 3.62,
      "grad_norm": 90.5,
      "learning_rate": 9.563984168865434e-05,
      "loss": 0.9883,
      "step": 2747
    },
    {
      "epoch": 3.63,
      "grad_norm": 55.5,
      "learning_rate": 9.562005277044854e-05,
      "loss": 0.6172,
      "step": 2748
    },
    {
      "epoch": 3.63,
      "grad_norm": 30.875,
      "learning_rate": 9.560026385224274e-05,
      "loss": 0.8867,
      "step": 2749
    },
    {
      "epoch": 3.63,
      "grad_norm": 30.5,
      "learning_rate": 9.558047493403694e-05,
      "loss": 0.9414,
      "step": 2750
    },
    {
      "epoch": 3.63,
      "grad_norm": 69.5,
      "learning_rate": 9.556068601583114e-05,
      "loss": 0.9805,
      "step": 2751
    },
    {
      "epoch": 3.63,
      "grad_norm": 32.25,
      "learning_rate": 9.554089709762534e-05,
      "loss": 0.6055,
      "step": 2752
    },
    {
      "epoch": 3.63,
      "grad_norm": 314.0,
      "learning_rate": 9.55211081794195e-05,
      "loss": 5.2188,
      "step": 2753
    },
    {
      "epoch": 3.63,
      "grad_norm": 57.75,
      "learning_rate": 9.55013192612137e-05,
      "loss": 0.5742,
      "step": 2754
    },
    {
      "epoch": 3.63,
      "grad_norm": 59.75,
      "learning_rate": 9.54815303430079e-05,
      "loss": 0.9531,
      "step": 2755
    },
    {
      "epoch": 3.64,
      "grad_norm": 110.0,
      "learning_rate": 9.54617414248021e-05,
      "loss": 1.0078,
      "step": 2756
    },
    {
      "epoch": 3.64,
      "grad_norm": 55.75,
      "learning_rate": 9.54419525065963e-05,
      "loss": 0.8281,
      "step": 2757
    },
    {
      "epoch": 3.64,
      "grad_norm": 29.875,
      "learning_rate": 9.542216358839048e-05,
      "loss": 0.8633,
      "step": 2758
    },
    {
      "epoch": 3.64,
      "grad_norm": 56.25,
      "learning_rate": 9.540237467018468e-05,
      "loss": 1.0859,
      "step": 2759
    },
    {
      "epoch": 3.64,
      "grad_norm": 74.5,
      "learning_rate": 9.538258575197888e-05,
      "loss": 0.7578,
      "step": 2760
    },
    {
      "epoch": 3.64,
      "grad_norm": 66.5,
      "learning_rate": 9.536279683377308e-05,
      "loss": 0.9453,
      "step": 2761
    },
    {
      "epoch": 3.64,
      "grad_norm": 51.75,
      "learning_rate": 9.534300791556728e-05,
      "loss": 0.4727,
      "step": 2762
    },
    {
      "epoch": 3.65,
      "grad_norm": 220.0,
      "learning_rate": 9.532321899736147e-05,
      "loss": 4.2188,
      "step": 2763
    },
    {
      "epoch": 3.65,
      "grad_norm": 67.5,
      "learning_rate": 9.530343007915566e-05,
      "loss": 0.8828,
      "step": 2764
    },
    {
      "epoch": 3.65,
      "grad_norm": 253.0,
      "learning_rate": 9.528364116094986e-05,
      "loss": 4.5312,
      "step": 2765
    },
    {
      "epoch": 3.65,
      "grad_norm": 48.0,
      "learning_rate": 9.526385224274405e-05,
      "loss": 0.6914,
      "step": 2766
    },
    {
      "epoch": 3.65,
      "grad_norm": 12.75,
      "learning_rate": 9.524406332453825e-05,
      "loss": 0.0669,
      "step": 2767
    },
    {
      "epoch": 3.65,
      "grad_norm": 33.5,
      "learning_rate": 9.522427440633245e-05,
      "loss": 0.1729,
      "step": 2768
    },
    {
      "epoch": 3.65,
      "grad_norm": 22.5,
      "learning_rate": 9.520448548812665e-05,
      "loss": 0.291,
      "step": 2769
    },
    {
      "epoch": 3.65,
      "grad_norm": 25.375,
      "learning_rate": 9.518469656992083e-05,
      "loss": 0.1494,
      "step": 2770
    },
    {
      "epoch": 3.66,
      "grad_norm": 80.5,
      "learning_rate": 9.516490765171503e-05,
      "loss": 0.9219,
      "step": 2771
    },
    {
      "epoch": 3.66,
      "grad_norm": 122.0,
      "learning_rate": 9.514511873350923e-05,
      "loss": 1.8594,
      "step": 2772
    },
    {
      "epoch": 3.66,
      "grad_norm": 79.5,
      "learning_rate": 9.512532981530343e-05,
      "loss": 1.1016,
      "step": 2773
    },
    {
      "epoch": 3.66,
      "grad_norm": 318.0,
      "learning_rate": 9.510554089709762e-05,
      "loss": 5.6562,
      "step": 2774
    },
    {
      "epoch": 3.66,
      "grad_norm": 65.5,
      "learning_rate": 9.508575197889182e-05,
      "loss": 0.7891,
      "step": 2775
    },
    {
      "epoch": 3.66,
      "grad_norm": 35.5,
      "learning_rate": 9.506596306068601e-05,
      "loss": 0.3047,
      "step": 2776
    },
    {
      "epoch": 3.66,
      "grad_norm": 7.3125,
      "learning_rate": 9.50461741424802e-05,
      "loss": 0.2832,
      "step": 2777
    },
    {
      "epoch": 3.66,
      "grad_norm": 22.125,
      "learning_rate": 9.50263852242744e-05,
      "loss": 0.2373,
      "step": 2778
    },
    {
      "epoch": 3.67,
      "grad_norm": 13.625,
      "learning_rate": 9.50065963060686e-05,
      "loss": 0.8867,
      "step": 2779
    },
    {
      "epoch": 3.67,
      "grad_norm": 137.0,
      "learning_rate": 9.49868073878628e-05,
      "loss": 2.9531,
      "step": 2780
    },
    {
      "epoch": 3.67,
      "grad_norm": 36.25,
      "learning_rate": 9.4967018469657e-05,
      "loss": 0.2539,
      "step": 2781
    },
    {
      "epoch": 3.67,
      "grad_norm": 207.0,
      "learning_rate": 9.494722955145118e-05,
      "loss": 4.4688,
      "step": 2782
    },
    {
      "epoch": 3.67,
      "grad_norm": 16.875,
      "learning_rate": 9.492744063324537e-05,
      "loss": 0.2217,
      "step": 2783
    },
    {
      "epoch": 3.67,
      "grad_norm": 42.5,
      "learning_rate": 9.490765171503956e-05,
      "loss": 0.5547,
      "step": 2784
    },
    {
      "epoch": 3.67,
      "grad_norm": 266.0,
      "learning_rate": 9.488786279683376e-05,
      "loss": 5.9688,
      "step": 2785
    },
    {
      "epoch": 3.68,
      "grad_norm": 213.0,
      "learning_rate": 9.486807387862795e-05,
      "loss": 4.3125,
      "step": 2786
    },
    {
      "epoch": 3.68,
      "grad_norm": 8.6875,
      "learning_rate": 9.484828496042215e-05,
      "loss": 0.2246,
      "step": 2787
    },
    {
      "epoch": 3.68,
      "grad_norm": 21.25,
      "learning_rate": 9.482849604221634e-05,
      "loss": 0.1641,
      "step": 2788
    },
    {
      "epoch": 3.68,
      "grad_norm": 41.75,
      "learning_rate": 9.480870712401054e-05,
      "loss": 0.334,
      "step": 2789
    },
    {
      "epoch": 3.68,
      "grad_norm": 32.5,
      "learning_rate": 9.478891820580474e-05,
      "loss": 0.3574,
      "step": 2790
    },
    {
      "epoch": 3.68,
      "grad_norm": 254.0,
      "learning_rate": 9.476912928759894e-05,
      "loss": 5.4375,
      "step": 2791
    },
    {
      "epoch": 3.68,
      "grad_norm": 71.5,
      "learning_rate": 9.474934036939312e-05,
      "loss": 0.8203,
      "step": 2792
    },
    {
      "epoch": 3.68,
      "grad_norm": 240.0,
      "learning_rate": 9.472955145118732e-05,
      "loss": 4.625,
      "step": 2793
    },
    {
      "epoch": 3.69,
      "grad_norm": 59.25,
      "learning_rate": 9.470976253298152e-05,
      "loss": 0.9453,
      "step": 2794
    },
    {
      "epoch": 3.69,
      "grad_norm": 37.25,
      "learning_rate": 9.468997361477572e-05,
      "loss": 0.5547,
      "step": 2795
    },
    {
      "epoch": 3.69,
      "grad_norm": 217.0,
      "learning_rate": 9.467018469656991e-05,
      "loss": 3.8594,
      "step": 2796
    },
    {
      "epoch": 3.69,
      "grad_norm": 34.5,
      "learning_rate": 9.465039577836411e-05,
      "loss": 0.5,
      "step": 2797
    },
    {
      "epoch": 3.69,
      "grad_norm": 225.0,
      "learning_rate": 9.46306068601583e-05,
      "loss": 3.6719,
      "step": 2798
    },
    {
      "epoch": 3.69,
      "grad_norm": 342.0,
      "learning_rate": 9.46108179419525e-05,
      "loss": 6.2812,
      "step": 2799
    },
    {
      "epoch": 3.69,
      "grad_norm": 29.875,
      "learning_rate": 9.459102902374669e-05,
      "loss": 0.2158,
      "step": 2800
    },
    {
      "epoch": 3.7,
      "grad_norm": 16.5,
      "learning_rate": 9.457124010554089e-05,
      "loss": 0.5977,
      "step": 2801
    },
    {
      "epoch": 3.7,
      "grad_norm": 20.375,
      "learning_rate": 9.455145118733509e-05,
      "loss": 0.5781,
      "step": 2802
    },
    {
      "epoch": 3.7,
      "grad_norm": 342.0,
      "learning_rate": 9.453166226912929e-05,
      "loss": 4.3438,
      "step": 2803
    },
    {
      "epoch": 3.7,
      "grad_norm": 298.0,
      "learning_rate": 9.451187335092347e-05,
      "loss": 6.2812,
      "step": 2804
    },
    {
      "epoch": 3.7,
      "grad_norm": 26.875,
      "learning_rate": 9.449208443271767e-05,
      "loss": 0.4883,
      "step": 2805
    },
    {
      "epoch": 3.7,
      "grad_norm": 161.0,
      "learning_rate": 9.447229551451187e-05,
      "loss": 2.0156,
      "step": 2806
    },
    {
      "epoch": 3.7,
      "grad_norm": 24.375,
      "learning_rate": 9.445250659630607e-05,
      "loss": 0.4746,
      "step": 2807
    },
    {
      "epoch": 3.7,
      "grad_norm": 25.875,
      "learning_rate": 9.443271767810026e-05,
      "loss": 0.4688,
      "step": 2808
    },
    {
      "epoch": 3.71,
      "grad_norm": 44.5,
      "learning_rate": 9.441292875989446e-05,
      "loss": 0.6758,
      "step": 2809
    },
    {
      "epoch": 3.71,
      "grad_norm": 195.0,
      "learning_rate": 9.439313984168865e-05,
      "loss": 3.9844,
      "step": 2810
    },
    {
      "epoch": 3.71,
      "grad_norm": 22.75,
      "learning_rate": 9.437335092348284e-05,
      "loss": 0.3789,
      "step": 2811
    },
    {
      "epoch": 3.71,
      "grad_norm": 159.0,
      "learning_rate": 9.435356200527704e-05,
      "loss": 2.125,
      "step": 2812
    },
    {
      "epoch": 3.71,
      "grad_norm": 21.125,
      "learning_rate": 9.433377308707123e-05,
      "loss": 0.3633,
      "step": 2813
    },
    {
      "epoch": 3.71,
      "grad_norm": 33.5,
      "learning_rate": 9.431398416886543e-05,
      "loss": 0.4805,
      "step": 2814
    },
    {
      "epoch": 3.71,
      "grad_norm": 38.0,
      "learning_rate": 9.429419525065961e-05,
      "loss": 0.4902,
      "step": 2815
    },
    {
      "epoch": 3.72,
      "grad_norm": 82.5,
      "learning_rate": 9.427440633245381e-05,
      "loss": 0.9727,
      "step": 2816
    },
    {
      "epoch": 3.72,
      "grad_norm": 52.75,
      "learning_rate": 9.4254617414248e-05,
      "loss": 0.6328,
      "step": 2817
    },
    {
      "epoch": 3.72,
      "grad_norm": 38.5,
      "learning_rate": 9.42348284960422e-05,
      "loss": 0.8203,
      "step": 2818
    },
    {
      "epoch": 3.72,
      "grad_norm": 65.0,
      "learning_rate": 9.42150395778364e-05,
      "loss": 0.5625,
      "step": 2819
    },
    {
      "epoch": 3.72,
      "grad_norm": 14.625,
      "learning_rate": 9.41952506596306e-05,
      "loss": 0.3457,
      "step": 2820
    },
    {
      "epoch": 3.72,
      "grad_norm": 143.0,
      "learning_rate": 9.417546174142478e-05,
      "loss": 2.7969,
      "step": 2821
    },
    {
      "epoch": 3.72,
      "grad_norm": 42.0,
      "learning_rate": 9.415567282321898e-05,
      "loss": 0.2773,
      "step": 2822
    },
    {
      "epoch": 3.72,
      "grad_norm": 8.625,
      "learning_rate": 9.413588390501318e-05,
      "loss": 0.3164,
      "step": 2823
    },
    {
      "epoch": 3.73,
      "grad_norm": 5.90625,
      "learning_rate": 9.411609498680738e-05,
      "loss": 0.1738,
      "step": 2824
    },
    {
      "epoch": 3.73,
      "grad_norm": 6.71875,
      "learning_rate": 9.409630606860158e-05,
      "loss": 0.0938,
      "step": 2825
    },
    {
      "epoch": 3.73,
      "grad_norm": 157.0,
      "learning_rate": 9.407651715039577e-05,
      "loss": 3.5156,
      "step": 2826
    },
    {
      "epoch": 3.73,
      "grad_norm": 167.0,
      "learning_rate": 9.405672823218996e-05,
      "loss": 3.2969,
      "step": 2827
    },
    {
      "epoch": 3.73,
      "grad_norm": 2.71875,
      "learning_rate": 9.403693931398416e-05,
      "loss": 0.0693,
      "step": 2828
    },
    {
      "epoch": 3.73,
      "grad_norm": 28.25,
      "learning_rate": 9.401715039577836e-05,
      "loss": 0.2422,
      "step": 2829
    },
    {
      "epoch": 3.73,
      "grad_norm": 187.0,
      "learning_rate": 9.399736147757255e-05,
      "loss": 3.5625,
      "step": 2830
    },
    {
      "epoch": 3.73,
      "grad_norm": 232.0,
      "learning_rate": 9.397757255936675e-05,
      "loss": 6.1562,
      "step": 2831
    },
    {
      "epoch": 3.74,
      "grad_norm": 45.75,
      "learning_rate": 9.395778364116095e-05,
      "loss": 0.5781,
      "step": 2832
    },
    {
      "epoch": 3.74,
      "grad_norm": 201.0,
      "learning_rate": 9.393799472295513e-05,
      "loss": 3.9844,
      "step": 2833
    },
    {
      "epoch": 3.74,
      "grad_norm": 80.0,
      "learning_rate": 9.391820580474933e-05,
      "loss": 0.9023,
      "step": 2834
    },
    {
      "epoch": 3.74,
      "grad_norm": 25.375,
      "learning_rate": 9.389841688654353e-05,
      "loss": 0.1152,
      "step": 2835
    },
    {
      "epoch": 3.74,
      "grad_norm": 31.625,
      "learning_rate": 9.387862796833773e-05,
      "loss": 0.6914,
      "step": 2836
    },
    {
      "epoch": 3.74,
      "grad_norm": 41.25,
      "learning_rate": 9.385883905013193e-05,
      "loss": 0.375,
      "step": 2837
    },
    {
      "epoch": 3.74,
      "grad_norm": 175.0,
      "learning_rate": 9.383905013192612e-05,
      "loss": 2.8594,
      "step": 2838
    },
    {
      "epoch": 3.75,
      "grad_norm": 172.0,
      "learning_rate": 9.381926121372031e-05,
      "loss": 2.7656,
      "step": 2839
    },
    {
      "epoch": 3.75,
      "grad_norm": 171.0,
      "learning_rate": 9.379947229551451e-05,
      "loss": 2.7031,
      "step": 2840
    },
    {
      "epoch": 3.75,
      "grad_norm": 14.0625,
      "learning_rate": 9.37796833773087e-05,
      "loss": 0.7891,
      "step": 2841
    },
    {
      "epoch": 3.75,
      "grad_norm": 156.0,
      "learning_rate": 9.37598944591029e-05,
      "loss": 2.0781,
      "step": 2842
    },
    {
      "epoch": 3.75,
      "grad_norm": 274.0,
      "learning_rate": 9.374010554089709e-05,
      "loss": 3.7344,
      "step": 2843
    },
    {
      "epoch": 3.75,
      "grad_norm": 137.0,
      "learning_rate": 9.372031662269127e-05,
      "loss": 1.8047,
      "step": 2844
    },
    {
      "epoch": 3.75,
      "grad_norm": 42.75,
      "learning_rate": 9.370052770448547e-05,
      "loss": 0.2812,
      "step": 2845
    },
    {
      "epoch": 3.75,
      "grad_norm": 118.0,
      "learning_rate": 9.368073878627967e-05,
      "loss": 1.1875,
      "step": 2846
    },
    {
      "epoch": 3.76,
      "grad_norm": 37.25,
      "learning_rate": 9.366094986807387e-05,
      "loss": 1.0859,
      "step": 2847
    },
    {
      "epoch": 3.76,
      "grad_norm": 51.0,
      "learning_rate": 9.364116094986806e-05,
      "loss": 0.5625,
      "step": 2848
    },
    {
      "epoch": 3.76,
      "grad_norm": 42.25,
      "learning_rate": 9.362137203166226e-05,
      "loss": 1.1719,
      "step": 2849
    },
    {
      "epoch": 3.76,
      "grad_norm": 90.0,
      "learning_rate": 9.360158311345645e-05,
      "loss": 1.375,
      "step": 2850
    },
    {
      "epoch": 3.76,
      "grad_norm": 49.5,
      "learning_rate": 9.358179419525064e-05,
      "loss": 0.5625,
      "step": 2851
    },
    {
      "epoch": 3.76,
      "grad_norm": 48.0,
      "learning_rate": 9.356200527704484e-05,
      "loss": 0.5898,
      "step": 2852
    },
    {
      "epoch": 3.76,
      "grad_norm": 63.75,
      "learning_rate": 9.354221635883904e-05,
      "loss": 0.5781,
      "step": 2853
    },
    {
      "epoch": 3.77,
      "grad_norm": 57.5,
      "learning_rate": 9.352242744063324e-05,
      "loss": 0.7656,
      "step": 2854
    },
    {
      "epoch": 3.77,
      "grad_norm": 75.0,
      "learning_rate": 9.350263852242744e-05,
      "loss": 0.8828,
      "step": 2855
    },
    {
      "epoch": 3.77,
      "grad_norm": 60.0,
      "learning_rate": 9.348284960422162e-05,
      "loss": 1.1172,
      "step": 2856
    },
    {
      "epoch": 3.77,
      "grad_norm": 59.0,
      "learning_rate": 9.346306068601582e-05,
      "loss": 0.7891,
      "step": 2857
    },
    {
      "epoch": 3.77,
      "grad_norm": 31.625,
      "learning_rate": 9.344327176781002e-05,
      "loss": 0.2676,
      "step": 2858
    },
    {
      "epoch": 3.77,
      "grad_norm": 86.5,
      "learning_rate": 9.342348284960422e-05,
      "loss": 1.2188,
      "step": 2859
    },
    {
      "epoch": 3.77,
      "grad_norm": 49.0,
      "learning_rate": 9.340369393139841e-05,
      "loss": 0.3438,
      "step": 2860
    },
    {
      "epoch": 3.77,
      "grad_norm": 122.0,
      "learning_rate": 9.338390501319261e-05,
      "loss": 1.2891,
      "step": 2861
    },
    {
      "epoch": 3.78,
      "grad_norm": 102.0,
      "learning_rate": 9.33641160949868e-05,
      "loss": 1.8672,
      "step": 2862
    },
    {
      "epoch": 3.78,
      "grad_norm": 121.0,
      "learning_rate": 9.3344327176781e-05,
      "loss": 1.5547,
      "step": 2863
    },
    {
      "epoch": 3.78,
      "grad_norm": 134.0,
      "learning_rate": 9.332453825857519e-05,
      "loss": 1.75,
      "step": 2864
    },
    {
      "epoch": 3.78,
      "grad_norm": 320.0,
      "learning_rate": 9.330474934036939e-05,
      "loss": 7.3438,
      "step": 2865
    },
    {
      "epoch": 3.78,
      "grad_norm": 247.0,
      "learning_rate": 9.328496042216359e-05,
      "loss": 2.6094,
      "step": 2866
    },
    {
      "epoch": 3.78,
      "grad_norm": 83.0,
      "learning_rate": 9.326517150395779e-05,
      "loss": 1.0,
      "step": 2867
    },
    {
      "epoch": 3.78,
      "grad_norm": 42.5,
      "learning_rate": 9.324538258575197e-05,
      "loss": 0.4297,
      "step": 2868
    },
    {
      "epoch": 3.78,
      "grad_norm": 30.5,
      "learning_rate": 9.322559366754617e-05,
      "loss": 0.4082,
      "step": 2869
    },
    {
      "epoch": 3.79,
      "grad_norm": 91.0,
      "learning_rate": 9.320580474934037e-05,
      "loss": 1.0781,
      "step": 2870
    },
    {
      "epoch": 3.79,
      "grad_norm": 214.0,
      "learning_rate": 9.318601583113457e-05,
      "loss": 5.5312,
      "step": 2871
    },
    {
      "epoch": 3.79,
      "grad_norm": 44.25,
      "learning_rate": 9.316622691292876e-05,
      "loss": 0.7539,
      "step": 2872
    },
    {
      "epoch": 3.79,
      "grad_norm": 30.625,
      "learning_rate": 9.314643799472293e-05,
      "loss": 0.4238,
      "step": 2873
    },
    {
      "epoch": 3.79,
      "grad_norm": 56.5,
      "learning_rate": 9.312664907651713e-05,
      "loss": 0.4414,
      "step": 2874
    },
    {
      "epoch": 3.79,
      "grad_norm": 34.5,
      "learning_rate": 9.310686015831133e-05,
      "loss": 0.4297,
      "step": 2875
    },
    {
      "epoch": 3.79,
      "grad_norm": 101.0,
      "learning_rate": 9.308707124010553e-05,
      "loss": 1.25,
      "step": 2876
    },
    {
      "epoch": 3.8,
      "grad_norm": 50.0,
      "learning_rate": 9.306728232189973e-05,
      "loss": 0.4199,
      "step": 2877
    },
    {
      "epoch": 3.8,
      "grad_norm": 99.0,
      "learning_rate": 9.304749340369392e-05,
      "loss": 1.5391,
      "step": 2878
    },
    {
      "epoch": 3.8,
      "grad_norm": 105.5,
      "learning_rate": 9.302770448548811e-05,
      "loss": 1.7422,
      "step": 2879
    },
    {
      "epoch": 3.8,
      "grad_norm": 41.5,
      "learning_rate": 9.300791556728231e-05,
      "loss": 0.3242,
      "step": 2880
    },
    {
      "epoch": 3.8,
      "grad_norm": 24.0,
      "learning_rate": 9.29881266490765e-05,
      "loss": 0.5078,
      "step": 2881
    },
    {
      "epoch": 3.8,
      "grad_norm": 236.0,
      "learning_rate": 9.29683377308707e-05,
      "loss": 2.6406,
      "step": 2882
    },
    {
      "epoch": 3.8,
      "grad_norm": 26.125,
      "learning_rate": 9.29485488126649e-05,
      "loss": 0.3652,
      "step": 2883
    },
    {
      "epoch": 3.8,
      "grad_norm": 21.375,
      "learning_rate": 9.29287598944591e-05,
      "loss": 0.4277,
      "step": 2884
    },
    {
      "epoch": 3.81,
      "grad_norm": 35.0,
      "learning_rate": 9.290897097625328e-05,
      "loss": 0.5898,
      "step": 2885
    },
    {
      "epoch": 3.81,
      "grad_norm": 74.0,
      "learning_rate": 9.288918205804748e-05,
      "loss": 0.6367,
      "step": 2886
    },
    {
      "epoch": 3.81,
      "grad_norm": 42.5,
      "learning_rate": 9.286939313984168e-05,
      "loss": 0.3066,
      "step": 2887
    },
    {
      "epoch": 3.81,
      "grad_norm": 111.0,
      "learning_rate": 9.284960422163588e-05,
      "loss": 1.4453,
      "step": 2888
    },
    {
      "epoch": 3.81,
      "grad_norm": 24.875,
      "learning_rate": 9.282981530343008e-05,
      "loss": 0.4121,
      "step": 2889
    },
    {
      "epoch": 3.81,
      "grad_norm": 215.0,
      "learning_rate": 9.281002638522427e-05,
      "loss": 5.2188,
      "step": 2890
    },
    {
      "epoch": 3.81,
      "grad_norm": 39.25,
      "learning_rate": 9.279023746701846e-05,
      "loss": 0.2949,
      "step": 2891
    },
    {
      "epoch": 3.82,
      "grad_norm": 35.25,
      "learning_rate": 9.277044854881266e-05,
      "loss": 0.6328,
      "step": 2892
    },
    {
      "epoch": 3.82,
      "grad_norm": 132.0,
      "learning_rate": 9.275065963060685e-05,
      "loss": 1.5703,
      "step": 2893
    },
    {
      "epoch": 3.82,
      "grad_norm": 19.25,
      "learning_rate": 9.273087071240105e-05,
      "loss": 0.3047,
      "step": 2894
    },
    {
      "epoch": 3.82,
      "grad_norm": 116.0,
      "learning_rate": 9.271108179419525e-05,
      "loss": 1.8203,
      "step": 2895
    },
    {
      "epoch": 3.82,
      "grad_norm": 15.625,
      "learning_rate": 9.269129287598945e-05,
      "loss": 0.2695,
      "step": 2896
    },
    {
      "epoch": 3.82,
      "grad_norm": 36.75,
      "learning_rate": 9.267150395778363e-05,
      "loss": 0.293,
      "step": 2897
    },
    {
      "epoch": 3.82,
      "grad_norm": 121.5,
      "learning_rate": 9.265171503957783e-05,
      "loss": 1.9141,
      "step": 2898
    },
    {
      "epoch": 3.82,
      "grad_norm": 216.0,
      "learning_rate": 9.263192612137203e-05,
      "loss": 6.0625,
      "step": 2899
    },
    {
      "epoch": 3.83,
      "grad_norm": 220.0,
      "learning_rate": 9.261213720316623e-05,
      "loss": 5.1562,
      "step": 2900
    },
    {
      "epoch": 3.83,
      "grad_norm": 73.0,
      "learning_rate": 9.259234828496043e-05,
      "loss": 0.5469,
      "step": 2901
    },
    {
      "epoch": 3.83,
      "grad_norm": 60.75,
      "learning_rate": 9.257255936675462e-05,
      "loss": 0.4883,
      "step": 2902
    },
    {
      "epoch": 3.83,
      "grad_norm": 22.125,
      "learning_rate": 9.25527704485488e-05,
      "loss": 0.5,
      "step": 2903
    },
    {
      "epoch": 3.83,
      "grad_norm": 122.0,
      "learning_rate": 9.253298153034299e-05,
      "loss": 1.8594,
      "step": 2904
    },
    {
      "epoch": 3.83,
      "grad_norm": 51.0,
      "learning_rate": 9.251319261213719e-05,
      "loss": 0.3652,
      "step": 2905
    },
    {
      "epoch": 3.83,
      "grad_norm": 39.25,
      "learning_rate": 9.249340369393139e-05,
      "loss": 0.4727,
      "step": 2906
    },
    {
      "epoch": 3.84,
      "grad_norm": 37.5,
      "learning_rate": 9.247361477572557e-05,
      "loss": 0.2373,
      "step": 2907
    },
    {
      "epoch": 3.84,
      "grad_norm": 11.9375,
      "learning_rate": 9.245382585751977e-05,
      "loss": 0.2061,
      "step": 2908
    },
    {
      "epoch": 3.84,
      "grad_norm": 29.0,
      "learning_rate": 9.243403693931397e-05,
      "loss": 0.2988,
      "step": 2909
    },
    {
      "epoch": 3.84,
      "grad_norm": 256.0,
      "learning_rate": 9.241424802110817e-05,
      "loss": 4.7188,
      "step": 2910
    },
    {
      "epoch": 3.84,
      "grad_norm": 14.6875,
      "learning_rate": 9.239445910290237e-05,
      "loss": 0.4766,
      "step": 2911
    },
    {
      "epoch": 3.84,
      "grad_norm": 24.375,
      "learning_rate": 9.237467018469656e-05,
      "loss": 0.1865,
      "step": 2912
    },
    {
      "epoch": 3.84,
      "grad_norm": 11.6875,
      "learning_rate": 9.235488126649075e-05,
      "loss": 0.3828,
      "step": 2913
    },
    {
      "epoch": 3.84,
      "grad_norm": 322.0,
      "learning_rate": 9.233509234828495e-05,
      "loss": 6.4688,
      "step": 2914
    },
    {
      "epoch": 3.85,
      "grad_norm": 153.0,
      "learning_rate": 9.231530343007914e-05,
      "loss": 2.5781,
      "step": 2915
    },
    {
      "epoch": 3.85,
      "grad_norm": 16.5,
      "learning_rate": 9.229551451187334e-05,
      "loss": 0.3945,
      "step": 2916
    },
    {
      "epoch": 3.85,
      "grad_norm": 10.1875,
      "learning_rate": 9.227572559366754e-05,
      "loss": 0.3281,
      "step": 2917
    },
    {
      "epoch": 3.85,
      "grad_norm": 11.375,
      "learning_rate": 9.225593667546174e-05,
      "loss": 0.2246,
      "step": 2918
    },
    {
      "epoch": 3.85,
      "grad_norm": 237.0,
      "learning_rate": 9.223614775725592e-05,
      "loss": 4.3438,
      "step": 2919
    },
    {
      "epoch": 3.85,
      "grad_norm": 304.0,
      "learning_rate": 9.221635883905012e-05,
      "loss": 6.5938,
      "step": 2920
    },
    {
      "epoch": 3.85,
      "grad_norm": 145.0,
      "learning_rate": 9.219656992084432e-05,
      "loss": 2.5469,
      "step": 2921
    },
    {
      "epoch": 3.85,
      "grad_norm": 45.25,
      "learning_rate": 9.217678100263852e-05,
      "loss": 0.3301,
      "step": 2922
    },
    {
      "epoch": 3.86,
      "grad_norm": 137.0,
      "learning_rate": 9.215699208443272e-05,
      "loss": 2.625,
      "step": 2923
    },
    {
      "epoch": 3.86,
      "grad_norm": 145.0,
      "learning_rate": 9.213720316622691e-05,
      "loss": 2.4375,
      "step": 2924
    },
    {
      "epoch": 3.86,
      "grad_norm": 59.5,
      "learning_rate": 9.21174142480211e-05,
      "loss": 0.4199,
      "step": 2925
    },
    {
      "epoch": 3.86,
      "grad_norm": 74.5,
      "learning_rate": 9.20976253298153e-05,
      "loss": 0.5898,
      "step": 2926
    },
    {
      "epoch": 3.86,
      "grad_norm": 136.0,
      "learning_rate": 9.20778364116095e-05,
      "loss": 2.6875,
      "step": 2927
    },
    {
      "epoch": 3.86,
      "grad_norm": 49.0,
      "learning_rate": 9.205804749340369e-05,
      "loss": 0.5703,
      "step": 2928
    },
    {
      "epoch": 3.86,
      "grad_norm": 25.125,
      "learning_rate": 9.203825857519789e-05,
      "loss": 0.3711,
      "step": 2929
    },
    {
      "epoch": 3.87,
      "grad_norm": 286.0,
      "learning_rate": 9.201846965699209e-05,
      "loss": 5.8438,
      "step": 2930
    },
    {
      "epoch": 3.87,
      "grad_norm": 22.625,
      "learning_rate": 9.199868073878627e-05,
      "loss": 0.1641,
      "step": 2931
    },
    {
      "epoch": 3.87,
      "grad_norm": 280.0,
      "learning_rate": 9.197889182058047e-05,
      "loss": 5.0312,
      "step": 2932
    },
    {
      "epoch": 3.87,
      "grad_norm": 490.0,
      "learning_rate": 9.195910290237466e-05,
      "loss": 8.125,
      "step": 2933
    },
    {
      "epoch": 3.87,
      "grad_norm": 141.0,
      "learning_rate": 9.193931398416885e-05,
      "loss": 1.7266,
      "step": 2934
    },
    {
      "epoch": 3.87,
      "grad_norm": 194.0,
      "learning_rate": 9.191952506596305e-05,
      "loss": 3.5312,
      "step": 2935
    },
    {
      "epoch": 3.87,
      "grad_norm": 17.625,
      "learning_rate": 9.189973614775724e-05,
      "loss": 0.1504,
      "step": 2936
    },
    {
      "epoch": 3.87,
      "grad_norm": 57.5,
      "learning_rate": 9.187994722955143e-05,
      "loss": 0.793,
      "step": 2937
    },
    {
      "epoch": 3.88,
      "grad_norm": 235.0,
      "learning_rate": 9.186015831134563e-05,
      "loss": 3.4062,
      "step": 2938
    },
    {
      "epoch": 3.88,
      "grad_norm": 46.0,
      "learning_rate": 9.184036939313983e-05,
      "loss": 0.2949,
      "step": 2939
    },
    {
      "epoch": 3.88,
      "grad_norm": 35.5,
      "learning_rate": 9.182058047493403e-05,
      "loss": 0.6562,
      "step": 2940
    },
    {
      "epoch": 3.88,
      "grad_norm": 35.75,
      "learning_rate": 9.180079155672823e-05,
      "loss": 0.75,
      "step": 2941
    },
    {
      "epoch": 3.88,
      "grad_norm": 264.0,
      "learning_rate": 9.178100263852241e-05,
      "loss": 4.4062,
      "step": 2942
    },
    {
      "epoch": 3.88,
      "grad_norm": 32.25,
      "learning_rate": 9.176121372031661e-05,
      "loss": 0.3516,
      "step": 2943
    },
    {
      "epoch": 3.88,
      "grad_norm": 39.25,
      "learning_rate": 9.174142480211081e-05,
      "loss": 0.6406,
      "step": 2944
    },
    {
      "epoch": 3.89,
      "grad_norm": 30.875,
      "learning_rate": 9.1721635883905e-05,
      "loss": 0.3652,
      "step": 2945
    },
    {
      "epoch": 3.89,
      "grad_norm": 204.0,
      "learning_rate": 9.17018469656992e-05,
      "loss": 2.2969,
      "step": 2946
    },
    {
      "epoch": 3.89,
      "grad_norm": 296.0,
      "learning_rate": 9.16820580474934e-05,
      "loss": 3.875,
      "step": 2947
    },
    {
      "epoch": 3.89,
      "grad_norm": 31.0,
      "learning_rate": 9.166226912928759e-05,
      "loss": 0.5195,
      "step": 2948
    },
    {
      "epoch": 3.89,
      "grad_norm": 444.0,
      "learning_rate": 9.164248021108178e-05,
      "loss": 5.9375,
      "step": 2949
    },
    {
      "epoch": 3.89,
      "grad_norm": 134.0,
      "learning_rate": 9.162269129287598e-05,
      "loss": 1.9141,
      "step": 2950
    },
    {
      "epoch": 3.89,
      "grad_norm": 199.0,
      "learning_rate": 9.160290237467018e-05,
      "loss": 2.2344,
      "step": 2951
    },
    {
      "epoch": 3.89,
      "grad_norm": 141.0,
      "learning_rate": 9.158311345646438e-05,
      "loss": 1.9453,
      "step": 2952
    },
    {
      "epoch": 3.9,
      "grad_norm": 38.0,
      "learning_rate": 9.156332453825858e-05,
      "loss": 0.9609,
      "step": 2953
    },
    {
      "epoch": 3.9,
      "grad_norm": 39.25,
      "learning_rate": 9.154353562005276e-05,
      "loss": 0.5781,
      "step": 2954
    },
    {
      "epoch": 3.9,
      "grad_norm": 64.5,
      "learning_rate": 9.152374670184696e-05,
      "loss": 0.625,
      "step": 2955
    },
    {
      "epoch": 3.9,
      "grad_norm": 143.0,
      "learning_rate": 9.150395778364116e-05,
      "loss": 1.5156,
      "step": 2956
    },
    {
      "epoch": 3.9,
      "grad_norm": 37.75,
      "learning_rate": 9.148416886543535e-05,
      "loss": 0.2773,
      "step": 2957
    },
    {
      "epoch": 3.9,
      "grad_norm": 154.0,
      "learning_rate": 9.146437994722955e-05,
      "loss": 2.125,
      "step": 2958
    },
    {
      "epoch": 3.9,
      "grad_norm": 27.625,
      "learning_rate": 9.144459102902375e-05,
      "loss": 0.2354,
      "step": 2959
    },
    {
      "epoch": 3.91,
      "grad_norm": 127.5,
      "learning_rate": 9.142480211081794e-05,
      "loss": 1.6641,
      "step": 2960
    },
    {
      "epoch": 3.91,
      "grad_norm": 28.5,
      "learning_rate": 9.140501319261213e-05,
      "loss": 0.4375,
      "step": 2961
    },
    {
      "epoch": 3.91,
      "grad_norm": 38.0,
      "learning_rate": 9.138522427440633e-05,
      "loss": 0.3125,
      "step": 2962
    },
    {
      "epoch": 3.91,
      "grad_norm": 54.25,
      "learning_rate": 9.136543535620052e-05,
      "loss": 0.416,
      "step": 2963
    },
    {
      "epoch": 3.91,
      "grad_norm": 234.0,
      "learning_rate": 9.134564643799471e-05,
      "loss": 3.1719,
      "step": 2964
    },
    {
      "epoch": 3.91,
      "grad_norm": 294.0,
      "learning_rate": 9.13258575197889e-05,
      "loss": 2.9688,
      "step": 2965
    },
    {
      "epoch": 3.91,
      "grad_norm": 219.0,
      "learning_rate": 9.13060686015831e-05,
      "loss": 3.0469,
      "step": 2966
    },
    {
      "epoch": 3.91,
      "grad_norm": 29.0,
      "learning_rate": 9.12862796833773e-05,
      "loss": 0.4805,
      "step": 2967
    },
    {
      "epoch": 3.92,
      "grad_norm": 22.25,
      "learning_rate": 9.126649076517149e-05,
      "loss": 0.4453,
      "step": 2968
    },
    {
      "epoch": 3.92,
      "grad_norm": 207.0,
      "learning_rate": 9.124670184696569e-05,
      "loss": 3.2656,
      "step": 2969
    },
    {
      "epoch": 3.92,
      "grad_norm": 125.0,
      "learning_rate": 9.122691292875989e-05,
      "loss": 1.9688,
      "step": 2970
    },
    {
      "epoch": 3.92,
      "grad_norm": 121.0,
      "learning_rate": 9.120712401055407e-05,
      "loss": 1.6406,
      "step": 2971
    },
    {
      "epoch": 3.92,
      "grad_norm": 198.0,
      "learning_rate": 9.118733509234827e-05,
      "loss": 3.4375,
      "step": 2972
    },
    {
      "epoch": 3.92,
      "grad_norm": 25.25,
      "learning_rate": 9.116754617414247e-05,
      "loss": 0.3887,
      "step": 2973
    },
    {
      "epoch": 3.92,
      "grad_norm": 126.5,
      "learning_rate": 9.114775725593667e-05,
      "loss": 1.7344,
      "step": 2974
    },
    {
      "epoch": 3.92,
      "grad_norm": 224.0,
      "learning_rate": 9.112796833773087e-05,
      "loss": 3.1562,
      "step": 2975
    },
    {
      "epoch": 3.93,
      "grad_norm": 193.0,
      "learning_rate": 9.110817941952506e-05,
      "loss": 2.9062,
      "step": 2976
    },
    {
      "epoch": 3.93,
      "grad_norm": 31.625,
      "learning_rate": 9.108839050131925e-05,
      "loss": 0.4785,
      "step": 2977
    },
    {
      "epoch": 3.93,
      "grad_norm": 25.125,
      "learning_rate": 9.106860158311345e-05,
      "loss": 0.3008,
      "step": 2978
    },
    {
      "epoch": 3.93,
      "grad_norm": 225.0,
      "learning_rate": 9.104881266490764e-05,
      "loss": 3.8594,
      "step": 2979
    },
    {
      "epoch": 3.93,
      "grad_norm": 115.5,
      "learning_rate": 9.102902374670184e-05,
      "loss": 1.3672,
      "step": 2980
    },
    {
      "epoch": 3.93,
      "grad_norm": 232.0,
      "learning_rate": 9.100923482849604e-05,
      "loss": 3.6094,
      "step": 2981
    },
    {
      "epoch": 3.93,
      "grad_norm": 65.5,
      "learning_rate": 9.098944591029024e-05,
      "loss": 1.0234,
      "step": 2982
    },
    {
      "epoch": 3.94,
      "grad_norm": 49.75,
      "learning_rate": 9.096965699208442e-05,
      "loss": 0.6133,
      "step": 2983
    },
    {
      "epoch": 3.94,
      "grad_norm": 185.0,
      "learning_rate": 9.094986807387862e-05,
      "loss": 2.25,
      "step": 2984
    },
    {
      "epoch": 3.94,
      "grad_norm": 110.5,
      "learning_rate": 9.093007915567282e-05,
      "loss": 2.0625,
      "step": 2985
    },
    {
      "epoch": 3.94,
      "grad_norm": 60.5,
      "learning_rate": 9.091029023746702e-05,
      "loss": 0.4707,
      "step": 2986
    },
    {
      "epoch": 3.94,
      "grad_norm": 109.5,
      "learning_rate": 9.089050131926121e-05,
      "loss": 1.5469,
      "step": 2987
    },
    {
      "epoch": 3.94,
      "grad_norm": 169.0,
      "learning_rate": 9.087071240105541e-05,
      "loss": 2.0469,
      "step": 2988
    },
    {
      "epoch": 3.94,
      "grad_norm": 19.125,
      "learning_rate": 9.08509234828496e-05,
      "loss": 0.167,
      "step": 2989
    },
    {
      "epoch": 3.94,
      "grad_norm": 117.0,
      "learning_rate": 9.08311345646438e-05,
      "loss": 1.3047,
      "step": 2990
    },
    {
      "epoch": 3.95,
      "grad_norm": 105.0,
      "learning_rate": 9.0811345646438e-05,
      "loss": 1.4375,
      "step": 2991
    },
    {
      "epoch": 3.95,
      "grad_norm": 106.0,
      "learning_rate": 9.079155672823219e-05,
      "loss": 1.5078,
      "step": 2992
    },
    {
      "epoch": 3.95,
      "grad_norm": 42.25,
      "learning_rate": 9.077176781002636e-05,
      "loss": 0.6133,
      "step": 2993
    },
    {
      "epoch": 3.95,
      "grad_norm": 39.75,
      "learning_rate": 9.075197889182056e-05,
      "loss": 0.707,
      "step": 2994
    },
    {
      "epoch": 3.95,
      "grad_norm": 198.0,
      "learning_rate": 9.073218997361476e-05,
      "loss": 2.1719,
      "step": 2995
    },
    {
      "epoch": 3.95,
      "grad_norm": 34.75,
      "learning_rate": 9.071240105540896e-05,
      "loss": 0.3555,
      "step": 2996
    },
    {
      "epoch": 3.95,
      "grad_norm": 410.0,
      "learning_rate": 9.069261213720315e-05,
      "loss": 5.8125,
      "step": 2997
    },
    {
      "epoch": 3.96,
      "grad_norm": 75.5,
      "learning_rate": 9.067282321899735e-05,
      "loss": 1.4844,
      "step": 2998
    },
    {
      "epoch": 3.96,
      "grad_norm": 241.0,
      "learning_rate": 9.065303430079154e-05,
      "loss": 3.8281,
      "step": 2999
    },
    {
      "epoch": 3.96,
      "grad_norm": 55.5,
      "learning_rate": 9.063324538258574e-05,
      "loss": 0.5,
      "step": 3000
    },
    {
      "epoch": 3.96,
      "grad_norm": 33.75,
      "learning_rate": 9.061345646437993e-05,
      "loss": 0.3672,
      "step": 3001
    },
    {
      "epoch": 3.96,
      "grad_norm": 36.0,
      "learning_rate": 9.059366754617413e-05,
      "loss": 0.6836,
      "step": 3002
    },
    {
      "epoch": 3.96,
      "grad_norm": 249.0,
      "learning_rate": 9.057387862796833e-05,
      "loss": 3.9375,
      "step": 3003
    },
    {
      "epoch": 3.96,
      "grad_norm": 68.0,
      "learning_rate": 9.055408970976253e-05,
      "loss": 1.0938,
      "step": 3004
    },
    {
      "epoch": 3.96,
      "grad_norm": 226.0,
      "learning_rate": 9.053430079155671e-05,
      "loss": 4.5,
      "step": 3005
    },
    {
      "epoch": 3.97,
      "grad_norm": 76.5,
      "learning_rate": 9.051451187335091e-05,
      "loss": 1.2188,
      "step": 3006
    },
    {
      "epoch": 3.97,
      "grad_norm": 71.5,
      "learning_rate": 9.049472295514511e-05,
      "loss": 1.0156,
      "step": 3007
    },
    {
      "epoch": 3.97,
      "grad_norm": 203.0,
      "learning_rate": 9.04749340369393e-05,
      "loss": 3.2188,
      "step": 3008
    },
    {
      "epoch": 3.97,
      "grad_norm": 80.0,
      "learning_rate": 9.04551451187335e-05,
      "loss": 0.8672,
      "step": 3009
    },
    {
      "epoch": 3.97,
      "grad_norm": 128.0,
      "learning_rate": 9.04353562005277e-05,
      "loss": 1.4297,
      "step": 3010
    },
    {
      "epoch": 3.97,
      "grad_norm": 70.5,
      "learning_rate": 9.041556728232189e-05,
      "loss": 0.5352,
      "step": 3011
    },
    {
      "epoch": 3.97,
      "grad_norm": 70.5,
      "learning_rate": 9.039577836411609e-05,
      "loss": 0.6094,
      "step": 3012
    },
    {
      "epoch": 3.97,
      "grad_norm": 49.0,
      "learning_rate": 9.037598944591028e-05,
      "loss": 0.9844,
      "step": 3013
    },
    {
      "epoch": 3.98,
      "grad_norm": 70.0,
      "learning_rate": 9.035620052770448e-05,
      "loss": 0.6172,
      "step": 3014
    },
    {
      "epoch": 3.98,
      "grad_norm": 39.75,
      "learning_rate": 9.033641160949868e-05,
      "loss": 0.3535,
      "step": 3015
    },
    {
      "epoch": 3.98,
      "grad_norm": 49.5,
      "learning_rate": 9.031662269129288e-05,
      "loss": 0.4355,
      "step": 3016
    },
    {
      "epoch": 3.98,
      "grad_norm": 39.75,
      "learning_rate": 9.029683377308706e-05,
      "loss": 0.3984,
      "step": 3017
    },
    {
      "epoch": 3.98,
      "grad_norm": 89.0,
      "learning_rate": 9.027704485488126e-05,
      "loss": 1.1094,
      "step": 3018
    },
    {
      "epoch": 3.98,
      "grad_norm": 241.0,
      "learning_rate": 9.025725593667546e-05,
      "loss": 3.9844,
      "step": 3019
    },
    {
      "epoch": 3.98,
      "grad_norm": 245.0,
      "learning_rate": 9.023746701846966e-05,
      "loss": 4.3438,
      "step": 3020
    },
    {
      "epoch": 3.99,
      "grad_norm": 104.0,
      "learning_rate": 9.021767810026385e-05,
      "loss": 1.4141,
      "step": 3021
    },
    {
      "epoch": 3.99,
      "grad_norm": 55.5,
      "learning_rate": 9.019788918205805e-05,
      "loss": 0.8516,
      "step": 3022
    },
    {
      "epoch": 3.99,
      "grad_norm": 251.0,
      "learning_rate": 9.017810026385222e-05,
      "loss": 4.0312,
      "step": 3023
    },
    {
      "epoch": 3.99,
      "grad_norm": 37.75,
      "learning_rate": 9.015831134564642e-05,
      "loss": 0.7812,
      "step": 3024
    },
    {
      "epoch": 3.99,
      "grad_norm": 125.0,
      "learning_rate": 9.013852242744062e-05,
      "loss": 1.6562,
      "step": 3025
    },
    {
      "epoch": 3.99,
      "grad_norm": 212.0,
      "learning_rate": 9.011873350923482e-05,
      "loss": 3.6562,
      "step": 3026
    },
    {
      "epoch": 3.99,
      "grad_norm": 29.875,
      "learning_rate": 9.009894459102902e-05,
      "loss": 0.2178,
      "step": 3027
    },
    {
      "epoch": 3.99,
      "grad_norm": 31.0,
      "learning_rate": 9.00791556728232e-05,
      "loss": 0.5586,
      "step": 3028
    },
    {
      "epoch": 4.0,
      "grad_norm": 239.0,
      "learning_rate": 9.00593667546174e-05,
      "loss": 3.6094,
      "step": 3029
    },
    {
      "epoch": 4.0,
      "grad_norm": 111.0,
      "learning_rate": 9.00395778364116e-05,
      "loss": 1.6406,
      "step": 3030
    },
    {
      "epoch": 4.0,
      "grad_norm": 21.125,
      "learning_rate": 9.00197889182058e-05,
      "loss": 0.3984,
      "step": 3031
    },
    {
      "epoch": 4.0,
      "grad_norm": 159.0,
      "learning_rate": 8.999999999999999e-05,
      "loss": 2.2812,
      "step": 3032
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.3952804803848267,
      "eval_runtime": 18.3106,
      "eval_samples_per_second": 42.708,
      "eval_steps_per_second": 10.704,
      "step": 3032
    },
    {
      "epoch": 4.0,
      "grad_norm": 31.75,
      "learning_rate": 8.998021108179419e-05,
      "loss": 0.2715,
      "step": 3033
    },
    {
      "epoch": 4.0,
      "grad_norm": 48.5,
      "learning_rate": 8.996042216358837e-05,
      "loss": 0.3652,
      "step": 3034
    },
    {
      "epoch": 4.0,
      "grad_norm": 54.25,
      "learning_rate": 8.994063324538257e-05,
      "loss": 0.5039,
      "step": 3035
    },
    {
      "epoch": 4.01,
      "grad_norm": 37.25,
      "learning_rate": 8.992084432717677e-05,
      "loss": 0.3457,
      "step": 3036
    },
    {
      "epoch": 4.01,
      "grad_norm": 231.0,
      "learning_rate": 8.990105540897097e-05,
      "loss": 4.375,
      "step": 3037
    },
    {
      "epoch": 4.01,
      "grad_norm": 195.0,
      "learning_rate": 8.988126649076517e-05,
      "loss": 2.9375,
      "step": 3038
    },
    {
      "epoch": 4.01,
      "grad_norm": 125.5,
      "learning_rate": 8.986147757255936e-05,
      "loss": 1.9297,
      "step": 3039
    },
    {
      "epoch": 4.01,
      "grad_norm": 17.5,
      "learning_rate": 8.984168865435355e-05,
      "loss": 0.2383,
      "step": 3040
    },
    {
      "epoch": 4.01,
      "grad_norm": 22.0,
      "learning_rate": 8.982189973614775e-05,
      "loss": 0.4355,
      "step": 3041
    },
    {
      "epoch": 4.01,
      "grad_norm": 266.0,
      "learning_rate": 8.980211081794195e-05,
      "loss": 3.3125,
      "step": 3042
    },
    {
      "epoch": 4.01,
      "grad_norm": 29.25,
      "learning_rate": 8.978232189973614e-05,
      "loss": 0.1865,
      "step": 3043
    },
    {
      "epoch": 4.02,
      "grad_norm": 144.0,
      "learning_rate": 8.976253298153034e-05,
      "loss": 1.9766,
      "step": 3044
    },
    {
      "epoch": 4.02,
      "grad_norm": 274.0,
      "learning_rate": 8.974274406332454e-05,
      "loss": 4.4375,
      "step": 3045
    },
    {
      "epoch": 4.02,
      "grad_norm": 48.5,
      "learning_rate": 8.972295514511872e-05,
      "loss": 0.5977,
      "step": 3046
    },
    {
      "epoch": 4.02,
      "grad_norm": 126.0,
      "learning_rate": 8.970316622691292e-05,
      "loss": 1.6641,
      "step": 3047
    },
    {
      "epoch": 4.02,
      "grad_norm": 49.5,
      "learning_rate": 8.968337730870712e-05,
      "loss": 0.7422,
      "step": 3048
    },
    {
      "epoch": 4.02,
      "grad_norm": 204.0,
      "learning_rate": 8.966358839050132e-05,
      "loss": 2.9375,
      "step": 3049
    },
    {
      "epoch": 4.02,
      "grad_norm": 239.0,
      "learning_rate": 8.964379947229552e-05,
      "loss": 3.25,
      "step": 3050
    },
    {
      "epoch": 4.03,
      "grad_norm": 108.0,
      "learning_rate": 8.962401055408971e-05,
      "loss": 1.5,
      "step": 3051
    },
    {
      "epoch": 4.03,
      "grad_norm": 45.5,
      "learning_rate": 8.96042216358839e-05,
      "loss": 0.334,
      "step": 3052
    },
    {
      "epoch": 4.03,
      "grad_norm": 173.0,
      "learning_rate": 8.95844327176781e-05,
      "loss": 2.5156,
      "step": 3053
    },
    {
      "epoch": 4.03,
      "grad_norm": 245.0,
      "learning_rate": 8.956464379947228e-05,
      "loss": 2.3281,
      "step": 3054
    },
    {
      "epoch": 4.03,
      "grad_norm": 33.25,
      "learning_rate": 8.954485488126648e-05,
      "loss": 0.5156,
      "step": 3055
    },
    {
      "epoch": 4.03,
      "grad_norm": 53.25,
      "learning_rate": 8.952506596306068e-05,
      "loss": 0.4121,
      "step": 3056
    },
    {
      "epoch": 4.03,
      "grad_norm": 32.0,
      "learning_rate": 8.950527704485486e-05,
      "loss": 0.5352,
      "step": 3057
    },
    {
      "epoch": 4.03,
      "grad_norm": 31.125,
      "learning_rate": 8.948548812664906e-05,
      "loss": 0.5469,
      "step": 3058
    },
    {
      "epoch": 4.04,
      "grad_norm": 89.5,
      "learning_rate": 8.946569920844326e-05,
      "loss": 1.5938,
      "step": 3059
    },
    {
      "epoch": 4.04,
      "grad_norm": 129.0,
      "learning_rate": 8.944591029023746e-05,
      "loss": 1.2422,
      "step": 3060
    },
    {
      "epoch": 4.04,
      "grad_norm": 29.25,
      "learning_rate": 8.942612137203165e-05,
      "loss": 0.4844,
      "step": 3061
    },
    {
      "epoch": 4.04,
      "grad_norm": 35.5,
      "learning_rate": 8.940633245382585e-05,
      "loss": 0.5547,
      "step": 3062
    },
    {
      "epoch": 4.04,
      "grad_norm": 35.0,
      "learning_rate": 8.938654353562004e-05,
      "loss": 0.4531,
      "step": 3063
    },
    {
      "epoch": 4.04,
      "grad_norm": 62.0,
      "learning_rate": 8.936675461741424e-05,
      "loss": 0.5703,
      "step": 3064
    },
    {
      "epoch": 4.04,
      "grad_norm": 22.5,
      "learning_rate": 8.934696569920843e-05,
      "loss": 0.3105,
      "step": 3065
    },
    {
      "epoch": 4.04,
      "grad_norm": 20.625,
      "learning_rate": 8.932717678100263e-05,
      "loss": 0.3984,
      "step": 3066
    },
    {
      "epoch": 4.05,
      "grad_norm": 190.0,
      "learning_rate": 8.930738786279683e-05,
      "loss": 3.25,
      "step": 3067
    },
    {
      "epoch": 4.05,
      "grad_norm": 132.0,
      "learning_rate": 8.928759894459103e-05,
      "loss": 1.6484,
      "step": 3068
    },
    {
      "epoch": 4.05,
      "grad_norm": 25.875,
      "learning_rate": 8.926781002638521e-05,
      "loss": 0.4688,
      "step": 3069
    },
    {
      "epoch": 4.05,
      "grad_norm": 206.0,
      "learning_rate": 8.924802110817941e-05,
      "loss": 3.5469,
      "step": 3070
    },
    {
      "epoch": 4.05,
      "grad_norm": 18.25,
      "learning_rate": 8.922823218997361e-05,
      "loss": 0.377,
      "step": 3071
    },
    {
      "epoch": 4.05,
      "grad_norm": 32.0,
      "learning_rate": 8.92084432717678e-05,
      "loss": 0.9297,
      "step": 3072
    },
    {
      "epoch": 4.05,
      "grad_norm": 17.125,
      "learning_rate": 8.9188654353562e-05,
      "loss": 0.1377,
      "step": 3073
    },
    {
      "epoch": 4.06,
      "grad_norm": 130.0,
      "learning_rate": 8.91688654353562e-05,
      "loss": 2.3438,
      "step": 3074
    },
    {
      "epoch": 4.06,
      "grad_norm": 129.0,
      "learning_rate": 8.914907651715039e-05,
      "loss": 2.0469,
      "step": 3075
    },
    {
      "epoch": 4.06,
      "grad_norm": 133.0,
      "learning_rate": 8.912928759894458e-05,
      "loss": 1.9922,
      "step": 3076
    },
    {
      "epoch": 4.06,
      "grad_norm": 24.0,
      "learning_rate": 8.910949868073878e-05,
      "loss": 0.2129,
      "step": 3077
    },
    {
      "epoch": 4.06,
      "grad_norm": 33.75,
      "learning_rate": 8.908970976253298e-05,
      "loss": 0.3262,
      "step": 3078
    },
    {
      "epoch": 4.06,
      "grad_norm": 24.875,
      "learning_rate": 8.906992084432718e-05,
      "loss": 0.2324,
      "step": 3079
    },
    {
      "epoch": 4.06,
      "grad_norm": 138.0,
      "learning_rate": 8.905013192612138e-05,
      "loss": 1.9141,
      "step": 3080
    },
    {
      "epoch": 4.06,
      "grad_norm": 11.1875,
      "learning_rate": 8.903034300791556e-05,
      "loss": 0.3145,
      "step": 3081
    },
    {
      "epoch": 4.07,
      "grad_norm": 29.625,
      "learning_rate": 8.901055408970976e-05,
      "loss": 0.2598,
      "step": 3082
    },
    {
      "epoch": 4.07,
      "grad_norm": 139.0,
      "learning_rate": 8.899076517150396e-05,
      "loss": 2.0469,
      "step": 3083
    },
    {
      "epoch": 4.07,
      "grad_norm": 135.0,
      "learning_rate": 8.897097625329814e-05,
      "loss": 1.8359,
      "step": 3084
    },
    {
      "epoch": 4.07,
      "grad_norm": 30.5,
      "learning_rate": 8.895118733509233e-05,
      "loss": 0.3438,
      "step": 3085
    },
    {
      "epoch": 4.07,
      "grad_norm": 247.0,
      "learning_rate": 8.893139841688652e-05,
      "loss": 4.625,
      "step": 3086
    },
    {
      "epoch": 4.07,
      "grad_norm": 23.75,
      "learning_rate": 8.891160949868072e-05,
      "loss": 0.2305,
      "step": 3087
    },
    {
      "epoch": 4.07,
      "grad_norm": 31.125,
      "learning_rate": 8.889182058047492e-05,
      "loss": 0.1895,
      "step": 3088
    },
    {
      "epoch": 4.08,
      "grad_norm": 132.0,
      "learning_rate": 8.887203166226912e-05,
      "loss": 3.1406,
      "step": 3089
    },
    {
      "epoch": 4.08,
      "grad_norm": 35.5,
      "learning_rate": 8.885224274406332e-05,
      "loss": 0.4043,
      "step": 3090
    },
    {
      "epoch": 4.08,
      "grad_norm": 54.75,
      "learning_rate": 8.88324538258575e-05,
      "loss": 0.707,
      "step": 3091
    },
    {
      "epoch": 4.08,
      "grad_norm": 17.25,
      "learning_rate": 8.88126649076517e-05,
      "loss": 0.1235,
      "step": 3092
    },
    {
      "epoch": 4.08,
      "grad_norm": 221.0,
      "learning_rate": 8.87928759894459e-05,
      "loss": 2.9219,
      "step": 3093
    },
    {
      "epoch": 4.08,
      "grad_norm": 15.8125,
      "learning_rate": 8.87730870712401e-05,
      "loss": 0.1123,
      "step": 3094
    },
    {
      "epoch": 4.08,
      "grad_norm": 304.0,
      "learning_rate": 8.87532981530343e-05,
      "loss": 3.4531,
      "step": 3095
    },
    {
      "epoch": 4.08,
      "grad_norm": 160.0,
      "learning_rate": 8.873350923482849e-05,
      "loss": 1.8203,
      "step": 3096
    },
    {
      "epoch": 4.09,
      "grad_norm": 23.375,
      "learning_rate": 8.871372031662268e-05,
      "loss": 0.1299,
      "step": 3097
    },
    {
      "epoch": 4.09,
      "grad_norm": 123.5,
      "learning_rate": 8.869393139841687e-05,
      "loss": 1.6484,
      "step": 3098
    },
    {
      "epoch": 4.09,
      "grad_norm": 25.375,
      "learning_rate": 8.867414248021107e-05,
      "loss": 0.2949,
      "step": 3099
    },
    {
      "epoch": 4.09,
      "grad_norm": 157.0,
      "learning_rate": 8.865435356200527e-05,
      "loss": 1.8203,
      "step": 3100
    },
    {
      "epoch": 4.09,
      "grad_norm": 35.75,
      "learning_rate": 8.863456464379947e-05,
      "loss": 0.4668,
      "step": 3101
    },
    {
      "epoch": 4.09,
      "grad_norm": 126.5,
      "learning_rate": 8.861477572559367e-05,
      "loss": 1.3828,
      "step": 3102
    },
    {
      "epoch": 4.09,
      "grad_norm": 376.0,
      "learning_rate": 8.859498680738785e-05,
      "loss": 7.0,
      "step": 3103
    },
    {
      "epoch": 4.09,
      "grad_norm": 288.0,
      "learning_rate": 8.857519788918205e-05,
      "loss": 5.4688,
      "step": 3104
    },
    {
      "epoch": 4.1,
      "grad_norm": 223.0,
      "learning_rate": 8.855540897097625e-05,
      "loss": 4.1562,
      "step": 3105
    },
    {
      "epoch": 4.1,
      "grad_norm": 255.0,
      "learning_rate": 8.853562005277045e-05,
      "loss": 4.75,
      "step": 3106
    },
    {
      "epoch": 4.1,
      "grad_norm": 226.0,
      "learning_rate": 8.851583113456464e-05,
      "loss": 4.4375,
      "step": 3107
    },
    {
      "epoch": 4.1,
      "grad_norm": 27.875,
      "learning_rate": 8.849604221635884e-05,
      "loss": 0.3418,
      "step": 3108
    },
    {
      "epoch": 4.1,
      "grad_norm": 46.75,
      "learning_rate": 8.847625329815303e-05,
      "loss": 0.6133,
      "step": 3109
    },
    {
      "epoch": 4.1,
      "grad_norm": 42.75,
      "learning_rate": 8.845646437994722e-05,
      "loss": 0.6211,
      "step": 3110
    },
    {
      "epoch": 4.1,
      "grad_norm": 78.5,
      "learning_rate": 8.843667546174142e-05,
      "loss": 0.9609,
      "step": 3111
    },
    {
      "epoch": 4.11,
      "grad_norm": 44.5,
      "learning_rate": 8.841688654353562e-05,
      "loss": 0.9023,
      "step": 3112
    },
    {
      "epoch": 4.11,
      "grad_norm": 92.0,
      "learning_rate": 8.839709762532982e-05,
      "loss": 1.5625,
      "step": 3113
    },
    {
      "epoch": 4.11,
      "grad_norm": 67.0,
      "learning_rate": 8.837730870712399e-05,
      "loss": 0.7109,
      "step": 3114
    },
    {
      "epoch": 4.11,
      "grad_norm": 40.75,
      "learning_rate": 8.835751978891819e-05,
      "loss": 0.6875,
      "step": 3115
    },
    {
      "epoch": 4.11,
      "grad_norm": 38.75,
      "learning_rate": 8.833773087071239e-05,
      "loss": 0.5,
      "step": 3116
    },
    {
      "epoch": 4.11,
      "grad_norm": 215.0,
      "learning_rate": 8.831794195250658e-05,
      "loss": 3.0625,
      "step": 3117
    },
    {
      "epoch": 4.11,
      "grad_norm": 31.625,
      "learning_rate": 8.829815303430078e-05,
      "loss": 0.4531,
      "step": 3118
    },
    {
      "epoch": 4.11,
      "grad_norm": 120.0,
      "learning_rate": 8.827836411609498e-05,
      "loss": 1.9141,
      "step": 3119
    },
    {
      "epoch": 4.12,
      "grad_norm": 16.25,
      "learning_rate": 8.825857519788916e-05,
      "loss": 0.2793,
      "step": 3120
    },
    {
      "epoch": 4.12,
      "grad_norm": 17.625,
      "learning_rate": 8.823878627968336e-05,
      "loss": 0.3613,
      "step": 3121
    },
    {
      "epoch": 4.12,
      "grad_norm": 121.0,
      "learning_rate": 8.821899736147756e-05,
      "loss": 1.9531,
      "step": 3122
    },
    {
      "epoch": 4.12,
      "grad_norm": 15.0,
      "learning_rate": 8.819920844327176e-05,
      "loss": 0.3164,
      "step": 3123
    },
    {
      "epoch": 4.12,
      "grad_norm": 12.875,
      "learning_rate": 8.817941952506596e-05,
      "loss": 0.1797,
      "step": 3124
    },
    {
      "epoch": 4.12,
      "grad_norm": 13.3125,
      "learning_rate": 8.815963060686015e-05,
      "loss": 0.4395,
      "step": 3125
    },
    {
      "epoch": 4.12,
      "grad_norm": 47.25,
      "learning_rate": 8.813984168865434e-05,
      "loss": 0.3242,
      "step": 3126
    },
    {
      "epoch": 4.13,
      "grad_norm": 246.0,
      "learning_rate": 8.812005277044854e-05,
      "loss": 4.0,
      "step": 3127
    },
    {
      "epoch": 4.13,
      "grad_norm": 516.0,
      "learning_rate": 8.810026385224273e-05,
      "loss": 8.25,
      "step": 3128
    },
    {
      "epoch": 4.13,
      "grad_norm": 302.0,
      "learning_rate": 8.808047493403693e-05,
      "loss": 4.6875,
      "step": 3129
    },
    {
      "epoch": 4.13,
      "grad_norm": 139.0,
      "learning_rate": 8.806068601583113e-05,
      "loss": 2.7656,
      "step": 3130
    },
    {
      "epoch": 4.13,
      "grad_norm": 33.75,
      "learning_rate": 8.804089709762533e-05,
      "loss": 0.2148,
      "step": 3131
    },
    {
      "epoch": 4.13,
      "grad_norm": 132.0,
      "learning_rate": 8.802110817941951e-05,
      "loss": 2.3594,
      "step": 3132
    },
    {
      "epoch": 4.13,
      "grad_norm": 31.375,
      "learning_rate": 8.800131926121371e-05,
      "loss": 0.4062,
      "step": 3133
    },
    {
      "epoch": 4.13,
      "grad_norm": 30.0,
      "learning_rate": 8.798153034300791e-05,
      "loss": 0.2441,
      "step": 3134
    },
    {
      "epoch": 4.14,
      "grad_norm": 41.5,
      "learning_rate": 8.796174142480211e-05,
      "loss": 0.3008,
      "step": 3135
    },
    {
      "epoch": 4.14,
      "grad_norm": 129.0,
      "learning_rate": 8.79419525065963e-05,
      "loss": 2.75,
      "step": 3136
    },
    {
      "epoch": 4.14,
      "grad_norm": 174.0,
      "learning_rate": 8.79221635883905e-05,
      "loss": 2.2969,
      "step": 3137
    },
    {
      "epoch": 4.14,
      "grad_norm": 135.0,
      "learning_rate": 8.790237467018469e-05,
      "loss": 2.0469,
      "step": 3138
    },
    {
      "epoch": 4.14,
      "grad_norm": 51.5,
      "learning_rate": 8.788258575197889e-05,
      "loss": 0.7031,
      "step": 3139
    },
    {
      "epoch": 4.14,
      "grad_norm": 402.0,
      "learning_rate": 8.786279683377308e-05,
      "loss": 7.5312,
      "step": 3140
    },
    {
      "epoch": 4.14,
      "grad_norm": 31.375,
      "learning_rate": 8.784300791556728e-05,
      "loss": 0.2324,
      "step": 3141
    },
    {
      "epoch": 4.15,
      "grad_norm": 42.75,
      "learning_rate": 8.782321899736148e-05,
      "loss": 0.4961,
      "step": 3142
    },
    {
      "epoch": 4.15,
      "grad_norm": 124.0,
      "learning_rate": 8.780343007915568e-05,
      "loss": 1.6641,
      "step": 3143
    },
    {
      "epoch": 4.15,
      "grad_norm": 110.0,
      "learning_rate": 8.778364116094985e-05,
      "loss": 1.4922,
      "step": 3144
    },
    {
      "epoch": 4.15,
      "grad_norm": 49.0,
      "learning_rate": 8.776385224274405e-05,
      "loss": 0.5508,
      "step": 3145
    },
    {
      "epoch": 4.15,
      "grad_norm": 224.0,
      "learning_rate": 8.774406332453825e-05,
      "loss": 5.5938,
      "step": 3146
    },
    {
      "epoch": 4.15,
      "grad_norm": 35.75,
      "learning_rate": 8.772427440633244e-05,
      "loss": 0.2637,
      "step": 3147
    },
    {
      "epoch": 4.15,
      "grad_norm": 39.0,
      "learning_rate": 8.770448548812664e-05,
      "loss": 0.3086,
      "step": 3148
    },
    {
      "epoch": 4.15,
      "grad_norm": 35.5,
      "learning_rate": 8.768469656992083e-05,
      "loss": 0.543,
      "step": 3149
    },
    {
      "epoch": 4.16,
      "grad_norm": 242.0,
      "learning_rate": 8.766490765171502e-05,
      "loss": 4.3438,
      "step": 3150
    },
    {
      "epoch": 4.16,
      "grad_norm": 209.0,
      "learning_rate": 8.764511873350922e-05,
      "loss": 3.8281,
      "step": 3151
    },
    {
      "epoch": 4.16,
      "grad_norm": 36.25,
      "learning_rate": 8.762532981530342e-05,
      "loss": 0.2812,
      "step": 3152
    },
    {
      "epoch": 4.16,
      "grad_norm": 180.0,
      "learning_rate": 8.760554089709762e-05,
      "loss": 3.0938,
      "step": 3153
    },
    {
      "epoch": 4.16,
      "grad_norm": 23.875,
      "learning_rate": 8.758575197889182e-05,
      "loss": 0.2344,
      "step": 3154
    },
    {
      "epoch": 4.16,
      "grad_norm": 21.125,
      "learning_rate": 8.7565963060686e-05,
      "loss": 0.1875,
      "step": 3155
    },
    {
      "epoch": 4.16,
      "grad_norm": 121.0,
      "learning_rate": 8.75461741424802e-05,
      "loss": 1.6016,
      "step": 3156
    },
    {
      "epoch": 4.16,
      "grad_norm": 31.75,
      "learning_rate": 8.75263852242744e-05,
      "loss": 0.6914,
      "step": 3157
    },
    {
      "epoch": 4.17,
      "grad_norm": 310.0,
      "learning_rate": 8.75065963060686e-05,
      "loss": 2.8906,
      "step": 3158
    },
    {
      "epoch": 4.17,
      "grad_norm": 256.0,
      "learning_rate": 8.74868073878628e-05,
      "loss": 3.7188,
      "step": 3159
    },
    {
      "epoch": 4.17,
      "grad_norm": 85.5,
      "learning_rate": 8.746701846965699e-05,
      "loss": 0.9727,
      "step": 3160
    },
    {
      "epoch": 4.17,
      "grad_norm": 25.25,
      "learning_rate": 8.744722955145118e-05,
      "loss": 0.5469,
      "step": 3161
    },
    {
      "epoch": 4.17,
      "grad_norm": 422.0,
      "learning_rate": 8.742744063324537e-05,
      "loss": 4.3125,
      "step": 3162
    },
    {
      "epoch": 4.17,
      "grad_norm": 36.25,
      "learning_rate": 8.740765171503957e-05,
      "loss": 0.6484,
      "step": 3163
    },
    {
      "epoch": 4.17,
      "grad_norm": 120.5,
      "learning_rate": 8.738786279683377e-05,
      "loss": 1.4531,
      "step": 3164
    },
    {
      "epoch": 4.18,
      "grad_norm": 141.0,
      "learning_rate": 8.736807387862797e-05,
      "loss": 1.7266,
      "step": 3165
    },
    {
      "epoch": 4.18,
      "grad_norm": 199.0,
      "learning_rate": 8.734828496042217e-05,
      "loss": 2.7812,
      "step": 3166
    },
    {
      "epoch": 4.18,
      "grad_norm": 110.5,
      "learning_rate": 8.732849604221635e-05,
      "loss": 1.8984,
      "step": 3167
    },
    {
      "epoch": 4.18,
      "grad_norm": 22.875,
      "learning_rate": 8.730870712401055e-05,
      "loss": 0.2373,
      "step": 3168
    },
    {
      "epoch": 4.18,
      "grad_norm": 110.5,
      "learning_rate": 8.728891820580475e-05,
      "loss": 1.6484,
      "step": 3169
    },
    {
      "epoch": 4.18,
      "grad_norm": 35.0,
      "learning_rate": 8.726912928759894e-05,
      "loss": 0.4453,
      "step": 3170
    },
    {
      "epoch": 4.18,
      "grad_norm": 24.75,
      "learning_rate": 8.724934036939314e-05,
      "loss": 0.5391,
      "step": 3171
    },
    {
      "epoch": 4.18,
      "grad_norm": 24.125,
      "learning_rate": 8.722955145118734e-05,
      "loss": 0.4512,
      "step": 3172
    },
    {
      "epoch": 4.19,
      "grad_norm": 107.0,
      "learning_rate": 8.720976253298153e-05,
      "loss": 1.3672,
      "step": 3173
    },
    {
      "epoch": 4.19,
      "grad_norm": 196.0,
      "learning_rate": 8.718997361477571e-05,
      "loss": 3.9688,
      "step": 3174
    },
    {
      "epoch": 4.19,
      "grad_norm": 71.5,
      "learning_rate": 8.717018469656991e-05,
      "loss": 0.7227,
      "step": 3175
    },
    {
      "epoch": 4.19,
      "grad_norm": 251.0,
      "learning_rate": 8.71503957783641e-05,
      "loss": 4.2188,
      "step": 3176
    },
    {
      "epoch": 4.19,
      "grad_norm": 60.5,
      "learning_rate": 8.71306068601583e-05,
      "loss": 0.625,
      "step": 3177
    },
    {
      "epoch": 4.19,
      "grad_norm": 89.0,
      "learning_rate": 8.711081794195249e-05,
      "loss": 1.5469,
      "step": 3178
    },
    {
      "epoch": 4.19,
      "grad_norm": 19.75,
      "learning_rate": 8.709102902374669e-05,
      "loss": 0.543,
      "step": 3179
    },
    {
      "epoch": 4.2,
      "grad_norm": 207.0,
      "learning_rate": 8.707124010554088e-05,
      "loss": 3.0938,
      "step": 3180
    },
    {
      "epoch": 4.2,
      "grad_norm": 105.5,
      "learning_rate": 8.705145118733508e-05,
      "loss": 1.6016,
      "step": 3181
    },
    {
      "epoch": 4.2,
      "grad_norm": 46.25,
      "learning_rate": 8.703166226912928e-05,
      "loss": 1.0234,
      "step": 3182
    },
    {
      "epoch": 4.2,
      "grad_norm": 199.0,
      "learning_rate": 8.701187335092348e-05,
      "loss": 2.4219,
      "step": 3183
    },
    {
      "epoch": 4.2,
      "grad_norm": 24.625,
      "learning_rate": 8.699208443271766e-05,
      "loss": 0.3535,
      "step": 3184
    },
    {
      "epoch": 4.2,
      "grad_norm": 31.0,
      "learning_rate": 8.697229551451186e-05,
      "loss": 0.2227,
      "step": 3185
    },
    {
      "epoch": 4.2,
      "grad_norm": 48.0,
      "learning_rate": 8.695250659630606e-05,
      "loss": 0.4805,
      "step": 3186
    },
    {
      "epoch": 4.2,
      "grad_norm": 49.5,
      "learning_rate": 8.693271767810026e-05,
      "loss": 0.5625,
      "step": 3187
    },
    {
      "epoch": 4.21,
      "grad_norm": 197.0,
      "learning_rate": 8.691292875989446e-05,
      "loss": 2.4219,
      "step": 3188
    },
    {
      "epoch": 4.21,
      "grad_norm": 400.0,
      "learning_rate": 8.689313984168865e-05,
      "loss": 6.4375,
      "step": 3189
    },
    {
      "epoch": 4.21,
      "grad_norm": 121.5,
      "learning_rate": 8.687335092348284e-05,
      "loss": 1.7266,
      "step": 3190
    },
    {
      "epoch": 4.21,
      "grad_norm": 21.5,
      "learning_rate": 8.685356200527704e-05,
      "loss": 0.3848,
      "step": 3191
    },
    {
      "epoch": 4.21,
      "grad_norm": 29.875,
      "learning_rate": 8.683377308707123e-05,
      "loss": 0.3633,
      "step": 3192
    },
    {
      "epoch": 4.21,
      "grad_norm": 121.5,
      "learning_rate": 8.681398416886543e-05,
      "loss": 1.4453,
      "step": 3193
    },
    {
      "epoch": 4.21,
      "grad_norm": 252.0,
      "learning_rate": 8.679419525065963e-05,
      "loss": 4.5625,
      "step": 3194
    },
    {
      "epoch": 4.22,
      "grad_norm": 83.5,
      "learning_rate": 8.677440633245383e-05,
      "loss": 1.2734,
      "step": 3195
    },
    {
      "epoch": 4.22,
      "grad_norm": 57.25,
      "learning_rate": 8.675461741424801e-05,
      "loss": 0.4512,
      "step": 3196
    },
    {
      "epoch": 4.22,
      "grad_norm": 36.75,
      "learning_rate": 8.673482849604221e-05,
      "loss": 0.5586,
      "step": 3197
    },
    {
      "epoch": 4.22,
      "grad_norm": 45.0,
      "learning_rate": 8.671503957783641e-05,
      "loss": 0.7656,
      "step": 3198
    },
    {
      "epoch": 4.22,
      "grad_norm": 28.25,
      "learning_rate": 8.669525065963061e-05,
      "loss": 0.2812,
      "step": 3199
    },
    {
      "epoch": 4.22,
      "grad_norm": 604.0,
      "learning_rate": 8.66754617414248e-05,
      "loss": 9.625,
      "step": 3200
    },
    {
      "epoch": 4.22,
      "grad_norm": 49.75,
      "learning_rate": 8.6655672823219e-05,
      "loss": 0.3301,
      "step": 3201
    },
    {
      "epoch": 4.22,
      "grad_norm": 24.375,
      "learning_rate": 8.663588390501319e-05,
      "loss": 0.4297,
      "step": 3202
    },
    {
      "epoch": 4.23,
      "grad_norm": 33.5,
      "learning_rate": 8.661609498680739e-05,
      "loss": 0.4766,
      "step": 3203
    },
    {
      "epoch": 4.23,
      "grad_norm": 256.0,
      "learning_rate": 8.659630606860157e-05,
      "loss": 4.9062,
      "step": 3204
    },
    {
      "epoch": 4.23,
      "grad_norm": 233.0,
      "learning_rate": 8.657651715039577e-05,
      "loss": 3.8125,
      "step": 3205
    },
    {
      "epoch": 4.23,
      "grad_norm": 50.5,
      "learning_rate": 8.655672823218995e-05,
      "loss": 0.7383,
      "step": 3206
    },
    {
      "epoch": 4.23,
      "grad_norm": 18.75,
      "learning_rate": 8.653693931398415e-05,
      "loss": 0.2314,
      "step": 3207
    },
    {
      "epoch": 4.23,
      "grad_norm": 31.75,
      "learning_rate": 8.651715039577835e-05,
      "loss": 0.2793,
      "step": 3208
    },
    {
      "epoch": 4.23,
      "grad_norm": 121.0,
      "learning_rate": 8.649736147757255e-05,
      "loss": 1.8438,
      "step": 3209
    },
    {
      "epoch": 4.23,
      "grad_norm": 15.5,
      "learning_rate": 8.647757255936675e-05,
      "loss": 0.3516,
      "step": 3210
    },
    {
      "epoch": 4.24,
      "grad_norm": 22.625,
      "learning_rate": 8.645778364116094e-05,
      "loss": 0.7734,
      "step": 3211
    },
    {
      "epoch": 4.24,
      "grad_norm": 25.875,
      "learning_rate": 8.643799472295513e-05,
      "loss": 0.4961,
      "step": 3212
    },
    {
      "epoch": 4.24,
      "grad_norm": 133.0,
      "learning_rate": 8.641820580474933e-05,
      "loss": 2.2656,
      "step": 3213
    },
    {
      "epoch": 4.24,
      "grad_norm": 34.5,
      "learning_rate": 8.639841688654352e-05,
      "loss": 0.2285,
      "step": 3214
    },
    {
      "epoch": 4.24,
      "grad_norm": 13.5,
      "learning_rate": 8.637862796833772e-05,
      "loss": 0.3281,
      "step": 3215
    },
    {
      "epoch": 4.24,
      "grad_norm": 138.0,
      "learning_rate": 8.635883905013192e-05,
      "loss": 2.5312,
      "step": 3216
    },
    {
      "epoch": 4.24,
      "grad_norm": 20.25,
      "learning_rate": 8.633905013192612e-05,
      "loss": 0.2041,
      "step": 3217
    },
    {
      "epoch": 4.25,
      "grad_norm": 208.0,
      "learning_rate": 8.63192612137203e-05,
      "loss": 4.125,
      "step": 3218
    },
    {
      "epoch": 4.25,
      "grad_norm": 30.5,
      "learning_rate": 8.62994722955145e-05,
      "loss": 0.5117,
      "step": 3219
    },
    {
      "epoch": 4.25,
      "grad_norm": 220.0,
      "learning_rate": 8.62796833773087e-05,
      "loss": 3.7188,
      "step": 3220
    },
    {
      "epoch": 4.25,
      "grad_norm": 29.25,
      "learning_rate": 8.62598944591029e-05,
      "loss": 0.1855,
      "step": 3221
    },
    {
      "epoch": 4.25,
      "grad_norm": 50.75,
      "learning_rate": 8.62401055408971e-05,
      "loss": 0.5898,
      "step": 3222
    },
    {
      "epoch": 4.25,
      "grad_norm": 10.75,
      "learning_rate": 8.622031662269129e-05,
      "loss": 0.2832,
      "step": 3223
    },
    {
      "epoch": 4.25,
      "grad_norm": 128.0,
      "learning_rate": 8.620052770448548e-05,
      "loss": 2.5781,
      "step": 3224
    },
    {
      "epoch": 4.25,
      "grad_norm": 25.625,
      "learning_rate": 8.618073878627968e-05,
      "loss": 0.3984,
      "step": 3225
    },
    {
      "epoch": 4.26,
      "grad_norm": 130.0,
      "learning_rate": 8.616094986807387e-05,
      "loss": 2.2812,
      "step": 3226
    },
    {
      "epoch": 4.26,
      "grad_norm": 10.0,
      "learning_rate": 8.614116094986807e-05,
      "loss": 0.1582,
      "step": 3227
    },
    {
      "epoch": 4.26,
      "grad_norm": 50.5,
      "learning_rate": 8.612137203166227e-05,
      "loss": 0.6797,
      "step": 3228
    },
    {
      "epoch": 4.26,
      "grad_norm": 268.0,
      "learning_rate": 8.610158311345647e-05,
      "loss": 4.0938,
      "step": 3229
    },
    {
      "epoch": 4.26,
      "grad_norm": 27.75,
      "learning_rate": 8.608179419525065e-05,
      "loss": 0.1631,
      "step": 3230
    },
    {
      "epoch": 4.26,
      "grad_norm": 10.5625,
      "learning_rate": 8.606200527704485e-05,
      "loss": 0.2891,
      "step": 3231
    },
    {
      "epoch": 4.26,
      "grad_norm": 11.25,
      "learning_rate": 8.604221635883905e-05,
      "loss": 0.3203,
      "step": 3232
    },
    {
      "epoch": 4.27,
      "grad_norm": 284.0,
      "learning_rate": 8.602242744063325e-05,
      "loss": 4.2188,
      "step": 3233
    },
    {
      "epoch": 4.27,
      "grad_norm": 158.0,
      "learning_rate": 8.600263852242743e-05,
      "loss": 2.3906,
      "step": 3234
    },
    {
      "epoch": 4.27,
      "grad_norm": 203.0,
      "learning_rate": 8.598284960422162e-05,
      "loss": 3.9844,
      "step": 3235
    },
    {
      "epoch": 4.27,
      "grad_norm": 135.0,
      "learning_rate": 8.596306068601581e-05,
      "loss": 2.25,
      "step": 3236
    },
    {
      "epoch": 4.27,
      "grad_norm": 132.0,
      "learning_rate": 8.594327176781001e-05,
      "loss": 2.2969,
      "step": 3237
    },
    {
      "epoch": 4.27,
      "grad_norm": 203.0,
      "learning_rate": 8.592348284960421e-05,
      "loss": 3.875,
      "step": 3238
    },
    {
      "epoch": 4.27,
      "grad_norm": 288.0,
      "learning_rate": 8.590369393139841e-05,
      "loss": 3.6719,
      "step": 3239
    },
    {
      "epoch": 4.27,
      "grad_norm": 29.5,
      "learning_rate": 8.58839050131926e-05,
      "loss": 0.2969,
      "step": 3240
    },
    {
      "epoch": 4.28,
      "grad_norm": 9.3125,
      "learning_rate": 8.586411609498679e-05,
      "loss": 0.2578,
      "step": 3241
    },
    {
      "epoch": 4.28,
      "grad_norm": 38.25,
      "learning_rate": 8.584432717678099e-05,
      "loss": 0.3281,
      "step": 3242
    },
    {
      "epoch": 4.28,
      "grad_norm": 23.25,
      "learning_rate": 8.582453825857519e-05,
      "loss": 0.5391,
      "step": 3243
    },
    {
      "epoch": 4.28,
      "grad_norm": 34.0,
      "learning_rate": 8.580474934036938e-05,
      "loss": 0.4277,
      "step": 3244
    },
    {
      "epoch": 4.28,
      "grad_norm": 42.5,
      "learning_rate": 8.578496042216358e-05,
      "loss": 0.5391,
      "step": 3245
    },
    {
      "epoch": 4.28,
      "grad_norm": 206.0,
      "learning_rate": 8.576517150395778e-05,
      "loss": 3.5469,
      "step": 3246
    },
    {
      "epoch": 4.28,
      "grad_norm": 26.5,
      "learning_rate": 8.574538258575197e-05,
      "loss": 0.7227,
      "step": 3247
    },
    {
      "epoch": 4.28,
      "grad_norm": 30.125,
      "learning_rate": 8.572559366754616e-05,
      "loss": 0.2139,
      "step": 3248
    },
    {
      "epoch": 4.29,
      "grad_norm": 128.0,
      "learning_rate": 8.570580474934036e-05,
      "loss": 1.6016,
      "step": 3249
    },
    {
      "epoch": 4.29,
      "grad_norm": 18.375,
      "learning_rate": 8.568601583113456e-05,
      "loss": 0.1631,
      "step": 3250
    },
    {
      "epoch": 4.29,
      "grad_norm": 16.375,
      "learning_rate": 8.566622691292876e-05,
      "loss": 0.3574,
      "step": 3251
    },
    {
      "epoch": 4.29,
      "grad_norm": 20.875,
      "learning_rate": 8.564643799472296e-05,
      "loss": 0.4023,
      "step": 3252
    },
    {
      "epoch": 4.29,
      "grad_norm": 12.4375,
      "learning_rate": 8.562664907651714e-05,
      "loss": 0.3105,
      "step": 3253
    },
    {
      "epoch": 4.29,
      "grad_norm": 12.8125,
      "learning_rate": 8.560686015831134e-05,
      "loss": 0.2344,
      "step": 3254
    },
    {
      "epoch": 4.29,
      "grad_norm": 141.0,
      "learning_rate": 8.558707124010554e-05,
      "loss": 1.9688,
      "step": 3255
    },
    {
      "epoch": 4.3,
      "grad_norm": 142.0,
      "learning_rate": 8.556728232189973e-05,
      "loss": 2.2031,
      "step": 3256
    },
    {
      "epoch": 4.3,
      "grad_norm": 326.0,
      "learning_rate": 8.554749340369393e-05,
      "loss": 5.2812,
      "step": 3257
    },
    {
      "epoch": 4.3,
      "grad_norm": 52.0,
      "learning_rate": 8.552770448548813e-05,
      "loss": 0.6367,
      "step": 3258
    },
    {
      "epoch": 4.3,
      "grad_norm": 13.1875,
      "learning_rate": 8.550791556728231e-05,
      "loss": 0.1035,
      "step": 3259
    },
    {
      "epoch": 4.3,
      "grad_norm": 5.75,
      "learning_rate": 8.548812664907651e-05,
      "loss": 0.0718,
      "step": 3260
    },
    {
      "epoch": 4.3,
      "grad_norm": 6.8125,
      "learning_rate": 8.546833773087071e-05,
      "loss": 0.0991,
      "step": 3261
    },
    {
      "epoch": 4.3,
      "grad_norm": 65.0,
      "learning_rate": 8.544854881266491e-05,
      "loss": 0.5156,
      "step": 3262
    },
    {
      "epoch": 4.3,
      "grad_norm": 266.0,
      "learning_rate": 8.542875989445911e-05,
      "loss": 4.8125,
      "step": 3263
    },
    {
      "epoch": 4.31,
      "grad_norm": 318.0,
      "learning_rate": 8.540897097625328e-05,
      "loss": 4.5,
      "step": 3264
    },
    {
      "epoch": 4.31,
      "grad_norm": 27.5,
      "learning_rate": 8.538918205804748e-05,
      "loss": 0.3809,
      "step": 3265
    },
    {
      "epoch": 4.31,
      "grad_norm": 159.0,
      "learning_rate": 8.536939313984167e-05,
      "loss": 2.3594,
      "step": 3266
    },
    {
      "epoch": 4.31,
      "grad_norm": 17.375,
      "learning_rate": 8.534960422163587e-05,
      "loss": 0.1108,
      "step": 3267
    },
    {
      "epoch": 4.31,
      "grad_norm": 18.75,
      "learning_rate": 8.532981530343007e-05,
      "loss": 0.1045,
      "step": 3268
    },
    {
      "epoch": 4.31,
      "grad_norm": 17.625,
      "learning_rate": 8.531002638522427e-05,
      "loss": 0.3711,
      "step": 3269
    },
    {
      "epoch": 4.31,
      "grad_norm": 155.0,
      "learning_rate": 8.529023746701845e-05,
      "loss": 2.5625,
      "step": 3270
    },
    {
      "epoch": 4.32,
      "grad_norm": 16.5,
      "learning_rate": 8.527044854881265e-05,
      "loss": 0.1187,
      "step": 3271
    },
    {
      "epoch": 4.32,
      "grad_norm": 13.8125,
      "learning_rate": 8.525065963060685e-05,
      "loss": 0.3457,
      "step": 3272
    },
    {
      "epoch": 4.32,
      "grad_norm": 16.25,
      "learning_rate": 8.523087071240105e-05,
      "loss": 0.5156,
      "step": 3273
    },
    {
      "epoch": 4.32,
      "grad_norm": 225.0,
      "learning_rate": 8.521108179419524e-05,
      "loss": 4.3438,
      "step": 3274
    },
    {
      "epoch": 4.32,
      "grad_norm": 215.0,
      "learning_rate": 8.519129287598944e-05,
      "loss": 5.0312,
      "step": 3275
    },
    {
      "epoch": 4.32,
      "grad_norm": 138.0,
      "learning_rate": 8.517150395778363e-05,
      "loss": 2.8281,
      "step": 3276
    },
    {
      "epoch": 4.32,
      "grad_norm": 47.5,
      "learning_rate": 8.515171503957783e-05,
      "loss": 0.3457,
      "step": 3277
    },
    {
      "epoch": 4.32,
      "grad_norm": 229.0,
      "learning_rate": 8.513192612137202e-05,
      "loss": 4.1562,
      "step": 3278
    },
    {
      "epoch": 4.33,
      "grad_norm": 24.0,
      "learning_rate": 8.511213720316622e-05,
      "loss": 0.4258,
      "step": 3279
    },
    {
      "epoch": 4.33,
      "grad_norm": 25.0,
      "learning_rate": 8.509234828496042e-05,
      "loss": 1.0469,
      "step": 3280
    },
    {
      "epoch": 4.33,
      "grad_norm": 25.75,
      "learning_rate": 8.507255936675462e-05,
      "loss": 0.1719,
      "step": 3281
    },
    {
      "epoch": 4.33,
      "grad_norm": 42.0,
      "learning_rate": 8.50527704485488e-05,
      "loss": 0.5469,
      "step": 3282
    },
    {
      "epoch": 4.33,
      "grad_norm": 17.375,
      "learning_rate": 8.5032981530343e-05,
      "loss": 0.3164,
      "step": 3283
    },
    {
      "epoch": 4.33,
      "grad_norm": 165.0,
      "learning_rate": 8.50131926121372e-05,
      "loss": 2.3125,
      "step": 3284
    },
    {
      "epoch": 4.33,
      "grad_norm": 27.5,
      "learning_rate": 8.49934036939314e-05,
      "loss": 0.1943,
      "step": 3285
    },
    {
      "epoch": 4.34,
      "grad_norm": 23.375,
      "learning_rate": 8.49736147757256e-05,
      "loss": 0.1367,
      "step": 3286
    },
    {
      "epoch": 4.34,
      "grad_norm": 222.0,
      "learning_rate": 8.495382585751979e-05,
      "loss": 4.25,
      "step": 3287
    },
    {
      "epoch": 4.34,
      "grad_norm": 84.5,
      "learning_rate": 8.493403693931398e-05,
      "loss": 1.3047,
      "step": 3288
    },
    {
      "epoch": 4.34,
      "grad_norm": 356.0,
      "learning_rate": 8.491424802110818e-05,
      "loss": 6.5625,
      "step": 3289
    },
    {
      "epoch": 4.34,
      "grad_norm": 206.0,
      "learning_rate": 8.489445910290237e-05,
      "loss": 2.9531,
      "step": 3290
    },
    {
      "epoch": 4.34,
      "grad_norm": 52.5,
      "learning_rate": 8.487467018469657e-05,
      "loss": 0.5586,
      "step": 3291
    },
    {
      "epoch": 4.34,
      "grad_norm": 13.5,
      "learning_rate": 8.485488126649077e-05,
      "loss": 0.1494,
      "step": 3292
    },
    {
      "epoch": 4.34,
      "grad_norm": 7.84375,
      "learning_rate": 8.483509234828497e-05,
      "loss": 0.0593,
      "step": 3293
    },
    {
      "epoch": 4.35,
      "grad_norm": 10.25,
      "learning_rate": 8.481530343007914e-05,
      "loss": 0.1191,
      "step": 3294
    },
    {
      "epoch": 4.35,
      "grad_norm": 12.875,
      "learning_rate": 8.479551451187334e-05,
      "loss": 0.1128,
      "step": 3295
    },
    {
      "epoch": 4.35,
      "grad_norm": 163.0,
      "learning_rate": 8.477572559366753e-05,
      "loss": 2.2344,
      "step": 3296
    },
    {
      "epoch": 4.35,
      "grad_norm": 19.875,
      "learning_rate": 8.475593667546173e-05,
      "loss": 0.2969,
      "step": 3297
    },
    {
      "epoch": 4.35,
      "grad_norm": 153.0,
      "learning_rate": 8.473614775725592e-05,
      "loss": 2.1875,
      "step": 3298
    },
    {
      "epoch": 4.35,
      "grad_norm": 6.9375,
      "learning_rate": 8.471635883905012e-05,
      "loss": 0.0845,
      "step": 3299
    },
    {
      "epoch": 4.35,
      "grad_norm": 8.625,
      "learning_rate": 8.469656992084431e-05,
      "loss": 0.0586,
      "step": 3300
    },
    {
      "epoch": 4.35,
      "grad_norm": 89.0,
      "learning_rate": 8.467678100263851e-05,
      "loss": 1.0547,
      "step": 3301
    },
    {
      "epoch": 4.36,
      "grad_norm": 195.0,
      "learning_rate": 8.465699208443271e-05,
      "loss": 2.5625,
      "step": 3302
    },
    {
      "epoch": 4.36,
      "grad_norm": 163.0,
      "learning_rate": 8.463720316622691e-05,
      "loss": 2.25,
      "step": 3303
    },
    {
      "epoch": 4.36,
      "grad_norm": 241.0,
      "learning_rate": 8.461741424802109e-05,
      "loss": 4.0312,
      "step": 3304
    },
    {
      "epoch": 4.36,
      "grad_norm": 12.8125,
      "learning_rate": 8.459762532981529e-05,
      "loss": 0.0923,
      "step": 3305
    },
    {
      "epoch": 4.36,
      "grad_norm": 16.5,
      "learning_rate": 8.457783641160949e-05,
      "loss": 0.2031,
      "step": 3306
    },
    {
      "epoch": 4.36,
      "grad_norm": 14.6875,
      "learning_rate": 8.455804749340369e-05,
      "loss": 0.0894,
      "step": 3307
    },
    {
      "epoch": 4.36,
      "grad_norm": 304.0,
      "learning_rate": 8.453825857519788e-05,
      "loss": 4.125,
      "step": 3308
    },
    {
      "epoch": 4.37,
      "grad_norm": 266.0,
      "learning_rate": 8.451846965699208e-05,
      "loss": 4.5,
      "step": 3309
    },
    {
      "epoch": 4.37,
      "grad_norm": 4.625,
      "learning_rate": 8.449868073878627e-05,
      "loss": 0.0459,
      "step": 3310
    },
    {
      "epoch": 4.37,
      "grad_norm": 229.0,
      "learning_rate": 8.447889182058046e-05,
      "loss": 3.8438,
      "step": 3311
    },
    {
      "epoch": 4.37,
      "grad_norm": 77.0,
      "learning_rate": 8.445910290237466e-05,
      "loss": 0.793,
      "step": 3312
    },
    {
      "epoch": 4.37,
      "grad_norm": 25.0,
      "learning_rate": 8.443931398416886e-05,
      "loss": 0.3691,
      "step": 3313
    },
    {
      "epoch": 4.37,
      "grad_norm": 235.0,
      "learning_rate": 8.441952506596306e-05,
      "loss": 3.9688,
      "step": 3314
    },
    {
      "epoch": 4.37,
      "grad_norm": 19.875,
      "learning_rate": 8.439973614775726e-05,
      "loss": 0.1206,
      "step": 3315
    },
    {
      "epoch": 4.37,
      "grad_norm": 196.0,
      "learning_rate": 8.437994722955144e-05,
      "loss": 3.7344,
      "step": 3316
    },
    {
      "epoch": 4.38,
      "grad_norm": 35.0,
      "learning_rate": 8.436015831134564e-05,
      "loss": 0.2734,
      "step": 3317
    },
    {
      "epoch": 4.38,
      "grad_norm": 364.0,
      "learning_rate": 8.434036939313984e-05,
      "loss": 15.0625,
      "step": 3318
    },
    {
      "epoch": 4.38,
      "grad_norm": 28.25,
      "learning_rate": 8.432058047493404e-05,
      "loss": 0.2021,
      "step": 3319
    },
    {
      "epoch": 4.38,
      "grad_norm": 212.0,
      "learning_rate": 8.430079155672823e-05,
      "loss": 3.125,
      "step": 3320
    },
    {
      "epoch": 4.38,
      "grad_norm": 167.0,
      "learning_rate": 8.428100263852243e-05,
      "loss": 1.9922,
      "step": 3321
    },
    {
      "epoch": 4.38,
      "grad_norm": 45.75,
      "learning_rate": 8.426121372031662e-05,
      "loss": 0.3379,
      "step": 3322
    },
    {
      "epoch": 4.38,
      "grad_norm": 34.75,
      "learning_rate": 8.424142480211081e-05,
      "loss": 0.4531,
      "step": 3323
    },
    {
      "epoch": 4.39,
      "grad_norm": 52.5,
      "learning_rate": 8.4221635883905e-05,
      "loss": 0.5703,
      "step": 3324
    },
    {
      "epoch": 4.39,
      "grad_norm": 21.125,
      "learning_rate": 8.42018469656992e-05,
      "loss": 0.2344,
      "step": 3325
    },
    {
      "epoch": 4.39,
      "grad_norm": 175.0,
      "learning_rate": 8.41820580474934e-05,
      "loss": 2.6094,
      "step": 3326
    },
    {
      "epoch": 4.39,
      "grad_norm": 28.75,
      "learning_rate": 8.416226912928758e-05,
      "loss": 0.2354,
      "step": 3327
    },
    {
      "epoch": 4.39,
      "grad_norm": 204.0,
      "learning_rate": 8.414248021108178e-05,
      "loss": 2.4219,
      "step": 3328
    },
    {
      "epoch": 4.39,
      "grad_norm": 44.5,
      "learning_rate": 8.412269129287598e-05,
      "loss": 0.3086,
      "step": 3329
    },
    {
      "epoch": 4.39,
      "grad_norm": 48.75,
      "learning_rate": 8.410290237467017e-05,
      "loss": 0.5352,
      "step": 3330
    },
    {
      "epoch": 4.39,
      "grad_norm": 60.25,
      "learning_rate": 8.408311345646437e-05,
      "loss": 0.8828,
      "step": 3331
    },
    {
      "epoch": 4.4,
      "grad_norm": 181.0,
      "learning_rate": 8.406332453825857e-05,
      "loss": 2.2812,
      "step": 3332
    },
    {
      "epoch": 4.4,
      "grad_norm": 19.25,
      "learning_rate": 8.404353562005275e-05,
      "loss": 0.168,
      "step": 3333
    },
    {
      "epoch": 4.4,
      "grad_norm": 165.0,
      "learning_rate": 8.402374670184695e-05,
      "loss": 3.1094,
      "step": 3334
    },
    {
      "epoch": 4.4,
      "grad_norm": 426.0,
      "learning_rate": 8.400395778364115e-05,
      "loss": 4.7812,
      "step": 3335
    },
    {
      "epoch": 4.4,
      "grad_norm": 33.5,
      "learning_rate": 8.398416886543535e-05,
      "loss": 0.5352,
      "step": 3336
    },
    {
      "epoch": 4.4,
      "grad_norm": 31.125,
      "learning_rate": 8.396437994722955e-05,
      "loss": 0.4609,
      "step": 3337
    },
    {
      "epoch": 4.4,
      "grad_norm": 28.5,
      "learning_rate": 8.394459102902374e-05,
      "loss": 0.7344,
      "step": 3338
    },
    {
      "epoch": 4.41,
      "grad_norm": 23.75,
      "learning_rate": 8.392480211081793e-05,
      "loss": 0.127,
      "step": 3339
    },
    {
      "epoch": 4.41,
      "grad_norm": 126.5,
      "learning_rate": 8.390501319261213e-05,
      "loss": 2.25,
      "step": 3340
    },
    {
      "epoch": 4.41,
      "grad_norm": 16.0,
      "learning_rate": 8.388522427440633e-05,
      "loss": 0.2617,
      "step": 3341
    },
    {
      "epoch": 4.41,
      "grad_norm": 237.0,
      "learning_rate": 8.386543535620052e-05,
      "loss": 4.125,
      "step": 3342
    },
    {
      "epoch": 4.41,
      "grad_norm": 190.0,
      "learning_rate": 8.384564643799472e-05,
      "loss": 2.2969,
      "step": 3343
    },
    {
      "epoch": 4.41,
      "grad_norm": 272.0,
      "learning_rate": 8.382585751978892e-05,
      "loss": 4.9062,
      "step": 3344
    },
    {
      "epoch": 4.41,
      "grad_norm": 225.0,
      "learning_rate": 8.38060686015831e-05,
      "loss": 3.0,
      "step": 3345
    },
    {
      "epoch": 4.41,
      "grad_norm": 28.5,
      "learning_rate": 8.37862796833773e-05,
      "loss": 0.1602,
      "step": 3346
    },
    {
      "epoch": 4.42,
      "grad_norm": 141.0,
      "learning_rate": 8.37664907651715e-05,
      "loss": 2.4531,
      "step": 3347
    },
    {
      "epoch": 4.42,
      "grad_norm": 32.75,
      "learning_rate": 8.37467018469657e-05,
      "loss": 0.4492,
      "step": 3348
    },
    {
      "epoch": 4.42,
      "grad_norm": 26.75,
      "learning_rate": 8.37269129287599e-05,
      "loss": 0.2148,
      "step": 3349
    },
    {
      "epoch": 4.42,
      "grad_norm": 135.0,
      "learning_rate": 8.37071240105541e-05,
      "loss": 2.1562,
      "step": 3350
    },
    {
      "epoch": 4.42,
      "grad_norm": 28.5,
      "learning_rate": 8.368733509234828e-05,
      "loss": 0.1885,
      "step": 3351
    },
    {
      "epoch": 4.42,
      "grad_norm": 37.25,
      "learning_rate": 8.366754617414248e-05,
      "loss": 0.3848,
      "step": 3352
    },
    {
      "epoch": 4.42,
      "grad_norm": 17.75,
      "learning_rate": 8.364775725593667e-05,
      "loss": 0.1348,
      "step": 3353
    },
    {
      "epoch": 4.42,
      "grad_norm": 35.75,
      "learning_rate": 8.362796833773086e-05,
      "loss": 0.2344,
      "step": 3354
    },
    {
      "epoch": 4.43,
      "grad_norm": 59.25,
      "learning_rate": 8.360817941952506e-05,
      "loss": 0.8203,
      "step": 3355
    },
    {
      "epoch": 4.43,
      "grad_norm": 141.0,
      "learning_rate": 8.358839050131924e-05,
      "loss": 2.75,
      "step": 3356
    },
    {
      "epoch": 4.43,
      "grad_norm": 26.125,
      "learning_rate": 8.356860158311344e-05,
      "loss": 0.1533,
      "step": 3357
    },
    {
      "epoch": 4.43,
      "grad_norm": 30.5,
      "learning_rate": 8.354881266490764e-05,
      "loss": 0.2002,
      "step": 3358
    },
    {
      "epoch": 4.43,
      "grad_norm": 3.265625,
      "learning_rate": 8.352902374670184e-05,
      "loss": 0.0183,
      "step": 3359
    },
    {
      "epoch": 4.43,
      "grad_norm": 47.75,
      "learning_rate": 8.350923482849603e-05,
      "loss": 0.4453,
      "step": 3360
    },
    {
      "epoch": 4.43,
      "grad_norm": 24.25,
      "learning_rate": 8.348944591029023e-05,
      "loss": 0.2832,
      "step": 3361
    },
    {
      "epoch": 4.44,
      "grad_norm": 188.0,
      "learning_rate": 8.346965699208442e-05,
      "loss": 2.5312,
      "step": 3362
    },
    {
      "epoch": 4.44,
      "grad_norm": 11.3125,
      "learning_rate": 8.344986807387861e-05,
      "loss": 0.0679,
      "step": 3363
    },
    {
      "epoch": 4.44,
      "grad_norm": 10.75,
      "learning_rate": 8.343007915567281e-05,
      "loss": 0.0603,
      "step": 3364
    },
    {
      "epoch": 4.44,
      "grad_norm": 165.0,
      "learning_rate": 8.341029023746701e-05,
      "loss": 2.2188,
      "step": 3365
    },
    {
      "epoch": 4.44,
      "grad_norm": 14.1875,
      "learning_rate": 8.339050131926121e-05,
      "loss": 0.0786,
      "step": 3366
    },
    {
      "epoch": 4.44,
      "grad_norm": 294.0,
      "learning_rate": 8.337071240105541e-05,
      "loss": 4.7812,
      "step": 3367
    },
    {
      "epoch": 4.44,
      "grad_norm": 36.5,
      "learning_rate": 8.335092348284959e-05,
      "loss": 0.5977,
      "step": 3368
    },
    {
      "epoch": 4.44,
      "grad_norm": 40.0,
      "learning_rate": 8.333113456464379e-05,
      "loss": 0.4355,
      "step": 3369
    },
    {
      "epoch": 4.45,
      "grad_norm": 342.0,
      "learning_rate": 8.331134564643799e-05,
      "loss": 4.3125,
      "step": 3370
    },
    {
      "epoch": 4.45,
      "grad_norm": 27.25,
      "learning_rate": 8.329155672823219e-05,
      "loss": 0.332,
      "step": 3371
    },
    {
      "epoch": 4.45,
      "grad_norm": 22.125,
      "learning_rate": 8.327176781002638e-05,
      "loss": 0.1523,
      "step": 3372
    },
    {
      "epoch": 4.45,
      "grad_norm": 22.75,
      "learning_rate": 8.325197889182058e-05,
      "loss": 0.125,
      "step": 3373
    },
    {
      "epoch": 4.45,
      "grad_norm": 18.375,
      "learning_rate": 8.323218997361477e-05,
      "loss": 0.1035,
      "step": 3374
    },
    {
      "epoch": 4.45,
      "grad_norm": 15.0625,
      "learning_rate": 8.321240105540896e-05,
      "loss": 0.1631,
      "step": 3375
    },
    {
      "epoch": 4.45,
      "grad_norm": 328.0,
      "learning_rate": 8.319261213720316e-05,
      "loss": 4.0312,
      "step": 3376
    },
    {
      "epoch": 4.46,
      "grad_norm": 237.0,
      "learning_rate": 8.317282321899736e-05,
      "loss": 8.125,
      "step": 3377
    },
    {
      "epoch": 4.46,
      "grad_norm": 5.21875,
      "learning_rate": 8.315303430079156e-05,
      "loss": 0.0277,
      "step": 3378
    },
    {
      "epoch": 4.46,
      "grad_norm": 27.125,
      "learning_rate": 8.313324538258576e-05,
      "loss": 0.2236,
      "step": 3379
    },
    {
      "epoch": 4.46,
      "grad_norm": 12.5,
      "learning_rate": 8.311345646437994e-05,
      "loss": 0.1348,
      "step": 3380
    },
    {
      "epoch": 4.46,
      "grad_norm": 148.0,
      "learning_rate": 8.309366754617414e-05,
      "loss": 2.3281,
      "step": 3381
    },
    {
      "epoch": 4.46,
      "grad_norm": 10.4375,
      "learning_rate": 8.307387862796834e-05,
      "loss": 0.0693,
      "step": 3382
    },
    {
      "epoch": 4.46,
      "grad_norm": 10.8125,
      "learning_rate": 8.305408970976254e-05,
      "loss": 0.3438,
      "step": 3383
    },
    {
      "epoch": 4.46,
      "grad_norm": 258.0,
      "learning_rate": 8.30343007915567e-05,
      "loss": 4.4688,
      "step": 3384
    },
    {
      "epoch": 4.47,
      "grad_norm": 25.5,
      "learning_rate": 8.30145118733509e-05,
      "loss": 0.1377,
      "step": 3385
    },
    {
      "epoch": 4.47,
      "grad_norm": 158.0,
      "learning_rate": 8.29947229551451e-05,
      "loss": 2.3906,
      "step": 3386
    },
    {
      "epoch": 4.47,
      "grad_norm": 15.3125,
      "learning_rate": 8.29749340369393e-05,
      "loss": 0.1094,
      "step": 3387
    },
    {
      "epoch": 4.47,
      "grad_norm": 64.0,
      "learning_rate": 8.29551451187335e-05,
      "loss": 0.4727,
      "step": 3388
    },
    {
      "epoch": 4.47,
      "grad_norm": 17.25,
      "learning_rate": 8.29353562005277e-05,
      "loss": 0.168,
      "step": 3389
    },
    {
      "epoch": 4.47,
      "grad_norm": 160.0,
      "learning_rate": 8.291556728232188e-05,
      "loss": 1.9609,
      "step": 3390
    },
    {
      "epoch": 4.47,
      "grad_norm": 169.0,
      "learning_rate": 8.289577836411608e-05,
      "loss": 2.0781,
      "step": 3391
    },
    {
      "epoch": 4.47,
      "grad_norm": 16.75,
      "learning_rate": 8.287598944591028e-05,
      "loss": 0.0796,
      "step": 3392
    },
    {
      "epoch": 4.48,
      "grad_norm": 192.0,
      "learning_rate": 8.285620052770448e-05,
      "loss": 2.375,
      "step": 3393
    },
    {
      "epoch": 4.48,
      "grad_norm": 6.65625,
      "learning_rate": 8.283641160949867e-05,
      "loss": 0.0297,
      "step": 3394
    },
    {
      "epoch": 4.48,
      "grad_norm": 286.0,
      "learning_rate": 8.281662269129287e-05,
      "loss": 5.625,
      "step": 3395
    },
    {
      "epoch": 4.48,
      "grad_norm": 8.1875,
      "learning_rate": 8.279683377308706e-05,
      "loss": 0.0339,
      "step": 3396
    },
    {
      "epoch": 4.48,
      "grad_norm": 456.0,
      "learning_rate": 8.277704485488125e-05,
      "loss": 8.1875,
      "step": 3397
    },
    {
      "epoch": 4.48,
      "grad_norm": 62.5,
      "learning_rate": 8.275725593667545e-05,
      "loss": 0.7266,
      "step": 3398
    },
    {
      "epoch": 4.48,
      "grad_norm": 286.0,
      "learning_rate": 8.273746701846965e-05,
      "loss": 4.9688,
      "step": 3399
    },
    {
      "epoch": 4.49,
      "grad_norm": 388.0,
      "learning_rate": 8.271767810026385e-05,
      "loss": 4.6562,
      "step": 3400
    },
    {
      "epoch": 4.49,
      "grad_norm": 5.59375,
      "learning_rate": 8.269788918205805e-05,
      "loss": 0.0256,
      "step": 3401
    },
    {
      "epoch": 4.49,
      "grad_norm": 171.0,
      "learning_rate": 8.267810026385223e-05,
      "loss": 1.9609,
      "step": 3402
    },
    {
      "epoch": 4.49,
      "grad_norm": 368.0,
      "learning_rate": 8.265831134564643e-05,
      "loss": 4.4688,
      "step": 3403
    },
    {
      "epoch": 4.49,
      "grad_norm": 126.5,
      "learning_rate": 8.263852242744063e-05,
      "loss": 1.8203,
      "step": 3404
    },
    {
      "epoch": 4.49,
      "grad_norm": 39.25,
      "learning_rate": 8.261873350923482e-05,
      "loss": 0.6523,
      "step": 3405
    },
    {
      "epoch": 4.49,
      "grad_norm": 75.5,
      "learning_rate": 8.259894459102902e-05,
      "loss": 1.0625,
      "step": 3406
    },
    {
      "epoch": 4.49,
      "grad_norm": 111.0,
      "learning_rate": 8.257915567282322e-05,
      "loss": 1.8438,
      "step": 3407
    },
    {
      "epoch": 4.5,
      "grad_norm": 15.375,
      "learning_rate": 8.25593667546174e-05,
      "loss": 0.0918,
      "step": 3408
    },
    {
      "epoch": 4.5,
      "grad_norm": 14.25,
      "learning_rate": 8.25395778364116e-05,
      "loss": 0.0737,
      "step": 3409
    },
    {
      "epoch": 4.5,
      "grad_norm": 113.0,
      "learning_rate": 8.25197889182058e-05,
      "loss": 1.4609,
      "step": 3410
    },
    {
      "epoch": 4.5,
      "grad_norm": 28.625,
      "learning_rate": 8.25e-05,
      "loss": 0.2012,
      "step": 3411
    },
    {
      "epoch": 4.5,
      "grad_norm": 244.0,
      "learning_rate": 8.24802110817942e-05,
      "loss": 2.3594,
      "step": 3412
    },
    {
      "epoch": 4.5,
      "grad_norm": 27.25,
      "learning_rate": 8.24604221635884e-05,
      "loss": 0.5781,
      "step": 3413
    },
    {
      "epoch": 4.5,
      "grad_norm": 27.375,
      "learning_rate": 8.244063324538258e-05,
      "loss": 0.5117,
      "step": 3414
    },
    {
      "epoch": 4.51,
      "grad_norm": 93.0,
      "learning_rate": 8.242084432717676e-05,
      "loss": 1.3828,
      "step": 3415
    },
    {
      "epoch": 4.51,
      "grad_norm": 237.0,
      "learning_rate": 8.240105540897096e-05,
      "loss": 4.6562,
      "step": 3416
    },
    {
      "epoch": 4.51,
      "grad_norm": 29.125,
      "learning_rate": 8.238126649076516e-05,
      "loss": 0.2051,
      "step": 3417
    },
    {
      "epoch": 4.51,
      "grad_norm": 219.0,
      "learning_rate": 8.236147757255936e-05,
      "loss": 4.0312,
      "step": 3418
    },
    {
      "epoch": 4.51,
      "grad_norm": 224.0,
      "learning_rate": 8.234168865435354e-05,
      "loss": 4.5625,
      "step": 3419
    },
    {
      "epoch": 4.51,
      "grad_norm": 47.25,
      "learning_rate": 8.232189973614774e-05,
      "loss": 0.375,
      "step": 3420
    },
    {
      "epoch": 4.51,
      "grad_norm": 96.0,
      "learning_rate": 8.230211081794194e-05,
      "loss": 1.1875,
      "step": 3421
    },
    {
      "epoch": 4.51,
      "grad_norm": 27.875,
      "learning_rate": 8.228232189973614e-05,
      "loss": 0.5117,
      "step": 3422
    },
    {
      "epoch": 4.52,
      "grad_norm": 212.0,
      "learning_rate": 8.226253298153034e-05,
      "loss": 3.625,
      "step": 3423
    },
    {
      "epoch": 4.52,
      "grad_norm": 20.0,
      "learning_rate": 8.224274406332453e-05,
      "loss": 0.4746,
      "step": 3424
    },
    {
      "epoch": 4.52,
      "grad_norm": 102.0,
      "learning_rate": 8.222295514511872e-05,
      "loss": 1.4922,
      "step": 3425
    },
    {
      "epoch": 4.52,
      "grad_norm": 91.5,
      "learning_rate": 8.220316622691292e-05,
      "loss": 1.5,
      "step": 3426
    },
    {
      "epoch": 4.52,
      "grad_norm": 12.0,
      "learning_rate": 8.218337730870711e-05,
      "loss": 0.1011,
      "step": 3427
    },
    {
      "epoch": 4.52,
      "grad_norm": 14.0,
      "learning_rate": 8.216358839050131e-05,
      "loss": 0.1396,
      "step": 3428
    },
    {
      "epoch": 4.52,
      "grad_norm": 215.0,
      "learning_rate": 8.214379947229551e-05,
      "loss": 4.125,
      "step": 3429
    },
    {
      "epoch": 4.53,
      "grad_norm": 26.125,
      "learning_rate": 8.212401055408971e-05,
      "loss": 0.4434,
      "step": 3430
    },
    {
      "epoch": 4.53,
      "grad_norm": 17.75,
      "learning_rate": 8.210422163588389e-05,
      "loss": 0.1162,
      "step": 3431
    },
    {
      "epoch": 4.53,
      "grad_norm": 21.125,
      "learning_rate": 8.208443271767809e-05,
      "loss": 0.3887,
      "step": 3432
    },
    {
      "epoch": 4.53,
      "grad_norm": 38.0,
      "learning_rate": 8.206464379947229e-05,
      "loss": 0.2969,
      "step": 3433
    },
    {
      "epoch": 4.53,
      "grad_norm": 29.625,
      "learning_rate": 8.204485488126649e-05,
      "loss": 0.6055,
      "step": 3434
    },
    {
      "epoch": 4.53,
      "grad_norm": 46.75,
      "learning_rate": 8.202506596306069e-05,
      "loss": 0.4668,
      "step": 3435
    },
    {
      "epoch": 4.53,
      "grad_norm": 41.5,
      "learning_rate": 8.200527704485488e-05,
      "loss": 0.5938,
      "step": 3436
    },
    {
      "epoch": 4.53,
      "grad_norm": 30.375,
      "learning_rate": 8.198548812664907e-05,
      "loss": 0.1611,
      "step": 3437
    },
    {
      "epoch": 4.54,
      "grad_norm": 262.0,
      "learning_rate": 8.196569920844327e-05,
      "loss": 5.0312,
      "step": 3438
    },
    {
      "epoch": 4.54,
      "grad_norm": 26.625,
      "learning_rate": 8.194591029023746e-05,
      "loss": 0.2012,
      "step": 3439
    },
    {
      "epoch": 4.54,
      "grad_norm": 14.5,
      "learning_rate": 8.192612137203166e-05,
      "loss": 0.3711,
      "step": 3440
    },
    {
      "epoch": 4.54,
      "grad_norm": 378.0,
      "learning_rate": 8.190633245382586e-05,
      "loss": 6.9062,
      "step": 3441
    },
    {
      "epoch": 4.54,
      "grad_norm": 125.0,
      "learning_rate": 8.188654353562006e-05,
      "loss": 2.0781,
      "step": 3442
    },
    {
      "epoch": 4.54,
      "grad_norm": 272.0,
      "learning_rate": 8.186675461741424e-05,
      "loss": 7.9375,
      "step": 3443
    },
    {
      "epoch": 4.54,
      "grad_norm": 32.75,
      "learning_rate": 8.184696569920844e-05,
      "loss": 0.2227,
      "step": 3444
    },
    {
      "epoch": 4.54,
      "grad_norm": 15.5,
      "learning_rate": 8.182717678100263e-05,
      "loss": 0.166,
      "step": 3445
    },
    {
      "epoch": 4.55,
      "grad_norm": 197.0,
      "learning_rate": 8.180738786279682e-05,
      "loss": 3.375,
      "step": 3446
    },
    {
      "epoch": 4.55,
      "grad_norm": 166.0,
      "learning_rate": 8.178759894459102e-05,
      "loss": 3.0781,
      "step": 3447
    },
    {
      "epoch": 4.55,
      "grad_norm": 10.625,
      "learning_rate": 8.17678100263852e-05,
      "loss": 0.2969,
      "step": 3448
    },
    {
      "epoch": 4.55,
      "grad_norm": 131.0,
      "learning_rate": 8.17480211081794e-05,
      "loss": 2.1562,
      "step": 3449
    },
    {
      "epoch": 4.55,
      "grad_norm": 122.0,
      "learning_rate": 8.17282321899736e-05,
      "loss": 1.9922,
      "step": 3450
    },
    {
      "epoch": 4.55,
      "grad_norm": 260.0,
      "learning_rate": 8.17084432717678e-05,
      "loss": 5.0625,
      "step": 3451
    },
    {
      "epoch": 4.55,
      "grad_norm": 31.25,
      "learning_rate": 8.1688654353562e-05,
      "loss": 0.5664,
      "step": 3452
    },
    {
      "epoch": 4.56,
      "grad_norm": 15.8125,
      "learning_rate": 8.16688654353562e-05,
      "loss": 0.1855,
      "step": 3453
    },
    {
      "epoch": 4.56,
      "grad_norm": 25.75,
      "learning_rate": 8.164907651715038e-05,
      "loss": 0.3535,
      "step": 3454
    },
    {
      "epoch": 4.56,
      "grad_norm": 36.5,
      "learning_rate": 8.162928759894458e-05,
      "loss": 0.252,
      "step": 3455
    },
    {
      "epoch": 4.56,
      "grad_norm": 202.0,
      "learning_rate": 8.160949868073878e-05,
      "loss": 3.125,
      "step": 3456
    },
    {
      "epoch": 4.56,
      "grad_norm": 24.5,
      "learning_rate": 8.158970976253297e-05,
      "loss": 0.1729,
      "step": 3457
    },
    {
      "epoch": 4.56,
      "grad_norm": 21.25,
      "learning_rate": 8.156992084432717e-05,
      "loss": 0.8359,
      "step": 3458
    },
    {
      "epoch": 4.56,
      "grad_norm": 15.875,
      "learning_rate": 8.155013192612137e-05,
      "loss": 0.1992,
      "step": 3459
    },
    {
      "epoch": 4.56,
      "grad_norm": 24.5,
      "learning_rate": 8.153034300791556e-05,
      "loss": 0.2969,
      "step": 3460
    },
    {
      "epoch": 4.57,
      "grad_norm": 24.5,
      "learning_rate": 8.151055408970975e-05,
      "loss": 0.7148,
      "step": 3461
    },
    {
      "epoch": 4.57,
      "grad_norm": 17.625,
      "learning_rate": 8.149076517150395e-05,
      "loss": 0.1338,
      "step": 3462
    },
    {
      "epoch": 4.57,
      "grad_norm": 43.5,
      "learning_rate": 8.147097625329815e-05,
      "loss": 0.5156,
      "step": 3463
    },
    {
      "epoch": 4.57,
      "grad_norm": 5.75,
      "learning_rate": 8.145118733509235e-05,
      "loss": 0.0437,
      "step": 3464
    },
    {
      "epoch": 4.57,
      "grad_norm": 124.5,
      "learning_rate": 8.143139841688655e-05,
      "loss": 2.1094,
      "step": 3465
    },
    {
      "epoch": 4.57,
      "grad_norm": 13.75,
      "learning_rate": 8.141160949868073e-05,
      "loss": 0.1797,
      "step": 3466
    },
    {
      "epoch": 4.57,
      "grad_norm": 5.5625,
      "learning_rate": 8.139182058047493e-05,
      "loss": 0.042,
      "step": 3467
    },
    {
      "epoch": 4.58,
      "grad_norm": 26.125,
      "learning_rate": 8.137203166226913e-05,
      "loss": 0.2461,
      "step": 3468
    },
    {
      "epoch": 4.58,
      "grad_norm": 9.0,
      "learning_rate": 8.135224274406332e-05,
      "loss": 0.104,
      "step": 3469
    },
    {
      "epoch": 4.58,
      "grad_norm": 60.25,
      "learning_rate": 8.133245382585752e-05,
      "loss": 1.0547,
      "step": 3470
    },
    {
      "epoch": 4.58,
      "grad_norm": 178.0,
      "learning_rate": 8.131266490765172e-05,
      "loss": 3.75,
      "step": 3471
    },
    {
      "epoch": 4.58,
      "grad_norm": 18.75,
      "learning_rate": 8.12928759894459e-05,
      "loss": 0.1191,
      "step": 3472
    },
    {
      "epoch": 4.58,
      "grad_norm": 15.9375,
      "learning_rate": 8.12730870712401e-05,
      "loss": 0.1436,
      "step": 3473
    },
    {
      "epoch": 4.58,
      "grad_norm": 218.0,
      "learning_rate": 8.12532981530343e-05,
      "loss": 6.3125,
      "step": 3474
    },
    {
      "epoch": 4.58,
      "grad_norm": 12.6875,
      "learning_rate": 8.123350923482849e-05,
      "loss": 0.0771,
      "step": 3475
    },
    {
      "epoch": 4.59,
      "grad_norm": 226.0,
      "learning_rate": 8.121372031662267e-05,
      "loss": 4.3438,
      "step": 3476
    },
    {
      "epoch": 4.59,
      "grad_norm": 344.0,
      "learning_rate": 8.119393139841687e-05,
      "loss": 5.7188,
      "step": 3477
    },
    {
      "epoch": 4.59,
      "grad_norm": 5.375,
      "learning_rate": 8.117414248021107e-05,
      "loss": 0.0486,
      "step": 3478
    },
    {
      "epoch": 4.59,
      "grad_norm": 342.0,
      "learning_rate": 8.115435356200526e-05,
      "loss": 7.5625,
      "step": 3479
    },
    {
      "epoch": 4.59,
      "grad_norm": 36.25,
      "learning_rate": 8.113456464379946e-05,
      "loss": 0.4668,
      "step": 3480
    },
    {
      "epoch": 4.59,
      "grad_norm": 29.875,
      "learning_rate": 8.111477572559366e-05,
      "loss": 0.4004,
      "step": 3481
    },
    {
      "epoch": 4.59,
      "grad_norm": 225.0,
      "learning_rate": 8.109498680738784e-05,
      "loss": 4.4688,
      "step": 3482
    },
    {
      "epoch": 4.59,
      "grad_norm": 232.0,
      "learning_rate": 8.107519788918204e-05,
      "loss": 4.4062,
      "step": 3483
    },
    {
      "epoch": 4.6,
      "grad_norm": 241.0,
      "learning_rate": 8.105540897097624e-05,
      "loss": 4.4062,
      "step": 3484
    },
    {
      "epoch": 4.6,
      "grad_norm": 27.375,
      "learning_rate": 8.103562005277044e-05,
      "loss": 0.5117,
      "step": 3485
    },
    {
      "epoch": 4.6,
      "grad_norm": 60.0,
      "learning_rate": 8.101583113456464e-05,
      "loss": 0.3867,
      "step": 3486
    },
    {
      "epoch": 4.6,
      "grad_norm": 205.0,
      "learning_rate": 8.099604221635884e-05,
      "loss": 3.0312,
      "step": 3487
    },
    {
      "epoch": 4.6,
      "grad_norm": 4.875,
      "learning_rate": 8.097625329815303e-05,
      "loss": 0.0483,
      "step": 3488
    },
    {
      "epoch": 4.6,
      "grad_norm": 121.0,
      "learning_rate": 8.095646437994722e-05,
      "loss": 2.25,
      "step": 3489
    },
    {
      "epoch": 4.6,
      "grad_norm": 57.0,
      "learning_rate": 8.093667546174142e-05,
      "loss": 0.5156,
      "step": 3490
    },
    {
      "epoch": 4.61,
      "grad_norm": 47.75,
      "learning_rate": 8.091688654353561e-05,
      "loss": 0.5781,
      "step": 3491
    },
    {
      "epoch": 4.61,
      "grad_norm": 28.625,
      "learning_rate": 8.089709762532981e-05,
      "loss": 0.2344,
      "step": 3492
    },
    {
      "epoch": 4.61,
      "grad_norm": 40.5,
      "learning_rate": 8.087730870712401e-05,
      "loss": 0.6055,
      "step": 3493
    },
    {
      "epoch": 4.61,
      "grad_norm": 18.375,
      "learning_rate": 8.085751978891821e-05,
      "loss": 0.1611,
      "step": 3494
    },
    {
      "epoch": 4.61,
      "grad_norm": 21.375,
      "learning_rate": 8.083773087071239e-05,
      "loss": 0.9688,
      "step": 3495
    },
    {
      "epoch": 4.61,
      "grad_norm": 12.0625,
      "learning_rate": 8.081794195250659e-05,
      "loss": 0.0781,
      "step": 3496
    },
    {
      "epoch": 4.61,
      "grad_norm": 342.0,
      "learning_rate": 8.079815303430079e-05,
      "loss": 4.6562,
      "step": 3497
    },
    {
      "epoch": 4.61,
      "grad_norm": 6.65625,
      "learning_rate": 8.077836411609499e-05,
      "loss": 0.0679,
      "step": 3498
    },
    {
      "epoch": 4.62,
      "grad_norm": 246.0,
      "learning_rate": 8.075857519788918e-05,
      "loss": 4.2812,
      "step": 3499
    },
    {
      "epoch": 4.62,
      "grad_norm": 13.875,
      "learning_rate": 8.073878627968338e-05,
      "loss": 0.1045,
      "step": 3500
    },
    {
      "epoch": 4.62,
      "grad_norm": 22.875,
      "learning_rate": 8.071899736147757e-05,
      "loss": 0.0889,
      "step": 3501
    },
    {
      "epoch": 4.62,
      "grad_norm": 154.0,
      "learning_rate": 8.069920844327177e-05,
      "loss": 2.5156,
      "step": 3502
    },
    {
      "epoch": 4.62,
      "grad_norm": 23.875,
      "learning_rate": 8.067941952506596e-05,
      "loss": 0.6523,
      "step": 3503
    },
    {
      "epoch": 4.62,
      "grad_norm": 14.9375,
      "learning_rate": 8.065963060686016e-05,
      "loss": 0.2441,
      "step": 3504
    },
    {
      "epoch": 4.62,
      "grad_norm": 50.75,
      "learning_rate": 8.063984168865433e-05,
      "loss": 0.625,
      "step": 3505
    },
    {
      "epoch": 4.63,
      "grad_norm": 203.0,
      "learning_rate": 8.062005277044853e-05,
      "loss": 3.4062,
      "step": 3506
    },
    {
      "epoch": 4.63,
      "grad_norm": 23.5,
      "learning_rate": 8.060026385224273e-05,
      "loss": 0.2412,
      "step": 3507
    },
    {
      "epoch": 4.63,
      "grad_norm": 12.5625,
      "learning_rate": 8.058047493403693e-05,
      "loss": 0.2451,
      "step": 3508
    },
    {
      "epoch": 4.63,
      "grad_norm": 236.0,
      "learning_rate": 8.056068601583112e-05,
      "loss": 5.8125,
      "step": 3509
    },
    {
      "epoch": 4.63,
      "grad_norm": 139.0,
      "learning_rate": 8.054089709762532e-05,
      "loss": 2.3906,
      "step": 3510
    },
    {
      "epoch": 4.63,
      "grad_norm": 234.0,
      "learning_rate": 8.052110817941951e-05,
      "loss": 3.4688,
      "step": 3511
    },
    {
      "epoch": 4.63,
      "grad_norm": 131.0,
      "learning_rate": 8.05013192612137e-05,
      "loss": 2.5781,
      "step": 3512
    },
    {
      "epoch": 4.63,
      "grad_norm": 132.0,
      "learning_rate": 8.04815303430079e-05,
      "loss": 2.4375,
      "step": 3513
    },
    {
      "epoch": 4.64,
      "grad_norm": 272.0,
      "learning_rate": 8.04617414248021e-05,
      "loss": 5.0938,
      "step": 3514
    },
    {
      "epoch": 4.64,
      "grad_norm": 195.0,
      "learning_rate": 8.04419525065963e-05,
      "loss": 3.0938,
      "step": 3515
    },
    {
      "epoch": 4.64,
      "grad_norm": 350.0,
      "learning_rate": 8.04221635883905e-05,
      "loss": 6.9375,
      "step": 3516
    },
    {
      "epoch": 4.64,
      "grad_norm": 130.0,
      "learning_rate": 8.040237467018468e-05,
      "loss": 2.4688,
      "step": 3517
    },
    {
      "epoch": 4.64,
      "grad_norm": 182.0,
      "learning_rate": 8.038258575197888e-05,
      "loss": 3.1406,
      "step": 3518
    },
    {
      "epoch": 4.64,
      "grad_norm": 135.0,
      "learning_rate": 8.036279683377308e-05,
      "loss": 4.4062,
      "step": 3519
    },
    {
      "epoch": 4.64,
      "grad_norm": 31.75,
      "learning_rate": 8.034300791556728e-05,
      "loss": 0.7266,
      "step": 3520
    },
    {
      "epoch": 4.65,
      "grad_norm": 163.0,
      "learning_rate": 8.032321899736147e-05,
      "loss": 2.5625,
      "step": 3521
    },
    {
      "epoch": 4.65,
      "grad_norm": 89.0,
      "learning_rate": 8.030343007915567e-05,
      "loss": 1.4453,
      "step": 3522
    },
    {
      "epoch": 4.65,
      "grad_norm": 119.0,
      "learning_rate": 8.028364116094986e-05,
      "loss": 1.5312,
      "step": 3523
    },
    {
      "epoch": 4.65,
      "grad_norm": 33.75,
      "learning_rate": 8.026385224274406e-05,
      "loss": 0.334,
      "step": 3524
    },
    {
      "epoch": 4.65,
      "grad_norm": 188.0,
      "learning_rate": 8.024406332453825e-05,
      "loss": 3.1719,
      "step": 3525
    },
    {
      "epoch": 4.65,
      "grad_norm": 49.5,
      "learning_rate": 8.022427440633245e-05,
      "loss": 0.5117,
      "step": 3526
    },
    {
      "epoch": 4.65,
      "grad_norm": 148.0,
      "learning_rate": 8.020448548812665e-05,
      "loss": 2.6406,
      "step": 3527
    },
    {
      "epoch": 4.65,
      "grad_norm": 146.0,
      "learning_rate": 8.018469656992085e-05,
      "loss": 2.9062,
      "step": 3528
    },
    {
      "epoch": 4.66,
      "grad_norm": 40.5,
      "learning_rate": 8.016490765171503e-05,
      "loss": 0.8125,
      "step": 3529
    },
    {
      "epoch": 4.66,
      "grad_norm": 73.5,
      "learning_rate": 8.014511873350923e-05,
      "loss": 1.1719,
      "step": 3530
    },
    {
      "epoch": 4.66,
      "grad_norm": 39.5,
      "learning_rate": 8.012532981530343e-05,
      "loss": 0.498,
      "step": 3531
    },
    {
      "epoch": 4.66,
      "grad_norm": 77.0,
      "learning_rate": 8.010554089709763e-05,
      "loss": 1.0469,
      "step": 3532
    },
    {
      "epoch": 4.66,
      "grad_norm": 119.5,
      "learning_rate": 8.008575197889182e-05,
      "loss": 2.375,
      "step": 3533
    },
    {
      "epoch": 4.66,
      "grad_norm": 57.25,
      "learning_rate": 8.006596306068602e-05,
      "loss": 0.5586,
      "step": 3534
    },
    {
      "epoch": 4.66,
      "grad_norm": 67.5,
      "learning_rate": 8.004617414248019e-05,
      "loss": 1.1641,
      "step": 3535
    },
    {
      "epoch": 4.66,
      "grad_norm": 57.0,
      "learning_rate": 8.002638522427439e-05,
      "loss": 0.6719,
      "step": 3536
    },
    {
      "epoch": 4.67,
      "grad_norm": 125.0,
      "learning_rate": 8.000659630606859e-05,
      "loss": 2.6875,
      "step": 3537
    },
    {
      "epoch": 4.67,
      "grad_norm": 71.0,
      "learning_rate": 7.998680738786279e-05,
      "loss": 1.0625,
      "step": 3538
    },
    {
      "epoch": 4.67,
      "grad_norm": 70.5,
      "learning_rate": 7.996701846965699e-05,
      "loss": 0.9961,
      "step": 3539
    },
    {
      "epoch": 4.67,
      "grad_norm": 48.0,
      "learning_rate": 7.994722955145117e-05,
      "loss": 0.9062,
      "step": 3540
    },
    {
      "epoch": 4.67,
      "grad_norm": 165.0,
      "learning_rate": 7.992744063324537e-05,
      "loss": 2.7812,
      "step": 3541
    },
    {
      "epoch": 4.67,
      "grad_norm": 49.25,
      "learning_rate": 7.990765171503957e-05,
      "loss": 0.8594,
      "step": 3542
    },
    {
      "epoch": 4.67,
      "grad_norm": 40.5,
      "learning_rate": 7.988786279683376e-05,
      "loss": 0.5898,
      "step": 3543
    },
    {
      "epoch": 4.68,
      "grad_norm": 51.5,
      "learning_rate": 7.986807387862796e-05,
      "loss": 0.4453,
      "step": 3544
    },
    {
      "epoch": 4.68,
      "grad_norm": 34.25,
      "learning_rate": 7.984828496042216e-05,
      "loss": 0.5703,
      "step": 3545
    },
    {
      "epoch": 4.68,
      "grad_norm": 280.0,
      "learning_rate": 7.982849604221634e-05,
      "loss": 3.0625,
      "step": 3546
    },
    {
      "epoch": 4.68,
      "grad_norm": 34.25,
      "learning_rate": 7.980870712401054e-05,
      "loss": 0.4648,
      "step": 3547
    },
    {
      "epoch": 4.68,
      "grad_norm": 30.375,
      "learning_rate": 7.978891820580474e-05,
      "loss": 0.2617,
      "step": 3548
    },
    {
      "epoch": 4.68,
      "grad_norm": 29.375,
      "learning_rate": 7.976912928759894e-05,
      "loss": 0.4648,
      "step": 3549
    },
    {
      "epoch": 4.68,
      "grad_norm": 63.5,
      "learning_rate": 7.974934036939314e-05,
      "loss": 0.8398,
      "step": 3550
    },
    {
      "epoch": 4.68,
      "grad_norm": 18.625,
      "learning_rate": 7.972955145118733e-05,
      "loss": 0.373,
      "step": 3551
    },
    {
      "epoch": 4.69,
      "grad_norm": 170.0,
      "learning_rate": 7.970976253298152e-05,
      "loss": 3.1875,
      "step": 3552
    },
    {
      "epoch": 4.69,
      "grad_norm": 18.25,
      "learning_rate": 7.968997361477572e-05,
      "loss": 0.2637,
      "step": 3553
    },
    {
      "epoch": 4.69,
      "grad_norm": 25.375,
      "learning_rate": 7.967018469656992e-05,
      "loss": 0.1787,
      "step": 3554
    },
    {
      "epoch": 4.69,
      "grad_norm": 110.0,
      "learning_rate": 7.965039577836411e-05,
      "loss": 2.5156,
      "step": 3555
    },
    {
      "epoch": 4.69,
      "grad_norm": 199.0,
      "learning_rate": 7.963060686015831e-05,
      "loss": 3.9219,
      "step": 3556
    },
    {
      "epoch": 4.69,
      "grad_norm": 36.75,
      "learning_rate": 7.961081794195251e-05,
      "loss": 0.6953,
      "step": 3557
    },
    {
      "epoch": 4.69,
      "grad_norm": 27.75,
      "learning_rate": 7.95910290237467e-05,
      "loss": 0.1885,
      "step": 3558
    },
    {
      "epoch": 4.7,
      "grad_norm": 55.0,
      "learning_rate": 7.957124010554089e-05,
      "loss": 0.4395,
      "step": 3559
    },
    {
      "epoch": 4.7,
      "grad_norm": 119.0,
      "learning_rate": 7.955145118733509e-05,
      "loss": 2.7969,
      "step": 3560
    },
    {
      "epoch": 4.7,
      "grad_norm": 42.0,
      "learning_rate": 7.953166226912929e-05,
      "loss": 0.6211,
      "step": 3561
    },
    {
      "epoch": 4.7,
      "grad_norm": 21.75,
      "learning_rate": 7.951187335092349e-05,
      "loss": 0.1816,
      "step": 3562
    },
    {
      "epoch": 4.7,
      "grad_norm": 149.0,
      "learning_rate": 7.949208443271768e-05,
      "loss": 2.8125,
      "step": 3563
    },
    {
      "epoch": 4.7,
      "grad_norm": 484.0,
      "learning_rate": 7.947229551451187e-05,
      "loss": 9.5625,
      "step": 3564
    },
    {
      "epoch": 4.7,
      "grad_norm": 312.0,
      "learning_rate": 7.945250659630605e-05,
      "loss": 5.0,
      "step": 3565
    },
    {
      "epoch": 4.7,
      "grad_norm": 5.5625,
      "learning_rate": 7.943271767810025e-05,
      "loss": 0.0623,
      "step": 3566
    },
    {
      "epoch": 4.71,
      "grad_norm": 38.0,
      "learning_rate": 7.941292875989445e-05,
      "loss": 0.6211,
      "step": 3567
    },
    {
      "epoch": 4.71,
      "grad_norm": 11.1875,
      "learning_rate": 7.939313984168865e-05,
      "loss": 0.1572,
      "step": 3568
    },
    {
      "epoch": 4.71,
      "grad_norm": 11.6875,
      "learning_rate": 7.937335092348283e-05,
      "loss": 0.3008,
      "step": 3569
    },
    {
      "epoch": 4.71,
      "grad_norm": 19.625,
      "learning_rate": 7.935356200527703e-05,
      "loss": 0.1689,
      "step": 3570
    },
    {
      "epoch": 4.71,
      "grad_norm": 182.0,
      "learning_rate": 7.933377308707123e-05,
      "loss": 4.625,
      "step": 3571
    },
    {
      "epoch": 4.71,
      "grad_norm": 48.25,
      "learning_rate": 7.931398416886543e-05,
      "loss": 0.3242,
      "step": 3572
    },
    {
      "epoch": 4.71,
      "grad_norm": 396.0,
      "learning_rate": 7.929419525065962e-05,
      "loss": 8.1875,
      "step": 3573
    },
    {
      "epoch": 4.72,
      "grad_norm": 165.0,
      "learning_rate": 7.927440633245382e-05,
      "loss": 2.5781,
      "step": 3574
    },
    {
      "epoch": 4.72,
      "grad_norm": 81.5,
      "learning_rate": 7.925461741424801e-05,
      "loss": 1.0703,
      "step": 3575
    },
    {
      "epoch": 4.72,
      "grad_norm": 22.25,
      "learning_rate": 7.92348284960422e-05,
      "loss": 0.498,
      "step": 3576
    },
    {
      "epoch": 4.72,
      "grad_norm": 150.0,
      "learning_rate": 7.92150395778364e-05,
      "loss": 2.2812,
      "step": 3577
    },
    {
      "epoch": 4.72,
      "grad_norm": 280.0,
      "learning_rate": 7.91952506596306e-05,
      "loss": 5.5938,
      "step": 3578
    },
    {
      "epoch": 4.72,
      "grad_norm": 5.96875,
      "learning_rate": 7.91754617414248e-05,
      "loss": 0.1309,
      "step": 3579
    },
    {
      "epoch": 4.72,
      "grad_norm": 135.0,
      "learning_rate": 7.9155672823219e-05,
      "loss": 2.3281,
      "step": 3580
    },
    {
      "epoch": 4.72,
      "grad_norm": 25.875,
      "learning_rate": 7.913588390501318e-05,
      "loss": 0.5625,
      "step": 3581
    },
    {
      "epoch": 4.73,
      "grad_norm": 13.0,
      "learning_rate": 7.911609498680738e-05,
      "loss": 0.0869,
      "step": 3582
    },
    {
      "epoch": 4.73,
      "grad_norm": 53.0,
      "learning_rate": 7.909630606860158e-05,
      "loss": 0.4941,
      "step": 3583
    },
    {
      "epoch": 4.73,
      "grad_norm": 294.0,
      "learning_rate": 7.907651715039578e-05,
      "loss": 5.125,
      "step": 3584
    },
    {
      "epoch": 4.73,
      "grad_norm": 276.0,
      "learning_rate": 7.905672823218997e-05,
      "loss": 3.4062,
      "step": 3585
    },
    {
      "epoch": 4.73,
      "grad_norm": 36.25,
      "learning_rate": 7.903693931398417e-05,
      "loss": 0.4531,
      "step": 3586
    },
    {
      "epoch": 4.73,
      "grad_norm": 71.5,
      "learning_rate": 7.901715039577836e-05,
      "loss": 0.5625,
      "step": 3587
    },
    {
      "epoch": 4.73,
      "grad_norm": 206.0,
      "learning_rate": 7.899736147757255e-05,
      "loss": 4.5938,
      "step": 3588
    },
    {
      "epoch": 4.73,
      "grad_norm": 294.0,
      "learning_rate": 7.897757255936675e-05,
      "loss": 4.9688,
      "step": 3589
    },
    {
      "epoch": 4.74,
      "grad_norm": 136.0,
      "learning_rate": 7.895778364116095e-05,
      "loss": 1.4375,
      "step": 3590
    },
    {
      "epoch": 4.74,
      "grad_norm": 208.0,
      "learning_rate": 7.893799472295515e-05,
      "loss": 3.3125,
      "step": 3591
    },
    {
      "epoch": 4.74,
      "grad_norm": 145.0,
      "learning_rate": 7.891820580474935e-05,
      "loss": 2.0,
      "step": 3592
    },
    {
      "epoch": 4.74,
      "grad_norm": 264.0,
      "learning_rate": 7.889841688654353e-05,
      "loss": 3.1562,
      "step": 3593
    },
    {
      "epoch": 4.74,
      "grad_norm": 226.0,
      "learning_rate": 7.887862796833773e-05,
      "loss": 3.9688,
      "step": 3594
    },
    {
      "epoch": 4.74,
      "grad_norm": 39.5,
      "learning_rate": 7.885883905013191e-05,
      "loss": 0.2949,
      "step": 3595
    },
    {
      "epoch": 4.74,
      "grad_norm": 42.75,
      "learning_rate": 7.883905013192611e-05,
      "loss": 0.2793,
      "step": 3596
    },
    {
      "epoch": 4.75,
      "grad_norm": 217.0,
      "learning_rate": 7.88192612137203e-05,
      "loss": 2.7656,
      "step": 3597
    },
    {
      "epoch": 4.75,
      "grad_norm": 238.0,
      "learning_rate": 7.87994722955145e-05,
      "loss": 3.1094,
      "step": 3598
    },
    {
      "epoch": 4.75,
      "grad_norm": 205.0,
      "learning_rate": 7.877968337730869e-05,
      "loss": 3.0312,
      "step": 3599
    },
    {
      "epoch": 4.75,
      "grad_norm": 204.0,
      "learning_rate": 7.875989445910289e-05,
      "loss": 2.3281,
      "step": 3600
    },
    {
      "epoch": 4.75,
      "grad_norm": 51.75,
      "learning_rate": 7.874010554089709e-05,
      "loss": 0.3691,
      "step": 3601
    },
    {
      "epoch": 4.75,
      "grad_norm": 71.5,
      "learning_rate": 7.872031662269129e-05,
      "loss": 0.9375,
      "step": 3602
    },
    {
      "epoch": 4.75,
      "grad_norm": 212.0,
      "learning_rate": 7.870052770448547e-05,
      "loss": 1.6953,
      "step": 3603
    },
    {
      "epoch": 4.75,
      "grad_norm": 81.5,
      "learning_rate": 7.868073878627967e-05,
      "loss": 0.5742,
      "step": 3604
    },
    {
      "epoch": 4.76,
      "grad_norm": 103.5,
      "learning_rate": 7.866094986807387e-05,
      "loss": 1.0469,
      "step": 3605
    },
    {
      "epoch": 4.76,
      "grad_norm": 73.0,
      "learning_rate": 7.864116094986807e-05,
      "loss": 0.8516,
      "step": 3606
    },
    {
      "epoch": 4.76,
      "grad_norm": 141.0,
      "learning_rate": 7.862137203166226e-05,
      "loss": 1.5078,
      "step": 3607
    },
    {
      "epoch": 4.76,
      "grad_norm": 67.0,
      "learning_rate": 7.860158311345646e-05,
      "loss": 0.6328,
      "step": 3608
    },
    {
      "epoch": 4.76,
      "grad_norm": 63.75,
      "learning_rate": 7.858179419525065e-05,
      "loss": 0.6055,
      "step": 3609
    },
    {
      "epoch": 4.76,
      "grad_norm": 256.0,
      "learning_rate": 7.856200527704484e-05,
      "loss": 2.8594,
      "step": 3610
    },
    {
      "epoch": 4.76,
      "grad_norm": 143.0,
      "learning_rate": 7.854221635883904e-05,
      "loss": 2.2656,
      "step": 3611
    },
    {
      "epoch": 4.77,
      "grad_norm": 70.5,
      "learning_rate": 7.852242744063324e-05,
      "loss": 0.6445,
      "step": 3612
    },
    {
      "epoch": 4.77,
      "grad_norm": 119.5,
      "learning_rate": 7.850263852242744e-05,
      "loss": 1.9297,
      "step": 3613
    },
    {
      "epoch": 4.77,
      "grad_norm": 53.25,
      "learning_rate": 7.848284960422164e-05,
      "loss": 0.3887,
      "step": 3614
    },
    {
      "epoch": 4.77,
      "grad_norm": 180.0,
      "learning_rate": 7.846306068601582e-05,
      "loss": 2.2656,
      "step": 3615
    },
    {
      "epoch": 4.77,
      "grad_norm": 370.0,
      "learning_rate": 7.844327176781002e-05,
      "loss": 4.6562,
      "step": 3616
    },
    {
      "epoch": 4.77,
      "grad_norm": 35.25,
      "learning_rate": 7.842348284960422e-05,
      "loss": 0.2559,
      "step": 3617
    },
    {
      "epoch": 4.77,
      "grad_norm": 33.5,
      "learning_rate": 7.840369393139842e-05,
      "loss": 0.4883,
      "step": 3618
    },
    {
      "epoch": 4.77,
      "grad_norm": 41.25,
      "learning_rate": 7.838390501319261e-05,
      "loss": 0.3535,
      "step": 3619
    },
    {
      "epoch": 4.78,
      "grad_norm": 29.5,
      "learning_rate": 7.836411609498681e-05,
      "loss": 0.2412,
      "step": 3620
    },
    {
      "epoch": 4.78,
      "grad_norm": 38.0,
      "learning_rate": 7.8344327176781e-05,
      "loss": 0.252,
      "step": 3621
    },
    {
      "epoch": 4.78,
      "grad_norm": 166.0,
      "learning_rate": 7.83245382585752e-05,
      "loss": 2.7188,
      "step": 3622
    },
    {
      "epoch": 4.78,
      "grad_norm": 121.5,
      "learning_rate": 7.830474934036939e-05,
      "loss": 1.75,
      "step": 3623
    },
    {
      "epoch": 4.78,
      "grad_norm": 250.0,
      "learning_rate": 7.828496042216359e-05,
      "loss": 3.4375,
      "step": 3624
    },
    {
      "epoch": 4.78,
      "grad_norm": 73.5,
      "learning_rate": 7.826517150395777e-05,
      "loss": 0.5195,
      "step": 3625
    },
    {
      "epoch": 4.78,
      "grad_norm": 122.5,
      "learning_rate": 7.824538258575196e-05,
      "loss": 2.1406,
      "step": 3626
    },
    {
      "epoch": 4.78,
      "grad_norm": 16.125,
      "learning_rate": 7.822559366754616e-05,
      "loss": 0.2119,
      "step": 3627
    },
    {
      "epoch": 4.79,
      "grad_norm": 152.0,
      "learning_rate": 7.820580474934036e-05,
      "loss": 1.9609,
      "step": 3628
    },
    {
      "epoch": 4.79,
      "grad_norm": 11.8125,
      "learning_rate": 7.818601583113455e-05,
      "loss": 0.0996,
      "step": 3629
    },
    {
      "epoch": 4.79,
      "grad_norm": 23.75,
      "learning_rate": 7.816622691292875e-05,
      "loss": 0.1924,
      "step": 3630
    },
    {
      "epoch": 4.79,
      "grad_norm": 142.0,
      "learning_rate": 7.814643799472295e-05,
      "loss": 1.9219,
      "step": 3631
    },
    {
      "epoch": 4.79,
      "grad_norm": 168.0,
      "learning_rate": 7.812664907651713e-05,
      "loss": 2.4219,
      "step": 3632
    },
    {
      "epoch": 4.79,
      "grad_norm": 316.0,
      "learning_rate": 7.810686015831133e-05,
      "loss": 5.2812,
      "step": 3633
    },
    {
      "epoch": 4.79,
      "grad_norm": 123.0,
      "learning_rate": 7.808707124010553e-05,
      "loss": 1.6875,
      "step": 3634
    },
    {
      "epoch": 4.8,
      "grad_norm": 264.0,
      "learning_rate": 7.806728232189973e-05,
      "loss": 3.1094,
      "step": 3635
    },
    {
      "epoch": 4.8,
      "grad_norm": 16.875,
      "learning_rate": 7.804749340369393e-05,
      "loss": 0.1328,
      "step": 3636
    },
    {
      "epoch": 4.8,
      "grad_norm": 18.75,
      "learning_rate": 7.802770448548812e-05,
      "loss": 0.1348,
      "step": 3637
    },
    {
      "epoch": 4.8,
      "grad_norm": 54.25,
      "learning_rate": 7.800791556728231e-05,
      "loss": 0.6523,
      "step": 3638
    },
    {
      "epoch": 4.8,
      "grad_norm": 219.0,
      "learning_rate": 7.79881266490765e-05,
      "loss": 3.2969,
      "step": 3639
    },
    {
      "epoch": 4.8,
      "grad_norm": 123.0,
      "learning_rate": 7.79683377308707e-05,
      "loss": 1.7969,
      "step": 3640
    },
    {
      "epoch": 4.8,
      "grad_norm": 27.875,
      "learning_rate": 7.79485488126649e-05,
      "loss": 0.6641,
      "step": 3641
    },
    {
      "epoch": 4.8,
      "grad_norm": 117.0,
      "learning_rate": 7.79287598944591e-05,
      "loss": 1.3047,
      "step": 3642
    },
    {
      "epoch": 4.81,
      "grad_norm": 210.0,
      "learning_rate": 7.79089709762533e-05,
      "loss": 3.6562,
      "step": 3643
    },
    {
      "epoch": 4.81,
      "grad_norm": 70.5,
      "learning_rate": 7.788918205804748e-05,
      "loss": 0.8086,
      "step": 3644
    },
    {
      "epoch": 4.81,
      "grad_norm": 26.5,
      "learning_rate": 7.786939313984168e-05,
      "loss": 0.3027,
      "step": 3645
    },
    {
      "epoch": 4.81,
      "grad_norm": 231.0,
      "learning_rate": 7.784960422163588e-05,
      "loss": 4.3125,
      "step": 3646
    },
    {
      "epoch": 4.81,
      "grad_norm": 186.0,
      "learning_rate": 7.782981530343008e-05,
      "loss": 4.0938,
      "step": 3647
    },
    {
      "epoch": 4.81,
      "grad_norm": 56.5,
      "learning_rate": 7.781002638522428e-05,
      "loss": 0.7344,
      "step": 3648
    },
    {
      "epoch": 4.81,
      "grad_norm": 164.0,
      "learning_rate": 7.779023746701847e-05,
      "loss": 2.9531,
      "step": 3649
    },
    {
      "epoch": 4.82,
      "grad_norm": 73.5,
      "learning_rate": 7.777044854881266e-05,
      "loss": 1.2109,
      "step": 3650
    },
    {
      "epoch": 4.82,
      "grad_norm": 27.625,
      "learning_rate": 7.775065963060686e-05,
      "loss": 0.3633,
      "step": 3651
    },
    {
      "epoch": 4.82,
      "grad_norm": 111.5,
      "learning_rate": 7.773087071240105e-05,
      "loss": 2.1094,
      "step": 3652
    },
    {
      "epoch": 4.82,
      "grad_norm": 27.0,
      "learning_rate": 7.771108179419525e-05,
      "loss": 0.4902,
      "step": 3653
    },
    {
      "epoch": 4.82,
      "grad_norm": 15.5625,
      "learning_rate": 7.769129287598945e-05,
      "loss": 0.2217,
      "step": 3654
    },
    {
      "epoch": 4.82,
      "grad_norm": 174.0,
      "learning_rate": 7.767150395778362e-05,
      "loss": 3.7812,
      "step": 3655
    },
    {
      "epoch": 4.82,
      "grad_norm": 103.5,
      "learning_rate": 7.765171503957782e-05,
      "loss": 1.7656,
      "step": 3656
    },
    {
      "epoch": 4.82,
      "grad_norm": 14.5,
      "learning_rate": 7.763192612137202e-05,
      "loss": 0.1729,
      "step": 3657
    },
    {
      "epoch": 4.83,
      "grad_norm": 28.75,
      "learning_rate": 7.761213720316622e-05,
      "loss": 0.4297,
      "step": 3658
    },
    {
      "epoch": 4.83,
      "grad_norm": 122.0,
      "learning_rate": 7.759234828496041e-05,
      "loss": 1.6406,
      "step": 3659
    },
    {
      "epoch": 4.83,
      "grad_norm": 185.0,
      "learning_rate": 7.757255936675461e-05,
      "loss": 2.4062,
      "step": 3660
    },
    {
      "epoch": 4.83,
      "grad_norm": 32.5,
      "learning_rate": 7.75527704485488e-05,
      "loss": 0.5859,
      "step": 3661
    },
    {
      "epoch": 4.83,
      "grad_norm": 42.0,
      "learning_rate": 7.7532981530343e-05,
      "loss": 0.625,
      "step": 3662
    },
    {
      "epoch": 4.83,
      "grad_norm": 189.0,
      "learning_rate": 7.751319261213719e-05,
      "loss": 2.2188,
      "step": 3663
    },
    {
      "epoch": 4.83,
      "grad_norm": 37.5,
      "learning_rate": 7.749340369393139e-05,
      "loss": 0.7188,
      "step": 3664
    },
    {
      "epoch": 4.84,
      "grad_norm": 176.0,
      "learning_rate": 7.747361477572559e-05,
      "loss": 2.1562,
      "step": 3665
    },
    {
      "epoch": 4.84,
      "grad_norm": 28.75,
      "learning_rate": 7.745382585751979e-05,
      "loss": 0.457,
      "step": 3666
    },
    {
      "epoch": 4.84,
      "grad_norm": 168.0,
      "learning_rate": 7.743403693931397e-05,
      "loss": 2.8594,
      "step": 3667
    },
    {
      "epoch": 4.84,
      "grad_norm": 56.25,
      "learning_rate": 7.741424802110817e-05,
      "loss": 1.0547,
      "step": 3668
    },
    {
      "epoch": 4.84,
      "grad_norm": 25.125,
      "learning_rate": 7.739445910290237e-05,
      "loss": 0.4043,
      "step": 3669
    },
    {
      "epoch": 4.84,
      "grad_norm": 90.0,
      "learning_rate": 7.737467018469657e-05,
      "loss": 1.2578,
      "step": 3670
    },
    {
      "epoch": 4.84,
      "grad_norm": 45.25,
      "learning_rate": 7.735488126649076e-05,
      "loss": 1.0234,
      "step": 3671
    },
    {
      "epoch": 4.84,
      "grad_norm": 50.5,
      "learning_rate": 7.733509234828496e-05,
      "loss": 0.7031,
      "step": 3672
    },
    {
      "epoch": 4.85,
      "grad_norm": 188.0,
      "learning_rate": 7.731530343007915e-05,
      "loss": 2.0625,
      "step": 3673
    },
    {
      "epoch": 4.85,
      "grad_norm": 201.0,
      "learning_rate": 7.729551451187334e-05,
      "loss": 2.8906,
      "step": 3674
    },
    {
      "epoch": 4.85,
      "grad_norm": 100.5,
      "learning_rate": 7.727572559366754e-05,
      "loss": 1.4219,
      "step": 3675
    },
    {
      "epoch": 4.85,
      "grad_norm": 30.375,
      "learning_rate": 7.725593667546174e-05,
      "loss": 0.8672,
      "step": 3676
    },
    {
      "epoch": 4.85,
      "grad_norm": 193.0,
      "learning_rate": 7.723614775725594e-05,
      "loss": 3.0781,
      "step": 3677
    },
    {
      "epoch": 4.85,
      "grad_norm": 202.0,
      "learning_rate": 7.721635883905014e-05,
      "loss": 4.1562,
      "step": 3678
    },
    {
      "epoch": 4.85,
      "grad_norm": 83.0,
      "learning_rate": 7.719656992084432e-05,
      "loss": 1.2578,
      "step": 3679
    },
    {
      "epoch": 4.85,
      "grad_norm": 26.0,
      "learning_rate": 7.717678100263852e-05,
      "loss": 0.3105,
      "step": 3680
    },
    {
      "epoch": 4.86,
      "grad_norm": 168.0,
      "learning_rate": 7.715699208443272e-05,
      "loss": 4.3438,
      "step": 3681
    },
    {
      "epoch": 4.86,
      "grad_norm": 25.25,
      "learning_rate": 7.713720316622691e-05,
      "loss": 0.4512,
      "step": 3682
    },
    {
      "epoch": 4.86,
      "grad_norm": 57.0,
      "learning_rate": 7.711741424802111e-05,
      "loss": 0.5977,
      "step": 3683
    },
    {
      "epoch": 4.86,
      "grad_norm": 23.875,
      "learning_rate": 7.709762532981531e-05,
      "loss": 0.418,
      "step": 3684
    },
    {
      "epoch": 4.86,
      "grad_norm": 170.0,
      "learning_rate": 7.707783641160948e-05,
      "loss": 3.0625,
      "step": 3685
    },
    {
      "epoch": 4.86,
      "grad_norm": 93.5,
      "learning_rate": 7.705804749340368e-05,
      "loss": 1.5156,
      "step": 3686
    },
    {
      "epoch": 4.86,
      "grad_norm": 23.0,
      "learning_rate": 7.703825857519788e-05,
      "loss": 0.2207,
      "step": 3687
    },
    {
      "epoch": 4.87,
      "grad_norm": 23.75,
      "learning_rate": 7.701846965699208e-05,
      "loss": 0.4258,
      "step": 3688
    },
    {
      "epoch": 4.87,
      "grad_norm": 13.5625,
      "learning_rate": 7.699868073878626e-05,
      "loss": 0.1074,
      "step": 3689
    },
    {
      "epoch": 4.87,
      "grad_norm": 48.0,
      "learning_rate": 7.697889182058046e-05,
      "loss": 0.416,
      "step": 3690
    },
    {
      "epoch": 4.87,
      "grad_norm": 216.0,
      "learning_rate": 7.695910290237466e-05,
      "loss": 4.5938,
      "step": 3691
    },
    {
      "epoch": 4.87,
      "grad_norm": 20.375,
      "learning_rate": 7.693931398416885e-05,
      "loss": 0.4121,
      "step": 3692
    },
    {
      "epoch": 4.87,
      "grad_norm": 206.0,
      "learning_rate": 7.691952506596305e-05,
      "loss": 3.8125,
      "step": 3693
    },
    {
      "epoch": 4.87,
      "grad_norm": 35.0,
      "learning_rate": 7.689973614775725e-05,
      "loss": 0.334,
      "step": 3694
    },
    {
      "epoch": 4.87,
      "grad_norm": 24.25,
      "learning_rate": 7.687994722955144e-05,
      "loss": 0.2871,
      "step": 3695
    },
    {
      "epoch": 4.88,
      "grad_norm": 15.0625,
      "learning_rate": 7.686015831134563e-05,
      "loss": 0.1406,
      "step": 3696
    },
    {
      "epoch": 4.88,
      "grad_norm": 163.0,
      "learning_rate": 7.684036939313983e-05,
      "loss": 2.7031,
      "step": 3697
    },
    {
      "epoch": 4.88,
      "grad_norm": 22.5,
      "learning_rate": 7.682058047493403e-05,
      "loss": 0.4727,
      "step": 3698
    },
    {
      "epoch": 4.88,
      "grad_norm": 14.125,
      "learning_rate": 7.680079155672823e-05,
      "loss": 0.3203,
      "step": 3699
    },
    {
      "epoch": 4.88,
      "grad_norm": 22.5,
      "learning_rate": 7.678100263852243e-05,
      "loss": 0.7461,
      "step": 3700
    },
    {
      "epoch": 4.88,
      "grad_norm": 46.75,
      "learning_rate": 7.676121372031661e-05,
      "loss": 0.5977,
      "step": 3701
    },
    {
      "epoch": 4.88,
      "grad_norm": 126.0,
      "learning_rate": 7.674142480211081e-05,
      "loss": 2.0469,
      "step": 3702
    },
    {
      "epoch": 4.89,
      "grad_norm": 32.5,
      "learning_rate": 7.6721635883905e-05,
      "loss": 0.25,
      "step": 3703
    },
    {
      "epoch": 4.89,
      "grad_norm": 256.0,
      "learning_rate": 7.67018469656992e-05,
      "loss": 4.5,
      "step": 3704
    },
    {
      "epoch": 4.89,
      "grad_norm": 286.0,
      "learning_rate": 7.66820580474934e-05,
      "loss": 5.5,
      "step": 3705
    },
    {
      "epoch": 4.89,
      "grad_norm": 179.0,
      "learning_rate": 7.66622691292876e-05,
      "loss": 3.1719,
      "step": 3706
    },
    {
      "epoch": 4.89,
      "grad_norm": 22.75,
      "learning_rate": 7.664248021108178e-05,
      "loss": 0.1621,
      "step": 3707
    },
    {
      "epoch": 4.89,
      "grad_norm": 27.125,
      "learning_rate": 7.662269129287598e-05,
      "loss": 0.1885,
      "step": 3708
    },
    {
      "epoch": 4.89,
      "grad_norm": 10.6875,
      "learning_rate": 7.660290237467018e-05,
      "loss": 0.0806,
      "step": 3709
    },
    {
      "epoch": 4.89,
      "grad_norm": 20.625,
      "learning_rate": 7.658311345646438e-05,
      "loss": 0.3789,
      "step": 3710
    },
    {
      "epoch": 4.9,
      "grad_norm": 7.40625,
      "learning_rate": 7.656332453825858e-05,
      "loss": 0.0859,
      "step": 3711
    },
    {
      "epoch": 4.9,
      "grad_norm": 131.0,
      "learning_rate": 7.654353562005278e-05,
      "loss": 2.4844,
      "step": 3712
    },
    {
      "epoch": 4.9,
      "grad_norm": 14.5,
      "learning_rate": 7.652374670184696e-05,
      "loss": 0.6016,
      "step": 3713
    },
    {
      "epoch": 4.9,
      "grad_norm": 116.0,
      "learning_rate": 7.650395778364116e-05,
      "loss": 2.2031,
      "step": 3714
    },
    {
      "epoch": 4.9,
      "grad_norm": 10.625,
      "learning_rate": 7.648416886543534e-05,
      "loss": 0.2109,
      "step": 3715
    },
    {
      "epoch": 4.9,
      "grad_norm": 61.25,
      "learning_rate": 7.646437994722954e-05,
      "loss": 0.9883,
      "step": 3716
    },
    {
      "epoch": 4.9,
      "grad_norm": 38.5,
      "learning_rate": 7.644459102902374e-05,
      "loss": 0.4258,
      "step": 3717
    },
    {
      "epoch": 4.91,
      "grad_norm": 206.0,
      "learning_rate": 7.642480211081792e-05,
      "loss": 3.7812,
      "step": 3718
    },
    {
      "epoch": 4.91,
      "grad_norm": 108.0,
      "learning_rate": 7.640501319261212e-05,
      "loss": 2.375,
      "step": 3719
    },
    {
      "epoch": 4.91,
      "grad_norm": 108.0,
      "learning_rate": 7.638522427440632e-05,
      "loss": 2.2656,
      "step": 3720
    },
    {
      "epoch": 4.91,
      "grad_norm": 21.0,
      "learning_rate": 7.636543535620052e-05,
      "loss": 0.4844,
      "step": 3721
    },
    {
      "epoch": 4.91,
      "grad_norm": 34.0,
      "learning_rate": 7.634564643799472e-05,
      "loss": 0.2402,
      "step": 3722
    },
    {
      "epoch": 4.91,
      "grad_norm": 5.53125,
      "learning_rate": 7.632585751978891e-05,
      "loss": 0.1157,
      "step": 3723
    },
    {
      "epoch": 4.91,
      "grad_norm": 140.0,
      "learning_rate": 7.63060686015831e-05,
      "loss": 2.1875,
      "step": 3724
    },
    {
      "epoch": 4.91,
      "grad_norm": 135.0,
      "learning_rate": 7.62862796833773e-05,
      "loss": 2.0781,
      "step": 3725
    },
    {
      "epoch": 4.92,
      "grad_norm": 23.125,
      "learning_rate": 7.62664907651715e-05,
      "loss": 0.1953,
      "step": 3726
    },
    {
      "epoch": 4.92,
      "grad_norm": 255.0,
      "learning_rate": 7.624670184696569e-05,
      "loss": 5.2188,
      "step": 3727
    },
    {
      "epoch": 4.92,
      "grad_norm": 28.625,
      "learning_rate": 7.622691292875989e-05,
      "loss": 0.3984,
      "step": 3728
    },
    {
      "epoch": 4.92,
      "grad_norm": 37.0,
      "learning_rate": 7.620712401055409e-05,
      "loss": 0.2246,
      "step": 3729
    },
    {
      "epoch": 4.92,
      "grad_norm": 206.0,
      "learning_rate": 7.618733509234827e-05,
      "loss": 3.7031,
      "step": 3730
    },
    {
      "epoch": 4.92,
      "grad_norm": 11.125,
      "learning_rate": 7.616754617414247e-05,
      "loss": 0.1465,
      "step": 3731
    },
    {
      "epoch": 4.92,
      "grad_norm": 20.375,
      "learning_rate": 7.614775725593667e-05,
      "loss": 0.1367,
      "step": 3732
    },
    {
      "epoch": 4.92,
      "grad_norm": 157.0,
      "learning_rate": 7.612796833773087e-05,
      "loss": 2.2344,
      "step": 3733
    },
    {
      "epoch": 4.93,
      "grad_norm": 49.75,
      "learning_rate": 7.610817941952506e-05,
      "loss": 0.4023,
      "step": 3734
    },
    {
      "epoch": 4.93,
      "grad_norm": 22.875,
      "learning_rate": 7.608839050131926e-05,
      "loss": 0.1865,
      "step": 3735
    },
    {
      "epoch": 4.93,
      "grad_norm": 258.0,
      "learning_rate": 7.606860158311345e-05,
      "loss": 3.375,
      "step": 3736
    },
    {
      "epoch": 4.93,
      "grad_norm": 134.0,
      "learning_rate": 7.604881266490765e-05,
      "loss": 2.1094,
      "step": 3737
    },
    {
      "epoch": 4.93,
      "grad_norm": 8.8125,
      "learning_rate": 7.602902374670184e-05,
      "loss": 0.0623,
      "step": 3738
    },
    {
      "epoch": 4.93,
      "grad_norm": 30.0,
      "learning_rate": 7.600923482849604e-05,
      "loss": 0.543,
      "step": 3739
    },
    {
      "epoch": 4.93,
      "grad_norm": 154.0,
      "learning_rate": 7.598944591029024e-05,
      "loss": 2.0156,
      "step": 3740
    },
    {
      "epoch": 4.94,
      "grad_norm": 211.0,
      "learning_rate": 7.596965699208444e-05,
      "loss": 4.0625,
      "step": 3741
    },
    {
      "epoch": 4.94,
      "grad_norm": 43.0,
      "learning_rate": 7.594986807387862e-05,
      "loss": 0.5469,
      "step": 3742
    },
    {
      "epoch": 4.94,
      "grad_norm": 21.5,
      "learning_rate": 7.593007915567282e-05,
      "loss": 0.7227,
      "step": 3743
    },
    {
      "epoch": 4.94,
      "grad_norm": 145.0,
      "learning_rate": 7.591029023746702e-05,
      "loss": 2.2188,
      "step": 3744
    },
    {
      "epoch": 4.94,
      "grad_norm": 176.0,
      "learning_rate": 7.58905013192612e-05,
      "loss": 3.3438,
      "step": 3745
    },
    {
      "epoch": 4.94,
      "grad_norm": 42.0,
      "learning_rate": 7.58707124010554e-05,
      "loss": 0.373,
      "step": 3746
    },
    {
      "epoch": 4.94,
      "grad_norm": 122.5,
      "learning_rate": 7.585092348284959e-05,
      "loss": 1.8359,
      "step": 3747
    },
    {
      "epoch": 4.94,
      "grad_norm": 97.0,
      "learning_rate": 7.583113456464378e-05,
      "loss": 1.2812,
      "step": 3748
    },
    {
      "epoch": 4.95,
      "grad_norm": 55.0,
      "learning_rate": 7.581134564643798e-05,
      "loss": 0.8711,
      "step": 3749
    },
    {
      "epoch": 4.95,
      "grad_norm": 87.5,
      "learning_rate": 7.579155672823218e-05,
      "loss": 1.7031,
      "step": 3750
    },
    {
      "epoch": 4.95,
      "grad_norm": 20.5,
      "learning_rate": 7.577176781002638e-05,
      "loss": 0.2373,
      "step": 3751
    },
    {
      "epoch": 4.95,
      "grad_norm": 21.875,
      "learning_rate": 7.575197889182058e-05,
      "loss": 0.2793,
      "step": 3752
    },
    {
      "epoch": 4.95,
      "grad_norm": 18.375,
      "learning_rate": 7.573218997361476e-05,
      "loss": 0.4199,
      "step": 3753
    },
    {
      "epoch": 4.95,
      "grad_norm": 25.25,
      "learning_rate": 7.571240105540896e-05,
      "loss": 0.4551,
      "step": 3754
    },
    {
      "epoch": 4.95,
      "grad_norm": 18.25,
      "learning_rate": 7.569261213720316e-05,
      "loss": 0.6016,
      "step": 3755
    },
    {
      "epoch": 4.96,
      "grad_norm": 38.0,
      "learning_rate": 7.567282321899735e-05,
      "loss": 0.4023,
      "step": 3756
    },
    {
      "epoch": 4.96,
      "grad_norm": 43.25,
      "learning_rate": 7.565303430079155e-05,
      "loss": 0.4844,
      "step": 3757
    },
    {
      "epoch": 4.96,
      "grad_norm": 7.5625,
      "learning_rate": 7.563324538258575e-05,
      "loss": 0.1377,
      "step": 3758
    },
    {
      "epoch": 4.96,
      "grad_norm": 108.0,
      "learning_rate": 7.561345646437993e-05,
      "loss": 2.2188,
      "step": 3759
    },
    {
      "epoch": 4.96,
      "grad_norm": 17.125,
      "learning_rate": 7.559366754617413e-05,
      "loss": 0.2812,
      "step": 3760
    },
    {
      "epoch": 4.96,
      "grad_norm": 103.5,
      "learning_rate": 7.557387862796833e-05,
      "loss": 1.9609,
      "step": 3761
    },
    {
      "epoch": 4.96,
      "grad_norm": 22.0,
      "learning_rate": 7.555408970976253e-05,
      "loss": 0.3496,
      "step": 3762
    },
    {
      "epoch": 4.96,
      "grad_norm": 125.0,
      "learning_rate": 7.553430079155673e-05,
      "loss": 1.8203,
      "step": 3763
    },
    {
      "epoch": 4.97,
      "grad_norm": 128.0,
      "learning_rate": 7.551451187335093e-05,
      "loss": 1.8359,
      "step": 3764
    },
    {
      "epoch": 4.97,
      "grad_norm": 15.9375,
      "learning_rate": 7.549472295514511e-05,
      "loss": 0.5391,
      "step": 3765
    },
    {
      "epoch": 4.97,
      "grad_norm": 9.625,
      "learning_rate": 7.547493403693931e-05,
      "loss": 0.4199,
      "step": 3766
    },
    {
      "epoch": 4.97,
      "grad_norm": 18.75,
      "learning_rate": 7.54551451187335e-05,
      "loss": 0.1328,
      "step": 3767
    },
    {
      "epoch": 4.97,
      "grad_norm": 30.125,
      "learning_rate": 7.54353562005277e-05,
      "loss": 0.6758,
      "step": 3768
    },
    {
      "epoch": 4.97,
      "grad_norm": 123.0,
      "learning_rate": 7.54155672823219e-05,
      "loss": 1.7266,
      "step": 3769
    },
    {
      "epoch": 4.97,
      "grad_norm": 13.5625,
      "learning_rate": 7.53957783641161e-05,
      "loss": 0.106,
      "step": 3770
    },
    {
      "epoch": 4.97,
      "grad_norm": 6.34375,
      "learning_rate": 7.537598944591028e-05,
      "loss": 0.1367,
      "step": 3771
    },
    {
      "epoch": 4.98,
      "grad_norm": 214.0,
      "learning_rate": 7.535620052770448e-05,
      "loss": 4.9688,
      "step": 3772
    },
    {
      "epoch": 4.98,
      "grad_norm": 213.0,
      "learning_rate": 7.533641160949868e-05,
      "loss": 8.0625,
      "step": 3773
    },
    {
      "epoch": 4.98,
      "grad_norm": 436.0,
      "learning_rate": 7.531662269129288e-05,
      "loss": 10.4375,
      "step": 3774
    },
    {
      "epoch": 4.98,
      "grad_norm": 5.84375,
      "learning_rate": 7.529683377308705e-05,
      "loss": 0.0635,
      "step": 3775
    },
    {
      "epoch": 4.98,
      "grad_norm": 13.75,
      "learning_rate": 7.527704485488125e-05,
      "loss": 0.1216,
      "step": 3776
    },
    {
      "epoch": 4.98,
      "grad_norm": 157.0,
      "learning_rate": 7.525725593667545e-05,
      "loss": 5.8438,
      "step": 3777
    },
    {
      "epoch": 4.98,
      "grad_norm": 183.0,
      "learning_rate": 7.523746701846964e-05,
      "loss": 4.375,
      "step": 3778
    },
    {
      "epoch": 4.99,
      "grad_norm": 31.875,
      "learning_rate": 7.521767810026384e-05,
      "loss": 0.4102,
      "step": 3779
    },
    {
      "epoch": 4.99,
      "grad_norm": 213.0,
      "learning_rate": 7.519788918205804e-05,
      "loss": 4.4688,
      "step": 3780
    },
    {
      "epoch": 4.99,
      "grad_norm": 124.5,
      "learning_rate": 7.517810026385222e-05,
      "loss": 2.2969,
      "step": 3781
    },
    {
      "epoch": 4.99,
      "grad_norm": 178.0,
      "learning_rate": 7.515831134564642e-05,
      "loss": 3.3594,
      "step": 3782
    },
    {
      "epoch": 4.99,
      "grad_norm": 15.5625,
      "learning_rate": 7.513852242744062e-05,
      "loss": 0.3535,
      "step": 3783
    },
    {
      "epoch": 4.99,
      "grad_norm": 15.0625,
      "learning_rate": 7.511873350923482e-05,
      "loss": 0.1011,
      "step": 3784
    },
    {
      "epoch": 4.99,
      "grad_norm": 24.375,
      "learning_rate": 7.509894459102902e-05,
      "loss": 0.1445,
      "step": 3785
    },
    {
      "epoch": 4.99,
      "grad_norm": 110.5,
      "learning_rate": 7.507915567282321e-05,
      "loss": 1.8594,
      "step": 3786
    },
    {
      "epoch": 5.0,
      "grad_norm": 16.125,
      "learning_rate": 7.50593667546174e-05,
      "loss": 0.1514,
      "step": 3787
    },
    {
      "epoch": 5.0,
      "grad_norm": 13.1875,
      "learning_rate": 7.50395778364116e-05,
      "loss": 0.0884,
      "step": 3788
    },
    {
      "epoch": 5.0,
      "grad_norm": 26.75,
      "learning_rate": 7.50197889182058e-05,
      "loss": 0.4805,
      "step": 3789
    },
    {
      "epoch": 5.0,
      "grad_norm": 19.875,
      "learning_rate": 7.5e-05,
      "loss": 0.1211,
      "step": 3790
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.532875895500183,
      "eval_runtime": 18.2892,
      "eval_samples_per_second": 42.757,
      "eval_steps_per_second": 10.717,
      "step": 3790
    },
    {
      "epoch": 5.0,
      "grad_norm": 53.75,
      "learning_rate": 7.498021108179419e-05,
      "loss": 0.6719,
      "step": 3791
    },
    {
      "epoch": 5.0,
      "grad_norm": 141.0,
      "learning_rate": 7.496042216358839e-05,
      "loss": 2.1719,
      "step": 3792
    },
    {
      "epoch": 5.0,
      "grad_norm": 13.125,
      "learning_rate": 7.494063324538259e-05,
      "loss": 0.3008,
      "step": 3793
    },
    {
      "epoch": 5.01,
      "grad_norm": 13.125,
      "learning_rate": 7.492084432717677e-05,
      "loss": 0.1973,
      "step": 3794
    },
    {
      "epoch": 5.01,
      "grad_norm": 30.75,
      "learning_rate": 7.490105540897097e-05,
      "loss": 0.4531,
      "step": 3795
    },
    {
      "epoch": 5.01,
      "grad_norm": 110.5,
      "learning_rate": 7.488126649076517e-05,
      "loss": 1.8438,
      "step": 3796
    },
    {
      "epoch": 5.01,
      "grad_norm": 120.5,
      "learning_rate": 7.486147757255937e-05,
      "loss": 2.1875,
      "step": 3797
    },
    {
      "epoch": 5.01,
      "grad_norm": 12.25,
      "learning_rate": 7.484168865435355e-05,
      "loss": 0.1455,
      "step": 3798
    },
    {
      "epoch": 5.01,
      "grad_norm": 12.0625,
      "learning_rate": 7.482189973614775e-05,
      "loss": 0.2676,
      "step": 3799
    },
    {
      "epoch": 5.01,
      "grad_norm": 38.75,
      "learning_rate": 7.480211081794195e-05,
      "loss": 0.5195,
      "step": 3800
    },
    {
      "epoch": 5.01,
      "grad_norm": 147.0,
      "learning_rate": 7.478232189973614e-05,
      "loss": 2.2031,
      "step": 3801
    },
    {
      "epoch": 5.02,
      "grad_norm": 29.25,
      "learning_rate": 7.476253298153033e-05,
      "loss": 0.4219,
      "step": 3802
    },
    {
      "epoch": 5.02,
      "grad_norm": 13.3125,
      "learning_rate": 7.474274406332453e-05,
      "loss": 0.1299,
      "step": 3803
    },
    {
      "epoch": 5.02,
      "grad_norm": 157.0,
      "learning_rate": 7.472295514511873e-05,
      "loss": 3.6406,
      "step": 3804
    },
    {
      "epoch": 5.02,
      "grad_norm": 9.3125,
      "learning_rate": 7.470316622691292e-05,
      "loss": 0.0718,
      "step": 3805
    },
    {
      "epoch": 5.02,
      "grad_norm": 10.875,
      "learning_rate": 7.468337730870712e-05,
      "loss": 0.6992,
      "step": 3806
    },
    {
      "epoch": 5.02,
      "grad_norm": 29.75,
      "learning_rate": 7.466358839050132e-05,
      "loss": 0.6953,
      "step": 3807
    },
    {
      "epoch": 5.02,
      "grad_norm": 40.0,
      "learning_rate": 7.46437994722955e-05,
      "loss": 0.3301,
      "step": 3808
    },
    {
      "epoch": 5.03,
      "grad_norm": 111.0,
      "learning_rate": 7.46240105540897e-05,
      "loss": 2.2344,
      "step": 3809
    },
    {
      "epoch": 5.03,
      "grad_norm": 220.0,
      "learning_rate": 7.46042216358839e-05,
      "loss": 4.375,
      "step": 3810
    },
    {
      "epoch": 5.03,
      "grad_norm": 131.0,
      "learning_rate": 7.45844327176781e-05,
      "loss": 3.25,
      "step": 3811
    },
    {
      "epoch": 5.03,
      "grad_norm": 24.25,
      "learning_rate": 7.45646437994723e-05,
      "loss": 0.334,
      "step": 3812
    },
    {
      "epoch": 5.03,
      "grad_norm": 53.0,
      "learning_rate": 7.454485488126648e-05,
      "loss": 0.7656,
      "step": 3813
    },
    {
      "epoch": 5.03,
      "grad_norm": 24.25,
      "learning_rate": 7.452506596306068e-05,
      "loss": 0.1846,
      "step": 3814
    },
    {
      "epoch": 5.03,
      "grad_norm": 34.25,
      "learning_rate": 7.450527704485488e-05,
      "loss": 0.3926,
      "step": 3815
    },
    {
      "epoch": 5.03,
      "grad_norm": 346.0,
      "learning_rate": 7.448548812664906e-05,
      "loss": 7.2188,
      "step": 3816
    },
    {
      "epoch": 5.04,
      "grad_norm": 26.75,
      "learning_rate": 7.446569920844326e-05,
      "loss": 0.2559,
      "step": 3817
    },
    {
      "epoch": 5.04,
      "grad_norm": 8.25,
      "learning_rate": 7.444591029023746e-05,
      "loss": 0.1309,
      "step": 3818
    },
    {
      "epoch": 5.04,
      "grad_norm": 25.0,
      "learning_rate": 7.442612137203166e-05,
      "loss": 0.2402,
      "step": 3819
    },
    {
      "epoch": 5.04,
      "grad_norm": 19.25,
      "learning_rate": 7.440633245382585e-05,
      "loss": 0.1719,
      "step": 3820
    },
    {
      "epoch": 5.04,
      "grad_norm": 13.8125,
      "learning_rate": 7.438654353562005e-05,
      "loss": 0.1758,
      "step": 3821
    },
    {
      "epoch": 5.04,
      "grad_norm": 28.875,
      "learning_rate": 7.436675461741424e-05,
      "loss": 0.208,
      "step": 3822
    },
    {
      "epoch": 5.04,
      "grad_norm": 10.3125,
      "learning_rate": 7.434696569920843e-05,
      "loss": 0.1348,
      "step": 3823
    },
    {
      "epoch": 5.04,
      "grad_norm": 17.75,
      "learning_rate": 7.432717678100263e-05,
      "loss": 0.4805,
      "step": 3824
    },
    {
      "epoch": 5.05,
      "grad_norm": 18.375,
      "learning_rate": 7.430738786279683e-05,
      "loss": 0.1455,
      "step": 3825
    },
    {
      "epoch": 5.05,
      "grad_norm": 17.25,
      "learning_rate": 7.428759894459103e-05,
      "loss": 0.2295,
      "step": 3826
    },
    {
      "epoch": 5.05,
      "grad_norm": 19.0,
      "learning_rate": 7.426781002638523e-05,
      "loss": 0.1406,
      "step": 3827
    },
    {
      "epoch": 5.05,
      "grad_norm": 28.875,
      "learning_rate": 7.424802110817941e-05,
      "loss": 0.2109,
      "step": 3828
    },
    {
      "epoch": 5.05,
      "grad_norm": 15.0,
      "learning_rate": 7.422823218997361e-05,
      "loss": 0.1035,
      "step": 3829
    },
    {
      "epoch": 5.05,
      "grad_norm": 5.9375,
      "learning_rate": 7.420844327176781e-05,
      "loss": 0.0386,
      "step": 3830
    },
    {
      "epoch": 5.05,
      "grad_norm": 222.0,
      "learning_rate": 7.418865435356199e-05,
      "loss": 5.8125,
      "step": 3831
    },
    {
      "epoch": 5.06,
      "grad_norm": 318.0,
      "learning_rate": 7.416886543535619e-05,
      "loss": 8.5625,
      "step": 3832
    },
    {
      "epoch": 5.06,
      "grad_norm": 246.0,
      "learning_rate": 7.414907651715039e-05,
      "loss": 8.0625,
      "step": 3833
    },
    {
      "epoch": 5.06,
      "grad_norm": 34.0,
      "learning_rate": 7.412928759894459e-05,
      "loss": 0.1855,
      "step": 3834
    },
    {
      "epoch": 5.06,
      "grad_norm": 13.25,
      "learning_rate": 7.410949868073878e-05,
      "loss": 0.125,
      "step": 3835
    },
    {
      "epoch": 5.06,
      "grad_norm": 3.171875,
      "learning_rate": 7.408970976253298e-05,
      "loss": 0.019,
      "step": 3836
    },
    {
      "epoch": 5.06,
      "grad_norm": 332.0,
      "learning_rate": 7.406992084432717e-05,
      "loss": 7.9375,
      "step": 3837
    },
    {
      "epoch": 5.06,
      "grad_norm": 498.0,
      "learning_rate": 7.405013192612136e-05,
      "loss": 13.3125,
      "step": 3838
    },
    {
      "epoch": 5.06,
      "grad_norm": 288.0,
      "learning_rate": 7.403034300791556e-05,
      "loss": 5.6875,
      "step": 3839
    },
    {
      "epoch": 5.07,
      "grad_norm": 150.0,
      "learning_rate": 7.401055408970976e-05,
      "loss": 2.9062,
      "step": 3840
    },
    {
      "epoch": 5.07,
      "grad_norm": 228.0,
      "learning_rate": 7.399076517150396e-05,
      "loss": 4.7812,
      "step": 3841
    },
    {
      "epoch": 5.07,
      "grad_norm": 153.0,
      "learning_rate": 7.397097625329816e-05,
      "loss": 2.9219,
      "step": 3842
    },
    {
      "epoch": 5.07,
      "grad_norm": 239.0,
      "learning_rate": 7.395118733509234e-05,
      "loss": 5.625,
      "step": 3843
    },
    {
      "epoch": 5.07,
      "grad_norm": 53.0,
      "learning_rate": 7.393139841688654e-05,
      "loss": 0.1572,
      "step": 3844
    },
    {
      "epoch": 5.07,
      "grad_norm": 3.453125,
      "learning_rate": 7.391160949868072e-05,
      "loss": 0.0381,
      "step": 3845
    },
    {
      "epoch": 5.07,
      "grad_norm": 20.5,
      "learning_rate": 7.389182058047492e-05,
      "loss": 0.5195,
      "step": 3846
    },
    {
      "epoch": 5.08,
      "grad_norm": 10.375,
      "learning_rate": 7.387203166226912e-05,
      "loss": 0.0615,
      "step": 3847
    },
    {
      "epoch": 5.08,
      "grad_norm": 199.0,
      "learning_rate": 7.385224274406332e-05,
      "loss": 3.375,
      "step": 3848
    },
    {
      "epoch": 5.08,
      "grad_norm": 151.0,
      "learning_rate": 7.383245382585752e-05,
      "loss": 2.6562,
      "step": 3849
    },
    {
      "epoch": 5.08,
      "grad_norm": 398.0,
      "learning_rate": 7.381266490765171e-05,
      "loss": 5.875,
      "step": 3850
    },
    {
      "epoch": 5.08,
      "grad_norm": 50.75,
      "learning_rate": 7.37928759894459e-05,
      "loss": 0.1904,
      "step": 3851
    },
    {
      "epoch": 5.08,
      "grad_norm": 32.25,
      "learning_rate": 7.37730870712401e-05,
      "loss": 0.75,
      "step": 3852
    },
    {
      "epoch": 5.08,
      "grad_norm": 288.0,
      "learning_rate": 7.37532981530343e-05,
      "loss": 4.875,
      "step": 3853
    },
    {
      "epoch": 5.08,
      "grad_norm": 9.6875,
      "learning_rate": 7.373350923482849e-05,
      "loss": 0.0854,
      "step": 3854
    },
    {
      "epoch": 5.09,
      "grad_norm": 29.625,
      "learning_rate": 7.371372031662269e-05,
      "loss": 1.1719,
      "step": 3855
    },
    {
      "epoch": 5.09,
      "grad_norm": 360.0,
      "learning_rate": 7.369393139841689e-05,
      "loss": 5.6562,
      "step": 3856
    },
    {
      "epoch": 5.09,
      "grad_norm": 34.25,
      "learning_rate": 7.367414248021107e-05,
      "loss": 0.6484,
      "step": 3857
    },
    {
      "epoch": 5.09,
      "grad_norm": 318.0,
      "learning_rate": 7.365435356200527e-05,
      "loss": 5.0312,
      "step": 3858
    },
    {
      "epoch": 5.09,
      "grad_norm": 55.5,
      "learning_rate": 7.363456464379946e-05,
      "loss": 0.8242,
      "step": 3859
    },
    {
      "epoch": 5.09,
      "grad_norm": 318.0,
      "learning_rate": 7.361477572559365e-05,
      "loss": 3.25,
      "step": 3860
    },
    {
      "epoch": 5.09,
      "grad_norm": 37.0,
      "learning_rate": 7.359498680738785e-05,
      "loss": 0.3184,
      "step": 3861
    },
    {
      "epoch": 5.09,
      "grad_norm": 288.0,
      "learning_rate": 7.357519788918205e-05,
      "loss": 4.2812,
      "step": 3862
    },
    {
      "epoch": 5.1,
      "grad_norm": 27.0,
      "learning_rate": 7.355540897097625e-05,
      "loss": 0.167,
      "step": 3863
    },
    {
      "epoch": 5.1,
      "grad_norm": 294.0,
      "learning_rate": 7.353562005277045e-05,
      "loss": 4.0,
      "step": 3864
    },
    {
      "epoch": 5.1,
      "grad_norm": 26.375,
      "learning_rate": 7.351583113456463e-05,
      "loss": 0.5938,
      "step": 3865
    },
    {
      "epoch": 5.1,
      "grad_norm": 43.25,
      "learning_rate": 7.349604221635883e-05,
      "loss": 0.5312,
      "step": 3866
    },
    {
      "epoch": 5.1,
      "grad_norm": 48.75,
      "learning_rate": 7.347625329815303e-05,
      "loss": 0.3516,
      "step": 3867
    },
    {
      "epoch": 5.1,
      "grad_norm": 34.75,
      "learning_rate": 7.345646437994723e-05,
      "loss": 0.2285,
      "step": 3868
    },
    {
      "epoch": 5.1,
      "grad_norm": 118.5,
      "learning_rate": 7.343667546174142e-05,
      "loss": 1.4531,
      "step": 3869
    },
    {
      "epoch": 5.11,
      "grad_norm": 115.5,
      "learning_rate": 7.341688654353562e-05,
      "loss": 1.8203,
      "step": 3870
    },
    {
      "epoch": 5.11,
      "grad_norm": 33.5,
      "learning_rate": 7.33970976253298e-05,
      "loss": 0.2363,
      "step": 3871
    },
    {
      "epoch": 5.11,
      "grad_norm": 111.5,
      "learning_rate": 7.3377308707124e-05,
      "loss": 1.3281,
      "step": 3872
    },
    {
      "epoch": 5.11,
      "grad_norm": 20.75,
      "learning_rate": 7.33575197889182e-05,
      "loss": 0.4316,
      "step": 3873
    },
    {
      "epoch": 5.11,
      "grad_norm": 34.5,
      "learning_rate": 7.333773087071239e-05,
      "loss": 0.4238,
      "step": 3874
    },
    {
      "epoch": 5.11,
      "grad_norm": 24.0,
      "learning_rate": 7.331794195250658e-05,
      "loss": 0.4355,
      "step": 3875
    },
    {
      "epoch": 5.11,
      "grad_norm": 107.5,
      "learning_rate": 7.329815303430078e-05,
      "loss": 1.8828,
      "step": 3876
    },
    {
      "epoch": 5.11,
      "grad_norm": 38.75,
      "learning_rate": 7.327836411609498e-05,
      "loss": 0.2197,
      "step": 3877
    },
    {
      "epoch": 5.12,
      "grad_norm": 125.0,
      "learning_rate": 7.325857519788918e-05,
      "loss": 1.5156,
      "step": 3878
    },
    {
      "epoch": 5.12,
      "grad_norm": 120.0,
      "learning_rate": 7.323878627968338e-05,
      "loss": 1.4609,
      "step": 3879
    },
    {
      "epoch": 5.12,
      "grad_norm": 22.25,
      "learning_rate": 7.321899736147756e-05,
      "loss": 0.3984,
      "step": 3880
    },
    {
      "epoch": 5.12,
      "grad_norm": 20.375,
      "learning_rate": 7.319920844327176e-05,
      "loss": 0.4883,
      "step": 3881
    },
    {
      "epoch": 5.12,
      "grad_norm": 54.5,
      "learning_rate": 7.317941952506596e-05,
      "loss": 0.5078,
      "step": 3882
    },
    {
      "epoch": 5.12,
      "grad_norm": 35.5,
      "learning_rate": 7.315963060686016e-05,
      "loss": 0.3594,
      "step": 3883
    },
    {
      "epoch": 5.12,
      "grad_norm": 36.0,
      "learning_rate": 7.313984168865435e-05,
      "loss": 0.3086,
      "step": 3884
    },
    {
      "epoch": 5.13,
      "grad_norm": 198.0,
      "learning_rate": 7.312005277044855e-05,
      "loss": 3.4375,
      "step": 3885
    },
    {
      "epoch": 5.13,
      "grad_norm": 15.375,
      "learning_rate": 7.310026385224274e-05,
      "loss": 0.4863,
      "step": 3886
    },
    {
      "epoch": 5.13,
      "grad_norm": 114.0,
      "learning_rate": 7.308047493403693e-05,
      "loss": 1.9766,
      "step": 3887
    },
    {
      "epoch": 5.13,
      "grad_norm": 40.5,
      "learning_rate": 7.306068601583112e-05,
      "loss": 0.4004,
      "step": 3888
    },
    {
      "epoch": 5.13,
      "grad_norm": 123.5,
      "learning_rate": 7.304089709762532e-05,
      "loss": 2.125,
      "step": 3889
    },
    {
      "epoch": 5.13,
      "grad_norm": 117.0,
      "learning_rate": 7.302110817941951e-05,
      "loss": 1.6406,
      "step": 3890
    },
    {
      "epoch": 5.13,
      "grad_norm": 111.5,
      "learning_rate": 7.300131926121371e-05,
      "loss": 1.7031,
      "step": 3891
    },
    {
      "epoch": 5.13,
      "grad_norm": 276.0,
      "learning_rate": 7.298153034300791e-05,
      "loss": 4.875,
      "step": 3892
    },
    {
      "epoch": 5.14,
      "grad_norm": 20.0,
      "learning_rate": 7.296174142480211e-05,
      "loss": 0.1602,
      "step": 3893
    },
    {
      "epoch": 5.14,
      "grad_norm": 21.75,
      "learning_rate": 7.29419525065963e-05,
      "loss": 0.4707,
      "step": 3894
    },
    {
      "epoch": 5.14,
      "grad_norm": 104.0,
      "learning_rate": 7.292216358839049e-05,
      "loss": 1.5703,
      "step": 3895
    },
    {
      "epoch": 5.14,
      "grad_norm": 7.75,
      "learning_rate": 7.290237467018469e-05,
      "loss": 0.2148,
      "step": 3896
    },
    {
      "epoch": 5.14,
      "grad_norm": 102.0,
      "learning_rate": 7.288258575197889e-05,
      "loss": 1.7422,
      "step": 3897
    },
    {
      "epoch": 5.14,
      "grad_norm": 26.5,
      "learning_rate": 7.286279683377309e-05,
      "loss": 0.3594,
      "step": 3898
    },
    {
      "epoch": 5.14,
      "grad_norm": 50.5,
      "learning_rate": 7.284300791556728e-05,
      "loss": 0.4023,
      "step": 3899
    },
    {
      "epoch": 5.15,
      "grad_norm": 101.0,
      "learning_rate": 7.282321899736147e-05,
      "loss": 1.3828,
      "step": 3900
    },
    {
      "epoch": 5.15,
      "grad_norm": 23.5,
      "learning_rate": 7.280343007915567e-05,
      "loss": 0.1885,
      "step": 3901
    },
    {
      "epoch": 5.15,
      "grad_norm": 183.0,
      "learning_rate": 7.278364116094986e-05,
      "loss": 3.6406,
      "step": 3902
    },
    {
      "epoch": 5.15,
      "grad_norm": 42.75,
      "learning_rate": 7.276385224274405e-05,
      "loss": 0.5312,
      "step": 3903
    },
    {
      "epoch": 5.15,
      "grad_norm": 41.75,
      "learning_rate": 7.274406332453825e-05,
      "loss": 0.3555,
      "step": 3904
    },
    {
      "epoch": 5.15,
      "grad_norm": 31.5,
      "learning_rate": 7.272427440633245e-05,
      "loss": 0.2988,
      "step": 3905
    },
    {
      "epoch": 5.15,
      "grad_norm": 20.75,
      "learning_rate": 7.270448548812664e-05,
      "loss": 0.3203,
      "step": 3906
    },
    {
      "epoch": 5.15,
      "grad_norm": 30.625,
      "learning_rate": 7.268469656992084e-05,
      "loss": 0.3477,
      "step": 3907
    },
    {
      "epoch": 5.16,
      "grad_norm": 24.875,
      "learning_rate": 7.266490765171503e-05,
      "loss": 0.2305,
      "step": 3908
    },
    {
      "epoch": 5.16,
      "grad_norm": 207.0,
      "learning_rate": 7.264511873350922e-05,
      "loss": 3.2969,
      "step": 3909
    },
    {
      "epoch": 5.16,
      "grad_norm": 21.25,
      "learning_rate": 7.262532981530342e-05,
      "loss": 0.2578,
      "step": 3910
    },
    {
      "epoch": 5.16,
      "grad_norm": 162.0,
      "learning_rate": 7.260554089709762e-05,
      "loss": 5.8438,
      "step": 3911
    },
    {
      "epoch": 5.16,
      "grad_norm": 26.125,
      "learning_rate": 7.258575197889182e-05,
      "loss": 0.1924,
      "step": 3912
    },
    {
      "epoch": 5.16,
      "grad_norm": 104.5,
      "learning_rate": 7.256596306068602e-05,
      "loss": 1.4922,
      "step": 3913
    },
    {
      "epoch": 5.16,
      "grad_norm": 258.0,
      "learning_rate": 7.25461741424802e-05,
      "loss": 5.1562,
      "step": 3914
    },
    {
      "epoch": 5.16,
      "grad_norm": 198.0,
      "learning_rate": 7.25263852242744e-05,
      "loss": 4.1875,
      "step": 3915
    },
    {
      "epoch": 5.17,
      "grad_norm": 30.875,
      "learning_rate": 7.25065963060686e-05,
      "loss": 0.2656,
      "step": 3916
    },
    {
      "epoch": 5.17,
      "grad_norm": 97.5,
      "learning_rate": 7.24868073878628e-05,
      "loss": 1.4375,
      "step": 3917
    },
    {
      "epoch": 5.17,
      "grad_norm": 193.0,
      "learning_rate": 7.246701846965698e-05,
      "loss": 3.7812,
      "step": 3918
    },
    {
      "epoch": 5.17,
      "grad_norm": 18.25,
      "learning_rate": 7.244722955145118e-05,
      "loss": 0.165,
      "step": 3919
    },
    {
      "epoch": 5.17,
      "grad_norm": 48.5,
      "learning_rate": 7.242744063324538e-05,
      "loss": 0.6953,
      "step": 3920
    },
    {
      "epoch": 5.17,
      "grad_norm": 34.0,
      "learning_rate": 7.240765171503957e-05,
      "loss": 0.332,
      "step": 3921
    },
    {
      "epoch": 5.17,
      "grad_norm": 204.0,
      "learning_rate": 7.238786279683377e-05,
      "loss": 3.7656,
      "step": 3922
    },
    {
      "epoch": 5.18,
      "grad_norm": 42.25,
      "learning_rate": 7.236807387862796e-05,
      "loss": 0.3574,
      "step": 3923
    },
    {
      "epoch": 5.18,
      "grad_norm": 95.0,
      "learning_rate": 7.234828496042215e-05,
      "loss": 1.4453,
      "step": 3924
    },
    {
      "epoch": 5.18,
      "grad_norm": 116.5,
      "learning_rate": 7.232849604221635e-05,
      "loss": 1.4062,
      "step": 3925
    },
    {
      "epoch": 5.18,
      "grad_norm": 94.0,
      "learning_rate": 7.230870712401055e-05,
      "loss": 1.7812,
      "step": 3926
    },
    {
      "epoch": 5.18,
      "grad_norm": 173.0,
      "learning_rate": 7.228891820580475e-05,
      "loss": 3.2031,
      "step": 3927
    },
    {
      "epoch": 5.18,
      "grad_norm": 17.0,
      "learning_rate": 7.226912928759895e-05,
      "loss": 0.1621,
      "step": 3928
    },
    {
      "epoch": 5.18,
      "grad_norm": 24.75,
      "learning_rate": 7.224934036939313e-05,
      "loss": 0.4062,
      "step": 3929
    },
    {
      "epoch": 5.18,
      "grad_norm": 95.5,
      "learning_rate": 7.222955145118733e-05,
      "loss": 1.2812,
      "step": 3930
    },
    {
      "epoch": 5.19,
      "grad_norm": 13.1875,
      "learning_rate": 7.220976253298153e-05,
      "loss": 0.1377,
      "step": 3931
    },
    {
      "epoch": 5.19,
      "grad_norm": 118.5,
      "learning_rate": 7.218997361477572e-05,
      "loss": 1.8984,
      "step": 3932
    },
    {
      "epoch": 5.19,
      "grad_norm": 98.0,
      "learning_rate": 7.217018469656991e-05,
      "loss": 1.1328,
      "step": 3933
    },
    {
      "epoch": 5.19,
      "grad_norm": 25.5,
      "learning_rate": 7.215039577836411e-05,
      "loss": 0.1904,
      "step": 3934
    },
    {
      "epoch": 5.19,
      "grad_norm": 27.0,
      "learning_rate": 7.21306068601583e-05,
      "loss": 0.2432,
      "step": 3935
    },
    {
      "epoch": 5.19,
      "grad_norm": 105.0,
      "learning_rate": 7.21108179419525e-05,
      "loss": 1.5234,
      "step": 3936
    },
    {
      "epoch": 5.19,
      "grad_norm": 39.75,
      "learning_rate": 7.209102902374669e-05,
      "loss": 0.2969,
      "step": 3937
    },
    {
      "epoch": 5.2,
      "grad_norm": 8.125,
      "learning_rate": 7.207124010554089e-05,
      "loss": 0.0588,
      "step": 3938
    },
    {
      "epoch": 5.2,
      "grad_norm": 11.8125,
      "learning_rate": 7.205145118733508e-05,
      "loss": 0.0889,
      "step": 3939
    },
    {
      "epoch": 5.2,
      "grad_norm": 27.75,
      "learning_rate": 7.203166226912928e-05,
      "loss": 0.5977,
      "step": 3940
    },
    {
      "epoch": 5.2,
      "grad_norm": 108.5,
      "learning_rate": 7.201187335092348e-05,
      "loss": 1.2188,
      "step": 3941
    },
    {
      "epoch": 5.2,
      "grad_norm": 22.5,
      "learning_rate": 7.199208443271768e-05,
      "loss": 0.3574,
      "step": 3942
    },
    {
      "epoch": 5.2,
      "grad_norm": 178.0,
      "learning_rate": 7.197229551451186e-05,
      "loss": 3.6406,
      "step": 3943
    },
    {
      "epoch": 5.2,
      "grad_norm": 95.5,
      "learning_rate": 7.195250659630606e-05,
      "loss": 1.6875,
      "step": 3944
    },
    {
      "epoch": 5.2,
      "grad_norm": 205.0,
      "learning_rate": 7.193271767810026e-05,
      "loss": 2.8125,
      "step": 3945
    },
    {
      "epoch": 5.21,
      "grad_norm": 21.375,
      "learning_rate": 7.191292875989446e-05,
      "loss": 0.8711,
      "step": 3946
    },
    {
      "epoch": 5.21,
      "grad_norm": 202.0,
      "learning_rate": 7.189313984168866e-05,
      "loss": 4.6875,
      "step": 3947
    },
    {
      "epoch": 5.21,
      "grad_norm": 25.375,
      "learning_rate": 7.187335092348284e-05,
      "loss": 0.2266,
      "step": 3948
    },
    {
      "epoch": 5.21,
      "grad_norm": 189.0,
      "learning_rate": 7.185356200527704e-05,
      "loss": 3.2812,
      "step": 3949
    },
    {
      "epoch": 5.21,
      "grad_norm": 298.0,
      "learning_rate": 7.183377308707124e-05,
      "loss": 8.0,
      "step": 3950
    },
    {
      "epoch": 5.21,
      "grad_norm": 23.875,
      "learning_rate": 7.181398416886542e-05,
      "loss": 0.2041,
      "step": 3951
    },
    {
      "epoch": 5.21,
      "grad_norm": 22.5,
      "learning_rate": 7.179419525065962e-05,
      "loss": 0.1914,
      "step": 3952
    },
    {
      "epoch": 5.22,
      "grad_norm": 19.875,
      "learning_rate": 7.177440633245382e-05,
      "loss": 0.1484,
      "step": 3953
    },
    {
      "epoch": 5.22,
      "grad_norm": 231.0,
      "learning_rate": 7.175461741424801e-05,
      "loss": 2.7969,
      "step": 3954
    },
    {
      "epoch": 5.22,
      "grad_norm": 92.0,
      "learning_rate": 7.173482849604221e-05,
      "loss": 1.2734,
      "step": 3955
    },
    {
      "epoch": 5.22,
      "grad_norm": 19.125,
      "learning_rate": 7.171503957783641e-05,
      "loss": 0.1562,
      "step": 3956
    },
    {
      "epoch": 5.22,
      "grad_norm": 153.0,
      "learning_rate": 7.16952506596306e-05,
      "loss": 3.3906,
      "step": 3957
    },
    {
      "epoch": 5.22,
      "grad_norm": 29.0,
      "learning_rate": 7.167546174142479e-05,
      "loss": 0.6562,
      "step": 3958
    },
    {
      "epoch": 5.22,
      "grad_norm": 109.0,
      "learning_rate": 7.165567282321899e-05,
      "loss": 1.5625,
      "step": 3959
    },
    {
      "epoch": 5.22,
      "grad_norm": 233.0,
      "learning_rate": 7.163588390501319e-05,
      "loss": 3.3594,
      "step": 3960
    },
    {
      "epoch": 5.23,
      "grad_norm": 214.0,
      "learning_rate": 7.161609498680739e-05,
      "loss": 4.2188,
      "step": 3961
    },
    {
      "epoch": 5.23,
      "grad_norm": 249.0,
      "learning_rate": 7.159630606860159e-05,
      "loss": 4.8438,
      "step": 3962
    },
    {
      "epoch": 5.23,
      "grad_norm": 96.0,
      "learning_rate": 7.157651715039577e-05,
      "loss": 1.5234,
      "step": 3963
    },
    {
      "epoch": 5.23,
      "grad_norm": 157.0,
      "learning_rate": 7.155672823218997e-05,
      "loss": 2.6562,
      "step": 3964
    },
    {
      "epoch": 5.23,
      "grad_norm": 9.1875,
      "learning_rate": 7.153693931398417e-05,
      "loss": 0.1025,
      "step": 3965
    },
    {
      "epoch": 5.23,
      "grad_norm": 190.0,
      "learning_rate": 7.151715039577835e-05,
      "loss": 3.2188,
      "step": 3966
    },
    {
      "epoch": 5.23,
      "grad_norm": 72.5,
      "learning_rate": 7.149736147757255e-05,
      "loss": 1.1328,
      "step": 3967
    },
    {
      "epoch": 5.23,
      "grad_norm": 174.0,
      "learning_rate": 7.147757255936675e-05,
      "loss": 2.9219,
      "step": 3968
    },
    {
      "epoch": 5.24,
      "grad_norm": 213.0,
      "learning_rate": 7.145778364116094e-05,
      "loss": 4.1562,
      "step": 3969
    },
    {
      "epoch": 5.24,
      "grad_norm": 27.125,
      "learning_rate": 7.143799472295514e-05,
      "loss": 0.8594,
      "step": 3970
    },
    {
      "epoch": 5.24,
      "grad_norm": 68.5,
      "learning_rate": 7.141820580474934e-05,
      "loss": 1.0156,
      "step": 3971
    },
    {
      "epoch": 5.24,
      "grad_norm": 30.0,
      "learning_rate": 7.139841688654353e-05,
      "loss": 0.4766,
      "step": 3972
    },
    {
      "epoch": 5.24,
      "grad_norm": 42.5,
      "learning_rate": 7.137862796833772e-05,
      "loss": 0.4219,
      "step": 3973
    },
    {
      "epoch": 5.24,
      "grad_norm": 91.5,
      "learning_rate": 7.135883905013192e-05,
      "loss": 1.6484,
      "step": 3974
    },
    {
      "epoch": 5.24,
      "grad_norm": 59.5,
      "learning_rate": 7.133905013192612e-05,
      "loss": 0.6406,
      "step": 3975
    },
    {
      "epoch": 5.25,
      "grad_norm": 194.0,
      "learning_rate": 7.131926121372032e-05,
      "loss": 3.0312,
      "step": 3976
    },
    {
      "epoch": 5.25,
      "grad_norm": 23.375,
      "learning_rate": 7.129947229551452e-05,
      "loss": 0.3281,
      "step": 3977
    },
    {
      "epoch": 5.25,
      "grad_norm": 41.0,
      "learning_rate": 7.12796833773087e-05,
      "loss": 0.6719,
      "step": 3978
    },
    {
      "epoch": 5.25,
      "grad_norm": 167.0,
      "learning_rate": 7.12598944591029e-05,
      "loss": 4.2188,
      "step": 3979
    },
    {
      "epoch": 5.25,
      "grad_norm": 135.0,
      "learning_rate": 7.124010554089708e-05,
      "loss": 3.7812,
      "step": 3980
    },
    {
      "epoch": 5.25,
      "grad_norm": 30.25,
      "learning_rate": 7.122031662269128e-05,
      "loss": 0.3965,
      "step": 3981
    },
    {
      "epoch": 5.25,
      "grad_norm": 35.75,
      "learning_rate": 7.120052770448548e-05,
      "loss": 0.498,
      "step": 3982
    },
    {
      "epoch": 5.25,
      "grad_norm": 14.625,
      "learning_rate": 7.118073878627968e-05,
      "loss": 0.1865,
      "step": 3983
    },
    {
      "epoch": 5.26,
      "grad_norm": 27.375,
      "learning_rate": 7.116094986807387e-05,
      "loss": 0.6172,
      "step": 3984
    },
    {
      "epoch": 5.26,
      "grad_norm": 29.125,
      "learning_rate": 7.114116094986807e-05,
      "loss": 0.5547,
      "step": 3985
    },
    {
      "epoch": 5.26,
      "grad_norm": 26.875,
      "learning_rate": 7.112137203166226e-05,
      "loss": 0.334,
      "step": 3986
    },
    {
      "epoch": 5.26,
      "grad_norm": 97.0,
      "learning_rate": 7.110158311345646e-05,
      "loss": 1.3672,
      "step": 3987
    },
    {
      "epoch": 5.26,
      "grad_norm": 29.625,
      "learning_rate": 7.108179419525065e-05,
      "loss": 0.2715,
      "step": 3988
    },
    {
      "epoch": 5.26,
      "grad_norm": 22.25,
      "learning_rate": 7.106200527704485e-05,
      "loss": 0.3535,
      "step": 3989
    },
    {
      "epoch": 5.26,
      "grad_norm": 88.0,
      "learning_rate": 7.104221635883905e-05,
      "loss": 1.4688,
      "step": 3990
    },
    {
      "epoch": 5.27,
      "grad_norm": 17.875,
      "learning_rate": 7.102242744063325e-05,
      "loss": 0.1631,
      "step": 3991
    },
    {
      "epoch": 5.27,
      "grad_norm": 25.0,
      "learning_rate": 7.100263852242743e-05,
      "loss": 0.5586,
      "step": 3992
    },
    {
      "epoch": 5.27,
      "grad_norm": 11.625,
      "learning_rate": 7.098284960422163e-05,
      "loss": 0.2148,
      "step": 3993
    },
    {
      "epoch": 5.27,
      "grad_norm": 15.75,
      "learning_rate": 7.096306068601581e-05,
      "loss": 0.3223,
      "step": 3994
    },
    {
      "epoch": 5.27,
      "grad_norm": 27.375,
      "learning_rate": 7.094327176781001e-05,
      "loss": 0.2539,
      "step": 3995
    },
    {
      "epoch": 5.27,
      "grad_norm": 20.75,
      "learning_rate": 7.092348284960421e-05,
      "loss": 0.3184,
      "step": 3996
    },
    {
      "epoch": 5.27,
      "grad_norm": 166.0,
      "learning_rate": 7.090369393139841e-05,
      "loss": 3.7188,
      "step": 3997
    },
    {
      "epoch": 5.27,
      "grad_norm": 110.5,
      "learning_rate": 7.088390501319261e-05,
      "loss": 2.5938,
      "step": 3998
    },
    {
      "epoch": 5.28,
      "grad_norm": 61.5,
      "learning_rate": 7.08641160949868e-05,
      "loss": 0.9844,
      "step": 3999
    },
    {
      "epoch": 5.28,
      "grad_norm": 108.5,
      "learning_rate": 7.084432717678099e-05,
      "loss": 2.2969,
      "step": 4000
    },
    {
      "epoch": 5.28,
      "grad_norm": 16.0,
      "learning_rate": 7.082453825857519e-05,
      "loss": 0.7227,
      "step": 4001
    },
    {
      "epoch": 5.28,
      "grad_norm": 127.0,
      "learning_rate": 7.080474934036939e-05,
      "loss": 2.4688,
      "step": 4002
    },
    {
      "epoch": 5.28,
      "grad_norm": 195.0,
      "learning_rate": 7.078496042216358e-05,
      "loss": 4.6875,
      "step": 4003
    },
    {
      "epoch": 5.28,
      "grad_norm": 34.75,
      "learning_rate": 7.076517150395778e-05,
      "loss": 0.5742,
      "step": 4004
    },
    {
      "epoch": 5.28,
      "grad_norm": 160.0,
      "learning_rate": 7.074538258575198e-05,
      "loss": 4.0312,
      "step": 4005
    },
    {
      "epoch": 5.28,
      "grad_norm": 9.125,
      "learning_rate": 7.072559366754616e-05,
      "loss": 0.0908,
      "step": 4006
    },
    {
      "epoch": 5.29,
      "grad_norm": 10.0,
      "learning_rate": 7.070580474934036e-05,
      "loss": 0.1504,
      "step": 4007
    },
    {
      "epoch": 5.29,
      "grad_norm": 176.0,
      "learning_rate": 7.068601583113456e-05,
      "loss": 3.9844,
      "step": 4008
    },
    {
      "epoch": 5.29,
      "grad_norm": 41.5,
      "learning_rate": 7.066622691292875e-05,
      "loss": 0.5938,
      "step": 4009
    },
    {
      "epoch": 5.29,
      "grad_norm": 15.3125,
      "learning_rate": 7.064643799472294e-05,
      "loss": 0.2988,
      "step": 4010
    },
    {
      "epoch": 5.29,
      "grad_norm": 310.0,
      "learning_rate": 7.062664907651714e-05,
      "loss": 5.5625,
      "step": 4011
    },
    {
      "epoch": 5.29,
      "grad_norm": 20.625,
      "learning_rate": 7.060686015831134e-05,
      "loss": 0.2461,
      "step": 4012
    },
    {
      "epoch": 5.29,
      "grad_norm": 30.875,
      "learning_rate": 7.058707124010554e-05,
      "loss": 0.3047,
      "step": 4013
    },
    {
      "epoch": 5.3,
      "grad_norm": 12.1875,
      "learning_rate": 7.056728232189974e-05,
      "loss": 0.2949,
      "step": 4014
    },
    {
      "epoch": 5.3,
      "grad_norm": 11.5,
      "learning_rate": 7.054749340369392e-05,
      "loss": 0.2412,
      "step": 4015
    },
    {
      "epoch": 5.3,
      "grad_norm": 11.0,
      "learning_rate": 7.052770448548812e-05,
      "loss": 0.1211,
      "step": 4016
    },
    {
      "epoch": 5.3,
      "grad_norm": 153.0,
      "learning_rate": 7.050791556728232e-05,
      "loss": 3.7344,
      "step": 4017
    },
    {
      "epoch": 5.3,
      "grad_norm": 4.90625,
      "learning_rate": 7.048812664907651e-05,
      "loss": 0.082,
      "step": 4018
    },
    {
      "epoch": 5.3,
      "grad_norm": 113.0,
      "learning_rate": 7.046833773087071e-05,
      "loss": 2.125,
      "step": 4019
    },
    {
      "epoch": 5.3,
      "grad_norm": 31.75,
      "learning_rate": 7.044854881266491e-05,
      "loss": 0.4316,
      "step": 4020
    },
    {
      "epoch": 5.3,
      "grad_norm": 197.0,
      "learning_rate": 7.04287598944591e-05,
      "loss": 3.9844,
      "step": 4021
    },
    {
      "epoch": 5.31,
      "grad_norm": 169.0,
      "learning_rate": 7.040897097625329e-05,
      "loss": 6.0312,
      "step": 4022
    },
    {
      "epoch": 5.31,
      "grad_norm": 5.1875,
      "learning_rate": 7.038918205804749e-05,
      "loss": 0.0723,
      "step": 4023
    },
    {
      "epoch": 5.31,
      "grad_norm": 96.5,
      "learning_rate": 7.036939313984168e-05,
      "loss": 2.0156,
      "step": 4024
    },
    {
      "epoch": 5.31,
      "grad_norm": 217.0,
      "learning_rate": 7.034960422163587e-05,
      "loss": 4.8438,
      "step": 4025
    },
    {
      "epoch": 5.31,
      "grad_norm": 27.375,
      "learning_rate": 7.032981530343007e-05,
      "loss": 0.1982,
      "step": 4026
    },
    {
      "epoch": 5.31,
      "grad_norm": 10.875,
      "learning_rate": 7.031002638522427e-05,
      "loss": 0.3105,
      "step": 4027
    },
    {
      "epoch": 5.31,
      "grad_norm": 340.0,
      "learning_rate": 7.029023746701847e-05,
      "loss": 6.4062,
      "step": 4028
    },
    {
      "epoch": 5.32,
      "grad_norm": 145.0,
      "learning_rate": 7.027044854881265e-05,
      "loss": 2.7812,
      "step": 4029
    },
    {
      "epoch": 5.32,
      "grad_norm": 13.4375,
      "learning_rate": 7.025065963060685e-05,
      "loss": 0.4629,
      "step": 4030
    },
    {
      "epoch": 5.32,
      "grad_norm": 233.0,
      "learning_rate": 7.023087071240105e-05,
      "loss": 5.0625,
      "step": 4031
    },
    {
      "epoch": 5.32,
      "grad_norm": 152.0,
      "learning_rate": 7.021108179419525e-05,
      "loss": 2.6094,
      "step": 4032
    },
    {
      "epoch": 5.32,
      "grad_norm": 92.5,
      "learning_rate": 7.019129287598944e-05,
      "loss": 1.5156,
      "step": 4033
    },
    {
      "epoch": 5.32,
      "grad_norm": 23.0,
      "learning_rate": 7.017150395778364e-05,
      "loss": 0.2441,
      "step": 4034
    },
    {
      "epoch": 5.32,
      "grad_norm": 130.0,
      "learning_rate": 7.015171503957783e-05,
      "loss": 2.0312,
      "step": 4035
    },
    {
      "epoch": 5.32,
      "grad_norm": 156.0,
      "learning_rate": 7.013192612137202e-05,
      "loss": 2.6094,
      "step": 4036
    },
    {
      "epoch": 5.33,
      "grad_norm": 112.5,
      "learning_rate": 7.011213720316622e-05,
      "loss": 2.0781,
      "step": 4037
    },
    {
      "epoch": 5.33,
      "grad_norm": 53.0,
      "learning_rate": 7.009234828496042e-05,
      "loss": 0.875,
      "step": 4038
    },
    {
      "epoch": 5.33,
      "grad_norm": 116.0,
      "learning_rate": 7.00725593667546e-05,
      "loss": 2.3281,
      "step": 4039
    },
    {
      "epoch": 5.33,
      "grad_norm": 131.0,
      "learning_rate": 7.00527704485488e-05,
      "loss": 2.0938,
      "step": 4040
    },
    {
      "epoch": 5.33,
      "grad_norm": 32.0,
      "learning_rate": 7.0032981530343e-05,
      "loss": 0.3535,
      "step": 4041
    },
    {
      "epoch": 5.33,
      "grad_norm": 34.5,
      "learning_rate": 7.00131926121372e-05,
      "loss": 0.8047,
      "step": 4042
    },
    {
      "epoch": 5.33,
      "grad_norm": 33.75,
      "learning_rate": 6.999340369393138e-05,
      "loss": 0.7578,
      "step": 4043
    },
    {
      "epoch": 5.34,
      "grad_norm": 95.0,
      "learning_rate": 6.997361477572558e-05,
      "loss": 1.6641,
      "step": 4044
    },
    {
      "epoch": 5.34,
      "grad_norm": 22.125,
      "learning_rate": 6.995382585751978e-05,
      "loss": 0.3262,
      "step": 4045
    },
    {
      "epoch": 5.34,
      "grad_norm": 32.5,
      "learning_rate": 6.993403693931398e-05,
      "loss": 0.334,
      "step": 4046
    },
    {
      "epoch": 5.34,
      "grad_norm": 26.875,
      "learning_rate": 6.991424802110818e-05,
      "loss": 0.3066,
      "step": 4047
    },
    {
      "epoch": 5.34,
      "grad_norm": 21.0,
      "learning_rate": 6.989445910290237e-05,
      "loss": 0.291,
      "step": 4048
    },
    {
      "epoch": 5.34,
      "grad_norm": 174.0,
      "learning_rate": 6.987467018469656e-05,
      "loss": 4.5625,
      "step": 4049
    },
    {
      "epoch": 5.34,
      "grad_norm": 92.0,
      "learning_rate": 6.985488126649076e-05,
      "loss": 1.7109,
      "step": 4050
    },
    {
      "epoch": 5.34,
      "grad_norm": 41.75,
      "learning_rate": 6.983509234828496e-05,
      "loss": 0.5703,
      "step": 4051
    },
    {
      "epoch": 5.35,
      "grad_norm": 32.5,
      "learning_rate": 6.981530343007915e-05,
      "loss": 0.3516,
      "step": 4052
    },
    {
      "epoch": 5.35,
      "grad_norm": 93.5,
      "learning_rate": 6.979551451187335e-05,
      "loss": 1.4453,
      "step": 4053
    },
    {
      "epoch": 5.35,
      "grad_norm": 22.25,
      "learning_rate": 6.977572559366754e-05,
      "loss": 0.3984,
      "step": 4054
    },
    {
      "epoch": 5.35,
      "grad_norm": 202.0,
      "learning_rate": 6.975593667546173e-05,
      "loss": 3.6562,
      "step": 4055
    },
    {
      "epoch": 5.35,
      "grad_norm": 20.75,
      "learning_rate": 6.973614775725593e-05,
      "loss": 0.1719,
      "step": 4056
    },
    {
      "epoch": 5.35,
      "grad_norm": 169.0,
      "learning_rate": 6.971635883905013e-05,
      "loss": 2.6875,
      "step": 4057
    },
    {
      "epoch": 5.35,
      "grad_norm": 30.875,
      "learning_rate": 6.969656992084431e-05,
      "loss": 0.2188,
      "step": 4058
    },
    {
      "epoch": 5.35,
      "grad_norm": 23.25,
      "learning_rate": 6.967678100263851e-05,
      "loss": 0.2334,
      "step": 4059
    },
    {
      "epoch": 5.36,
      "grad_norm": 29.875,
      "learning_rate": 6.965699208443271e-05,
      "loss": 0.2637,
      "step": 4060
    },
    {
      "epoch": 5.36,
      "grad_norm": 11.125,
      "learning_rate": 6.963720316622691e-05,
      "loss": 0.0796,
      "step": 4061
    },
    {
      "epoch": 5.36,
      "grad_norm": 51.5,
      "learning_rate": 6.96174142480211e-05,
      "loss": 0.4805,
      "step": 4062
    },
    {
      "epoch": 5.36,
      "grad_norm": 211.0,
      "learning_rate": 6.95976253298153e-05,
      "loss": 2.6094,
      "step": 4063
    },
    {
      "epoch": 5.36,
      "grad_norm": 190.0,
      "learning_rate": 6.957783641160949e-05,
      "loss": 3.25,
      "step": 4064
    },
    {
      "epoch": 5.36,
      "grad_norm": 19.875,
      "learning_rate": 6.955804749340369e-05,
      "loss": 0.2002,
      "step": 4065
    },
    {
      "epoch": 5.36,
      "grad_norm": 205.0,
      "learning_rate": 6.953825857519789e-05,
      "loss": 4.0938,
      "step": 4066
    },
    {
      "epoch": 5.37,
      "grad_norm": 168.0,
      "learning_rate": 6.951846965699208e-05,
      "loss": 4.0938,
      "step": 4067
    },
    {
      "epoch": 5.37,
      "grad_norm": 10.8125,
      "learning_rate": 6.949868073878628e-05,
      "loss": 0.106,
      "step": 4068
    },
    {
      "epoch": 5.37,
      "grad_norm": 10.875,
      "learning_rate": 6.947889182058047e-05,
      "loss": 0.0967,
      "step": 4069
    },
    {
      "epoch": 5.37,
      "grad_norm": 13.0625,
      "learning_rate": 6.945910290237466e-05,
      "loss": 0.1104,
      "step": 4070
    },
    {
      "epoch": 5.37,
      "grad_norm": 101.0,
      "learning_rate": 6.943931398416886e-05,
      "loss": 2.2344,
      "step": 4071
    },
    {
      "epoch": 5.37,
      "grad_norm": 129.0,
      "learning_rate": 6.941952506596305e-05,
      "loss": 1.8203,
      "step": 4072
    },
    {
      "epoch": 5.37,
      "grad_norm": 17.25,
      "learning_rate": 6.939973614775724e-05,
      "loss": 0.3867,
      "step": 4073
    },
    {
      "epoch": 5.37,
      "grad_norm": 7.15625,
      "learning_rate": 6.937994722955144e-05,
      "loss": 0.0776,
      "step": 4074
    },
    {
      "epoch": 5.38,
      "grad_norm": 146.0,
      "learning_rate": 6.936015831134564e-05,
      "loss": 2.8438,
      "step": 4075
    },
    {
      "epoch": 5.38,
      "grad_norm": 99.0,
      "learning_rate": 6.934036939313984e-05,
      "loss": 1.6641,
      "step": 4076
    },
    {
      "epoch": 5.38,
      "grad_norm": 22.375,
      "learning_rate": 6.932058047493404e-05,
      "loss": 0.7266,
      "step": 4077
    },
    {
      "epoch": 5.38,
      "grad_norm": 123.0,
      "learning_rate": 6.930079155672822e-05,
      "loss": 2.6719,
      "step": 4078
    },
    {
      "epoch": 5.38,
      "grad_norm": 109.0,
      "learning_rate": 6.928100263852242e-05,
      "loss": 1.6172,
      "step": 4079
    },
    {
      "epoch": 5.38,
      "grad_norm": 123.0,
      "learning_rate": 6.926121372031662e-05,
      "loss": 5.25,
      "step": 4080
    },
    {
      "epoch": 5.38,
      "grad_norm": 17.5,
      "learning_rate": 6.924142480211082e-05,
      "loss": 0.2314,
      "step": 4081
    },
    {
      "epoch": 5.39,
      "grad_norm": 175.0,
      "learning_rate": 6.922163588390501e-05,
      "loss": 3.3594,
      "step": 4082
    },
    {
      "epoch": 5.39,
      "grad_norm": 234.0,
      "learning_rate": 6.920184696569921e-05,
      "loss": 3.5,
      "step": 4083
    },
    {
      "epoch": 5.39,
      "grad_norm": 9.5625,
      "learning_rate": 6.91820580474934e-05,
      "loss": 0.0684,
      "step": 4084
    },
    {
      "epoch": 5.39,
      "grad_norm": 49.75,
      "learning_rate": 6.91622691292876e-05,
      "loss": 0.4902,
      "step": 4085
    },
    {
      "epoch": 5.39,
      "grad_norm": 27.25,
      "learning_rate": 6.914248021108178e-05,
      "loss": 1.2422,
      "step": 4086
    },
    {
      "epoch": 5.39,
      "grad_norm": 14.875,
      "learning_rate": 6.912269129287598e-05,
      "loss": 0.2344,
      "step": 4087
    },
    {
      "epoch": 5.39,
      "grad_norm": 5.8125,
      "learning_rate": 6.910290237467017e-05,
      "loss": 0.0703,
      "step": 4088
    },
    {
      "epoch": 5.39,
      "grad_norm": 24.75,
      "learning_rate": 6.908311345646437e-05,
      "loss": 0.5898,
      "step": 4089
    },
    {
      "epoch": 5.4,
      "grad_norm": 155.0,
      "learning_rate": 6.906332453825857e-05,
      "loss": 3.2812,
      "step": 4090
    },
    {
      "epoch": 5.4,
      "grad_norm": 11.125,
      "learning_rate": 6.904353562005277e-05,
      "loss": 0.5273,
      "step": 4091
    },
    {
      "epoch": 5.4,
      "grad_norm": 27.75,
      "learning_rate": 6.902374670184695e-05,
      "loss": 0.4961,
      "step": 4092
    },
    {
      "epoch": 5.4,
      "grad_norm": 23.75,
      "learning_rate": 6.900395778364115e-05,
      "loss": 0.4355,
      "step": 4093
    },
    {
      "epoch": 5.4,
      "grad_norm": 19.25,
      "learning_rate": 6.898416886543535e-05,
      "loss": 0.1523,
      "step": 4094
    },
    {
      "epoch": 5.4,
      "grad_norm": 106.5,
      "learning_rate": 6.896437994722955e-05,
      "loss": 1.8594,
      "step": 4095
    },
    {
      "epoch": 5.4,
      "grad_norm": 9.0,
      "learning_rate": 6.894459102902375e-05,
      "loss": 0.1055,
      "step": 4096
    },
    {
      "epoch": 5.41,
      "grad_norm": 114.5,
      "learning_rate": 6.892480211081794e-05,
      "loss": 2.0156,
      "step": 4097
    },
    {
      "epoch": 5.41,
      "grad_norm": 121.5,
      "learning_rate": 6.890501319261214e-05,
      "loss": 2.375,
      "step": 4098
    },
    {
      "epoch": 5.41,
      "grad_norm": 20.375,
      "learning_rate": 6.888522427440633e-05,
      "loss": 0.2432,
      "step": 4099
    },
    {
      "epoch": 5.41,
      "grad_norm": 23.0,
      "learning_rate": 6.886543535620052e-05,
      "loss": 0.3047,
      "step": 4100
    },
    {
      "epoch": 5.41,
      "grad_norm": 144.0,
      "learning_rate": 6.884564643799471e-05,
      "loss": 3.9688,
      "step": 4101
    },
    {
      "epoch": 5.41,
      "grad_norm": 6.0625,
      "learning_rate": 6.882585751978891e-05,
      "loss": 0.0908,
      "step": 4102
    },
    {
      "epoch": 5.41,
      "grad_norm": 58.0,
      "learning_rate": 6.88060686015831e-05,
      "loss": 0.9062,
      "step": 4103
    },
    {
      "epoch": 5.41,
      "grad_norm": 232.0,
      "learning_rate": 6.87862796833773e-05,
      "loss": 5.0625,
      "step": 4104
    },
    {
      "epoch": 5.42,
      "grad_norm": 16.875,
      "learning_rate": 6.87664907651715e-05,
      "loss": 0.2969,
      "step": 4105
    },
    {
      "epoch": 5.42,
      "grad_norm": 8.25,
      "learning_rate": 6.87467018469657e-05,
      "loss": 0.1216,
      "step": 4106
    },
    {
      "epoch": 5.42,
      "grad_norm": 12.75,
      "learning_rate": 6.872691292875988e-05,
      "loss": 0.1348,
      "step": 4107
    },
    {
      "epoch": 5.42,
      "grad_norm": 8.9375,
      "learning_rate": 6.870712401055408e-05,
      "loss": 0.2197,
      "step": 4108
    },
    {
      "epoch": 5.42,
      "grad_norm": 36.5,
      "learning_rate": 6.868733509234828e-05,
      "loss": 0.2285,
      "step": 4109
    },
    {
      "epoch": 5.42,
      "grad_norm": 8.5,
      "learning_rate": 6.866754617414248e-05,
      "loss": 0.2285,
      "step": 4110
    },
    {
      "epoch": 5.42,
      "grad_norm": 14.625,
      "learning_rate": 6.864775725593668e-05,
      "loss": 0.1553,
      "step": 4111
    },
    {
      "epoch": 5.42,
      "grad_norm": 178.0,
      "learning_rate": 6.862796833773087e-05,
      "loss": 4.0,
      "step": 4112
    },
    {
      "epoch": 5.43,
      "grad_norm": 22.625,
      "learning_rate": 6.860817941952506e-05,
      "loss": 0.1157,
      "step": 4113
    },
    {
      "epoch": 5.43,
      "grad_norm": 160.0,
      "learning_rate": 6.858839050131926e-05,
      "loss": 4.2188,
      "step": 4114
    },
    {
      "epoch": 5.43,
      "grad_norm": 56.0,
      "learning_rate": 6.856860158311344e-05,
      "loss": 0.918,
      "step": 4115
    },
    {
      "epoch": 5.43,
      "grad_norm": 31.625,
      "learning_rate": 6.854881266490764e-05,
      "loss": 0.3594,
      "step": 4116
    },
    {
      "epoch": 5.43,
      "grad_norm": 28.5,
      "learning_rate": 6.852902374670184e-05,
      "loss": 0.248,
      "step": 4117
    },
    {
      "epoch": 5.43,
      "grad_norm": 14.0,
      "learning_rate": 6.850923482849604e-05,
      "loss": 0.1816,
      "step": 4118
    },
    {
      "epoch": 5.43,
      "grad_norm": 112.0,
      "learning_rate": 6.848944591029023e-05,
      "loss": 2.5469,
      "step": 4119
    },
    {
      "epoch": 5.44,
      "grad_norm": 11.3125,
      "learning_rate": 6.846965699208443e-05,
      "loss": 0.0835,
      "step": 4120
    },
    {
      "epoch": 5.44,
      "grad_norm": 109.0,
      "learning_rate": 6.844986807387862e-05,
      "loss": 2.3594,
      "step": 4121
    },
    {
      "epoch": 5.44,
      "grad_norm": 106.5,
      "learning_rate": 6.843007915567281e-05,
      "loss": 2.1875,
      "step": 4122
    },
    {
      "epoch": 5.44,
      "grad_norm": 219.0,
      "learning_rate": 6.841029023746701e-05,
      "loss": 4.3438,
      "step": 4123
    },
    {
      "epoch": 5.44,
      "grad_norm": 37.75,
      "learning_rate": 6.839050131926121e-05,
      "loss": 0.5781,
      "step": 4124
    },
    {
      "epoch": 5.44,
      "grad_norm": 171.0,
      "learning_rate": 6.837071240105541e-05,
      "loss": 3.4531,
      "step": 4125
    },
    {
      "epoch": 5.44,
      "grad_norm": 123.5,
      "learning_rate": 6.83509234828496e-05,
      "loss": 1.9219,
      "step": 4126
    },
    {
      "epoch": 5.44,
      "grad_norm": 104.5,
      "learning_rate": 6.833113456464379e-05,
      "loss": 1.9453,
      "step": 4127
    },
    {
      "epoch": 5.45,
      "grad_norm": 19.5,
      "learning_rate": 6.831134564643799e-05,
      "loss": 0.1206,
      "step": 4128
    },
    {
      "epoch": 5.45,
      "grad_norm": 152.0,
      "learning_rate": 6.829155672823219e-05,
      "loss": 2.5156,
      "step": 4129
    },
    {
      "epoch": 5.45,
      "grad_norm": 224.0,
      "learning_rate": 6.827176781002637e-05,
      "loss": 4.2812,
      "step": 4130
    },
    {
      "epoch": 5.45,
      "grad_norm": 34.0,
      "learning_rate": 6.825197889182057e-05,
      "loss": 0.5586,
      "step": 4131
    },
    {
      "epoch": 5.45,
      "grad_norm": 7.0625,
      "learning_rate": 6.823218997361477e-05,
      "loss": 0.0581,
      "step": 4132
    },
    {
      "epoch": 5.45,
      "grad_norm": 34.5,
      "learning_rate": 6.821240105540897e-05,
      "loss": 0.3379,
      "step": 4133
    },
    {
      "epoch": 5.45,
      "grad_norm": 10.1875,
      "learning_rate": 6.819261213720316e-05,
      "loss": 0.0762,
      "step": 4134
    },
    {
      "epoch": 5.46,
      "grad_norm": 10.0,
      "learning_rate": 6.817282321899736e-05,
      "loss": 0.1846,
      "step": 4135
    },
    {
      "epoch": 5.46,
      "grad_norm": 21.375,
      "learning_rate": 6.815303430079155e-05,
      "loss": 0.1992,
      "step": 4136
    },
    {
      "epoch": 5.46,
      "grad_norm": 118.5,
      "learning_rate": 6.813324538258574e-05,
      "loss": 1.7344,
      "step": 4137
    },
    {
      "epoch": 5.46,
      "grad_norm": 35.0,
      "learning_rate": 6.811345646437994e-05,
      "loss": 0.3574,
      "step": 4138
    },
    {
      "epoch": 5.46,
      "grad_norm": 10.6875,
      "learning_rate": 6.809366754617414e-05,
      "loss": 0.4023,
      "step": 4139
    },
    {
      "epoch": 5.46,
      "grad_norm": 120.0,
      "learning_rate": 6.807387862796834e-05,
      "loss": 1.8828,
      "step": 4140
    },
    {
      "epoch": 5.46,
      "grad_norm": 39.0,
      "learning_rate": 6.805408970976254e-05,
      "loss": 0.3398,
      "step": 4141
    },
    {
      "epoch": 5.46,
      "grad_norm": 16.125,
      "learning_rate": 6.803430079155672e-05,
      "loss": 0.1387,
      "step": 4142
    },
    {
      "epoch": 5.47,
      "grad_norm": 6.0,
      "learning_rate": 6.801451187335092e-05,
      "loss": 0.0498,
      "step": 4143
    },
    {
      "epoch": 5.47,
      "grad_norm": 14.1875,
      "learning_rate": 6.79947229551451e-05,
      "loss": 0.0972,
      "step": 4144
    },
    {
      "epoch": 5.47,
      "grad_norm": 38.5,
      "learning_rate": 6.79749340369393e-05,
      "loss": 1.2578,
      "step": 4145
    },
    {
      "epoch": 5.47,
      "grad_norm": 150.0,
      "learning_rate": 6.79551451187335e-05,
      "loss": 2.5,
      "step": 4146
    },
    {
      "epoch": 5.47,
      "grad_norm": 235.0,
      "learning_rate": 6.79353562005277e-05,
      "loss": 7.875,
      "step": 4147
    },
    {
      "epoch": 5.47,
      "grad_norm": 18.5,
      "learning_rate": 6.79155672823219e-05,
      "loss": 0.1475,
      "step": 4148
    },
    {
      "epoch": 5.47,
      "grad_norm": 200.0,
      "learning_rate": 6.78957783641161e-05,
      "loss": 3.8594,
      "step": 4149
    },
    {
      "epoch": 5.47,
      "grad_norm": 17.375,
      "learning_rate": 6.787598944591028e-05,
      "loss": 0.1001,
      "step": 4150
    },
    {
      "epoch": 5.48,
      "grad_norm": 141.0,
      "learning_rate": 6.785620052770448e-05,
      "loss": 2.2031,
      "step": 4151
    },
    {
      "epoch": 5.48,
      "grad_norm": 24.75,
      "learning_rate": 6.783641160949867e-05,
      "loss": 0.5977,
      "step": 4152
    },
    {
      "epoch": 5.48,
      "grad_norm": 5.03125,
      "learning_rate": 6.781662269129287e-05,
      "loss": 0.0593,
      "step": 4153
    },
    {
      "epoch": 5.48,
      "grad_norm": 124.0,
      "learning_rate": 6.779683377308707e-05,
      "loss": 2.875,
      "step": 4154
    },
    {
      "epoch": 5.48,
      "grad_norm": 24.75,
      "learning_rate": 6.777704485488127e-05,
      "loss": 0.7266,
      "step": 4155
    },
    {
      "epoch": 5.48,
      "grad_norm": 34.75,
      "learning_rate": 6.775725593667545e-05,
      "loss": 0.6289,
      "step": 4156
    },
    {
      "epoch": 5.48,
      "grad_norm": 13.8125,
      "learning_rate": 6.773746701846965e-05,
      "loss": 0.1172,
      "step": 4157
    },
    {
      "epoch": 5.49,
      "grad_norm": 159.0,
      "learning_rate": 6.771767810026385e-05,
      "loss": 3.5625,
      "step": 4158
    },
    {
      "epoch": 5.49,
      "grad_norm": 12.6875,
      "learning_rate": 6.769788918205803e-05,
      "loss": 0.1245,
      "step": 4159
    },
    {
      "epoch": 5.49,
      "grad_norm": 24.375,
      "learning_rate": 6.767810026385223e-05,
      "loss": 0.3984,
      "step": 4160
    },
    {
      "epoch": 5.49,
      "grad_norm": 18.125,
      "learning_rate": 6.765831134564643e-05,
      "loss": 0.2451,
      "step": 4161
    },
    {
      "epoch": 5.49,
      "grad_norm": 103.0,
      "learning_rate": 6.763852242744063e-05,
      "loss": 2.0312,
      "step": 4162
    },
    {
      "epoch": 5.49,
      "grad_norm": 113.5,
      "learning_rate": 6.761873350923483e-05,
      "loss": 1.875,
      "step": 4163
    },
    {
      "epoch": 5.49,
      "grad_norm": 16.25,
      "learning_rate": 6.759894459102901e-05,
      "loss": 0.1157,
      "step": 4164
    },
    {
      "epoch": 5.49,
      "grad_norm": 123.5,
      "learning_rate": 6.757915567282321e-05,
      "loss": 2.1719,
      "step": 4165
    },
    {
      "epoch": 5.5,
      "grad_norm": 20.0,
      "learning_rate": 6.75593667546174e-05,
      "loss": 0.2256,
      "step": 4166
    },
    {
      "epoch": 5.5,
      "grad_norm": 121.0,
      "learning_rate": 6.75395778364116e-05,
      "loss": 2.2031,
      "step": 4167
    },
    {
      "epoch": 5.5,
      "grad_norm": 16.25,
      "learning_rate": 6.75197889182058e-05,
      "loss": 0.6445,
      "step": 4168
    },
    {
      "epoch": 5.5,
      "grad_norm": 12.75,
      "learning_rate": 6.75e-05,
      "loss": 0.1143,
      "step": 4169
    },
    {
      "epoch": 5.5,
      "grad_norm": 5.40625,
      "learning_rate": 6.748021108179419e-05,
      "loss": 0.0869,
      "step": 4170
    },
    {
      "epoch": 5.5,
      "grad_norm": 16.625,
      "learning_rate": 6.746042216358838e-05,
      "loss": 0.1631,
      "step": 4171
    },
    {
      "epoch": 5.5,
      "grad_norm": 103.0,
      "learning_rate": 6.744063324538258e-05,
      "loss": 1.8672,
      "step": 4172
    },
    {
      "epoch": 5.51,
      "grad_norm": 222.0,
      "learning_rate": 6.742084432717678e-05,
      "loss": 4.375,
      "step": 4173
    },
    {
      "epoch": 5.51,
      "grad_norm": 240.0,
      "learning_rate": 6.740105540897096e-05,
      "loss": 3.5469,
      "step": 4174
    },
    {
      "epoch": 5.51,
      "grad_norm": 112.0,
      "learning_rate": 6.738126649076516e-05,
      "loss": 1.6719,
      "step": 4175
    },
    {
      "epoch": 5.51,
      "grad_norm": 107.0,
      "learning_rate": 6.736147757255936e-05,
      "loss": 2.2188,
      "step": 4176
    },
    {
      "epoch": 5.51,
      "grad_norm": 28.0,
      "learning_rate": 6.734168865435356e-05,
      "loss": 0.4375,
      "step": 4177
    },
    {
      "epoch": 5.51,
      "grad_norm": 27.0,
      "learning_rate": 6.732189973614776e-05,
      "loss": 0.1992,
      "step": 4178
    },
    {
      "epoch": 5.51,
      "grad_norm": 103.0,
      "learning_rate": 6.730211081794194e-05,
      "loss": 1.8672,
      "step": 4179
    },
    {
      "epoch": 5.51,
      "grad_norm": 222.0,
      "learning_rate": 6.728232189973614e-05,
      "loss": 5.0,
      "step": 4180
    },
    {
      "epoch": 5.52,
      "grad_norm": 250.0,
      "learning_rate": 6.726253298153034e-05,
      "loss": 5.1562,
      "step": 4181
    },
    {
      "epoch": 5.52,
      "grad_norm": 24.5,
      "learning_rate": 6.724274406332453e-05,
      "loss": 0.5156,
      "step": 4182
    },
    {
      "epoch": 5.52,
      "grad_norm": 22.375,
      "learning_rate": 6.722295514511873e-05,
      "loss": 0.1738,
      "step": 4183
    },
    {
      "epoch": 5.52,
      "grad_norm": 176.0,
      "learning_rate": 6.720316622691293e-05,
      "loss": 3.9531,
      "step": 4184
    },
    {
      "epoch": 5.52,
      "grad_norm": 24.625,
      "learning_rate": 6.718337730870712e-05,
      "loss": 0.6055,
      "step": 4185
    },
    {
      "epoch": 5.52,
      "grad_norm": 188.0,
      "learning_rate": 6.716358839050131e-05,
      "loss": 2.25,
      "step": 4186
    },
    {
      "epoch": 5.52,
      "grad_norm": 18.0,
      "learning_rate": 6.714379947229551e-05,
      "loss": 0.2852,
      "step": 4187
    },
    {
      "epoch": 5.53,
      "grad_norm": 29.625,
      "learning_rate": 6.712401055408971e-05,
      "loss": 0.4102,
      "step": 4188
    },
    {
      "epoch": 5.53,
      "grad_norm": 167.0,
      "learning_rate": 6.71042216358839e-05,
      "loss": 3.5156,
      "step": 4189
    },
    {
      "epoch": 5.53,
      "grad_norm": 87.0,
      "learning_rate": 6.708443271767809e-05,
      "loss": 1.625,
      "step": 4190
    },
    {
      "epoch": 5.53,
      "grad_norm": 20.375,
      "learning_rate": 6.706464379947229e-05,
      "loss": 0.4473,
      "step": 4191
    },
    {
      "epoch": 5.53,
      "grad_norm": 155.0,
      "learning_rate": 6.704485488126649e-05,
      "loss": 3.4688,
      "step": 4192
    },
    {
      "epoch": 5.53,
      "grad_norm": 85.5,
      "learning_rate": 6.702506596306067e-05,
      "loss": 1.3828,
      "step": 4193
    },
    {
      "epoch": 5.53,
      "grad_norm": 169.0,
      "learning_rate": 6.700527704485487e-05,
      "loss": 3.2656,
      "step": 4194
    },
    {
      "epoch": 5.53,
      "grad_norm": 160.0,
      "learning_rate": 6.698548812664907e-05,
      "loss": 3.1719,
      "step": 4195
    },
    {
      "epoch": 5.54,
      "grad_norm": 156.0,
      "learning_rate": 6.696569920844327e-05,
      "loss": 2.9531,
      "step": 4196
    },
    {
      "epoch": 5.54,
      "grad_norm": 159.0,
      "learning_rate": 6.694591029023747e-05,
      "loss": 5.1562,
      "step": 4197
    },
    {
      "epoch": 5.54,
      "grad_norm": 26.0,
      "learning_rate": 6.692612137203166e-05,
      "loss": 0.293,
      "step": 4198
    },
    {
      "epoch": 5.54,
      "grad_norm": 35.75,
      "learning_rate": 6.690633245382585e-05,
      "loss": 0.8398,
      "step": 4199
    },
    {
      "epoch": 5.54,
      "grad_norm": 24.875,
      "learning_rate": 6.688654353562005e-05,
      "loss": 0.5586,
      "step": 4200
    },
    {
      "epoch": 5.54,
      "grad_norm": 31.75,
      "learning_rate": 6.686675461741424e-05,
      "loss": 0.3633,
      "step": 4201
    },
    {
      "epoch": 5.54,
      "grad_norm": 37.25,
      "learning_rate": 6.684696569920844e-05,
      "loss": 0.5,
      "step": 4202
    },
    {
      "epoch": 5.54,
      "grad_norm": 145.0,
      "learning_rate": 6.682717678100264e-05,
      "loss": 3.1562,
      "step": 4203
    },
    {
      "epoch": 5.55,
      "grad_norm": 196.0,
      "learning_rate": 6.680738786279682e-05,
      "loss": 2.4062,
      "step": 4204
    },
    {
      "epoch": 5.55,
      "grad_norm": 150.0,
      "learning_rate": 6.678759894459102e-05,
      "loss": 3.6719,
      "step": 4205
    },
    {
      "epoch": 5.55,
      "grad_norm": 134.0,
      "learning_rate": 6.676781002638522e-05,
      "loss": 2.1406,
      "step": 4206
    },
    {
      "epoch": 5.55,
      "grad_norm": 40.5,
      "learning_rate": 6.67480211081794e-05,
      "loss": 0.7773,
      "step": 4207
    },
    {
      "epoch": 5.55,
      "grad_norm": 89.0,
      "learning_rate": 6.67282321899736e-05,
      "loss": 1.6641,
      "step": 4208
    },
    {
      "epoch": 5.55,
      "grad_norm": 44.25,
      "learning_rate": 6.67084432717678e-05,
      "loss": 0.7109,
      "step": 4209
    },
    {
      "epoch": 5.55,
      "grad_norm": 90.5,
      "learning_rate": 6.6688654353562e-05,
      "loss": 1.7422,
      "step": 4210
    },
    {
      "epoch": 5.56,
      "grad_norm": 155.0,
      "learning_rate": 6.66688654353562e-05,
      "loss": 2.5469,
      "step": 4211
    },
    {
      "epoch": 5.56,
      "grad_norm": 95.0,
      "learning_rate": 6.66490765171504e-05,
      "loss": 1.7969,
      "step": 4212
    },
    {
      "epoch": 5.56,
      "grad_norm": 100.0,
      "learning_rate": 6.662928759894458e-05,
      "loss": 1.5703,
      "step": 4213
    },
    {
      "epoch": 5.56,
      "grad_norm": 124.0,
      "learning_rate": 6.660949868073878e-05,
      "loss": 1.7266,
      "step": 4214
    },
    {
      "epoch": 5.56,
      "grad_norm": 90.0,
      "learning_rate": 6.658970976253298e-05,
      "loss": 1.4844,
      "step": 4215
    },
    {
      "epoch": 5.56,
      "grad_norm": 88.0,
      "learning_rate": 6.656992084432717e-05,
      "loss": 1.4688,
      "step": 4216
    },
    {
      "epoch": 5.56,
      "grad_norm": 88.0,
      "learning_rate": 6.655013192612137e-05,
      "loss": 1.4453,
      "step": 4217
    },
    {
      "epoch": 5.56,
      "grad_norm": 33.0,
      "learning_rate": 6.653034300791557e-05,
      "loss": 0.4199,
      "step": 4218
    },
    {
      "epoch": 5.57,
      "grad_norm": 36.5,
      "learning_rate": 6.651055408970975e-05,
      "loss": 0.8008,
      "step": 4219
    },
    {
      "epoch": 5.57,
      "grad_norm": 154.0,
      "learning_rate": 6.649076517150395e-05,
      "loss": 3.3281,
      "step": 4220
    },
    {
      "epoch": 5.57,
      "grad_norm": 22.0,
      "learning_rate": 6.647097625329815e-05,
      "loss": 0.291,
      "step": 4221
    },
    {
      "epoch": 5.57,
      "grad_norm": 110.5,
      "learning_rate": 6.645118733509234e-05,
      "loss": 2.7656,
      "step": 4222
    },
    {
      "epoch": 5.57,
      "grad_norm": 29.125,
      "learning_rate": 6.643139841688653e-05,
      "loss": 0.3789,
      "step": 4223
    },
    {
      "epoch": 5.57,
      "grad_norm": 54.0,
      "learning_rate": 6.641160949868073e-05,
      "loss": 0.6055,
      "step": 4224
    },
    {
      "epoch": 5.57,
      "grad_norm": 78.5,
      "learning_rate": 6.639182058047493e-05,
      "loss": 1.0859,
      "step": 4225
    },
    {
      "epoch": 5.58,
      "grad_norm": 21.75,
      "learning_rate": 6.637203166226913e-05,
      "loss": 0.1504,
      "step": 4226
    },
    {
      "epoch": 5.58,
      "grad_norm": 62.0,
      "learning_rate": 6.635224274406333e-05,
      "loss": 0.9648,
      "step": 4227
    },
    {
      "epoch": 5.58,
      "grad_norm": 62.25,
      "learning_rate": 6.633245382585751e-05,
      "loss": 1.3359,
      "step": 4228
    },
    {
      "epoch": 5.58,
      "grad_norm": 54.75,
      "learning_rate": 6.631266490765171e-05,
      "loss": 1.3672,
      "step": 4229
    },
    {
      "epoch": 5.58,
      "grad_norm": 32.25,
      "learning_rate": 6.62928759894459e-05,
      "loss": 0.4062,
      "step": 4230
    },
    {
      "epoch": 5.58,
      "grad_norm": 157.0,
      "learning_rate": 6.62730870712401e-05,
      "loss": 3.0469,
      "step": 4231
    },
    {
      "epoch": 5.58,
      "grad_norm": 64.5,
      "learning_rate": 6.62532981530343e-05,
      "loss": 0.8711,
      "step": 4232
    },
    {
      "epoch": 5.58,
      "grad_norm": 131.0,
      "learning_rate": 6.62335092348285e-05,
      "loss": 2.8906,
      "step": 4233
    },
    {
      "epoch": 5.59,
      "grad_norm": 56.75,
      "learning_rate": 6.621372031662268e-05,
      "loss": 0.8281,
      "step": 4234
    },
    {
      "epoch": 5.59,
      "grad_norm": 47.5,
      "learning_rate": 6.619393139841688e-05,
      "loss": 0.9609,
      "step": 4235
    },
    {
      "epoch": 5.59,
      "grad_norm": 58.75,
      "learning_rate": 6.617414248021107e-05,
      "loss": 1.0156,
      "step": 4236
    },
    {
      "epoch": 5.59,
      "grad_norm": 47.25,
      "learning_rate": 6.615435356200527e-05,
      "loss": 0.6719,
      "step": 4237
    },
    {
      "epoch": 5.59,
      "grad_norm": 72.0,
      "learning_rate": 6.613456464379946e-05,
      "loss": 0.9766,
      "step": 4238
    },
    {
      "epoch": 5.59,
      "grad_norm": 31.0,
      "learning_rate": 6.611477572559366e-05,
      "loss": 1.2109,
      "step": 4239
    },
    {
      "epoch": 5.59,
      "grad_norm": 38.5,
      "learning_rate": 6.609498680738786e-05,
      "loss": 0.4453,
      "step": 4240
    },
    {
      "epoch": 5.59,
      "grad_norm": 49.0,
      "learning_rate": 6.607519788918206e-05,
      "loss": 0.4414,
      "step": 4241
    },
    {
      "epoch": 5.6,
      "grad_norm": 54.5,
      "learning_rate": 6.605540897097624e-05,
      "loss": 0.8789,
      "step": 4242
    },
    {
      "epoch": 5.6,
      "grad_norm": 47.5,
      "learning_rate": 6.603562005277044e-05,
      "loss": 0.3945,
      "step": 4243
    },
    {
      "epoch": 5.6,
      "grad_norm": 66.5,
      "learning_rate": 6.601583113456464e-05,
      "loss": 0.8672,
      "step": 4244
    },
    {
      "epoch": 5.6,
      "grad_norm": 204.0,
      "learning_rate": 6.599604221635884e-05,
      "loss": 3.3906,
      "step": 4245
    },
    {
      "epoch": 5.6,
      "grad_norm": 344.0,
      "learning_rate": 6.597625329815303e-05,
      "loss": 5.625,
      "step": 4246
    },
    {
      "epoch": 5.6,
      "grad_norm": 39.25,
      "learning_rate": 6.595646437994723e-05,
      "loss": 0.7695,
      "step": 4247
    },
    {
      "epoch": 5.6,
      "grad_norm": 32.5,
      "learning_rate": 6.593667546174142e-05,
      "loss": 0.3848,
      "step": 4248
    },
    {
      "epoch": 5.61,
      "grad_norm": 57.75,
      "learning_rate": 6.591688654353562e-05,
      "loss": 0.8125,
      "step": 4249
    },
    {
      "epoch": 5.61,
      "grad_norm": 171.0,
      "learning_rate": 6.58970976253298e-05,
      "loss": 3.6406,
      "step": 4250
    },
    {
      "epoch": 5.61,
      "grad_norm": 114.5,
      "learning_rate": 6.5877308707124e-05,
      "loss": 1.75,
      "step": 4251
    },
    {
      "epoch": 5.61,
      "grad_norm": 190.0,
      "learning_rate": 6.58575197889182e-05,
      "loss": 3.5469,
      "step": 4252
    },
    {
      "epoch": 5.61,
      "grad_norm": 60.25,
      "learning_rate": 6.58377308707124e-05,
      "loss": 0.875,
      "step": 4253
    },
    {
      "epoch": 5.61,
      "grad_norm": 14.9375,
      "learning_rate": 6.581794195250659e-05,
      "loss": 0.1279,
      "step": 4254
    },
    {
      "epoch": 5.61,
      "grad_norm": 92.0,
      "learning_rate": 6.579815303430079e-05,
      "loss": 1.0859,
      "step": 4255
    },
    {
      "epoch": 5.61,
      "grad_norm": 27.0,
      "learning_rate": 6.577836411609497e-05,
      "loss": 0.4785,
      "step": 4256
    },
    {
      "epoch": 5.62,
      "grad_norm": 19.375,
      "learning_rate": 6.575857519788917e-05,
      "loss": 0.1631,
      "step": 4257
    },
    {
      "epoch": 5.62,
      "grad_norm": 35.25,
      "learning_rate": 6.573878627968337e-05,
      "loss": 0.5781,
      "step": 4258
    },
    {
      "epoch": 5.62,
      "grad_norm": 21.375,
      "learning_rate": 6.571899736147757e-05,
      "loss": 0.2012,
      "step": 4259
    },
    {
      "epoch": 5.62,
      "grad_norm": 65.5,
      "learning_rate": 6.569920844327177e-05,
      "loss": 1.125,
      "step": 4260
    },
    {
      "epoch": 5.62,
      "grad_norm": 177.0,
      "learning_rate": 6.567941952506596e-05,
      "loss": 5.0,
      "step": 4261
    },
    {
      "epoch": 5.62,
      "grad_norm": 37.5,
      "learning_rate": 6.565963060686015e-05,
      "loss": 0.3125,
      "step": 4262
    },
    {
      "epoch": 5.62,
      "grad_norm": 23.375,
      "learning_rate": 6.563984168865435e-05,
      "loss": 0.3594,
      "step": 4263
    },
    {
      "epoch": 5.63,
      "grad_norm": 22.625,
      "learning_rate": 6.562005277044855e-05,
      "loss": 0.2451,
      "step": 4264
    },
    {
      "epoch": 5.63,
      "grad_norm": 15.8125,
      "learning_rate": 6.560026385224273e-05,
      "loss": 0.1396,
      "step": 4265
    },
    {
      "epoch": 5.63,
      "grad_norm": 31.125,
      "learning_rate": 6.558047493403693e-05,
      "loss": 0.2539,
      "step": 4266
    },
    {
      "epoch": 5.63,
      "grad_norm": 138.0,
      "learning_rate": 6.556068601583113e-05,
      "loss": 3.0,
      "step": 4267
    },
    {
      "epoch": 5.63,
      "grad_norm": 36.0,
      "learning_rate": 6.554089709762532e-05,
      "loss": 0.418,
      "step": 4268
    },
    {
      "epoch": 5.63,
      "grad_norm": 97.5,
      "learning_rate": 6.552110817941952e-05,
      "loss": 1.3516,
      "step": 4269
    },
    {
      "epoch": 5.63,
      "grad_norm": 172.0,
      "learning_rate": 6.550131926121372e-05,
      "loss": 3.7656,
      "step": 4270
    },
    {
      "epoch": 5.63,
      "grad_norm": 204.0,
      "learning_rate": 6.54815303430079e-05,
      "loss": 2.6562,
      "step": 4271
    },
    {
      "epoch": 5.64,
      "grad_norm": 58.75,
      "learning_rate": 6.54617414248021e-05,
      "loss": 1.2656,
      "step": 4272
    },
    {
      "epoch": 5.64,
      "grad_norm": 8.4375,
      "learning_rate": 6.54419525065963e-05,
      "loss": 0.0835,
      "step": 4273
    },
    {
      "epoch": 5.64,
      "grad_norm": 298.0,
      "learning_rate": 6.54221635883905e-05,
      "loss": 7.1875,
      "step": 4274
    },
    {
      "epoch": 5.64,
      "grad_norm": 19.625,
      "learning_rate": 6.54023746701847e-05,
      "loss": 0.291,
      "step": 4275
    },
    {
      "epoch": 5.64,
      "grad_norm": 199.0,
      "learning_rate": 6.53825857519789e-05,
      "loss": 3.8438,
      "step": 4276
    },
    {
      "epoch": 5.64,
      "grad_norm": 16.875,
      "learning_rate": 6.536279683377308e-05,
      "loss": 0.3867,
      "step": 4277
    },
    {
      "epoch": 5.64,
      "grad_norm": 204.0,
      "learning_rate": 6.534300791556728e-05,
      "loss": 2.5781,
      "step": 4278
    },
    {
      "epoch": 5.65,
      "grad_norm": 29.0,
      "learning_rate": 6.532321899736146e-05,
      "loss": 0.293,
      "step": 4279
    },
    {
      "epoch": 5.65,
      "grad_norm": 178.0,
      "learning_rate": 6.530343007915566e-05,
      "loss": 3.1562,
      "step": 4280
    },
    {
      "epoch": 5.65,
      "grad_norm": 19.5,
      "learning_rate": 6.528364116094986e-05,
      "loss": 0.1445,
      "step": 4281
    },
    {
      "epoch": 5.65,
      "grad_norm": 45.5,
      "learning_rate": 6.526385224274406e-05,
      "loss": 0.2676,
      "step": 4282
    },
    {
      "epoch": 5.65,
      "grad_norm": 151.0,
      "learning_rate": 6.524406332453825e-05,
      "loss": 2.7188,
      "step": 4283
    },
    {
      "epoch": 5.65,
      "grad_norm": 260.0,
      "learning_rate": 6.522427440633245e-05,
      "loss": 5.5938,
      "step": 4284
    },
    {
      "epoch": 5.65,
      "grad_norm": 17.0,
      "learning_rate": 6.520448548812664e-05,
      "loss": 0.3535,
      "step": 4285
    },
    {
      "epoch": 5.65,
      "grad_norm": 11.6875,
      "learning_rate": 6.518469656992084e-05,
      "loss": 0.1396,
      "step": 4286
    },
    {
      "epoch": 5.66,
      "grad_norm": 6.625,
      "learning_rate": 6.516490765171503e-05,
      "loss": 0.1011,
      "step": 4287
    },
    {
      "epoch": 5.66,
      "grad_norm": 19.875,
      "learning_rate": 6.514511873350923e-05,
      "loss": 0.2285,
      "step": 4288
    },
    {
      "epoch": 5.66,
      "grad_norm": 19.625,
      "learning_rate": 6.512532981530343e-05,
      "loss": 0.2129,
      "step": 4289
    },
    {
      "epoch": 5.66,
      "grad_norm": 161.0,
      "learning_rate": 6.510554089709763e-05,
      "loss": 3.0625,
      "step": 4290
    },
    {
      "epoch": 5.66,
      "grad_norm": 35.75,
      "learning_rate": 6.508575197889181e-05,
      "loss": 0.5195,
      "step": 4291
    },
    {
      "epoch": 5.66,
      "grad_norm": 105.0,
      "learning_rate": 6.506596306068601e-05,
      "loss": 1.8047,
      "step": 4292
    },
    {
      "epoch": 5.66,
      "grad_norm": 116.5,
      "learning_rate": 6.504617414248021e-05,
      "loss": 1.8438,
      "step": 4293
    },
    {
      "epoch": 5.66,
      "grad_norm": 159.0,
      "learning_rate": 6.502638522427439e-05,
      "loss": 2.6406,
      "step": 4294
    },
    {
      "epoch": 5.67,
      "grad_norm": 12.8125,
      "learning_rate": 6.500659630606859e-05,
      "loss": 0.1689,
      "step": 4295
    },
    {
      "epoch": 5.67,
      "grad_norm": 42.75,
      "learning_rate": 6.498680738786279e-05,
      "loss": 0.5195,
      "step": 4296
    },
    {
      "epoch": 5.67,
      "grad_norm": 93.0,
      "learning_rate": 6.496701846965699e-05,
      "loss": 2.2344,
      "step": 4297
    },
    {
      "epoch": 5.67,
      "grad_norm": 13.0625,
      "learning_rate": 6.494722955145118e-05,
      "loss": 0.1934,
      "step": 4298
    },
    {
      "epoch": 5.67,
      "grad_norm": 33.5,
      "learning_rate": 6.492744063324537e-05,
      "loss": 0.8789,
      "step": 4299
    },
    {
      "epoch": 5.67,
      "grad_norm": 141.0,
      "learning_rate": 6.490765171503957e-05,
      "loss": 3.9219,
      "step": 4300
    },
    {
      "epoch": 5.67,
      "grad_norm": 120.5,
      "learning_rate": 6.488786279683377e-05,
      "loss": 2.25,
      "step": 4301
    },
    {
      "epoch": 5.68,
      "grad_norm": 119.5,
      "learning_rate": 6.486807387862796e-05,
      "loss": 2.5469,
      "step": 4302
    },
    {
      "epoch": 5.68,
      "grad_norm": 22.5,
      "learning_rate": 6.484828496042216e-05,
      "loss": 0.2021,
      "step": 4303
    },
    {
      "epoch": 5.68,
      "grad_norm": 28.0,
      "learning_rate": 6.482849604221636e-05,
      "loss": 0.2432,
      "step": 4304
    },
    {
      "epoch": 5.68,
      "grad_norm": 6.8125,
      "learning_rate": 6.480870712401054e-05,
      "loss": 0.0796,
      "step": 4305
    },
    {
      "epoch": 5.68,
      "grad_norm": 9.5,
      "learning_rate": 6.478891820580474e-05,
      "loss": 0.0889,
      "step": 4306
    },
    {
      "epoch": 5.68,
      "grad_norm": 22.125,
      "learning_rate": 6.476912928759894e-05,
      "loss": 0.5273,
      "step": 4307
    },
    {
      "epoch": 5.68,
      "grad_norm": 11.375,
      "learning_rate": 6.474934036939314e-05,
      "loss": 0.1738,
      "step": 4308
    },
    {
      "epoch": 5.68,
      "grad_norm": 192.0,
      "learning_rate": 6.472955145118732e-05,
      "loss": 3.2656,
      "step": 4309
    },
    {
      "epoch": 5.69,
      "grad_norm": 19.0,
      "learning_rate": 6.470976253298152e-05,
      "loss": 0.2139,
      "step": 4310
    },
    {
      "epoch": 5.69,
      "grad_norm": 188.0,
      "learning_rate": 6.468997361477572e-05,
      "loss": 3.5625,
      "step": 4311
    },
    {
      "epoch": 5.69,
      "grad_norm": 35.5,
      "learning_rate": 6.467018469656992e-05,
      "loss": 0.6562,
      "step": 4312
    },
    {
      "epoch": 5.69,
      "grad_norm": 215.0,
      "learning_rate": 6.465039577836411e-05,
      "loss": 3.9688,
      "step": 4313
    },
    {
      "epoch": 5.69,
      "grad_norm": 196.0,
      "learning_rate": 6.46306068601583e-05,
      "loss": 3.6719,
      "step": 4314
    },
    {
      "epoch": 5.69,
      "grad_norm": 12.25,
      "learning_rate": 6.46108179419525e-05,
      "loss": 0.0986,
      "step": 4315
    },
    {
      "epoch": 5.69,
      "grad_norm": 133.0,
      "learning_rate": 6.45910290237467e-05,
      "loss": 2.1719,
      "step": 4316
    },
    {
      "epoch": 5.7,
      "grad_norm": 40.75,
      "learning_rate": 6.45712401055409e-05,
      "loss": 0.2949,
      "step": 4317
    },
    {
      "epoch": 5.7,
      "grad_norm": 5.3125,
      "learning_rate": 6.455145118733509e-05,
      "loss": 0.0781,
      "step": 4318
    },
    {
      "epoch": 5.7,
      "grad_norm": 5.625,
      "learning_rate": 6.453166226912929e-05,
      "loss": 0.0737,
      "step": 4319
    },
    {
      "epoch": 5.7,
      "grad_norm": 204.0,
      "learning_rate": 6.451187335092347e-05,
      "loss": 3.6562,
      "step": 4320
    },
    {
      "epoch": 5.7,
      "grad_norm": 7.03125,
      "learning_rate": 6.449208443271767e-05,
      "loss": 0.0608,
      "step": 4321
    },
    {
      "epoch": 5.7,
      "grad_norm": 6.375,
      "learning_rate": 6.447229551451187e-05,
      "loss": 0.0432,
      "step": 4322
    },
    {
      "epoch": 5.7,
      "grad_norm": 7.78125,
      "learning_rate": 6.445250659630607e-05,
      "loss": 0.0527,
      "step": 4323
    },
    {
      "epoch": 5.7,
      "grad_norm": 119.5,
      "learning_rate": 6.443271767810025e-05,
      "loss": 2.4219,
      "step": 4324
    },
    {
      "epoch": 5.71,
      "grad_norm": 137.0,
      "learning_rate": 6.441292875989445e-05,
      "loss": 2.3594,
      "step": 4325
    },
    {
      "epoch": 5.71,
      "grad_norm": 28.125,
      "learning_rate": 6.439313984168865e-05,
      "loss": 0.1177,
      "step": 4326
    },
    {
      "epoch": 5.71,
      "grad_norm": 137.0,
      "learning_rate": 6.437335092348285e-05,
      "loss": 2.3906,
      "step": 4327
    },
    {
      "epoch": 5.71,
      "grad_norm": 6.6875,
      "learning_rate": 6.435356200527703e-05,
      "loss": 0.0615,
      "step": 4328
    },
    {
      "epoch": 5.71,
      "grad_norm": 61.25,
      "learning_rate": 6.433377308707123e-05,
      "loss": 0.7773,
      "step": 4329
    },
    {
      "epoch": 5.71,
      "grad_norm": 30.75,
      "learning_rate": 6.431398416886543e-05,
      "loss": 0.293,
      "step": 4330
    },
    {
      "epoch": 5.71,
      "grad_norm": 7.03125,
      "learning_rate": 6.429419525065963e-05,
      "loss": 0.0442,
      "step": 4331
    },
    {
      "epoch": 5.72,
      "grad_norm": 386.0,
      "learning_rate": 6.427440633245382e-05,
      "loss": 7.125,
      "step": 4332
    },
    {
      "epoch": 5.72,
      "grad_norm": 125.0,
      "learning_rate": 6.425461741424802e-05,
      "loss": 2.7344,
      "step": 4333
    },
    {
      "epoch": 5.72,
      "grad_norm": 252.0,
      "learning_rate": 6.42348284960422e-05,
      "loss": 5.125,
      "step": 4334
    },
    {
      "epoch": 5.72,
      "grad_norm": 450.0,
      "learning_rate": 6.42150395778364e-05,
      "loss": 9.0,
      "step": 4335
    },
    {
      "epoch": 5.72,
      "grad_norm": 31.625,
      "learning_rate": 6.41952506596306e-05,
      "loss": 0.3125,
      "step": 4336
    },
    {
      "epoch": 5.72,
      "grad_norm": 137.0,
      "learning_rate": 6.41754617414248e-05,
      "loss": 2.1094,
      "step": 4337
    },
    {
      "epoch": 5.72,
      "grad_norm": 127.0,
      "learning_rate": 6.4155672823219e-05,
      "loss": 2.3906,
      "step": 4338
    },
    {
      "epoch": 5.72,
      "grad_norm": 25.125,
      "learning_rate": 6.413588390501318e-05,
      "loss": 0.6445,
      "step": 4339
    },
    {
      "epoch": 5.73,
      "grad_norm": 36.5,
      "learning_rate": 6.411609498680738e-05,
      "loss": 0.2637,
      "step": 4340
    },
    {
      "epoch": 5.73,
      "grad_norm": 201.0,
      "learning_rate": 6.409630606860158e-05,
      "loss": 3.7031,
      "step": 4341
    },
    {
      "epoch": 5.73,
      "grad_norm": 130.0,
      "learning_rate": 6.407651715039576e-05,
      "loss": 1.9531,
      "step": 4342
    },
    {
      "epoch": 5.73,
      "grad_norm": 105.0,
      "learning_rate": 6.405672823218996e-05,
      "loss": 2.0,
      "step": 4343
    },
    {
      "epoch": 5.73,
      "grad_norm": 197.0,
      "learning_rate": 6.403693931398416e-05,
      "loss": 4.6562,
      "step": 4344
    },
    {
      "epoch": 5.73,
      "grad_norm": 16.75,
      "learning_rate": 6.401715039577836e-05,
      "loss": 0.1416,
      "step": 4345
    },
    {
      "epoch": 5.73,
      "grad_norm": 17.75,
      "learning_rate": 6.399736147757256e-05,
      "loss": 0.1494,
      "step": 4346
    },
    {
      "epoch": 5.73,
      "grad_norm": 188.0,
      "learning_rate": 6.397757255936675e-05,
      "loss": 5.9375,
      "step": 4347
    },
    {
      "epoch": 5.74,
      "grad_norm": 25.0,
      "learning_rate": 6.395778364116094e-05,
      "loss": 0.582,
      "step": 4348
    },
    {
      "epoch": 5.74,
      "grad_norm": 24.25,
      "learning_rate": 6.393799472295514e-05,
      "loss": 0.4141,
      "step": 4349
    },
    {
      "epoch": 5.74,
      "grad_norm": 77.5,
      "learning_rate": 6.391820580474933e-05,
      "loss": 1.4453,
      "step": 4350
    },
    {
      "epoch": 5.74,
      "grad_norm": 29.75,
      "learning_rate": 6.389841688654353e-05,
      "loss": 0.3691,
      "step": 4351
    },
    {
      "epoch": 5.74,
      "grad_norm": 18.625,
      "learning_rate": 6.387862796833773e-05,
      "loss": 0.1172,
      "step": 4352
    },
    {
      "epoch": 5.74,
      "grad_norm": 36.5,
      "learning_rate": 6.385883905013193e-05,
      "loss": 0.5938,
      "step": 4353
    },
    {
      "epoch": 5.74,
      "grad_norm": 23.375,
      "learning_rate": 6.383905013192611e-05,
      "loss": 0.3613,
      "step": 4354
    },
    {
      "epoch": 5.75,
      "grad_norm": 15.25,
      "learning_rate": 6.381926121372031e-05,
      "loss": 0.1768,
      "step": 4355
    },
    {
      "epoch": 5.75,
      "grad_norm": 28.5,
      "learning_rate": 6.379947229551451e-05,
      "loss": 0.3203,
      "step": 4356
    },
    {
      "epoch": 5.75,
      "grad_norm": 14.9375,
      "learning_rate": 6.37796833773087e-05,
      "loss": 0.1562,
      "step": 4357
    },
    {
      "epoch": 5.75,
      "grad_norm": 130.0,
      "learning_rate": 6.375989445910289e-05,
      "loss": 2.8438,
      "step": 4358
    },
    {
      "epoch": 5.75,
      "grad_norm": 164.0,
      "learning_rate": 6.374010554089709e-05,
      "loss": 4.0625,
      "step": 4359
    },
    {
      "epoch": 5.75,
      "grad_norm": 141.0,
      "learning_rate": 6.372031662269129e-05,
      "loss": 2.6406,
      "step": 4360
    },
    {
      "epoch": 5.75,
      "grad_norm": 20.5,
      "learning_rate": 6.370052770448549e-05,
      "loss": 0.1768,
      "step": 4361
    },
    {
      "epoch": 5.75,
      "grad_norm": 20.625,
      "learning_rate": 6.368073878627968e-05,
      "loss": 0.1992,
      "step": 4362
    },
    {
      "epoch": 5.76,
      "grad_norm": 177.0,
      "learning_rate": 6.366094986807387e-05,
      "loss": 3.9688,
      "step": 4363
    },
    {
      "epoch": 5.76,
      "grad_norm": 172.0,
      "learning_rate": 6.364116094986807e-05,
      "loss": 3.9062,
      "step": 4364
    },
    {
      "epoch": 5.76,
      "grad_norm": 23.25,
      "learning_rate": 6.362137203166226e-05,
      "loss": 0.5586,
      "step": 4365
    },
    {
      "epoch": 5.76,
      "grad_norm": 137.0,
      "learning_rate": 6.360158311345646e-05,
      "loss": 2.6719,
      "step": 4366
    },
    {
      "epoch": 5.76,
      "grad_norm": 19.0,
      "learning_rate": 6.358179419525066e-05,
      "loss": 0.3066,
      "step": 4367
    },
    {
      "epoch": 5.76,
      "grad_norm": 20.125,
      "learning_rate": 6.356200527704486e-05,
      "loss": 0.1885,
      "step": 4368
    },
    {
      "epoch": 5.76,
      "grad_norm": 28.5,
      "learning_rate": 6.354221635883904e-05,
      "loss": 0.3164,
      "step": 4369
    },
    {
      "epoch": 5.77,
      "grad_norm": 157.0,
      "learning_rate": 6.352242744063324e-05,
      "loss": 3.2031,
      "step": 4370
    },
    {
      "epoch": 5.77,
      "grad_norm": 27.0,
      "learning_rate": 6.350263852242743e-05,
      "loss": 0.3984,
      "step": 4371
    },
    {
      "epoch": 5.77,
      "grad_norm": 37.0,
      "learning_rate": 6.348284960422162e-05,
      "loss": 0.4805,
      "step": 4372
    },
    {
      "epoch": 5.77,
      "grad_norm": 22.0,
      "learning_rate": 6.346306068601582e-05,
      "loss": 0.6055,
      "step": 4373
    },
    {
      "epoch": 5.77,
      "grad_norm": 300.0,
      "learning_rate": 6.344327176781002e-05,
      "loss": 6.25,
      "step": 4374
    },
    {
      "epoch": 5.77,
      "grad_norm": 28.25,
      "learning_rate": 6.342348284960422e-05,
      "loss": 0.3477,
      "step": 4375
    },
    {
      "epoch": 5.77,
      "grad_norm": 23.375,
      "learning_rate": 6.340369393139842e-05,
      "loss": 0.3965,
      "step": 4376
    },
    {
      "epoch": 5.77,
      "grad_norm": 298.0,
      "learning_rate": 6.33839050131926e-05,
      "loss": 5.1562,
      "step": 4377
    },
    {
      "epoch": 5.78,
      "grad_norm": 102.0,
      "learning_rate": 6.33641160949868e-05,
      "loss": 2.1562,
      "step": 4378
    },
    {
      "epoch": 5.78,
      "grad_norm": 21.125,
      "learning_rate": 6.3344327176781e-05,
      "loss": 0.3535,
      "step": 4379
    },
    {
      "epoch": 5.78,
      "grad_norm": 36.0,
      "learning_rate": 6.33245382585752e-05,
      "loss": 0.4043,
      "step": 4380
    },
    {
      "epoch": 5.78,
      "grad_norm": 16.625,
      "learning_rate": 6.330474934036939e-05,
      "loss": 0.1377,
      "step": 4381
    },
    {
      "epoch": 5.78,
      "grad_norm": 19.75,
      "learning_rate": 6.328496042216359e-05,
      "loss": 0.4121,
      "step": 4382
    },
    {
      "epoch": 5.78,
      "grad_norm": 121.0,
      "learning_rate": 6.326517150395778e-05,
      "loss": 3.7656,
      "step": 4383
    },
    {
      "epoch": 5.78,
      "grad_norm": 15.875,
      "learning_rate": 6.324538258575197e-05,
      "loss": 0.1514,
      "step": 4384
    },
    {
      "epoch": 5.78,
      "grad_norm": 7.625,
      "learning_rate": 6.322559366754616e-05,
      "loss": 0.104,
      "step": 4385
    },
    {
      "epoch": 5.79,
      "grad_norm": 27.25,
      "learning_rate": 6.320580474934036e-05,
      "loss": 0.7891,
      "step": 4386
    },
    {
      "epoch": 5.79,
      "grad_norm": 13.3125,
      "learning_rate": 6.318601583113455e-05,
      "loss": 0.1963,
      "step": 4387
    },
    {
      "epoch": 5.79,
      "grad_norm": 30.625,
      "learning_rate": 6.316622691292875e-05,
      "loss": 0.7109,
      "step": 4388
    },
    {
      "epoch": 5.79,
      "grad_norm": 169.0,
      "learning_rate": 6.314643799472295e-05,
      "loss": 2.9844,
      "step": 4389
    },
    {
      "epoch": 5.79,
      "grad_norm": 8.25,
      "learning_rate": 6.312664907651715e-05,
      "loss": 0.1621,
      "step": 4390
    },
    {
      "epoch": 5.79,
      "grad_norm": 150.0,
      "learning_rate": 6.310686015831133e-05,
      "loss": 3.0469,
      "step": 4391
    },
    {
      "epoch": 5.79,
      "grad_norm": 18.375,
      "learning_rate": 6.308707124010553e-05,
      "loss": 0.2578,
      "step": 4392
    },
    {
      "epoch": 5.8,
      "grad_norm": 222.0,
      "learning_rate": 6.306728232189973e-05,
      "loss": 4.1875,
      "step": 4393
    },
    {
      "epoch": 5.8,
      "grad_norm": 20.5,
      "learning_rate": 6.304749340369393e-05,
      "loss": 0.208,
      "step": 4394
    },
    {
      "epoch": 5.8,
      "grad_norm": 25.5,
      "learning_rate": 6.302770448548813e-05,
      "loss": 0.416,
      "step": 4395
    },
    {
      "epoch": 5.8,
      "grad_norm": 106.5,
      "learning_rate": 6.300791556728232e-05,
      "loss": 2.7031,
      "step": 4396
    },
    {
      "epoch": 5.8,
      "grad_norm": 169.0,
      "learning_rate": 6.298812664907651e-05,
      "loss": 3.1875,
      "step": 4397
    },
    {
      "epoch": 5.8,
      "grad_norm": 160.0,
      "learning_rate": 6.29683377308707e-05,
      "loss": 3.3125,
      "step": 4398
    },
    {
      "epoch": 5.8,
      "grad_norm": 213.0,
      "learning_rate": 6.29485488126649e-05,
      "loss": 4.6875,
      "step": 4399
    },
    {
      "epoch": 5.8,
      "grad_norm": 28.5,
      "learning_rate": 6.292875989445909e-05,
      "loss": 0.252,
      "step": 4400
    },
    {
      "epoch": 5.81,
      "grad_norm": 18.0,
      "learning_rate": 6.290897097625329e-05,
      "loss": 0.6094,
      "step": 4401
    },
    {
      "epoch": 5.81,
      "grad_norm": 18.75,
      "learning_rate": 6.288918205804748e-05,
      "loss": 0.1167,
      "step": 4402
    },
    {
      "epoch": 5.81,
      "grad_norm": 8.0625,
      "learning_rate": 6.286939313984168e-05,
      "loss": 0.1016,
      "step": 4403
    },
    {
      "epoch": 5.81,
      "grad_norm": 7.09375,
      "learning_rate": 6.284960422163588e-05,
      "loss": 0.083,
      "step": 4404
    },
    {
      "epoch": 5.81,
      "grad_norm": 8.875,
      "learning_rate": 6.282981530343008e-05,
      "loss": 0.1211,
      "step": 4405
    },
    {
      "epoch": 5.81,
      "grad_norm": 104.5,
      "learning_rate": 6.281002638522426e-05,
      "loss": 2.4375,
      "step": 4406
    },
    {
      "epoch": 5.81,
      "grad_norm": 3.859375,
      "learning_rate": 6.279023746701846e-05,
      "loss": 0.041,
      "step": 4407
    },
    {
      "epoch": 5.82,
      "grad_norm": 13.125,
      "learning_rate": 6.277044854881266e-05,
      "loss": 0.0996,
      "step": 4408
    },
    {
      "epoch": 5.82,
      "grad_norm": 116.0,
      "learning_rate": 6.275065963060686e-05,
      "loss": 2.1719,
      "step": 4409
    },
    {
      "epoch": 5.82,
      "grad_norm": 28.5,
      "learning_rate": 6.273087071240106e-05,
      "loss": 0.5664,
      "step": 4410
    },
    {
      "epoch": 5.82,
      "grad_norm": 106.0,
      "learning_rate": 6.271108179419525e-05,
      "loss": 2.1562,
      "step": 4411
    },
    {
      "epoch": 5.82,
      "grad_norm": 113.0,
      "learning_rate": 6.269129287598944e-05,
      "loss": 2.7188,
      "step": 4412
    },
    {
      "epoch": 5.82,
      "grad_norm": 232.0,
      "learning_rate": 6.267150395778364e-05,
      "loss": 4.4062,
      "step": 4413
    },
    {
      "epoch": 5.82,
      "grad_norm": 7.46875,
      "learning_rate": 6.265171503957783e-05,
      "loss": 0.0559,
      "step": 4414
    },
    {
      "epoch": 5.82,
      "grad_norm": 10.0625,
      "learning_rate": 6.263192612137202e-05,
      "loss": 0.0654,
      "step": 4415
    },
    {
      "epoch": 5.83,
      "grad_norm": 21.125,
      "learning_rate": 6.261213720316622e-05,
      "loss": 0.5938,
      "step": 4416
    },
    {
      "epoch": 5.83,
      "grad_norm": 12.5625,
      "learning_rate": 6.259234828496041e-05,
      "loss": 0.1328,
      "step": 4417
    },
    {
      "epoch": 5.83,
      "grad_norm": 39.5,
      "learning_rate": 6.257255936675461e-05,
      "loss": 0.4355,
      "step": 4418
    },
    {
      "epoch": 5.83,
      "grad_norm": 43.0,
      "learning_rate": 6.255277044854881e-05,
      "loss": 1.0781,
      "step": 4419
    },
    {
      "epoch": 5.83,
      "grad_norm": 40.75,
      "learning_rate": 6.2532981530343e-05,
      "loss": 0.6211,
      "step": 4420
    },
    {
      "epoch": 5.83,
      "grad_norm": 30.625,
      "learning_rate": 6.25131926121372e-05,
      "loss": 0.2227,
      "step": 4421
    },
    {
      "epoch": 5.83,
      "grad_norm": 143.0,
      "learning_rate": 6.249340369393139e-05,
      "loss": 2.3594,
      "step": 4422
    },
    {
      "epoch": 5.84,
      "grad_norm": 17.75,
      "learning_rate": 6.247361477572559e-05,
      "loss": 0.1318,
      "step": 4423
    },
    {
      "epoch": 5.84,
      "grad_norm": 115.5,
      "learning_rate": 6.245382585751979e-05,
      "loss": 1.8828,
      "step": 4424
    },
    {
      "epoch": 5.84,
      "grad_norm": 17.125,
      "learning_rate": 6.243403693931399e-05,
      "loss": 0.3242,
      "step": 4425
    },
    {
      "epoch": 5.84,
      "grad_norm": 130.0,
      "learning_rate": 6.241424802110817e-05,
      "loss": 2.125,
      "step": 4426
    },
    {
      "epoch": 5.84,
      "grad_norm": 5.59375,
      "learning_rate": 6.239445910290237e-05,
      "loss": 0.0481,
      "step": 4427
    },
    {
      "epoch": 5.84,
      "grad_norm": 139.0,
      "learning_rate": 6.237467018469657e-05,
      "loss": 2.4688,
      "step": 4428
    },
    {
      "epoch": 5.84,
      "grad_norm": 139.0,
      "learning_rate": 6.235488126649076e-05,
      "loss": 2.4219,
      "step": 4429
    },
    {
      "epoch": 5.84,
      "grad_norm": 152.0,
      "learning_rate": 6.233509234828495e-05,
      "loss": 3.5,
      "step": 4430
    },
    {
      "epoch": 5.85,
      "grad_norm": 29.875,
      "learning_rate": 6.231530343007915e-05,
      "loss": 0.5859,
      "step": 4431
    },
    {
      "epoch": 5.85,
      "grad_norm": 181.0,
      "learning_rate": 6.229551451187335e-05,
      "loss": 3.7188,
      "step": 4432
    },
    {
      "epoch": 5.85,
      "grad_norm": 28.25,
      "learning_rate": 6.227572559366754e-05,
      "loss": 0.6641,
      "step": 4433
    },
    {
      "epoch": 5.85,
      "grad_norm": 20.625,
      "learning_rate": 6.225593667546174e-05,
      "loss": 0.3379,
      "step": 4434
    },
    {
      "epoch": 5.85,
      "grad_norm": 27.5,
      "learning_rate": 6.223614775725593e-05,
      "loss": 0.6406,
      "step": 4435
    },
    {
      "epoch": 5.85,
      "grad_norm": 14.3125,
      "learning_rate": 6.221635883905012e-05,
      "loss": 0.1855,
      "step": 4436
    },
    {
      "epoch": 5.85,
      "grad_norm": 111.5,
      "learning_rate": 6.219656992084432e-05,
      "loss": 1.5781,
      "step": 4437
    },
    {
      "epoch": 5.85,
      "grad_norm": 171.0,
      "learning_rate": 6.217678100263852e-05,
      "loss": 3.4844,
      "step": 4438
    },
    {
      "epoch": 5.86,
      "grad_norm": 119.0,
      "learning_rate": 6.215699208443272e-05,
      "loss": 1.9219,
      "step": 4439
    },
    {
      "epoch": 5.86,
      "grad_norm": 6.09375,
      "learning_rate": 6.213720316622692e-05,
      "loss": 0.0513,
      "step": 4440
    },
    {
      "epoch": 5.86,
      "grad_norm": 16.25,
      "learning_rate": 6.21174142480211e-05,
      "loss": 0.5859,
      "step": 4441
    },
    {
      "epoch": 5.86,
      "grad_norm": 11.6875,
      "learning_rate": 6.20976253298153e-05,
      "loss": 0.208,
      "step": 4442
    },
    {
      "epoch": 5.86,
      "grad_norm": 41.0,
      "learning_rate": 6.20778364116095e-05,
      "loss": 0.5508,
      "step": 4443
    },
    {
      "epoch": 5.86,
      "grad_norm": 25.625,
      "learning_rate": 6.20580474934037e-05,
      "loss": 0.2432,
      "step": 4444
    },
    {
      "epoch": 5.86,
      "grad_norm": 15.8125,
      "learning_rate": 6.203825857519788e-05,
      "loss": 0.4395,
      "step": 4445
    },
    {
      "epoch": 5.87,
      "grad_norm": 24.5,
      "learning_rate": 6.201846965699208e-05,
      "loss": 0.209,
      "step": 4446
    },
    {
      "epoch": 5.87,
      "grad_norm": 15.5625,
      "learning_rate": 6.199868073878628e-05,
      "loss": 0.4609,
      "step": 4447
    },
    {
      "epoch": 5.87,
      "grad_norm": 17.5,
      "learning_rate": 6.197889182058047e-05,
      "loss": 0.1807,
      "step": 4448
    },
    {
      "epoch": 5.87,
      "grad_norm": 10.875,
      "learning_rate": 6.195910290237466e-05,
      "loss": 0.4688,
      "step": 4449
    },
    {
      "epoch": 5.87,
      "grad_norm": 31.625,
      "learning_rate": 6.193931398416886e-05,
      "loss": 0.459,
      "step": 4450
    },
    {
      "epoch": 5.87,
      "grad_norm": 99.0,
      "learning_rate": 6.191952506596305e-05,
      "loss": 1.9922,
      "step": 4451
    },
    {
      "epoch": 5.87,
      "grad_norm": 16.375,
      "learning_rate": 6.189973614775725e-05,
      "loss": 0.3105,
      "step": 4452
    },
    {
      "epoch": 5.87,
      "grad_norm": 6.40625,
      "learning_rate": 6.187994722955145e-05,
      "loss": 0.1328,
      "step": 4453
    },
    {
      "epoch": 5.88,
      "grad_norm": 42.25,
      "learning_rate": 6.186015831134565e-05,
      "loss": 0.7852,
      "step": 4454
    },
    {
      "epoch": 5.88,
      "grad_norm": 20.5,
      "learning_rate": 6.184036939313983e-05,
      "loss": 0.3926,
      "step": 4455
    },
    {
      "epoch": 5.88,
      "grad_norm": 168.0,
      "learning_rate": 6.182058047493403e-05,
      "loss": 4.4688,
      "step": 4456
    },
    {
      "epoch": 5.88,
      "grad_norm": 119.5,
      "learning_rate": 6.180079155672823e-05,
      "loss": 2.9219,
      "step": 4457
    },
    {
      "epoch": 5.88,
      "grad_norm": 15.0625,
      "learning_rate": 6.178100263852243e-05,
      "loss": 0.2891,
      "step": 4458
    },
    {
      "epoch": 5.88,
      "grad_norm": 223.0,
      "learning_rate": 6.176121372031662e-05,
      "loss": 6.5625,
      "step": 4459
    },
    {
      "epoch": 5.88,
      "grad_norm": 161.0,
      "learning_rate": 6.174142480211081e-05,
      "loss": 3.9219,
      "step": 4460
    },
    {
      "epoch": 5.89,
      "grad_norm": 9.375,
      "learning_rate": 6.172163588390501e-05,
      "loss": 0.0923,
      "step": 4461
    },
    {
      "epoch": 5.89,
      "grad_norm": 218.0,
      "learning_rate": 6.17018469656992e-05,
      "loss": 6.4062,
      "step": 4462
    },
    {
      "epoch": 5.89,
      "grad_norm": 198.0,
      "learning_rate": 6.168205804749339e-05,
      "loss": 5.5,
      "step": 4463
    },
    {
      "epoch": 5.89,
      "grad_norm": 14.1875,
      "learning_rate": 6.166226912928759e-05,
      "loss": 0.1235,
      "step": 4464
    },
    {
      "epoch": 5.89,
      "grad_norm": 101.5,
      "learning_rate": 6.164248021108179e-05,
      "loss": 1.9219,
      "step": 4465
    },
    {
      "epoch": 5.89,
      "grad_norm": 39.25,
      "learning_rate": 6.162269129287598e-05,
      "loss": 0.7812,
      "step": 4466
    },
    {
      "epoch": 5.89,
      "grad_norm": 96.0,
      "learning_rate": 6.160290237467018e-05,
      "loss": 4.5312,
      "step": 4467
    },
    {
      "epoch": 5.89,
      "grad_norm": 140.0,
      "learning_rate": 6.158311345646438e-05,
      "loss": 3.125,
      "step": 4468
    },
    {
      "epoch": 5.9,
      "grad_norm": 16.625,
      "learning_rate": 6.156332453825856e-05,
      "loss": 0.1367,
      "step": 4469
    },
    {
      "epoch": 5.9,
      "grad_norm": 192.0,
      "learning_rate": 6.154353562005276e-05,
      "loss": 3.7812,
      "step": 4470
    },
    {
      "epoch": 5.9,
      "grad_norm": 13.375,
      "learning_rate": 6.152374670184696e-05,
      "loss": 0.377,
      "step": 4471
    },
    {
      "epoch": 5.9,
      "grad_norm": 24.25,
      "learning_rate": 6.150395778364116e-05,
      "loss": 0.4512,
      "step": 4472
    },
    {
      "epoch": 5.9,
      "grad_norm": 18.875,
      "learning_rate": 6.148416886543536e-05,
      "loss": 0.1748,
      "step": 4473
    },
    {
      "epoch": 5.9,
      "grad_norm": 197.0,
      "learning_rate": 6.146437994722956e-05,
      "loss": 4.5938,
      "step": 4474
    },
    {
      "epoch": 5.9,
      "grad_norm": 62.0,
      "learning_rate": 6.144459102902374e-05,
      "loss": 0.8945,
      "step": 4475
    },
    {
      "epoch": 5.91,
      "grad_norm": 83.5,
      "learning_rate": 6.142480211081794e-05,
      "loss": 1.8125,
      "step": 4476
    },
    {
      "epoch": 5.91,
      "grad_norm": 159.0,
      "learning_rate": 6.140501319261214e-05,
      "loss": 3.0156,
      "step": 4477
    },
    {
      "epoch": 5.91,
      "grad_norm": 18.375,
      "learning_rate": 6.138522427440632e-05,
      "loss": 0.2197,
      "step": 4478
    },
    {
      "epoch": 5.91,
      "grad_norm": 14.75,
      "learning_rate": 6.136543535620052e-05,
      "loss": 0.5977,
      "step": 4479
    },
    {
      "epoch": 5.91,
      "grad_norm": 84.0,
      "learning_rate": 6.134564643799472e-05,
      "loss": 1.7031,
      "step": 4480
    },
    {
      "epoch": 5.91,
      "grad_norm": 40.75,
      "learning_rate": 6.132585751978891e-05,
      "loss": 0.5469,
      "step": 4481
    },
    {
      "epoch": 5.91,
      "grad_norm": 10.125,
      "learning_rate": 6.130606860158311e-05,
      "loss": 0.1123,
      "step": 4482
    },
    {
      "epoch": 5.91,
      "grad_norm": 14.9375,
      "learning_rate": 6.128627968337731e-05,
      "loss": 0.2109,
      "step": 4483
    },
    {
      "epoch": 5.92,
      "grad_norm": 25.625,
      "learning_rate": 6.12664907651715e-05,
      "loss": 0.3477,
      "step": 4484
    },
    {
      "epoch": 5.92,
      "grad_norm": 82.5,
      "learning_rate": 6.124670184696569e-05,
      "loss": 1.5547,
      "step": 4485
    },
    {
      "epoch": 5.92,
      "grad_norm": 14.375,
      "learning_rate": 6.122691292875989e-05,
      "loss": 0.1299,
      "step": 4486
    },
    {
      "epoch": 5.92,
      "grad_norm": 187.0,
      "learning_rate": 6.120712401055409e-05,
      "loss": 5.1875,
      "step": 4487
    },
    {
      "epoch": 5.92,
      "grad_norm": 85.5,
      "learning_rate": 6.118733509234829e-05,
      "loss": 1.7031,
      "step": 4488
    },
    {
      "epoch": 5.92,
      "grad_norm": 89.0,
      "learning_rate": 6.116754617414249e-05,
      "loss": 2.2031,
      "step": 4489
    },
    {
      "epoch": 5.92,
      "grad_norm": 90.5,
      "learning_rate": 6.114775725593667e-05,
      "loss": 1.4531,
      "step": 4490
    },
    {
      "epoch": 5.92,
      "grad_norm": 23.25,
      "learning_rate": 6.112796833773087e-05,
      "loss": 0.2266,
      "step": 4491
    },
    {
      "epoch": 5.93,
      "grad_norm": 72.0,
      "learning_rate": 6.110817941952505e-05,
      "loss": 1.2656,
      "step": 4492
    },
    {
      "epoch": 5.93,
      "grad_norm": 19.125,
      "learning_rate": 6.108839050131925e-05,
      "loss": 0.7617,
      "step": 4493
    },
    {
      "epoch": 5.93,
      "grad_norm": 35.75,
      "learning_rate": 6.106860158311345e-05,
      "loss": 0.5898,
      "step": 4494
    },
    {
      "epoch": 5.93,
      "grad_norm": 184.0,
      "learning_rate": 6.104881266490765e-05,
      "loss": 4.2812,
      "step": 4495
    },
    {
      "epoch": 5.93,
      "grad_norm": 25.625,
      "learning_rate": 6.102902374670184e-05,
      "loss": 0.5469,
      "step": 4496
    },
    {
      "epoch": 5.93,
      "grad_norm": 85.0,
      "learning_rate": 6.1009234828496036e-05,
      "loss": 1.375,
      "step": 4497
    },
    {
      "epoch": 5.93,
      "grad_norm": 33.0,
      "learning_rate": 6.0989445910290234e-05,
      "loss": 0.7109,
      "step": 4498
    },
    {
      "epoch": 5.94,
      "grad_norm": 27.0,
      "learning_rate": 6.0969656992084425e-05,
      "loss": 0.5977,
      "step": 4499
    },
    {
      "epoch": 5.94,
      "grad_norm": 161.0,
      "learning_rate": 6.0949868073878623e-05,
      "loss": 3.6562,
      "step": 4500
    },
    {
      "epoch": 5.94,
      "grad_norm": 30.5,
      "learning_rate": 6.093007915567282e-05,
      "loss": 0.2617,
      "step": 4501
    },
    {
      "epoch": 5.94,
      "grad_norm": 15.125,
      "learning_rate": 6.091029023746701e-05,
      "loss": 0.291,
      "step": 4502
    },
    {
      "epoch": 5.94,
      "grad_norm": 162.0,
      "learning_rate": 6.089050131926121e-05,
      "loss": 3.3906,
      "step": 4503
    },
    {
      "epoch": 5.94,
      "grad_norm": 154.0,
      "learning_rate": 6.087071240105541e-05,
      "loss": 3.3281,
      "step": 4504
    },
    {
      "epoch": 5.94,
      "grad_norm": 16.375,
      "learning_rate": 6.085092348284959e-05,
      "loss": 0.1904,
      "step": 4505
    },
    {
      "epoch": 5.94,
      "grad_norm": 24.625,
      "learning_rate": 6.083113456464379e-05,
      "loss": 0.4648,
      "step": 4506
    },
    {
      "epoch": 5.95,
      "grad_norm": 31.625,
      "learning_rate": 6.081134564643799e-05,
      "loss": 0.5703,
      "step": 4507
    },
    {
      "epoch": 5.95,
      "grad_norm": 20.75,
      "learning_rate": 6.079155672823218e-05,
      "loss": 0.334,
      "step": 4508
    },
    {
      "epoch": 5.95,
      "grad_norm": 79.5,
      "learning_rate": 6.077176781002638e-05,
      "loss": 1.8281,
      "step": 4509
    },
    {
      "epoch": 5.95,
      "grad_norm": 158.0,
      "learning_rate": 6.075197889182058e-05,
      "loss": 4.0312,
      "step": 4510
    },
    {
      "epoch": 5.95,
      "grad_norm": 8.5625,
      "learning_rate": 6.073218997361477e-05,
      "loss": 0.0874,
      "step": 4511
    },
    {
      "epoch": 5.95,
      "grad_norm": 16.125,
      "learning_rate": 6.0712401055408966e-05,
      "loss": 0.2383,
      "step": 4512
    },
    {
      "epoch": 5.95,
      "grad_norm": 129.0,
      "learning_rate": 6.0692612137203164e-05,
      "loss": 3.4844,
      "step": 4513
    },
    {
      "epoch": 5.96,
      "grad_norm": 81.0,
      "learning_rate": 6.0672823218997356e-05,
      "loss": 1.3594,
      "step": 4514
    },
    {
      "epoch": 5.96,
      "grad_norm": 78.5,
      "learning_rate": 6.0653034300791554e-05,
      "loss": 1.4219,
      "step": 4515
    },
    {
      "epoch": 5.96,
      "grad_norm": 139.0,
      "learning_rate": 6.063324538258575e-05,
      "loss": 3.0781,
      "step": 4516
    },
    {
      "epoch": 5.96,
      "grad_norm": 136.0,
      "learning_rate": 6.061345646437994e-05,
      "loss": 4.0312,
      "step": 4517
    },
    {
      "epoch": 5.96,
      "grad_norm": 89.5,
      "learning_rate": 6.059366754617414e-05,
      "loss": 1.6172,
      "step": 4518
    },
    {
      "epoch": 5.96,
      "grad_norm": 157.0,
      "learning_rate": 6.057387862796834e-05,
      "loss": 3.0781,
      "step": 4519
    },
    {
      "epoch": 5.96,
      "grad_norm": 91.0,
      "learning_rate": 6.0554089709762524e-05,
      "loss": 1.8906,
      "step": 4520
    },
    {
      "epoch": 5.96,
      "grad_norm": 121.0,
      "learning_rate": 6.053430079155672e-05,
      "loss": 2.3125,
      "step": 4521
    },
    {
      "epoch": 5.97,
      "grad_norm": 135.0,
      "learning_rate": 6.051451187335091e-05,
      "loss": 2.8906,
      "step": 4522
    },
    {
      "epoch": 5.97,
      "grad_norm": 70.0,
      "learning_rate": 6.049472295514511e-05,
      "loss": 1.3203,
      "step": 4523
    },
    {
      "epoch": 5.97,
      "grad_norm": 23.25,
      "learning_rate": 6.047493403693931e-05,
      "loss": 0.3828,
      "step": 4524
    },
    {
      "epoch": 5.97,
      "grad_norm": 69.5,
      "learning_rate": 6.04551451187335e-05,
      "loss": 1.6719,
      "step": 4525
    },
    {
      "epoch": 5.97,
      "grad_norm": 25.0,
      "learning_rate": 6.04353562005277e-05,
      "loss": 0.2969,
      "step": 4526
    },
    {
      "epoch": 5.97,
      "grad_norm": 24.25,
      "learning_rate": 6.0415567282321896e-05,
      "loss": 0.3203,
      "step": 4527
    },
    {
      "epoch": 5.97,
      "grad_norm": 29.875,
      "learning_rate": 6.039577836411609e-05,
      "loss": 0.75,
      "step": 4528
    },
    {
      "epoch": 5.97,
      "grad_norm": 115.0,
      "learning_rate": 6.0375989445910286e-05,
      "loss": 2.5625,
      "step": 4529
    },
    {
      "epoch": 5.98,
      "grad_norm": 103.0,
      "learning_rate": 6.0356200527704484e-05,
      "loss": 2.8438,
      "step": 4530
    },
    {
      "epoch": 5.98,
      "grad_norm": 71.0,
      "learning_rate": 6.0336411609498675e-05,
      "loss": 1.4375,
      "step": 4531
    },
    {
      "epoch": 5.98,
      "grad_norm": 63.5,
      "learning_rate": 6.031662269129287e-05,
      "loss": 1.2891,
      "step": 4532
    },
    {
      "epoch": 5.98,
      "grad_norm": 63.25,
      "learning_rate": 6.029683377308707e-05,
      "loss": 1.1562,
      "step": 4533
    },
    {
      "epoch": 5.98,
      "grad_norm": 14.9375,
      "learning_rate": 6.027704485488126e-05,
      "loss": 0.1709,
      "step": 4534
    },
    {
      "epoch": 5.98,
      "grad_norm": 30.0,
      "learning_rate": 6.0257255936675454e-05,
      "loss": 0.7461,
      "step": 4535
    },
    {
      "epoch": 5.98,
      "grad_norm": 53.25,
      "learning_rate": 6.0237467018469645e-05,
      "loss": 1.125,
      "step": 4536
    },
    {
      "epoch": 5.99,
      "grad_norm": 47.5,
      "learning_rate": 6.021767810026384e-05,
      "loss": 1.0781,
      "step": 4537
    },
    {
      "epoch": 5.99,
      "grad_norm": 17.75,
      "learning_rate": 6.019788918205804e-05,
      "loss": 0.2734,
      "step": 4538
    },
    {
      "epoch": 5.99,
      "grad_norm": 128.0,
      "learning_rate": 6.017810026385223e-05,
      "loss": 2.8906,
      "step": 4539
    },
    {
      "epoch": 5.99,
      "grad_norm": 25.25,
      "learning_rate": 6.015831134564643e-05,
      "loss": 0.6406,
      "step": 4540
    },
    {
      "epoch": 5.99,
      "grad_norm": 79.5,
      "learning_rate": 6.013852242744063e-05,
      "loss": 1.0234,
      "step": 4541
    },
    {
      "epoch": 5.99,
      "grad_norm": 21.75,
      "learning_rate": 6.011873350923482e-05,
      "loss": 0.2812,
      "step": 4542
    },
    {
      "epoch": 5.99,
      "grad_norm": 111.5,
      "learning_rate": 6.009894459102902e-05,
      "loss": 1.8828,
      "step": 4543
    },
    {
      "epoch": 5.99,
      "grad_norm": 52.0,
      "learning_rate": 6.0079155672823216e-05,
      "loss": 1.0469,
      "step": 4544
    },
    {
      "epoch": 6.0,
      "grad_norm": 55.25,
      "learning_rate": 6.005936675461741e-05,
      "loss": 0.7773,
      "step": 4545
    },
    {
      "epoch": 6.0,
      "grad_norm": 21.0,
      "learning_rate": 6.0039577836411605e-05,
      "loss": 0.291,
      "step": 4546
    },
    {
      "epoch": 6.0,
      "grad_norm": 52.5,
      "learning_rate": 6.0019788918205803e-05,
      "loss": 1.0703,
      "step": 4547
    },
    {
      "epoch": 6.0,
      "grad_norm": 35.25,
      "learning_rate": 5.9999999999999995e-05,
      "loss": 0.5977,
      "step": 4548
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.3001418113708496,
      "eval_runtime": 18.281,
      "eval_samples_per_second": 42.777,
      "eval_steps_per_second": 10.722,
      "step": 4548
    },
    {
      "epoch": 6.0,
      "grad_norm": 9.5625,
      "learning_rate": 5.998021108179419e-05,
      "loss": 0.1094,
      "step": 4549
    },
    {
      "epoch": 6.0,
      "grad_norm": 36.75,
      "learning_rate": 5.9960422163588384e-05,
      "loss": 0.4688,
      "step": 4550
    },
    {
      "epoch": 6.0,
      "grad_norm": 52.25,
      "learning_rate": 5.9940633245382575e-05,
      "loss": 0.5195,
      "step": 4551
    },
    {
      "epoch": 6.01,
      "grad_norm": 33.25,
      "learning_rate": 5.9920844327176773e-05,
      "loss": 0.2793,
      "step": 4552
    },
    {
      "epoch": 6.01,
      "grad_norm": 46.25,
      "learning_rate": 5.990105540897097e-05,
      "loss": 0.6406,
      "step": 4553
    },
    {
      "epoch": 6.01,
      "grad_norm": 26.875,
      "learning_rate": 5.988126649076516e-05,
      "loss": 0.3203,
      "step": 4554
    },
    {
      "epoch": 6.01,
      "grad_norm": 336.0,
      "learning_rate": 5.986147757255936e-05,
      "loss": 7.25,
      "step": 4555
    },
    {
      "epoch": 6.01,
      "grad_norm": 17.75,
      "learning_rate": 5.984168865435356e-05,
      "loss": 0.3281,
      "step": 4556
    },
    {
      "epoch": 6.01,
      "grad_norm": 27.5,
      "learning_rate": 5.982189973614775e-05,
      "loss": 0.2441,
      "step": 4557
    },
    {
      "epoch": 6.01,
      "grad_norm": 35.5,
      "learning_rate": 5.980211081794195e-05,
      "loss": 0.4492,
      "step": 4558
    },
    {
      "epoch": 6.01,
      "grad_norm": 37.75,
      "learning_rate": 5.9782321899736146e-05,
      "loss": 0.3652,
      "step": 4559
    },
    {
      "epoch": 6.02,
      "grad_norm": 25.25,
      "learning_rate": 5.976253298153034e-05,
      "loss": 0.2793,
      "step": 4560
    },
    {
      "epoch": 6.02,
      "grad_norm": 15.25,
      "learning_rate": 5.9742744063324536e-05,
      "loss": 0.1777,
      "step": 4561
    },
    {
      "epoch": 6.02,
      "grad_norm": 174.0,
      "learning_rate": 5.9722955145118734e-05,
      "loss": 3.5938,
      "step": 4562
    },
    {
      "epoch": 6.02,
      "grad_norm": 182.0,
      "learning_rate": 5.9703166226912925e-05,
      "loss": 3.8281,
      "step": 4563
    },
    {
      "epoch": 6.02,
      "grad_norm": 38.0,
      "learning_rate": 5.968337730870712e-05,
      "loss": 0.8438,
      "step": 4564
    },
    {
      "epoch": 6.02,
      "grad_norm": 40.75,
      "learning_rate": 5.966358839050131e-05,
      "loss": 0.2969,
      "step": 4565
    },
    {
      "epoch": 6.02,
      "grad_norm": 197.0,
      "learning_rate": 5.9643799472295506e-05,
      "loss": 4.2812,
      "step": 4566
    },
    {
      "epoch": 6.03,
      "grad_norm": 18.0,
      "learning_rate": 5.9624010554089704e-05,
      "loss": 0.3438,
      "step": 4567
    },
    {
      "epoch": 6.03,
      "grad_norm": 159.0,
      "learning_rate": 5.9604221635883895e-05,
      "loss": 3.1719,
      "step": 4568
    },
    {
      "epoch": 6.03,
      "grad_norm": 93.5,
      "learning_rate": 5.958443271767809e-05,
      "loss": 1.2656,
      "step": 4569
    },
    {
      "epoch": 6.03,
      "grad_norm": 17.5,
      "learning_rate": 5.956464379947229e-05,
      "loss": 0.332,
      "step": 4570
    },
    {
      "epoch": 6.03,
      "grad_norm": 90.5,
      "learning_rate": 5.954485488126648e-05,
      "loss": 1.5391,
      "step": 4571
    },
    {
      "epoch": 6.03,
      "grad_norm": 103.5,
      "learning_rate": 5.952506596306068e-05,
      "loss": 1.3672,
      "step": 4572
    },
    {
      "epoch": 6.03,
      "grad_norm": 25.75,
      "learning_rate": 5.950527704485488e-05,
      "loss": 0.4883,
      "step": 4573
    },
    {
      "epoch": 6.03,
      "grad_norm": 188.0,
      "learning_rate": 5.948548812664907e-05,
      "loss": 2.9688,
      "step": 4574
    },
    {
      "epoch": 6.04,
      "grad_norm": 35.5,
      "learning_rate": 5.946569920844327e-05,
      "loss": 0.5117,
      "step": 4575
    },
    {
      "epoch": 6.04,
      "grad_norm": 94.0,
      "learning_rate": 5.9445910290237466e-05,
      "loss": 1.5703,
      "step": 4576
    },
    {
      "epoch": 6.04,
      "grad_norm": 90.5,
      "learning_rate": 5.942612137203166e-05,
      "loss": 1.3125,
      "step": 4577
    },
    {
      "epoch": 6.04,
      "grad_norm": 80.5,
      "learning_rate": 5.9406332453825855e-05,
      "loss": 1.2734,
      "step": 4578
    },
    {
      "epoch": 6.04,
      "grad_norm": 81.0,
      "learning_rate": 5.938654353562005e-05,
      "loss": 1.3281,
      "step": 4579
    },
    {
      "epoch": 6.04,
      "grad_norm": 136.0,
      "learning_rate": 5.936675461741424e-05,
      "loss": 2.8438,
      "step": 4580
    },
    {
      "epoch": 6.04,
      "grad_norm": 63.75,
      "learning_rate": 5.9346965699208436e-05,
      "loss": 1.125,
      "step": 4581
    },
    {
      "epoch": 6.04,
      "grad_norm": 81.0,
      "learning_rate": 5.932717678100263e-05,
      "loss": 1.2031,
      "step": 4582
    },
    {
      "epoch": 6.05,
      "grad_norm": 61.25,
      "learning_rate": 5.9307387862796825e-05,
      "loss": 0.8945,
      "step": 4583
    },
    {
      "epoch": 6.05,
      "grad_norm": 100.5,
      "learning_rate": 5.928759894459102e-05,
      "loss": 1.1719,
      "step": 4584
    },
    {
      "epoch": 6.05,
      "grad_norm": 147.0,
      "learning_rate": 5.926781002638522e-05,
      "loss": 3.7031,
      "step": 4585
    },
    {
      "epoch": 6.05,
      "grad_norm": 26.25,
      "learning_rate": 5.924802110817941e-05,
      "loss": 0.5938,
      "step": 4586
    },
    {
      "epoch": 6.05,
      "grad_norm": 59.0,
      "learning_rate": 5.922823218997361e-05,
      "loss": 0.8789,
      "step": 4587
    },
    {
      "epoch": 6.05,
      "grad_norm": 18.5,
      "learning_rate": 5.920844327176781e-05,
      "loss": 0.2891,
      "step": 4588
    },
    {
      "epoch": 6.05,
      "grad_norm": 160.0,
      "learning_rate": 5.9188654353562e-05,
      "loss": 3.7188,
      "step": 4589
    },
    {
      "epoch": 6.06,
      "grad_norm": 30.125,
      "learning_rate": 5.91688654353562e-05,
      "loss": 0.4121,
      "step": 4590
    },
    {
      "epoch": 6.06,
      "grad_norm": 37.25,
      "learning_rate": 5.9149076517150396e-05,
      "loss": 0.5352,
      "step": 4591
    },
    {
      "epoch": 6.06,
      "grad_norm": 31.125,
      "learning_rate": 5.912928759894459e-05,
      "loss": 0.6836,
      "step": 4592
    },
    {
      "epoch": 6.06,
      "grad_norm": 144.0,
      "learning_rate": 5.9109498680738785e-05,
      "loss": 3.25,
      "step": 4593
    },
    {
      "epoch": 6.06,
      "grad_norm": 19.0,
      "learning_rate": 5.9089709762532984e-05,
      "loss": 0.6055,
      "step": 4594
    },
    {
      "epoch": 6.06,
      "grad_norm": 35.5,
      "learning_rate": 5.906992084432717e-05,
      "loss": 0.6953,
      "step": 4595
    },
    {
      "epoch": 6.06,
      "grad_norm": 80.0,
      "learning_rate": 5.9050131926121366e-05,
      "loss": 1.0312,
      "step": 4596
    },
    {
      "epoch": 6.06,
      "grad_norm": 29.0,
      "learning_rate": 5.903034300791556e-05,
      "loss": 1.0938,
      "step": 4597
    },
    {
      "epoch": 6.07,
      "grad_norm": 128.0,
      "learning_rate": 5.9010554089709755e-05,
      "loss": 3.6875,
      "step": 4598
    },
    {
      "epoch": 6.07,
      "grad_norm": 20.75,
      "learning_rate": 5.8990765171503953e-05,
      "loss": 0.3027,
      "step": 4599
    },
    {
      "epoch": 6.07,
      "grad_norm": 123.5,
      "learning_rate": 5.8970976253298145e-05,
      "loss": 3.4375,
      "step": 4600
    },
    {
      "epoch": 6.07,
      "grad_norm": 20.25,
      "learning_rate": 5.895118733509234e-05,
      "loss": 0.3672,
      "step": 4601
    },
    {
      "epoch": 6.07,
      "grad_norm": 33.0,
      "learning_rate": 5.893139841688654e-05,
      "loss": 0.457,
      "step": 4602
    },
    {
      "epoch": 6.07,
      "grad_norm": 36.75,
      "learning_rate": 5.891160949868073e-05,
      "loss": 0.5039,
      "step": 4603
    },
    {
      "epoch": 6.07,
      "grad_norm": 32.25,
      "learning_rate": 5.889182058047493e-05,
      "loss": 0.4805,
      "step": 4604
    },
    {
      "epoch": 6.08,
      "grad_norm": 123.5,
      "learning_rate": 5.887203166226913e-05,
      "loss": 3.5469,
      "step": 4605
    },
    {
      "epoch": 6.08,
      "grad_norm": 119.5,
      "learning_rate": 5.885224274406332e-05,
      "loss": 2.6562,
      "step": 4606
    },
    {
      "epoch": 6.08,
      "grad_norm": 130.0,
      "learning_rate": 5.883245382585752e-05,
      "loss": 3.375,
      "step": 4607
    },
    {
      "epoch": 6.08,
      "grad_norm": 102.5,
      "learning_rate": 5.8812664907651716e-05,
      "loss": 3.2344,
      "step": 4608
    },
    {
      "epoch": 6.08,
      "grad_norm": 33.5,
      "learning_rate": 5.879287598944591e-05,
      "loss": 0.2256,
      "step": 4609
    },
    {
      "epoch": 6.08,
      "grad_norm": 108.0,
      "learning_rate": 5.87730870712401e-05,
      "loss": 3.0625,
      "step": 4610
    },
    {
      "epoch": 6.08,
      "grad_norm": 193.0,
      "learning_rate": 5.875329815303429e-05,
      "loss": 3.8281,
      "step": 4611
    },
    {
      "epoch": 6.08,
      "grad_norm": 22.125,
      "learning_rate": 5.873350923482849e-05,
      "loss": 0.6562,
      "step": 4612
    },
    {
      "epoch": 6.09,
      "grad_norm": 49.0,
      "learning_rate": 5.8713720316622686e-05,
      "loss": 1.1484,
      "step": 4613
    },
    {
      "epoch": 6.09,
      "grad_norm": 143.0,
      "learning_rate": 5.869393139841688e-05,
      "loss": 3.1719,
      "step": 4614
    },
    {
      "epoch": 6.09,
      "grad_norm": 79.0,
      "learning_rate": 5.8674142480211075e-05,
      "loss": 1.4922,
      "step": 4615
    },
    {
      "epoch": 6.09,
      "grad_norm": 33.25,
      "learning_rate": 5.865435356200527e-05,
      "loss": 0.5898,
      "step": 4616
    },
    {
      "epoch": 6.09,
      "grad_norm": 22.75,
      "learning_rate": 5.8634564643799464e-05,
      "loss": 0.4141,
      "step": 4617
    },
    {
      "epoch": 6.09,
      "grad_norm": 73.0,
      "learning_rate": 5.861477572559366e-05,
      "loss": 1.5625,
      "step": 4618
    },
    {
      "epoch": 6.09,
      "grad_norm": 29.25,
      "learning_rate": 5.859498680738786e-05,
      "loss": 0.4316,
      "step": 4619
    },
    {
      "epoch": 6.09,
      "grad_norm": 62.75,
      "learning_rate": 5.857519788918205e-05,
      "loss": 1.4609,
      "step": 4620
    },
    {
      "epoch": 6.1,
      "grad_norm": 27.375,
      "learning_rate": 5.855540897097625e-05,
      "loss": 0.4199,
      "step": 4621
    },
    {
      "epoch": 6.1,
      "grad_norm": 19.125,
      "learning_rate": 5.853562005277045e-05,
      "loss": 0.3359,
      "step": 4622
    },
    {
      "epoch": 6.1,
      "grad_norm": 27.25,
      "learning_rate": 5.851583113456464e-05,
      "loss": 0.377,
      "step": 4623
    },
    {
      "epoch": 6.1,
      "grad_norm": 27.25,
      "learning_rate": 5.849604221635884e-05,
      "loss": 0.7031,
      "step": 4624
    },
    {
      "epoch": 6.1,
      "grad_norm": 30.875,
      "learning_rate": 5.847625329815303e-05,
      "loss": 0.373,
      "step": 4625
    },
    {
      "epoch": 6.1,
      "grad_norm": 65.5,
      "learning_rate": 5.845646437994722e-05,
      "loss": 1.6172,
      "step": 4626
    },
    {
      "epoch": 6.1,
      "grad_norm": 14.875,
      "learning_rate": 5.843667546174142e-05,
      "loss": 0.1758,
      "step": 4627
    },
    {
      "epoch": 6.11,
      "grad_norm": 18.375,
      "learning_rate": 5.8416886543535616e-05,
      "loss": 0.2295,
      "step": 4628
    },
    {
      "epoch": 6.11,
      "grad_norm": 141.0,
      "learning_rate": 5.839709762532981e-05,
      "loss": 3.2656,
      "step": 4629
    },
    {
      "epoch": 6.11,
      "grad_norm": 6.5,
      "learning_rate": 5.8377308707124005e-05,
      "loss": 0.1001,
      "step": 4630
    },
    {
      "epoch": 6.11,
      "grad_norm": 9.75,
      "learning_rate": 5.83575197889182e-05,
      "loss": 0.1108,
      "step": 4631
    },
    {
      "epoch": 6.11,
      "grad_norm": 6.625,
      "learning_rate": 5.8337730870712395e-05,
      "loss": 0.0889,
      "step": 4632
    },
    {
      "epoch": 6.11,
      "grad_norm": 180.0,
      "learning_rate": 5.831794195250659e-05,
      "loss": 4.625,
      "step": 4633
    },
    {
      "epoch": 6.11,
      "grad_norm": 27.125,
      "learning_rate": 5.829815303430079e-05,
      "loss": 0.4824,
      "step": 4634
    },
    {
      "epoch": 6.11,
      "grad_norm": 34.0,
      "learning_rate": 5.827836411609498e-05,
      "loss": 0.7109,
      "step": 4635
    },
    {
      "epoch": 6.12,
      "grad_norm": 143.0,
      "learning_rate": 5.825857519788918e-05,
      "loss": 5.375,
      "step": 4636
    },
    {
      "epoch": 6.12,
      "grad_norm": 218.0,
      "learning_rate": 5.823878627968338e-05,
      "loss": 3.9844,
      "step": 4637
    },
    {
      "epoch": 6.12,
      "grad_norm": 192.0,
      "learning_rate": 5.821899736147757e-05,
      "loss": 4.4688,
      "step": 4638
    },
    {
      "epoch": 6.12,
      "grad_norm": 82.5,
      "learning_rate": 5.819920844327177e-05,
      "loss": 1.8828,
      "step": 4639
    },
    {
      "epoch": 6.12,
      "grad_norm": 50.0,
      "learning_rate": 5.817941952506595e-05,
      "loss": 0.7148,
      "step": 4640
    },
    {
      "epoch": 6.12,
      "grad_norm": 87.0,
      "learning_rate": 5.815963060686015e-05,
      "loss": 1.7734,
      "step": 4641
    },
    {
      "epoch": 6.12,
      "grad_norm": 137.0,
      "learning_rate": 5.813984168865435e-05,
      "loss": 2.7812,
      "step": 4642
    },
    {
      "epoch": 6.13,
      "grad_norm": 171.0,
      "learning_rate": 5.812005277044854e-05,
      "loss": 5.9062,
      "step": 4643
    },
    {
      "epoch": 6.13,
      "grad_norm": 2.609375,
      "learning_rate": 5.810026385224274e-05,
      "loss": 0.0349,
      "step": 4644
    },
    {
      "epoch": 6.13,
      "grad_norm": 24.625,
      "learning_rate": 5.8080474934036935e-05,
      "loss": 0.5234,
      "step": 4645
    },
    {
      "epoch": 6.13,
      "grad_norm": 12.0625,
      "learning_rate": 5.806068601583113e-05,
      "loss": 0.1338,
      "step": 4646
    },
    {
      "epoch": 6.13,
      "grad_norm": 12.8125,
      "learning_rate": 5.8040897097625325e-05,
      "loss": 0.1211,
      "step": 4647
    },
    {
      "epoch": 6.13,
      "grad_norm": 109.0,
      "learning_rate": 5.802110817941952e-05,
      "loss": 3.375,
      "step": 4648
    },
    {
      "epoch": 6.13,
      "grad_norm": 101.5,
      "learning_rate": 5.8001319261213714e-05,
      "loss": 1.7656,
      "step": 4649
    },
    {
      "epoch": 6.13,
      "grad_norm": 27.5,
      "learning_rate": 5.798153034300791e-05,
      "loss": 0.1816,
      "step": 4650
    },
    {
      "epoch": 6.14,
      "grad_norm": 48.75,
      "learning_rate": 5.796174142480211e-05,
      "loss": 1.1016,
      "step": 4651
    },
    {
      "epoch": 6.14,
      "grad_norm": 90.0,
      "learning_rate": 5.79419525065963e-05,
      "loss": 1.5234,
      "step": 4652
    },
    {
      "epoch": 6.14,
      "grad_norm": 50.5,
      "learning_rate": 5.79221635883905e-05,
      "loss": 1.0469,
      "step": 4653
    },
    {
      "epoch": 6.14,
      "grad_norm": 18.375,
      "learning_rate": 5.79023746701847e-05,
      "loss": 0.1943,
      "step": 4654
    },
    {
      "epoch": 6.14,
      "grad_norm": 11.375,
      "learning_rate": 5.788258575197888e-05,
      "loss": 0.1328,
      "step": 4655
    },
    {
      "epoch": 6.14,
      "grad_norm": 83.0,
      "learning_rate": 5.786279683377308e-05,
      "loss": 1.4453,
      "step": 4656
    },
    {
      "epoch": 6.14,
      "grad_norm": 159.0,
      "learning_rate": 5.784300791556727e-05,
      "loss": 4.5625,
      "step": 4657
    },
    {
      "epoch": 6.15,
      "grad_norm": 14.6875,
      "learning_rate": 5.782321899736147e-05,
      "loss": 0.1104,
      "step": 4658
    },
    {
      "epoch": 6.15,
      "grad_norm": 35.5,
      "learning_rate": 5.780343007915567e-05,
      "loss": 0.5156,
      "step": 4659
    },
    {
      "epoch": 6.15,
      "grad_norm": 150.0,
      "learning_rate": 5.778364116094986e-05,
      "loss": 4.9062,
      "step": 4660
    },
    {
      "epoch": 6.15,
      "grad_norm": 51.25,
      "learning_rate": 5.776385224274406e-05,
      "loss": 0.6641,
      "step": 4661
    },
    {
      "epoch": 6.15,
      "grad_norm": 17.125,
      "learning_rate": 5.7744063324538255e-05,
      "loss": 0.21,
      "step": 4662
    },
    {
      "epoch": 6.15,
      "grad_norm": 27.0,
      "learning_rate": 5.7724274406332446e-05,
      "loss": 0.2715,
      "step": 4663
    },
    {
      "epoch": 6.15,
      "grad_norm": 190.0,
      "learning_rate": 5.7704485488126644e-05,
      "loss": 2.7031,
      "step": 4664
    },
    {
      "epoch": 6.15,
      "grad_norm": 89.5,
      "learning_rate": 5.768469656992084e-05,
      "loss": 1.3203,
      "step": 4665
    },
    {
      "epoch": 6.16,
      "grad_norm": 30.875,
      "learning_rate": 5.7664907651715034e-05,
      "loss": 0.3516,
      "step": 4666
    },
    {
      "epoch": 6.16,
      "grad_norm": 154.0,
      "learning_rate": 5.764511873350923e-05,
      "loss": 3.2656,
      "step": 4667
    },
    {
      "epoch": 6.16,
      "grad_norm": 145.0,
      "learning_rate": 5.762532981530343e-05,
      "loss": 2.375,
      "step": 4668
    },
    {
      "epoch": 6.16,
      "grad_norm": 107.0,
      "learning_rate": 5.760554089709762e-05,
      "loss": 1.7656,
      "step": 4669
    },
    {
      "epoch": 6.16,
      "grad_norm": 136.0,
      "learning_rate": 5.758575197889181e-05,
      "loss": 2.6719,
      "step": 4670
    },
    {
      "epoch": 6.16,
      "grad_norm": 25.875,
      "learning_rate": 5.756596306068601e-05,
      "loss": 0.5156,
      "step": 4671
    },
    {
      "epoch": 6.16,
      "grad_norm": 95.5,
      "learning_rate": 5.75461741424802e-05,
      "loss": 1.4297,
      "step": 4672
    },
    {
      "epoch": 6.16,
      "grad_norm": 135.0,
      "learning_rate": 5.75263852242744e-05,
      "loss": 2.7344,
      "step": 4673
    },
    {
      "epoch": 6.17,
      "grad_norm": 15.625,
      "learning_rate": 5.75065963060686e-05,
      "loss": 0.1924,
      "step": 4674
    },
    {
      "epoch": 6.17,
      "grad_norm": 13.9375,
      "learning_rate": 5.748680738786279e-05,
      "loss": 0.2539,
      "step": 4675
    },
    {
      "epoch": 6.17,
      "grad_norm": 18.5,
      "learning_rate": 5.746701846965699e-05,
      "loss": 0.3438,
      "step": 4676
    },
    {
      "epoch": 6.17,
      "grad_norm": 36.25,
      "learning_rate": 5.7447229551451185e-05,
      "loss": 0.5117,
      "step": 4677
    },
    {
      "epoch": 6.17,
      "grad_norm": 88.0,
      "learning_rate": 5.7427440633245377e-05,
      "loss": 1.1719,
      "step": 4678
    },
    {
      "epoch": 6.17,
      "grad_norm": 91.0,
      "learning_rate": 5.7407651715039575e-05,
      "loss": 1.6719,
      "step": 4679
    },
    {
      "epoch": 6.17,
      "grad_norm": 20.5,
      "learning_rate": 5.738786279683377e-05,
      "loss": 0.4961,
      "step": 4680
    },
    {
      "epoch": 6.18,
      "grad_norm": 17.0,
      "learning_rate": 5.7368073878627964e-05,
      "loss": 0.2002,
      "step": 4681
    },
    {
      "epoch": 6.18,
      "grad_norm": 21.375,
      "learning_rate": 5.734828496042216e-05,
      "loss": 0.2598,
      "step": 4682
    },
    {
      "epoch": 6.18,
      "grad_norm": 195.0,
      "learning_rate": 5.732849604221636e-05,
      "loss": 4.75,
      "step": 4683
    },
    {
      "epoch": 6.18,
      "grad_norm": 211.0,
      "learning_rate": 5.730870712401055e-05,
      "loss": 5.2812,
      "step": 4684
    },
    {
      "epoch": 6.18,
      "grad_norm": 13.8125,
      "learning_rate": 5.728891820580474e-05,
      "loss": 0.1953,
      "step": 4685
    },
    {
      "epoch": 6.18,
      "grad_norm": 162.0,
      "learning_rate": 5.7269129287598934e-05,
      "loss": 3.4688,
      "step": 4686
    },
    {
      "epoch": 6.18,
      "grad_norm": 122.0,
      "learning_rate": 5.724934036939313e-05,
      "loss": 3.1406,
      "step": 4687
    },
    {
      "epoch": 6.18,
      "grad_norm": 74.5,
      "learning_rate": 5.722955145118733e-05,
      "loss": 2.1094,
      "step": 4688
    },
    {
      "epoch": 6.19,
      "grad_norm": 95.5,
      "learning_rate": 5.720976253298152e-05,
      "loss": 1.9531,
      "step": 4689
    },
    {
      "epoch": 6.19,
      "grad_norm": 137.0,
      "learning_rate": 5.718997361477572e-05,
      "loss": 3.3438,
      "step": 4690
    },
    {
      "epoch": 6.19,
      "grad_norm": 14.3125,
      "learning_rate": 5.717018469656992e-05,
      "loss": 0.1289,
      "step": 4691
    },
    {
      "epoch": 6.19,
      "grad_norm": 73.0,
      "learning_rate": 5.715039577836411e-05,
      "loss": 1.4922,
      "step": 4692
    },
    {
      "epoch": 6.19,
      "grad_norm": 29.5,
      "learning_rate": 5.713060686015831e-05,
      "loss": 0.5859,
      "step": 4693
    },
    {
      "epoch": 6.19,
      "grad_norm": 30.625,
      "learning_rate": 5.7110817941952505e-05,
      "loss": 0.2676,
      "step": 4694
    },
    {
      "epoch": 6.19,
      "grad_norm": 21.125,
      "learning_rate": 5.7091029023746696e-05,
      "loss": 0.3867,
      "step": 4695
    },
    {
      "epoch": 6.2,
      "grad_norm": 20.25,
      "learning_rate": 5.7071240105540894e-05,
      "loss": 0.1953,
      "step": 4696
    },
    {
      "epoch": 6.2,
      "grad_norm": 21.625,
      "learning_rate": 5.705145118733509e-05,
      "loss": 0.2188,
      "step": 4697
    },
    {
      "epoch": 6.2,
      "grad_norm": 17.125,
      "learning_rate": 5.7031662269129284e-05,
      "loss": 0.3789,
      "step": 4698
    },
    {
      "epoch": 6.2,
      "grad_norm": 85.5,
      "learning_rate": 5.701187335092348e-05,
      "loss": 1.2656,
      "step": 4699
    },
    {
      "epoch": 6.2,
      "grad_norm": 11.625,
      "learning_rate": 5.6992084432717666e-05,
      "loss": 0.1523,
      "step": 4700
    },
    {
      "epoch": 6.2,
      "grad_norm": 20.375,
      "learning_rate": 5.6972295514511864e-05,
      "loss": 0.1924,
      "step": 4701
    },
    {
      "epoch": 6.2,
      "grad_norm": 154.0,
      "learning_rate": 5.695250659630606e-05,
      "loss": 3.1562,
      "step": 4702
    },
    {
      "epoch": 6.2,
      "grad_norm": 17.0,
      "learning_rate": 5.6932717678100254e-05,
      "loss": 0.1299,
      "step": 4703
    },
    {
      "epoch": 6.21,
      "grad_norm": 19.125,
      "learning_rate": 5.691292875989445e-05,
      "loss": 0.1758,
      "step": 4704
    },
    {
      "epoch": 6.21,
      "grad_norm": 20.0,
      "learning_rate": 5.689313984168865e-05,
      "loss": 0.4707,
      "step": 4705
    },
    {
      "epoch": 6.21,
      "grad_norm": 23.0,
      "learning_rate": 5.687335092348284e-05,
      "loss": 0.4824,
      "step": 4706
    },
    {
      "epoch": 6.21,
      "grad_norm": 16.625,
      "learning_rate": 5.685356200527704e-05,
      "loss": 0.1533,
      "step": 4707
    },
    {
      "epoch": 6.21,
      "grad_norm": 30.125,
      "learning_rate": 5.683377308707124e-05,
      "loss": 0.6719,
      "step": 4708
    },
    {
      "epoch": 6.21,
      "grad_norm": 88.0,
      "learning_rate": 5.681398416886543e-05,
      "loss": 1.7891,
      "step": 4709
    },
    {
      "epoch": 6.21,
      "grad_norm": 21.625,
      "learning_rate": 5.6794195250659626e-05,
      "loss": 0.4238,
      "step": 4710
    },
    {
      "epoch": 6.22,
      "grad_norm": 39.0,
      "learning_rate": 5.6774406332453824e-05,
      "loss": 0.9922,
      "step": 4711
    },
    {
      "epoch": 6.22,
      "grad_norm": 115.0,
      "learning_rate": 5.6754617414248016e-05,
      "loss": 2.375,
      "step": 4712
    },
    {
      "epoch": 6.22,
      "grad_norm": 15.25,
      "learning_rate": 5.6734828496042214e-05,
      "loss": 0.7422,
      "step": 4713
    },
    {
      "epoch": 6.22,
      "grad_norm": 15.875,
      "learning_rate": 5.671503957783641e-05,
      "loss": 0.3418,
      "step": 4714
    },
    {
      "epoch": 6.22,
      "grad_norm": 91.0,
      "learning_rate": 5.6695250659630596e-05,
      "loss": 1.7188,
      "step": 4715
    },
    {
      "epoch": 6.22,
      "grad_norm": 171.0,
      "learning_rate": 5.6675461741424794e-05,
      "loss": 3.1094,
      "step": 4716
    },
    {
      "epoch": 6.22,
      "grad_norm": 84.5,
      "learning_rate": 5.665567282321899e-05,
      "loss": 1.7656,
      "step": 4717
    },
    {
      "epoch": 6.22,
      "grad_norm": 142.0,
      "learning_rate": 5.6635883905013184e-05,
      "loss": 3.2031,
      "step": 4718
    },
    {
      "epoch": 6.23,
      "grad_norm": 11.3125,
      "learning_rate": 5.661609498680738e-05,
      "loss": 0.1309,
      "step": 4719
    },
    {
      "epoch": 6.23,
      "grad_norm": 19.0,
      "learning_rate": 5.659630606860158e-05,
      "loss": 0.2041,
      "step": 4720
    },
    {
      "epoch": 6.23,
      "grad_norm": 50.75,
      "learning_rate": 5.657651715039577e-05,
      "loss": 0.6484,
      "step": 4721
    },
    {
      "epoch": 6.23,
      "grad_norm": 43.75,
      "learning_rate": 5.655672823218997e-05,
      "loss": 0.5547,
      "step": 4722
    },
    {
      "epoch": 6.23,
      "grad_norm": 25.875,
      "learning_rate": 5.653693931398417e-05,
      "loss": 0.6641,
      "step": 4723
    },
    {
      "epoch": 6.23,
      "grad_norm": 17.25,
      "learning_rate": 5.651715039577836e-05,
      "loss": 0.125,
      "step": 4724
    },
    {
      "epoch": 6.23,
      "grad_norm": 94.0,
      "learning_rate": 5.6497361477572557e-05,
      "loss": 1.8984,
      "step": 4725
    },
    {
      "epoch": 6.23,
      "grad_norm": 143.0,
      "learning_rate": 5.6477572559366755e-05,
      "loss": 3.5469,
      "step": 4726
    },
    {
      "epoch": 6.24,
      "grad_norm": 15.375,
      "learning_rate": 5.6457783641160946e-05,
      "loss": 0.3672,
      "step": 4727
    },
    {
      "epoch": 6.24,
      "grad_norm": 17.5,
      "learning_rate": 5.6437994722955144e-05,
      "loss": 0.1719,
      "step": 4728
    },
    {
      "epoch": 6.24,
      "grad_norm": 11.3125,
      "learning_rate": 5.641820580474934e-05,
      "loss": 0.2324,
      "step": 4729
    },
    {
      "epoch": 6.24,
      "grad_norm": 198.0,
      "learning_rate": 5.6398416886543527e-05,
      "loss": 5.6875,
      "step": 4730
    },
    {
      "epoch": 6.24,
      "grad_norm": 28.0,
      "learning_rate": 5.6378627968337725e-05,
      "loss": 0.4238,
      "step": 4731
    },
    {
      "epoch": 6.24,
      "grad_norm": 168.0,
      "learning_rate": 5.6358839050131916e-05,
      "loss": 3.5938,
      "step": 4732
    },
    {
      "epoch": 6.24,
      "grad_norm": 167.0,
      "learning_rate": 5.6339050131926114e-05,
      "loss": 4.5,
      "step": 4733
    },
    {
      "epoch": 6.25,
      "grad_norm": 13.9375,
      "learning_rate": 5.631926121372031e-05,
      "loss": 0.1455,
      "step": 4734
    },
    {
      "epoch": 6.25,
      "grad_norm": 165.0,
      "learning_rate": 5.62994722955145e-05,
      "loss": 3.4844,
      "step": 4735
    },
    {
      "epoch": 6.25,
      "grad_norm": 19.5,
      "learning_rate": 5.62796833773087e-05,
      "loss": 0.2197,
      "step": 4736
    },
    {
      "epoch": 6.25,
      "grad_norm": 31.625,
      "learning_rate": 5.62598944591029e-05,
      "loss": 0.4766,
      "step": 4737
    },
    {
      "epoch": 6.25,
      "grad_norm": 79.0,
      "learning_rate": 5.624010554089709e-05,
      "loss": 1.5781,
      "step": 4738
    },
    {
      "epoch": 6.25,
      "grad_norm": 4.9375,
      "learning_rate": 5.622031662269129e-05,
      "loss": 0.0635,
      "step": 4739
    },
    {
      "epoch": 6.25,
      "grad_norm": 35.5,
      "learning_rate": 5.620052770448549e-05,
      "loss": 0.668,
      "step": 4740
    },
    {
      "epoch": 6.25,
      "grad_norm": 156.0,
      "learning_rate": 5.618073878627968e-05,
      "loss": 3.9531,
      "step": 4741
    },
    {
      "epoch": 6.26,
      "grad_norm": 10.0625,
      "learning_rate": 5.6160949868073876e-05,
      "loss": 0.1719,
      "step": 4742
    },
    {
      "epoch": 6.26,
      "grad_norm": 102.0,
      "learning_rate": 5.6141160949868074e-05,
      "loss": 2.4219,
      "step": 4743
    },
    {
      "epoch": 6.26,
      "grad_norm": 82.0,
      "learning_rate": 5.6121372031662266e-05,
      "loss": 1.3125,
      "step": 4744
    },
    {
      "epoch": 6.26,
      "grad_norm": 147.0,
      "learning_rate": 5.6101583113456464e-05,
      "loss": 3.3125,
      "step": 4745
    },
    {
      "epoch": 6.26,
      "grad_norm": 31.375,
      "learning_rate": 5.608179419525065e-05,
      "loss": 0.4062,
      "step": 4746
    },
    {
      "epoch": 6.26,
      "grad_norm": 12.625,
      "learning_rate": 5.6062005277044846e-05,
      "loss": 0.1104,
      "step": 4747
    },
    {
      "epoch": 6.26,
      "grad_norm": 18.625,
      "learning_rate": 5.6042216358839044e-05,
      "loss": 0.1924,
      "step": 4748
    },
    {
      "epoch": 6.27,
      "grad_norm": 88.5,
      "learning_rate": 5.6022427440633235e-05,
      "loss": 1.5625,
      "step": 4749
    },
    {
      "epoch": 6.27,
      "grad_norm": 288.0,
      "learning_rate": 5.6002638522427434e-05,
      "loss": 6.25,
      "step": 4750
    },
    {
      "epoch": 6.27,
      "grad_norm": 90.0,
      "learning_rate": 5.598284960422163e-05,
      "loss": 1.7109,
      "step": 4751
    },
    {
      "epoch": 6.27,
      "grad_norm": 28.75,
      "learning_rate": 5.596306068601582e-05,
      "loss": 0.6328,
      "step": 4752
    },
    {
      "epoch": 6.27,
      "grad_norm": 16.75,
      "learning_rate": 5.594327176781002e-05,
      "loss": 0.3242,
      "step": 4753
    },
    {
      "epoch": 6.27,
      "grad_norm": 184.0,
      "learning_rate": 5.592348284960422e-05,
      "loss": 3.0625,
      "step": 4754
    },
    {
      "epoch": 6.27,
      "grad_norm": 153.0,
      "learning_rate": 5.590369393139841e-05,
      "loss": 3.8125,
      "step": 4755
    },
    {
      "epoch": 6.27,
      "grad_norm": 153.0,
      "learning_rate": 5.588390501319261e-05,
      "loss": 3.7344,
      "step": 4756
    },
    {
      "epoch": 6.28,
      "grad_norm": 27.5,
      "learning_rate": 5.5864116094986806e-05,
      "loss": 0.3438,
      "step": 4757
    },
    {
      "epoch": 6.28,
      "grad_norm": 146.0,
      "learning_rate": 5.5844327176781e-05,
      "loss": 4.0938,
      "step": 4758
    },
    {
      "epoch": 6.28,
      "grad_norm": 155.0,
      "learning_rate": 5.5824538258575196e-05,
      "loss": 3.3281,
      "step": 4759
    },
    {
      "epoch": 6.28,
      "grad_norm": 83.5,
      "learning_rate": 5.5804749340369394e-05,
      "loss": 1.5391,
      "step": 4760
    },
    {
      "epoch": 6.28,
      "grad_norm": 31.0,
      "learning_rate": 5.578496042216358e-05,
      "loss": 0.4844,
      "step": 4761
    },
    {
      "epoch": 6.28,
      "grad_norm": 21.25,
      "learning_rate": 5.5765171503957776e-05,
      "loss": 0.3496,
      "step": 4762
    },
    {
      "epoch": 6.28,
      "grad_norm": 24.0,
      "learning_rate": 5.5745382585751974e-05,
      "loss": 0.4473,
      "step": 4763
    },
    {
      "epoch": 6.28,
      "grad_norm": 56.75,
      "learning_rate": 5.5725593667546166e-05,
      "loss": 0.5234,
      "step": 4764
    },
    {
      "epoch": 6.29,
      "grad_norm": 288.0,
      "learning_rate": 5.5705804749340364e-05,
      "loss": 6.3438,
      "step": 4765
    },
    {
      "epoch": 6.29,
      "grad_norm": 30.0,
      "learning_rate": 5.568601583113456e-05,
      "loss": 0.4238,
      "step": 4766
    },
    {
      "epoch": 6.29,
      "grad_norm": 22.0,
      "learning_rate": 5.566622691292875e-05,
      "loss": 0.2832,
      "step": 4767
    },
    {
      "epoch": 6.29,
      "grad_norm": 32.0,
      "learning_rate": 5.564643799472295e-05,
      "loss": 0.6523,
      "step": 4768
    },
    {
      "epoch": 6.29,
      "grad_norm": 13.9375,
      "learning_rate": 5.562664907651715e-05,
      "loss": 0.2207,
      "step": 4769
    },
    {
      "epoch": 6.29,
      "grad_norm": 9.5,
      "learning_rate": 5.560686015831134e-05,
      "loss": 0.1187,
      "step": 4770
    },
    {
      "epoch": 6.29,
      "grad_norm": 14.8125,
      "learning_rate": 5.558707124010554e-05,
      "loss": 0.126,
      "step": 4771
    },
    {
      "epoch": 6.3,
      "grad_norm": 167.0,
      "learning_rate": 5.556728232189974e-05,
      "loss": 2.625,
      "step": 4772
    },
    {
      "epoch": 6.3,
      "grad_norm": 169.0,
      "learning_rate": 5.554749340369393e-05,
      "loss": 3.5781,
      "step": 4773
    },
    {
      "epoch": 6.3,
      "grad_norm": 142.0,
      "learning_rate": 5.5527704485488126e-05,
      "loss": 4.6562,
      "step": 4774
    },
    {
      "epoch": 6.3,
      "grad_norm": 12.25,
      "learning_rate": 5.5507915567282324e-05,
      "loss": 0.2021,
      "step": 4775
    },
    {
      "epoch": 6.3,
      "grad_norm": 21.5,
      "learning_rate": 5.548812664907651e-05,
      "loss": 0.2363,
      "step": 4776
    },
    {
      "epoch": 6.3,
      "grad_norm": 19.5,
      "learning_rate": 5.546833773087071e-05,
      "loss": 0.5195,
      "step": 4777
    },
    {
      "epoch": 6.3,
      "grad_norm": 14.3125,
      "learning_rate": 5.54485488126649e-05,
      "loss": 0.209,
      "step": 4778
    },
    {
      "epoch": 6.3,
      "grad_norm": 21.625,
      "learning_rate": 5.5428759894459096e-05,
      "loss": 0.2305,
      "step": 4779
    },
    {
      "epoch": 6.31,
      "grad_norm": 19.375,
      "learning_rate": 5.5408970976253294e-05,
      "loss": 0.3633,
      "step": 4780
    },
    {
      "epoch": 6.31,
      "grad_norm": 4.90625,
      "learning_rate": 5.5389182058047485e-05,
      "loss": 0.0708,
      "step": 4781
    },
    {
      "epoch": 6.31,
      "grad_norm": 12.8125,
      "learning_rate": 5.536939313984168e-05,
      "loss": 0.1226,
      "step": 4782
    },
    {
      "epoch": 6.31,
      "grad_norm": 67.0,
      "learning_rate": 5.534960422163588e-05,
      "loss": 1.2891,
      "step": 4783
    },
    {
      "epoch": 6.31,
      "grad_norm": 29.75,
      "learning_rate": 5.532981530343007e-05,
      "loss": 0.4082,
      "step": 4784
    },
    {
      "epoch": 6.31,
      "grad_norm": 322.0,
      "learning_rate": 5.531002638522427e-05,
      "loss": 7.8125,
      "step": 4785
    },
    {
      "epoch": 6.31,
      "grad_norm": 25.375,
      "learning_rate": 5.529023746701847e-05,
      "loss": 0.3867,
      "step": 4786
    },
    {
      "epoch": 6.32,
      "grad_norm": 251.0,
      "learning_rate": 5.527044854881266e-05,
      "loss": 4.4688,
      "step": 4787
    },
    {
      "epoch": 6.32,
      "grad_norm": 134.0,
      "learning_rate": 5.525065963060686e-05,
      "loss": 2.9688,
      "step": 4788
    },
    {
      "epoch": 6.32,
      "grad_norm": 142.0,
      "learning_rate": 5.5230870712401056e-05,
      "loss": 3.1094,
      "step": 4789
    },
    {
      "epoch": 6.32,
      "grad_norm": 181.0,
      "learning_rate": 5.521108179419525e-05,
      "loss": 6.375,
      "step": 4790
    },
    {
      "epoch": 6.32,
      "grad_norm": 11.25,
      "learning_rate": 5.519129287598944e-05,
      "loss": 0.0835,
      "step": 4791
    },
    {
      "epoch": 6.32,
      "grad_norm": 89.5,
      "learning_rate": 5.517150395778363e-05,
      "loss": 1.8828,
      "step": 4792
    },
    {
      "epoch": 6.32,
      "grad_norm": 21.5,
      "learning_rate": 5.515171503957783e-05,
      "loss": 0.209,
      "step": 4793
    },
    {
      "epoch": 6.32,
      "grad_norm": 21.125,
      "learning_rate": 5.5131926121372026e-05,
      "loss": 0.2969,
      "step": 4794
    },
    {
      "epoch": 6.33,
      "grad_norm": 109.0,
      "learning_rate": 5.511213720316622e-05,
      "loss": 4.875,
      "step": 4795
    },
    {
      "epoch": 6.33,
      "grad_norm": 80.0,
      "learning_rate": 5.5092348284960416e-05,
      "loss": 1.3828,
      "step": 4796
    },
    {
      "epoch": 6.33,
      "grad_norm": 4.40625,
      "learning_rate": 5.5072559366754614e-05,
      "loss": 0.0659,
      "step": 4797
    },
    {
      "epoch": 6.33,
      "grad_norm": 8.125,
      "learning_rate": 5.5052770448548805e-05,
      "loss": 0.0967,
      "step": 4798
    },
    {
      "epoch": 6.33,
      "grad_norm": 135.0,
      "learning_rate": 5.5032981530343e-05,
      "loss": 2.7344,
      "step": 4799
    },
    {
      "epoch": 6.33,
      "grad_norm": 22.25,
      "learning_rate": 5.50131926121372e-05,
      "loss": 0.7773,
      "step": 4800
    },
    {
      "epoch": 6.33,
      "grad_norm": 55.25,
      "learning_rate": 5.499340369393139e-05,
      "loss": 0.6094,
      "step": 4801
    },
    {
      "epoch": 6.34,
      "grad_norm": 152.0,
      "learning_rate": 5.497361477572559e-05,
      "loss": 3.2812,
      "step": 4802
    },
    {
      "epoch": 6.34,
      "grad_norm": 144.0,
      "learning_rate": 5.495382585751979e-05,
      "loss": 3.5312,
      "step": 4803
    },
    {
      "epoch": 6.34,
      "grad_norm": 16.375,
      "learning_rate": 5.493403693931398e-05,
      "loss": 0.2246,
      "step": 4804
    },
    {
      "epoch": 6.34,
      "grad_norm": 214.0,
      "learning_rate": 5.491424802110818e-05,
      "loss": 3.75,
      "step": 4805
    },
    {
      "epoch": 6.34,
      "grad_norm": 6.25,
      "learning_rate": 5.489445910290237e-05,
      "loss": 0.0679,
      "step": 4806
    },
    {
      "epoch": 6.34,
      "grad_norm": 132.0,
      "learning_rate": 5.487467018469656e-05,
      "loss": 4.25,
      "step": 4807
    },
    {
      "epoch": 6.34,
      "grad_norm": 41.25,
      "learning_rate": 5.485488126649076e-05,
      "loss": 0.373,
      "step": 4808
    },
    {
      "epoch": 6.34,
      "grad_norm": 6.84375,
      "learning_rate": 5.4835092348284956e-05,
      "loss": 0.0796,
      "step": 4809
    },
    {
      "epoch": 6.35,
      "grad_norm": 129.0,
      "learning_rate": 5.481530343007915e-05,
      "loss": 2.2969,
      "step": 4810
    },
    {
      "epoch": 6.35,
      "grad_norm": 41.25,
      "learning_rate": 5.4795514511873346e-05,
      "loss": 0.7383,
      "step": 4811
    },
    {
      "epoch": 6.35,
      "grad_norm": 93.0,
      "learning_rate": 5.4775725593667544e-05,
      "loss": 1.8359,
      "step": 4812
    },
    {
      "epoch": 6.35,
      "grad_norm": 47.0,
      "learning_rate": 5.4755936675461735e-05,
      "loss": 0.4629,
      "step": 4813
    },
    {
      "epoch": 6.35,
      "grad_norm": 29.0,
      "learning_rate": 5.473614775725593e-05,
      "loss": 0.5547,
      "step": 4814
    },
    {
      "epoch": 6.35,
      "grad_norm": 155.0,
      "learning_rate": 5.471635883905013e-05,
      "loss": 3.1094,
      "step": 4815
    },
    {
      "epoch": 6.35,
      "grad_norm": 19.625,
      "learning_rate": 5.469656992084432e-05,
      "loss": 0.3535,
      "step": 4816
    },
    {
      "epoch": 6.35,
      "grad_norm": 19.5,
      "learning_rate": 5.467678100263852e-05,
      "loss": 0.582,
      "step": 4817
    },
    {
      "epoch": 6.36,
      "grad_norm": 9.25,
      "learning_rate": 5.465699208443272e-05,
      "loss": 0.1138,
      "step": 4818
    },
    {
      "epoch": 6.36,
      "grad_norm": 13.25,
      "learning_rate": 5.463720316622691e-05,
      "loss": 0.1396,
      "step": 4819
    },
    {
      "epoch": 6.36,
      "grad_norm": 17.625,
      "learning_rate": 5.461741424802111e-05,
      "loss": 0.2324,
      "step": 4820
    },
    {
      "epoch": 6.36,
      "grad_norm": 19.375,
      "learning_rate": 5.459762532981529e-05,
      "loss": 0.1484,
      "step": 4821
    },
    {
      "epoch": 6.36,
      "grad_norm": 37.25,
      "learning_rate": 5.457783641160949e-05,
      "loss": 0.6016,
      "step": 4822
    },
    {
      "epoch": 6.36,
      "grad_norm": 144.0,
      "learning_rate": 5.455804749340369e-05,
      "loss": 3.8594,
      "step": 4823
    },
    {
      "epoch": 6.36,
      "grad_norm": 83.5,
      "learning_rate": 5.453825857519788e-05,
      "loss": 1.875,
      "step": 4824
    },
    {
      "epoch": 6.37,
      "grad_norm": 17.375,
      "learning_rate": 5.451846965699208e-05,
      "loss": 0.1709,
      "step": 4825
    },
    {
      "epoch": 6.37,
      "grad_norm": 137.0,
      "learning_rate": 5.4498680738786276e-05,
      "loss": 2.9375,
      "step": 4826
    },
    {
      "epoch": 6.37,
      "grad_norm": 86.0,
      "learning_rate": 5.447889182058047e-05,
      "loss": 1.8438,
      "step": 4827
    },
    {
      "epoch": 6.37,
      "grad_norm": 69.5,
      "learning_rate": 5.4459102902374665e-05,
      "loss": 1.3906,
      "step": 4828
    },
    {
      "epoch": 6.37,
      "grad_norm": 13.1875,
      "learning_rate": 5.4439313984168863e-05,
      "loss": 0.1699,
      "step": 4829
    },
    {
      "epoch": 6.37,
      "grad_norm": 18.0,
      "learning_rate": 5.4419525065963055e-05,
      "loss": 0.1768,
      "step": 4830
    },
    {
      "epoch": 6.37,
      "grad_norm": 46.25,
      "learning_rate": 5.439973614775725e-05,
      "loss": 0.5391,
      "step": 4831
    },
    {
      "epoch": 6.37,
      "grad_norm": 180.0,
      "learning_rate": 5.437994722955145e-05,
      "loss": 3.5312,
      "step": 4832
    },
    {
      "epoch": 6.38,
      "grad_norm": 38.75,
      "learning_rate": 5.436015831134564e-05,
      "loss": 0.6484,
      "step": 4833
    },
    {
      "epoch": 6.38,
      "grad_norm": 132.0,
      "learning_rate": 5.434036939313984e-05,
      "loss": 2.9219,
      "step": 4834
    },
    {
      "epoch": 6.38,
      "grad_norm": 177.0,
      "learning_rate": 5.432058047493404e-05,
      "loss": 4.375,
      "step": 4835
    },
    {
      "epoch": 6.38,
      "grad_norm": 124.5,
      "learning_rate": 5.430079155672822e-05,
      "loss": 2.7031,
      "step": 4836
    },
    {
      "epoch": 6.38,
      "grad_norm": 89.5,
      "learning_rate": 5.428100263852242e-05,
      "loss": 1.7812,
      "step": 4837
    },
    {
      "epoch": 6.38,
      "grad_norm": 151.0,
      "learning_rate": 5.426121372031661e-05,
      "loss": 2.4844,
      "step": 4838
    },
    {
      "epoch": 6.38,
      "grad_norm": 28.375,
      "learning_rate": 5.424142480211081e-05,
      "loss": 0.3555,
      "step": 4839
    },
    {
      "epoch": 6.39,
      "grad_norm": 161.0,
      "learning_rate": 5.422163588390501e-05,
      "loss": 3.6406,
      "step": 4840
    },
    {
      "epoch": 6.39,
      "grad_norm": 66.0,
      "learning_rate": 5.42018469656992e-05,
      "loss": 1.1562,
      "step": 4841
    },
    {
      "epoch": 6.39,
      "grad_norm": 16.375,
      "learning_rate": 5.41820580474934e-05,
      "loss": 0.3418,
      "step": 4842
    },
    {
      "epoch": 6.39,
      "grad_norm": 15.625,
      "learning_rate": 5.4162269129287596e-05,
      "loss": 0.1689,
      "step": 4843
    },
    {
      "epoch": 6.39,
      "grad_norm": 27.375,
      "learning_rate": 5.414248021108179e-05,
      "loss": 0.5625,
      "step": 4844
    },
    {
      "epoch": 6.39,
      "grad_norm": 8.3125,
      "learning_rate": 5.4122691292875985e-05,
      "loss": 0.1016,
      "step": 4845
    },
    {
      "epoch": 6.39,
      "grad_norm": 74.0,
      "learning_rate": 5.410290237467018e-05,
      "loss": 1.6328,
      "step": 4846
    },
    {
      "epoch": 6.39,
      "grad_norm": 19.125,
      "learning_rate": 5.4083113456464374e-05,
      "loss": 0.1943,
      "step": 4847
    },
    {
      "epoch": 6.4,
      "grad_norm": 60.0,
      "learning_rate": 5.406332453825857e-05,
      "loss": 0.7109,
      "step": 4848
    },
    {
      "epoch": 6.4,
      "grad_norm": 17.375,
      "learning_rate": 5.404353562005277e-05,
      "loss": 0.3789,
      "step": 4849
    },
    {
      "epoch": 6.4,
      "grad_norm": 25.5,
      "learning_rate": 5.402374670184696e-05,
      "loss": 0.3398,
      "step": 4850
    },
    {
      "epoch": 6.4,
      "grad_norm": 14.1875,
      "learning_rate": 5.400395778364115e-05,
      "loss": 0.1904,
      "step": 4851
    },
    {
      "epoch": 6.4,
      "grad_norm": 137.0,
      "learning_rate": 5.398416886543535e-05,
      "loss": 3.2344,
      "step": 4852
    },
    {
      "epoch": 6.4,
      "grad_norm": 15.875,
      "learning_rate": 5.396437994722954e-05,
      "loss": 0.1719,
      "step": 4853
    },
    {
      "epoch": 6.4,
      "grad_norm": 16.375,
      "learning_rate": 5.394459102902374e-05,
      "loss": 0.25,
      "step": 4854
    },
    {
      "epoch": 6.41,
      "grad_norm": 3.984375,
      "learning_rate": 5.392480211081794e-05,
      "loss": 0.0522,
      "step": 4855
    },
    {
      "epoch": 6.41,
      "grad_norm": 83.5,
      "learning_rate": 5.390501319261213e-05,
      "loss": 1.75,
      "step": 4856
    },
    {
      "epoch": 6.41,
      "grad_norm": 69.0,
      "learning_rate": 5.388522427440633e-05,
      "loss": 1.2266,
      "step": 4857
    },
    {
      "epoch": 6.41,
      "grad_norm": 16.0,
      "learning_rate": 5.3865435356200526e-05,
      "loss": 0.1611,
      "step": 4858
    },
    {
      "epoch": 6.41,
      "grad_norm": 67.0,
      "learning_rate": 5.384564643799472e-05,
      "loss": 0.75,
      "step": 4859
    },
    {
      "epoch": 6.41,
      "grad_norm": 26.0,
      "learning_rate": 5.3825857519788915e-05,
      "loss": 0.3438,
      "step": 4860
    },
    {
      "epoch": 6.41,
      "grad_norm": 26.25,
      "learning_rate": 5.380606860158311e-05,
      "loss": 0.5742,
      "step": 4861
    },
    {
      "epoch": 6.41,
      "grad_norm": 6.0625,
      "learning_rate": 5.3786279683377304e-05,
      "loss": 0.0952,
      "step": 4862
    },
    {
      "epoch": 6.42,
      "grad_norm": 246.0,
      "learning_rate": 5.37664907651715e-05,
      "loss": 3.7812,
      "step": 4863
    },
    {
      "epoch": 6.42,
      "grad_norm": 10.75,
      "learning_rate": 5.37467018469657e-05,
      "loss": 0.104,
      "step": 4864
    },
    {
      "epoch": 6.42,
      "grad_norm": 10.125,
      "learning_rate": 5.372691292875989e-05,
      "loss": 0.1025,
      "step": 4865
    },
    {
      "epoch": 6.42,
      "grad_norm": 4.09375,
      "learning_rate": 5.370712401055408e-05,
      "loss": 0.0586,
      "step": 4866
    },
    {
      "epoch": 6.42,
      "grad_norm": 167.0,
      "learning_rate": 5.3687335092348274e-05,
      "loss": 2.8594,
      "step": 4867
    },
    {
      "epoch": 6.42,
      "grad_norm": 18.625,
      "learning_rate": 5.366754617414247e-05,
      "loss": 0.1719,
      "step": 4868
    },
    {
      "epoch": 6.42,
      "grad_norm": 8.4375,
      "learning_rate": 5.364775725593667e-05,
      "loss": 0.0825,
      "step": 4869
    },
    {
      "epoch": 6.42,
      "grad_norm": 106.5,
      "learning_rate": 5.362796833773086e-05,
      "loss": 1.9219,
      "step": 4870
    },
    {
      "epoch": 6.43,
      "grad_norm": 50.75,
      "learning_rate": 5.360817941952506e-05,
      "loss": 0.2217,
      "step": 4871
    },
    {
      "epoch": 6.43,
      "grad_norm": 4.46875,
      "learning_rate": 5.358839050131926e-05,
      "loss": 0.0513,
      "step": 4872
    },
    {
      "epoch": 6.43,
      "grad_norm": 6.0,
      "learning_rate": 5.356860158311345e-05,
      "loss": 0.0549,
      "step": 4873
    },
    {
      "epoch": 6.43,
      "grad_norm": 133.0,
      "learning_rate": 5.354881266490765e-05,
      "loss": 4.625,
      "step": 4874
    },
    {
      "epoch": 6.43,
      "grad_norm": 134.0,
      "learning_rate": 5.3529023746701845e-05,
      "loss": 4.25,
      "step": 4875
    },
    {
      "epoch": 6.43,
      "grad_norm": 198.0,
      "learning_rate": 5.350923482849604e-05,
      "loss": 4.6875,
      "step": 4876
    },
    {
      "epoch": 6.43,
      "grad_norm": 27.5,
      "learning_rate": 5.3489445910290235e-05,
      "loss": 0.0933,
      "step": 4877
    },
    {
      "epoch": 6.44,
      "grad_norm": 110.0,
      "learning_rate": 5.346965699208443e-05,
      "loss": 1.3203,
      "step": 4878
    },
    {
      "epoch": 6.44,
      "grad_norm": 143.0,
      "learning_rate": 5.3449868073878624e-05,
      "loss": 4.2812,
      "step": 4879
    },
    {
      "epoch": 6.44,
      "grad_norm": 528.0,
      "learning_rate": 5.343007915567282e-05,
      "loss": 5.0312,
      "step": 4880
    },
    {
      "epoch": 6.44,
      "grad_norm": 41.25,
      "learning_rate": 5.341029023746701e-05,
      "loss": 0.334,
      "step": 4881
    },
    {
      "epoch": 6.44,
      "grad_norm": 88.0,
      "learning_rate": 5.3390501319261205e-05,
      "loss": 2.6562,
      "step": 4882
    },
    {
      "epoch": 6.44,
      "grad_norm": 19.0,
      "learning_rate": 5.33707124010554e-05,
      "loss": 0.5508,
      "step": 4883
    },
    {
      "epoch": 6.44,
      "grad_norm": 10.625,
      "learning_rate": 5.3350923482849594e-05,
      "loss": 0.105,
      "step": 4884
    },
    {
      "epoch": 6.44,
      "grad_norm": 45.0,
      "learning_rate": 5.333113456464379e-05,
      "loss": 0.4688,
      "step": 4885
    },
    {
      "epoch": 6.45,
      "grad_norm": 28.0,
      "learning_rate": 5.331134564643799e-05,
      "loss": 0.1338,
      "step": 4886
    },
    {
      "epoch": 6.45,
      "grad_norm": 5.65625,
      "learning_rate": 5.329155672823218e-05,
      "loss": 0.0464,
      "step": 4887
    },
    {
      "epoch": 6.45,
      "grad_norm": 9.625,
      "learning_rate": 5.327176781002638e-05,
      "loss": 0.104,
      "step": 4888
    },
    {
      "epoch": 6.45,
      "grad_norm": 39.0,
      "learning_rate": 5.325197889182058e-05,
      "loss": 0.4219,
      "step": 4889
    },
    {
      "epoch": 6.45,
      "grad_norm": 204.0,
      "learning_rate": 5.323218997361477e-05,
      "loss": 4.9375,
      "step": 4890
    },
    {
      "epoch": 6.45,
      "grad_norm": 3.5625,
      "learning_rate": 5.321240105540897e-05,
      "loss": 0.0469,
      "step": 4891
    },
    {
      "epoch": 6.45,
      "grad_norm": 170.0,
      "learning_rate": 5.3192612137203165e-05,
      "loss": 3.4375,
      "step": 4892
    },
    {
      "epoch": 6.46,
      "grad_norm": 50.5,
      "learning_rate": 5.317282321899736e-05,
      "loss": 0.8516,
      "step": 4893
    },
    {
      "epoch": 6.46,
      "grad_norm": 150.0,
      "learning_rate": 5.3153034300791554e-05,
      "loss": 5.0938,
      "step": 4894
    },
    {
      "epoch": 6.46,
      "grad_norm": 151.0,
      "learning_rate": 5.313324538258575e-05,
      "loss": 5.3438,
      "step": 4895
    },
    {
      "epoch": 6.46,
      "grad_norm": 30.75,
      "learning_rate": 5.311345646437994e-05,
      "loss": 0.5312,
      "step": 4896
    },
    {
      "epoch": 6.46,
      "grad_norm": 92.5,
      "learning_rate": 5.3093667546174135e-05,
      "loss": 2.3906,
      "step": 4897
    },
    {
      "epoch": 6.46,
      "grad_norm": 155.0,
      "learning_rate": 5.307387862796833e-05,
      "loss": 4.1562,
      "step": 4898
    },
    {
      "epoch": 6.46,
      "grad_norm": 8.3125,
      "learning_rate": 5.3054089709762524e-05,
      "loss": 0.1011,
      "step": 4899
    },
    {
      "epoch": 6.46,
      "grad_norm": 95.0,
      "learning_rate": 5.303430079155672e-05,
      "loss": 2.0625,
      "step": 4900
    },
    {
      "epoch": 6.47,
      "grad_norm": 90.5,
      "learning_rate": 5.301451187335092e-05,
      "loss": 2.0781,
      "step": 4901
    },
    {
      "epoch": 6.47,
      "grad_norm": 72.5,
      "learning_rate": 5.299472295514511e-05,
      "loss": 1.4531,
      "step": 4902
    },
    {
      "epoch": 6.47,
      "grad_norm": 87.5,
      "learning_rate": 5.297493403693931e-05,
      "loss": 1.4766,
      "step": 4903
    },
    {
      "epoch": 6.47,
      "grad_norm": 168.0,
      "learning_rate": 5.295514511873351e-05,
      "loss": 6.9688,
      "step": 4904
    },
    {
      "epoch": 6.47,
      "grad_norm": 143.0,
      "learning_rate": 5.29353562005277e-05,
      "loss": 5.4688,
      "step": 4905
    },
    {
      "epoch": 6.47,
      "grad_norm": 10.0,
      "learning_rate": 5.29155672823219e-05,
      "loss": 0.1245,
      "step": 4906
    },
    {
      "epoch": 6.47,
      "grad_norm": 58.5,
      "learning_rate": 5.2895778364116095e-05,
      "loss": 1.1406,
      "step": 4907
    },
    {
      "epoch": 6.47,
      "grad_norm": 63.75,
      "learning_rate": 5.2875989445910286e-05,
      "loss": 0.2988,
      "step": 4908
    },
    {
      "epoch": 6.48,
      "grad_norm": 132.0,
      "learning_rate": 5.2856200527704485e-05,
      "loss": 3.1094,
      "step": 4909
    },
    {
      "epoch": 6.48,
      "grad_norm": 130.0,
      "learning_rate": 5.283641160949868e-05,
      "loss": 3.7656,
      "step": 4910
    },
    {
      "epoch": 6.48,
      "grad_norm": 229.0,
      "learning_rate": 5.281662269129287e-05,
      "loss": 5.5312,
      "step": 4911
    },
    {
      "epoch": 6.48,
      "grad_norm": 19.25,
      "learning_rate": 5.2796833773087065e-05,
      "loss": 0.2256,
      "step": 4912
    },
    {
      "epoch": 6.48,
      "grad_norm": 24.75,
      "learning_rate": 5.2777044854881256e-05,
      "loss": 0.5312,
      "step": 4913
    },
    {
      "epoch": 6.48,
      "grad_norm": 112.5,
      "learning_rate": 5.2757255936675455e-05,
      "loss": 2.2031,
      "step": 4914
    },
    {
      "epoch": 6.48,
      "grad_norm": 14.1875,
      "learning_rate": 5.273746701846965e-05,
      "loss": 0.1572,
      "step": 4915
    },
    {
      "epoch": 6.49,
      "grad_norm": 103.5,
      "learning_rate": 5.2717678100263844e-05,
      "loss": 1.9766,
      "step": 4916
    },
    {
      "epoch": 6.49,
      "grad_norm": 112.0,
      "learning_rate": 5.269788918205804e-05,
      "loss": 2.2812,
      "step": 4917
    },
    {
      "epoch": 6.49,
      "grad_norm": 115.0,
      "learning_rate": 5.267810026385224e-05,
      "loss": 2.2031,
      "step": 4918
    },
    {
      "epoch": 6.49,
      "grad_norm": 69.0,
      "learning_rate": 5.265831134564643e-05,
      "loss": 1.4688,
      "step": 4919
    },
    {
      "epoch": 6.49,
      "grad_norm": 38.0,
      "learning_rate": 5.263852242744063e-05,
      "loss": 0.7344,
      "step": 4920
    },
    {
      "epoch": 6.49,
      "grad_norm": 61.75,
      "learning_rate": 5.261873350923483e-05,
      "loss": 1.3828,
      "step": 4921
    },
    {
      "epoch": 6.49,
      "grad_norm": 13.5,
      "learning_rate": 5.259894459102902e-05,
      "loss": 0.1904,
      "step": 4922
    },
    {
      "epoch": 6.49,
      "grad_norm": 37.5,
      "learning_rate": 5.257915567282322e-05,
      "loss": 0.6875,
      "step": 4923
    },
    {
      "epoch": 6.5,
      "grad_norm": 60.75,
      "learning_rate": 5.2559366754617415e-05,
      "loss": 0.8008,
      "step": 4924
    },
    {
      "epoch": 6.5,
      "grad_norm": 65.0,
      "learning_rate": 5.2539577836411606e-05,
      "loss": 1.8281,
      "step": 4925
    },
    {
      "epoch": 6.5,
      "grad_norm": 26.625,
      "learning_rate": 5.25197889182058e-05,
      "loss": 0.5703,
      "step": 4926
    },
    {
      "epoch": 6.5,
      "grad_norm": 101.0,
      "learning_rate": 5.2499999999999995e-05,
      "loss": 1.8438,
      "step": 4927
    },
    {
      "epoch": 6.5,
      "grad_norm": 53.25,
      "learning_rate": 5.248021108179419e-05,
      "loss": 1.1875,
      "step": 4928
    },
    {
      "epoch": 6.5,
      "grad_norm": 26.125,
      "learning_rate": 5.2460422163588385e-05,
      "loss": 0.3887,
      "step": 4929
    },
    {
      "epoch": 6.5,
      "grad_norm": 71.5,
      "learning_rate": 5.244063324538258e-05,
      "loss": 1.4219,
      "step": 4930
    },
    {
      "epoch": 6.51,
      "grad_norm": 152.0,
      "learning_rate": 5.2420844327176774e-05,
      "loss": 2.1875,
      "step": 4931
    },
    {
      "epoch": 6.51,
      "grad_norm": 22.0,
      "learning_rate": 5.240105540897097e-05,
      "loss": 0.3984,
      "step": 4932
    },
    {
      "epoch": 6.51,
      "grad_norm": 19.375,
      "learning_rate": 5.238126649076517e-05,
      "loss": 0.2734,
      "step": 4933
    },
    {
      "epoch": 6.51,
      "grad_norm": 45.25,
      "learning_rate": 5.236147757255936e-05,
      "loss": 1.0859,
      "step": 4934
    },
    {
      "epoch": 6.51,
      "grad_norm": 44.5,
      "learning_rate": 5.234168865435356e-05,
      "loss": 0.9102,
      "step": 4935
    },
    {
      "epoch": 6.51,
      "grad_norm": 13.9375,
      "learning_rate": 5.232189973614776e-05,
      "loss": 0.2412,
      "step": 4936
    },
    {
      "epoch": 6.51,
      "grad_norm": 73.0,
      "learning_rate": 5.230211081794195e-05,
      "loss": 1.6875,
      "step": 4937
    },
    {
      "epoch": 6.51,
      "grad_norm": 20.0,
      "learning_rate": 5.228232189973615e-05,
      "loss": 0.2393,
      "step": 4938
    },
    {
      "epoch": 6.52,
      "grad_norm": 107.5,
      "learning_rate": 5.2262532981530345e-05,
      "loss": 2.625,
      "step": 4939
    },
    {
      "epoch": 6.52,
      "grad_norm": 21.875,
      "learning_rate": 5.2242744063324536e-05,
      "loss": 0.2949,
      "step": 4940
    },
    {
      "epoch": 6.52,
      "grad_norm": 27.0,
      "learning_rate": 5.222295514511873e-05,
      "loss": 0.5312,
      "step": 4941
    },
    {
      "epoch": 6.52,
      "grad_norm": 117.5,
      "learning_rate": 5.220316622691292e-05,
      "loss": 2.5625,
      "step": 4942
    },
    {
      "epoch": 6.52,
      "grad_norm": 20.5,
      "learning_rate": 5.218337730870712e-05,
      "loss": 0.418,
      "step": 4943
    },
    {
      "epoch": 6.52,
      "grad_norm": 104.0,
      "learning_rate": 5.2163588390501315e-05,
      "loss": 2.4062,
      "step": 4944
    },
    {
      "epoch": 6.52,
      "grad_norm": 20.75,
      "learning_rate": 5.2143799472295506e-05,
      "loss": 0.3418,
      "step": 4945
    },
    {
      "epoch": 6.53,
      "grad_norm": 20.125,
      "learning_rate": 5.2124010554089704e-05,
      "loss": 0.2285,
      "step": 4946
    },
    {
      "epoch": 6.53,
      "grad_norm": 92.0,
      "learning_rate": 5.21042216358839e-05,
      "loss": 2.2969,
      "step": 4947
    },
    {
      "epoch": 6.53,
      "grad_norm": 12.8125,
      "learning_rate": 5.2084432717678094e-05,
      "loss": 0.1738,
      "step": 4948
    },
    {
      "epoch": 6.53,
      "grad_norm": 22.5,
      "learning_rate": 5.206464379947229e-05,
      "loss": 0.7344,
      "step": 4949
    },
    {
      "epoch": 6.53,
      "grad_norm": 26.5,
      "learning_rate": 5.204485488126649e-05,
      "loss": 0.3438,
      "step": 4950
    },
    {
      "epoch": 6.53,
      "grad_norm": 23.5,
      "learning_rate": 5.202506596306068e-05,
      "loss": 0.2695,
      "step": 4951
    },
    {
      "epoch": 6.53,
      "grad_norm": 14.625,
      "learning_rate": 5.200527704485488e-05,
      "loss": 0.2119,
      "step": 4952
    },
    {
      "epoch": 6.53,
      "grad_norm": 18.625,
      "learning_rate": 5.198548812664908e-05,
      "loss": 0.3008,
      "step": 4953
    },
    {
      "epoch": 6.54,
      "grad_norm": 89.0,
      "learning_rate": 5.196569920844327e-05,
      "loss": 1.4297,
      "step": 4954
    },
    {
      "epoch": 6.54,
      "grad_norm": 16.5,
      "learning_rate": 5.1945910290237467e-05,
      "loss": 0.1875,
      "step": 4955
    },
    {
      "epoch": 6.54,
      "grad_norm": 119.0,
      "learning_rate": 5.192612137203165e-05,
      "loss": 2.9375,
      "step": 4956
    },
    {
      "epoch": 6.54,
      "grad_norm": 12.125,
      "learning_rate": 5.190633245382585e-05,
      "loss": 0.1611,
      "step": 4957
    },
    {
      "epoch": 6.54,
      "grad_norm": 139.0,
      "learning_rate": 5.188654353562005e-05,
      "loss": 3.3906,
      "step": 4958
    },
    {
      "epoch": 6.54,
      "grad_norm": 111.5,
      "learning_rate": 5.186675461741424e-05,
      "loss": 2.4688,
      "step": 4959
    },
    {
      "epoch": 6.54,
      "grad_norm": 10.4375,
      "learning_rate": 5.1846965699208436e-05,
      "loss": 0.1211,
      "step": 4960
    },
    {
      "epoch": 6.54,
      "grad_norm": 65.0,
      "learning_rate": 5.1827176781002635e-05,
      "loss": 0.8398,
      "step": 4961
    },
    {
      "epoch": 6.55,
      "grad_norm": 292.0,
      "learning_rate": 5.1807387862796826e-05,
      "loss": 7.2188,
      "step": 4962
    },
    {
      "epoch": 6.55,
      "grad_norm": 19.75,
      "learning_rate": 5.1787598944591024e-05,
      "loss": 0.3828,
      "step": 4963
    },
    {
      "epoch": 6.55,
      "grad_norm": 63.5,
      "learning_rate": 5.176781002638522e-05,
      "loss": 1.4297,
      "step": 4964
    },
    {
      "epoch": 6.55,
      "grad_norm": 7.09375,
      "learning_rate": 5.174802110817941e-05,
      "loss": 0.084,
      "step": 4965
    },
    {
      "epoch": 6.55,
      "grad_norm": 179.0,
      "learning_rate": 5.172823218997361e-05,
      "loss": 2.9062,
      "step": 4966
    },
    {
      "epoch": 6.55,
      "grad_norm": 95.5,
      "learning_rate": 5.170844327176781e-05,
      "loss": 2.4375,
      "step": 4967
    },
    {
      "epoch": 6.55,
      "grad_norm": 6.03125,
      "learning_rate": 5.1688654353562e-05,
      "loss": 0.0747,
      "step": 4968
    },
    {
      "epoch": 6.56,
      "grad_norm": 34.75,
      "learning_rate": 5.16688654353562e-05,
      "loss": 1.1484,
      "step": 4969
    },
    {
      "epoch": 6.56,
      "grad_norm": 4.625,
      "learning_rate": 5.16490765171504e-05,
      "loss": 0.0591,
      "step": 4970
    },
    {
      "epoch": 6.56,
      "grad_norm": 75.5,
      "learning_rate": 5.162928759894458e-05,
      "loss": 1.5078,
      "step": 4971
    },
    {
      "epoch": 6.56,
      "grad_norm": 155.0,
      "learning_rate": 5.160949868073878e-05,
      "loss": 3.7031,
      "step": 4972
    },
    {
      "epoch": 6.56,
      "grad_norm": 17.5,
      "learning_rate": 5.158970976253298e-05,
      "loss": 0.2793,
      "step": 4973
    },
    {
      "epoch": 6.56,
      "grad_norm": 3.796875,
      "learning_rate": 5.156992084432717e-05,
      "loss": 0.0417,
      "step": 4974
    },
    {
      "epoch": 6.56,
      "grad_norm": 141.0,
      "learning_rate": 5.155013192612137e-05,
      "loss": 3.2344,
      "step": 4975
    },
    {
      "epoch": 6.56,
      "grad_norm": 7.78125,
      "learning_rate": 5.1530343007915565e-05,
      "loss": 0.0654,
      "step": 4976
    },
    {
      "epoch": 6.57,
      "grad_norm": 13.6875,
      "learning_rate": 5.1510554089709756e-05,
      "loss": 0.1504,
      "step": 4977
    },
    {
      "epoch": 6.57,
      "grad_norm": 29.375,
      "learning_rate": 5.1490765171503954e-05,
      "loss": 0.8789,
      "step": 4978
    },
    {
      "epoch": 6.57,
      "grad_norm": 56.25,
      "learning_rate": 5.147097625329815e-05,
      "loss": 0.7891,
      "step": 4979
    },
    {
      "epoch": 6.57,
      "grad_norm": 156.0,
      "learning_rate": 5.1451187335092343e-05,
      "loss": 3.9688,
      "step": 4980
    },
    {
      "epoch": 6.57,
      "grad_norm": 83.5,
      "learning_rate": 5.143139841688654e-05,
      "loss": 1.5781,
      "step": 4981
    },
    {
      "epoch": 6.57,
      "grad_norm": 67.5,
      "learning_rate": 5.141160949868074e-05,
      "loss": 0.3379,
      "step": 4982
    },
    {
      "epoch": 6.57,
      "grad_norm": 78.0,
      "learning_rate": 5.139182058047493e-05,
      "loss": 2.3594,
      "step": 4983
    },
    {
      "epoch": 6.58,
      "grad_norm": 3.578125,
      "learning_rate": 5.137203166226913e-05,
      "loss": 0.0562,
      "step": 4984
    },
    {
      "epoch": 6.58,
      "grad_norm": 87.0,
      "learning_rate": 5.135224274406333e-05,
      "loss": 1.7734,
      "step": 4985
    },
    {
      "epoch": 6.58,
      "grad_norm": 6.09375,
      "learning_rate": 5.133245382585751e-05,
      "loss": 0.0649,
      "step": 4986
    },
    {
      "epoch": 6.58,
      "grad_norm": 5.71875,
      "learning_rate": 5.131266490765171e-05,
      "loss": 0.0786,
      "step": 4987
    },
    {
      "epoch": 6.58,
      "grad_norm": 14.5,
      "learning_rate": 5.12928759894459e-05,
      "loss": 0.1816,
      "step": 4988
    },
    {
      "epoch": 6.58,
      "grad_norm": 214.0,
      "learning_rate": 5.12730870712401e-05,
      "loss": 6.6875,
      "step": 4989
    },
    {
      "epoch": 6.58,
      "grad_norm": 2.421875,
      "learning_rate": 5.12532981530343e-05,
      "loss": 0.0234,
      "step": 4990
    },
    {
      "epoch": 6.58,
      "grad_norm": 155.0,
      "learning_rate": 5.123350923482849e-05,
      "loss": 4.75,
      "step": 4991
    },
    {
      "epoch": 6.59,
      "grad_norm": 23.75,
      "learning_rate": 5.1213720316622686e-05,
      "loss": 0.6367,
      "step": 4992
    },
    {
      "epoch": 6.59,
      "grad_norm": 8.1875,
      "learning_rate": 5.1193931398416884e-05,
      "loss": 0.0835,
      "step": 4993
    },
    {
      "epoch": 6.59,
      "grad_norm": 23.25,
      "learning_rate": 5.1174142480211076e-05,
      "loss": 0.2295,
      "step": 4994
    },
    {
      "epoch": 6.59,
      "grad_norm": 5.4375,
      "learning_rate": 5.1154353562005274e-05,
      "loss": 0.0547,
      "step": 4995
    },
    {
      "epoch": 6.59,
      "grad_norm": 3.328125,
      "learning_rate": 5.113456464379947e-05,
      "loss": 0.0283,
      "step": 4996
    },
    {
      "epoch": 6.59,
      "grad_norm": 12.875,
      "learning_rate": 5.111477572559366e-05,
      "loss": 0.0981,
      "step": 4997
    },
    {
      "epoch": 6.59,
      "grad_norm": 24.125,
      "learning_rate": 5.109498680738786e-05,
      "loss": 1.0312,
      "step": 4998
    },
    {
      "epoch": 6.59,
      "grad_norm": 43.5,
      "learning_rate": 5.107519788918206e-05,
      "loss": 1.1719,
      "step": 4999
    },
    {
      "epoch": 6.6,
      "grad_norm": 78.0,
      "learning_rate": 5.105540897097625e-05,
      "loss": 2.0938,
      "step": 5000
    },
    {
      "epoch": 6.6,
      "grad_norm": 88.0,
      "learning_rate": 5.103562005277044e-05,
      "loss": 1.4844,
      "step": 5001
    },
    {
      "epoch": 6.6,
      "grad_norm": 43.75,
      "learning_rate": 5.101583113456463e-05,
      "loss": 0.793,
      "step": 5002
    },
    {
      "epoch": 6.6,
      "grad_norm": 127.0,
      "learning_rate": 5.099604221635883e-05,
      "loss": 3.75,
      "step": 5003
    },
    {
      "epoch": 6.6,
      "grad_norm": 84.0,
      "learning_rate": 5.097625329815303e-05,
      "loss": 1.6094,
      "step": 5004
    },
    {
      "epoch": 6.6,
      "grad_norm": 84.0,
      "learning_rate": 5.095646437994722e-05,
      "loss": 1.9062,
      "step": 5005
    },
    {
      "epoch": 6.6,
      "grad_norm": 14.5,
      "learning_rate": 5.093667546174142e-05,
      "loss": 0.1377,
      "step": 5006
    },
    {
      "epoch": 6.61,
      "grad_norm": 166.0,
      "learning_rate": 5.0916886543535617e-05,
      "loss": 4.625,
      "step": 5007
    },
    {
      "epoch": 6.61,
      "grad_norm": 87.0,
      "learning_rate": 5.089709762532981e-05,
      "loss": 1.25,
      "step": 5008
    },
    {
      "epoch": 6.61,
      "grad_norm": 106.5,
      "learning_rate": 5.0877308707124006e-05,
      "loss": 1.6016,
      "step": 5009
    },
    {
      "epoch": 6.61,
      "grad_norm": 8.8125,
      "learning_rate": 5.0857519788918204e-05,
      "loss": 0.1108,
      "step": 5010
    },
    {
      "epoch": 6.61,
      "grad_norm": 9.9375,
      "learning_rate": 5.0837730870712395e-05,
      "loss": 0.1069,
      "step": 5011
    },
    {
      "epoch": 6.61,
      "grad_norm": 175.0,
      "learning_rate": 5.081794195250659e-05,
      "loss": 3.1875,
      "step": 5012
    },
    {
      "epoch": 6.61,
      "grad_norm": 12.625,
      "learning_rate": 5.079815303430079e-05,
      "loss": 0.3594,
      "step": 5013
    },
    {
      "epoch": 6.61,
      "grad_norm": 6.71875,
      "learning_rate": 5.077836411609498e-05,
      "loss": 0.0781,
      "step": 5014
    },
    {
      "epoch": 6.62,
      "grad_norm": 13.4375,
      "learning_rate": 5.075857519788918e-05,
      "loss": 0.1348,
      "step": 5015
    },
    {
      "epoch": 6.62,
      "grad_norm": 18.5,
      "learning_rate": 5.073878627968337e-05,
      "loss": 0.2285,
      "step": 5016
    },
    {
      "epoch": 6.62,
      "grad_norm": 9.625,
      "learning_rate": 5.071899736147756e-05,
      "loss": 0.1021,
      "step": 5017
    },
    {
      "epoch": 6.62,
      "grad_norm": 89.5,
      "learning_rate": 5.069920844327176e-05,
      "loss": 1.6562,
      "step": 5018
    },
    {
      "epoch": 6.62,
      "grad_norm": 23.0,
      "learning_rate": 5.067941952506596e-05,
      "loss": 0.2324,
      "step": 5019
    },
    {
      "epoch": 6.62,
      "grad_norm": 70.0,
      "learning_rate": 5.065963060686015e-05,
      "loss": 1.1328,
      "step": 5020
    },
    {
      "epoch": 6.62,
      "grad_norm": 131.0,
      "learning_rate": 5.063984168865435e-05,
      "loss": 3.5625,
      "step": 5021
    },
    {
      "epoch": 6.63,
      "grad_norm": 20.5,
      "learning_rate": 5.062005277044855e-05,
      "loss": 0.3633,
      "step": 5022
    },
    {
      "epoch": 6.63,
      "grad_norm": 7.09375,
      "learning_rate": 5.060026385224274e-05,
      "loss": 0.0815,
      "step": 5023
    },
    {
      "epoch": 6.63,
      "grad_norm": 164.0,
      "learning_rate": 5.0580474934036936e-05,
      "loss": 6.5938,
      "step": 5024
    },
    {
      "epoch": 6.63,
      "grad_norm": 10.25,
      "learning_rate": 5.0560686015831134e-05,
      "loss": 0.1309,
      "step": 5025
    },
    {
      "epoch": 6.63,
      "grad_norm": 10.5625,
      "learning_rate": 5.0540897097625325e-05,
      "loss": 0.106,
      "step": 5026
    },
    {
      "epoch": 6.63,
      "grad_norm": 93.5,
      "learning_rate": 5.0521108179419524e-05,
      "loss": 1.1719,
      "step": 5027
    },
    {
      "epoch": 6.63,
      "grad_norm": 9.5625,
      "learning_rate": 5.050131926121372e-05,
      "loss": 0.0947,
      "step": 5028
    },
    {
      "epoch": 6.63,
      "grad_norm": 4.78125,
      "learning_rate": 5.048153034300791e-05,
      "loss": 0.0598,
      "step": 5029
    },
    {
      "epoch": 6.64,
      "grad_norm": 93.5,
      "learning_rate": 5.046174142480211e-05,
      "loss": 1.4531,
      "step": 5030
    },
    {
      "epoch": 6.64,
      "grad_norm": 118.5,
      "learning_rate": 5.0441952506596295e-05,
      "loss": 2.9844,
      "step": 5031
    },
    {
      "epoch": 6.64,
      "grad_norm": 8.125,
      "learning_rate": 5.0422163588390493e-05,
      "loss": 0.082,
      "step": 5032
    },
    {
      "epoch": 6.64,
      "grad_norm": 75.5,
      "learning_rate": 5.040237467018469e-05,
      "loss": 2.2344,
      "step": 5033
    },
    {
      "epoch": 6.64,
      "grad_norm": 60.5,
      "learning_rate": 5.038258575197888e-05,
      "loss": 0.8711,
      "step": 5034
    },
    {
      "epoch": 6.64,
      "grad_norm": 32.5,
      "learning_rate": 5.036279683377308e-05,
      "loss": 0.2559,
      "step": 5035
    },
    {
      "epoch": 6.64,
      "grad_norm": 25.375,
      "learning_rate": 5.034300791556728e-05,
      "loss": 0.1748,
      "step": 5036
    },
    {
      "epoch": 6.65,
      "grad_norm": 30.125,
      "learning_rate": 5.032321899736147e-05,
      "loss": 0.1738,
      "step": 5037
    },
    {
      "epoch": 6.65,
      "grad_norm": 226.0,
      "learning_rate": 5.030343007915567e-05,
      "loss": 4.8438,
      "step": 5038
    },
    {
      "epoch": 6.65,
      "grad_norm": 184.0,
      "learning_rate": 5.0283641160949866e-05,
      "loss": 4.4062,
      "step": 5039
    },
    {
      "epoch": 6.65,
      "grad_norm": 93.0,
      "learning_rate": 5.026385224274406e-05,
      "loss": 2.3281,
      "step": 5040
    },
    {
      "epoch": 6.65,
      "grad_norm": 174.0,
      "learning_rate": 5.0244063324538256e-05,
      "loss": 4.6875,
      "step": 5041
    },
    {
      "epoch": 6.65,
      "grad_norm": 3.734375,
      "learning_rate": 5.0224274406332454e-05,
      "loss": 0.041,
      "step": 5042
    },
    {
      "epoch": 6.65,
      "grad_norm": 3.390625,
      "learning_rate": 5.0204485488126645e-05,
      "loss": 0.0391,
      "step": 5043
    },
    {
      "epoch": 6.65,
      "grad_norm": 35.25,
      "learning_rate": 5.018469656992084e-05,
      "loss": 0.4434,
      "step": 5044
    },
    {
      "epoch": 6.66,
      "grad_norm": 92.5,
      "learning_rate": 5.016490765171504e-05,
      "loss": 1.4453,
      "step": 5045
    },
    {
      "epoch": 6.66,
      "grad_norm": 205.0,
      "learning_rate": 5.0145118733509226e-05,
      "loss": 3.8594,
      "step": 5046
    },
    {
      "epoch": 6.66,
      "grad_norm": 2.53125,
      "learning_rate": 5.0125329815303424e-05,
      "loss": 0.0244,
      "step": 5047
    },
    {
      "epoch": 6.66,
      "grad_norm": 10.875,
      "learning_rate": 5.0105540897097615e-05,
      "loss": 0.0674,
      "step": 5048
    },
    {
      "epoch": 6.66,
      "grad_norm": 2.109375,
      "learning_rate": 5.008575197889181e-05,
      "loss": 0.0266,
      "step": 5049
    },
    {
      "epoch": 6.66,
      "grad_norm": 138.0,
      "learning_rate": 5.006596306068601e-05,
      "loss": 3.0312,
      "step": 5050
    },
    {
      "epoch": 6.66,
      "grad_norm": 83.0,
      "learning_rate": 5.00461741424802e-05,
      "loss": 1.2266,
      "step": 5051
    },
    {
      "epoch": 6.66,
      "grad_norm": 30.25,
      "learning_rate": 5.00263852242744e-05,
      "loss": 0.8203,
      "step": 5052
    },
    {
      "epoch": 6.67,
      "grad_norm": 42.25,
      "learning_rate": 5.00065963060686e-05,
      "loss": 0.3535,
      "step": 5053
    },
    {
      "epoch": 6.67,
      "grad_norm": 81.0,
      "learning_rate": 4.998680738786279e-05,
      "loss": 2.0781,
      "step": 5054
    },
    {
      "epoch": 6.67,
      "grad_norm": 71.0,
      "learning_rate": 4.996701846965699e-05,
      "loss": 2.2031,
      "step": 5055
    },
    {
      "epoch": 6.67,
      "grad_norm": 140.0,
      "learning_rate": 4.9947229551451186e-05,
      "loss": 1.5547,
      "step": 5056
    },
    {
      "epoch": 6.67,
      "grad_norm": 155.0,
      "learning_rate": 4.992744063324538e-05,
      "loss": 3.2031,
      "step": 5057
    },
    {
      "epoch": 6.67,
      "grad_norm": 14.875,
      "learning_rate": 4.9907651715039575e-05,
      "loss": 0.1895,
      "step": 5058
    },
    {
      "epoch": 6.67,
      "grad_norm": 79.5,
      "learning_rate": 4.988786279683377e-05,
      "loss": 1.5234,
      "step": 5059
    },
    {
      "epoch": 6.68,
      "grad_norm": 4.0625,
      "learning_rate": 4.9868073878627965e-05,
      "loss": 0.0391,
      "step": 5060
    },
    {
      "epoch": 6.68,
      "grad_norm": 20.25,
      "learning_rate": 4.9848284960422156e-05,
      "loss": 0.2207,
      "step": 5061
    },
    {
      "epoch": 6.68,
      "grad_norm": 13.25,
      "learning_rate": 4.9828496042216354e-05,
      "loss": 0.2227,
      "step": 5062
    },
    {
      "epoch": 6.68,
      "grad_norm": 36.25,
      "learning_rate": 4.9808707124010545e-05,
      "loss": 0.8906,
      "step": 5063
    },
    {
      "epoch": 6.68,
      "grad_norm": 39.0,
      "learning_rate": 4.978891820580474e-05,
      "loss": 0.3828,
      "step": 5064
    },
    {
      "epoch": 6.68,
      "grad_norm": 4.46875,
      "learning_rate": 4.976912928759894e-05,
      "loss": 0.0388,
      "step": 5065
    },
    {
      "epoch": 6.68,
      "grad_norm": 10.875,
      "learning_rate": 4.974934036939313e-05,
      "loss": 0.0864,
      "step": 5066
    },
    {
      "epoch": 6.68,
      "grad_norm": 16.75,
      "learning_rate": 4.972955145118733e-05,
      "loss": 0.0894,
      "step": 5067
    },
    {
      "epoch": 6.69,
      "grad_norm": 21.375,
      "learning_rate": 4.970976253298153e-05,
      "loss": 1.0547,
      "step": 5068
    },
    {
      "epoch": 6.69,
      "grad_norm": 14.875,
      "learning_rate": 4.968997361477572e-05,
      "loss": 0.1221,
      "step": 5069
    },
    {
      "epoch": 6.69,
      "grad_norm": 64.5,
      "learning_rate": 4.967018469656992e-05,
      "loss": 0.9922,
      "step": 5070
    },
    {
      "epoch": 6.69,
      "grad_norm": 270.0,
      "learning_rate": 4.9650395778364116e-05,
      "loss": 7.2188,
      "step": 5071
    },
    {
      "epoch": 6.69,
      "grad_norm": 43.0,
      "learning_rate": 4.963060686015831e-05,
      "loss": 0.5859,
      "step": 5072
    },
    {
      "epoch": 6.69,
      "grad_norm": 79.5,
      "learning_rate": 4.9610817941952506e-05,
      "loss": 1.1719,
      "step": 5073
    },
    {
      "epoch": 6.69,
      "grad_norm": 51.0,
      "learning_rate": 4.9591029023746704e-05,
      "loss": 0.2305,
      "step": 5074
    },
    {
      "epoch": 6.7,
      "grad_norm": 26.125,
      "learning_rate": 4.9571240105540895e-05,
      "loss": 0.3184,
      "step": 5075
    },
    {
      "epoch": 6.7,
      "grad_norm": 3.046875,
      "learning_rate": 4.9551451187335086e-05,
      "loss": 0.0297,
      "step": 5076
    },
    {
      "epoch": 6.7,
      "grad_norm": 18.625,
      "learning_rate": 4.953166226912928e-05,
      "loss": 0.5703,
      "step": 5077
    },
    {
      "epoch": 6.7,
      "grad_norm": 106.0,
      "learning_rate": 4.9511873350923475e-05,
      "loss": 2.3125,
      "step": 5078
    },
    {
      "epoch": 6.7,
      "grad_norm": 4.4375,
      "learning_rate": 4.9492084432717674e-05,
      "loss": 0.0417,
      "step": 5079
    },
    {
      "epoch": 6.7,
      "grad_norm": 141.0,
      "learning_rate": 4.9472295514511865e-05,
      "loss": 2.2031,
      "step": 5080
    },
    {
      "epoch": 6.7,
      "grad_norm": 17.25,
      "learning_rate": 4.945250659630606e-05,
      "loss": 0.165,
      "step": 5081
    },
    {
      "epoch": 6.7,
      "grad_norm": 19.875,
      "learning_rate": 4.943271767810026e-05,
      "loss": 0.1934,
      "step": 5082
    },
    {
      "epoch": 6.71,
      "grad_norm": 25.125,
      "learning_rate": 4.941292875989445e-05,
      "loss": 0.4863,
      "step": 5083
    },
    {
      "epoch": 6.71,
      "grad_norm": 77.5,
      "learning_rate": 4.939313984168865e-05,
      "loss": 1.7578,
      "step": 5084
    },
    {
      "epoch": 6.71,
      "grad_norm": 22.75,
      "learning_rate": 4.937335092348285e-05,
      "loss": 0.2754,
      "step": 5085
    },
    {
      "epoch": 6.71,
      "grad_norm": 8.375,
      "learning_rate": 4.935356200527704e-05,
      "loss": 0.0879,
      "step": 5086
    },
    {
      "epoch": 6.71,
      "grad_norm": 100.0,
      "learning_rate": 4.933377308707124e-05,
      "loss": 2.8125,
      "step": 5087
    },
    {
      "epoch": 6.71,
      "grad_norm": 306.0,
      "learning_rate": 4.9313984168865436e-05,
      "loss": 8.75,
      "step": 5088
    },
    {
      "epoch": 6.71,
      "grad_norm": 84.0,
      "learning_rate": 4.929419525065963e-05,
      "loss": 1.4844,
      "step": 5089
    },
    {
      "epoch": 6.72,
      "grad_norm": 31.375,
      "learning_rate": 4.9274406332453825e-05,
      "loss": 0.1592,
      "step": 5090
    },
    {
      "epoch": 6.72,
      "grad_norm": 5.625,
      "learning_rate": 4.925461741424801e-05,
      "loss": 0.0781,
      "step": 5091
    },
    {
      "epoch": 6.72,
      "grad_norm": 168.0,
      "learning_rate": 4.923482849604221e-05,
      "loss": 5.3438,
      "step": 5092
    },
    {
      "epoch": 6.72,
      "grad_norm": 28.125,
      "learning_rate": 4.9215039577836406e-05,
      "loss": 0.8164,
      "step": 5093
    },
    {
      "epoch": 6.72,
      "grad_norm": 3.859375,
      "learning_rate": 4.91952506596306e-05,
      "loss": 0.0425,
      "step": 5094
    },
    {
      "epoch": 6.72,
      "grad_norm": 95.0,
      "learning_rate": 4.9175461741424795e-05,
      "loss": 2.1719,
      "step": 5095
    },
    {
      "epoch": 6.72,
      "grad_norm": 32.25,
      "learning_rate": 4.915567282321899e-05,
      "loss": 0.4492,
      "step": 5096
    },
    {
      "epoch": 6.72,
      "grad_norm": 11.125,
      "learning_rate": 4.9135883905013184e-05,
      "loss": 0.1138,
      "step": 5097
    },
    {
      "epoch": 6.73,
      "grad_norm": 4.875,
      "learning_rate": 4.911609498680738e-05,
      "loss": 0.05,
      "step": 5098
    },
    {
      "epoch": 6.73,
      "grad_norm": 7.5625,
      "learning_rate": 4.909630606860158e-05,
      "loss": 0.0718,
      "step": 5099
    },
    {
      "epoch": 6.73,
      "grad_norm": 96.0,
      "learning_rate": 4.907651715039577e-05,
      "loss": 2.2188,
      "step": 5100
    },
    {
      "epoch": 6.73,
      "grad_norm": 130.0,
      "learning_rate": 4.905672823218997e-05,
      "loss": 3.5625,
      "step": 5101
    },
    {
      "epoch": 6.73,
      "grad_norm": 69.0,
      "learning_rate": 4.903693931398417e-05,
      "loss": 1.1875,
      "step": 5102
    },
    {
      "epoch": 6.73,
      "grad_norm": 153.0,
      "learning_rate": 4.901715039577836e-05,
      "loss": 3.75,
      "step": 5103
    },
    {
      "epoch": 6.73,
      "grad_norm": 149.0,
      "learning_rate": 4.899736147757256e-05,
      "loss": 4.125,
      "step": 5104
    },
    {
      "epoch": 6.73,
      "grad_norm": 4.0625,
      "learning_rate": 4.8977572559366755e-05,
      "loss": 0.0442,
      "step": 5105
    },
    {
      "epoch": 6.74,
      "grad_norm": 155.0,
      "learning_rate": 4.895778364116094e-05,
      "loss": 3.8281,
      "step": 5106
    },
    {
      "epoch": 6.74,
      "grad_norm": 14.875,
      "learning_rate": 4.893799472295514e-05,
      "loss": 0.1245,
      "step": 5107
    },
    {
      "epoch": 6.74,
      "grad_norm": 180.0,
      "learning_rate": 4.8918205804749336e-05,
      "loss": 6.375,
      "step": 5108
    },
    {
      "epoch": 6.74,
      "grad_norm": 255.0,
      "learning_rate": 4.889841688654353e-05,
      "loss": 1.8359,
      "step": 5109
    },
    {
      "epoch": 6.74,
      "grad_norm": 31.75,
      "learning_rate": 4.8878627968337725e-05,
      "loss": 0.4062,
      "step": 5110
    },
    {
      "epoch": 6.74,
      "grad_norm": 11.0625,
      "learning_rate": 4.885883905013192e-05,
      "loss": 0.127,
      "step": 5111
    },
    {
      "epoch": 6.74,
      "grad_norm": 8.125,
      "learning_rate": 4.8839050131926115e-05,
      "loss": 0.1118,
      "step": 5112
    },
    {
      "epoch": 6.75,
      "grad_norm": 6.46875,
      "learning_rate": 4.881926121372031e-05,
      "loss": 0.0747,
      "step": 5113
    },
    {
      "epoch": 6.75,
      "grad_norm": 30.125,
      "learning_rate": 4.879947229551451e-05,
      "loss": 0.4141,
      "step": 5114
    },
    {
      "epoch": 6.75,
      "grad_norm": 6.65625,
      "learning_rate": 4.87796833773087e-05,
      "loss": 0.0654,
      "step": 5115
    },
    {
      "epoch": 6.75,
      "grad_norm": 428.0,
      "learning_rate": 4.87598944591029e-05,
      "loss": 2.2656,
      "step": 5116
    },
    {
      "epoch": 6.75,
      "grad_norm": 26.5,
      "learning_rate": 4.87401055408971e-05,
      "loss": 0.2168,
      "step": 5117
    },
    {
      "epoch": 6.75,
      "grad_norm": 15.25,
      "learning_rate": 4.872031662269129e-05,
      "loss": 0.1709,
      "step": 5118
    },
    {
      "epoch": 6.75,
      "grad_norm": 135.0,
      "learning_rate": 4.870052770448549e-05,
      "loss": 3.4375,
      "step": 5119
    },
    {
      "epoch": 6.75,
      "grad_norm": 124.0,
      "learning_rate": 4.8680738786279686e-05,
      "loss": 1.7734,
      "step": 5120
    },
    {
      "epoch": 6.76,
      "grad_norm": 30.125,
      "learning_rate": 4.866094986807388e-05,
      "loss": 1.1719,
      "step": 5121
    },
    {
      "epoch": 6.76,
      "grad_norm": 8.5625,
      "learning_rate": 4.864116094986807e-05,
      "loss": 0.0898,
      "step": 5122
    },
    {
      "epoch": 6.76,
      "grad_norm": 81.5,
      "learning_rate": 4.862137203166226e-05,
      "loss": 1.3672,
      "step": 5123
    },
    {
      "epoch": 6.76,
      "grad_norm": 21.875,
      "learning_rate": 4.860158311345646e-05,
      "loss": 0.8398,
      "step": 5124
    },
    {
      "epoch": 6.76,
      "grad_norm": 168.0,
      "learning_rate": 4.8581794195250656e-05,
      "loss": 6.75,
      "step": 5125
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.78125,
      "learning_rate": 4.856200527704485e-05,
      "loss": 0.0109,
      "step": 5126
    },
    {
      "epoch": 6.76,
      "grad_norm": 26.875,
      "learning_rate": 4.8542216358839045e-05,
      "loss": 0.6016,
      "step": 5127
    },
    {
      "epoch": 6.77,
      "grad_norm": 3.375,
      "learning_rate": 4.852242744063324e-05,
      "loss": 0.0364,
      "step": 5128
    },
    {
      "epoch": 6.77,
      "grad_norm": 26.75,
      "learning_rate": 4.8502638522427434e-05,
      "loss": 0.1631,
      "step": 5129
    },
    {
      "epoch": 6.77,
      "grad_norm": 205.0,
      "learning_rate": 4.848284960422163e-05,
      "loss": 5.2188,
      "step": 5130
    },
    {
      "epoch": 6.77,
      "grad_norm": 4.3125,
      "learning_rate": 4.846306068601583e-05,
      "loss": 0.0415,
      "step": 5131
    },
    {
      "epoch": 6.77,
      "grad_norm": 49.25,
      "learning_rate": 4.844327176781002e-05,
      "loss": 1.1328,
      "step": 5132
    },
    {
      "epoch": 6.77,
      "grad_norm": 146.0,
      "learning_rate": 4.842348284960422e-05,
      "loss": 4.1875,
      "step": 5133
    },
    {
      "epoch": 6.77,
      "grad_norm": 83.5,
      "learning_rate": 4.840369393139842e-05,
      "loss": 2.1094,
      "step": 5134
    },
    {
      "epoch": 6.77,
      "grad_norm": 250.0,
      "learning_rate": 4.838390501319261e-05,
      "loss": 8.1875,
      "step": 5135
    },
    {
      "epoch": 6.78,
      "grad_norm": 124.0,
      "learning_rate": 4.836411609498681e-05,
      "loss": 1.9062,
      "step": 5136
    },
    {
      "epoch": 6.78,
      "grad_norm": 95.0,
      "learning_rate": 4.834432717678099e-05,
      "loss": 2.2969,
      "step": 5137
    },
    {
      "epoch": 6.78,
      "grad_norm": 10.875,
      "learning_rate": 4.832453825857519e-05,
      "loss": 0.1138,
      "step": 5138
    },
    {
      "epoch": 6.78,
      "grad_norm": 7.21875,
      "learning_rate": 4.830474934036939e-05,
      "loss": 0.1104,
      "step": 5139
    },
    {
      "epoch": 6.78,
      "grad_norm": 147.0,
      "learning_rate": 4.828496042216358e-05,
      "loss": 4.4688,
      "step": 5140
    },
    {
      "epoch": 6.78,
      "grad_norm": 115.5,
      "learning_rate": 4.826517150395778e-05,
      "loss": 2.0469,
      "step": 5141
    },
    {
      "epoch": 6.78,
      "grad_norm": 70.0,
      "learning_rate": 4.8245382585751975e-05,
      "loss": 1.1562,
      "step": 5142
    },
    {
      "epoch": 6.78,
      "grad_norm": 19.5,
      "learning_rate": 4.8225593667546166e-05,
      "loss": 0.459,
      "step": 5143
    },
    {
      "epoch": 6.79,
      "grad_norm": 6.25,
      "learning_rate": 4.8205804749340364e-05,
      "loss": 0.0378,
      "step": 5144
    },
    {
      "epoch": 6.79,
      "grad_norm": 178.0,
      "learning_rate": 4.818601583113456e-05,
      "loss": 6.0625,
      "step": 5145
    },
    {
      "epoch": 6.79,
      "grad_norm": 13.875,
      "learning_rate": 4.8166226912928754e-05,
      "loss": 0.1807,
      "step": 5146
    },
    {
      "epoch": 6.79,
      "grad_norm": 64.5,
      "learning_rate": 4.814643799472295e-05,
      "loss": 1.1484,
      "step": 5147
    },
    {
      "epoch": 6.79,
      "grad_norm": 5.5625,
      "learning_rate": 4.812664907651715e-05,
      "loss": 0.0757,
      "step": 5148
    },
    {
      "epoch": 6.79,
      "grad_norm": 8.0625,
      "learning_rate": 4.810686015831134e-05,
      "loss": 0.0933,
      "step": 5149
    },
    {
      "epoch": 6.79,
      "grad_norm": 23.5,
      "learning_rate": 4.808707124010554e-05,
      "loss": 0.1836,
      "step": 5150
    },
    {
      "epoch": 6.8,
      "grad_norm": 82.0,
      "learning_rate": 4.806728232189974e-05,
      "loss": 1.8438,
      "step": 5151
    },
    {
      "epoch": 6.8,
      "grad_norm": 88.0,
      "learning_rate": 4.804749340369392e-05,
      "loss": 2.0781,
      "step": 5152
    },
    {
      "epoch": 6.8,
      "grad_norm": 22.25,
      "learning_rate": 4.802770448548812e-05,
      "loss": 0.4707,
      "step": 5153
    },
    {
      "epoch": 6.8,
      "grad_norm": 24.125,
      "learning_rate": 4.800791556728232e-05,
      "loss": 0.4707,
      "step": 5154
    },
    {
      "epoch": 6.8,
      "grad_norm": 21.25,
      "learning_rate": 4.798812664907651e-05,
      "loss": 0.9062,
      "step": 5155
    },
    {
      "epoch": 6.8,
      "grad_norm": 27.0,
      "learning_rate": 4.796833773087071e-05,
      "loss": 0.6641,
      "step": 5156
    },
    {
      "epoch": 6.8,
      "grad_norm": 10.875,
      "learning_rate": 4.7948548812664905e-05,
      "loss": 0.0957,
      "step": 5157
    },
    {
      "epoch": 6.8,
      "grad_norm": 10.3125,
      "learning_rate": 4.7928759894459097e-05,
      "loss": 0.1719,
      "step": 5158
    },
    {
      "epoch": 6.81,
      "grad_norm": 88.0,
      "learning_rate": 4.7908970976253295e-05,
      "loss": 1.5234,
      "step": 5159
    },
    {
      "epoch": 6.81,
      "grad_norm": 163.0,
      "learning_rate": 4.788918205804749e-05,
      "loss": 2.875,
      "step": 5160
    },
    {
      "epoch": 6.81,
      "grad_norm": 19.25,
      "learning_rate": 4.7869393139841684e-05,
      "loss": 0.8906,
      "step": 5161
    },
    {
      "epoch": 6.81,
      "grad_norm": 20.5,
      "learning_rate": 4.784960422163588e-05,
      "loss": 0.4492,
      "step": 5162
    },
    {
      "epoch": 6.81,
      "grad_norm": 15.5625,
      "learning_rate": 4.782981530343008e-05,
      "loss": 0.4688,
      "step": 5163
    },
    {
      "epoch": 6.81,
      "grad_norm": 6.09375,
      "learning_rate": 4.781002638522427e-05,
      "loss": 0.0762,
      "step": 5164
    },
    {
      "epoch": 6.81,
      "grad_norm": 216.0,
      "learning_rate": 4.779023746701847e-05,
      "loss": 5.5625,
      "step": 5165
    },
    {
      "epoch": 6.82,
      "grad_norm": 130.0,
      "learning_rate": 4.777044854881267e-05,
      "loss": 3.0625,
      "step": 5166
    },
    {
      "epoch": 6.82,
      "grad_norm": 143.0,
      "learning_rate": 4.775065963060685e-05,
      "loss": 3.3125,
      "step": 5167
    },
    {
      "epoch": 6.82,
      "grad_norm": 16.5,
      "learning_rate": 4.773087071240105e-05,
      "loss": 0.2412,
      "step": 5168
    },
    {
      "epoch": 6.82,
      "grad_norm": 10.0625,
      "learning_rate": 4.771108179419524e-05,
      "loss": 0.0952,
      "step": 5169
    },
    {
      "epoch": 6.82,
      "grad_norm": 8.75,
      "learning_rate": 4.769129287598944e-05,
      "loss": 0.1006,
      "step": 5170
    },
    {
      "epoch": 6.82,
      "grad_norm": 13.0,
      "learning_rate": 4.767150395778364e-05,
      "loss": 0.1348,
      "step": 5171
    },
    {
      "epoch": 6.82,
      "grad_norm": 12.0,
      "learning_rate": 4.765171503957783e-05,
      "loss": 0.168,
      "step": 5172
    },
    {
      "epoch": 6.82,
      "grad_norm": 157.0,
      "learning_rate": 4.763192612137203e-05,
      "loss": 3.8594,
      "step": 5173
    },
    {
      "epoch": 6.83,
      "grad_norm": 11.0,
      "learning_rate": 4.7612137203166225e-05,
      "loss": 0.1572,
      "step": 5174
    },
    {
      "epoch": 6.83,
      "grad_norm": 96.5,
      "learning_rate": 4.7592348284960416e-05,
      "loss": 2.9062,
      "step": 5175
    },
    {
      "epoch": 6.83,
      "grad_norm": 91.0,
      "learning_rate": 4.7572559366754614e-05,
      "loss": 1.3906,
      "step": 5176
    },
    {
      "epoch": 6.83,
      "grad_norm": 71.0,
      "learning_rate": 4.755277044854881e-05,
      "loss": 1.2656,
      "step": 5177
    },
    {
      "epoch": 6.83,
      "grad_norm": 80.0,
      "learning_rate": 4.7532981530343004e-05,
      "loss": 1.5,
      "step": 5178
    },
    {
      "epoch": 6.83,
      "grad_norm": 14.5,
      "learning_rate": 4.75131926121372e-05,
      "loss": 0.165,
      "step": 5179
    },
    {
      "epoch": 6.83,
      "grad_norm": 18.5,
      "learning_rate": 4.74934036939314e-05,
      "loss": 0.5117,
      "step": 5180
    },
    {
      "epoch": 6.84,
      "grad_norm": 116.0,
      "learning_rate": 4.747361477572559e-05,
      "loss": 1.5234,
      "step": 5181
    },
    {
      "epoch": 6.84,
      "grad_norm": 131.0,
      "learning_rate": 4.745382585751978e-05,
      "loss": 3.7031,
      "step": 5182
    },
    {
      "epoch": 6.84,
      "grad_norm": 9.9375,
      "learning_rate": 4.7434036939313974e-05,
      "loss": 0.0938,
      "step": 5183
    },
    {
      "epoch": 6.84,
      "grad_norm": 8.875,
      "learning_rate": 4.741424802110817e-05,
      "loss": 0.0967,
      "step": 5184
    },
    {
      "epoch": 6.84,
      "grad_norm": 164.0,
      "learning_rate": 4.739445910290237e-05,
      "loss": 3.625,
      "step": 5185
    },
    {
      "epoch": 6.84,
      "grad_norm": 262.0,
      "learning_rate": 4.737467018469656e-05,
      "loss": 6.5312,
      "step": 5186
    },
    {
      "epoch": 6.84,
      "grad_norm": 14.4375,
      "learning_rate": 4.735488126649076e-05,
      "loss": 0.1865,
      "step": 5187
    },
    {
      "epoch": 6.84,
      "grad_norm": 97.0,
      "learning_rate": 4.733509234828496e-05,
      "loss": 2.9219,
      "step": 5188
    },
    {
      "epoch": 6.85,
      "grad_norm": 25.25,
      "learning_rate": 4.731530343007915e-05,
      "loss": 0.6797,
      "step": 5189
    },
    {
      "epoch": 6.85,
      "grad_norm": 12.0,
      "learning_rate": 4.7295514511873346e-05,
      "loss": 0.1108,
      "step": 5190
    },
    {
      "epoch": 6.85,
      "grad_norm": 25.375,
      "learning_rate": 4.7275725593667544e-05,
      "loss": 0.7109,
      "step": 5191
    },
    {
      "epoch": 6.85,
      "grad_norm": 22.25,
      "learning_rate": 4.7255936675461736e-05,
      "loss": 0.4746,
      "step": 5192
    },
    {
      "epoch": 6.85,
      "grad_norm": 14.8125,
      "learning_rate": 4.7236147757255934e-05,
      "loss": 0.2754,
      "step": 5193
    },
    {
      "epoch": 6.85,
      "grad_norm": 13.875,
      "learning_rate": 4.721635883905013e-05,
      "loss": 0.1543,
      "step": 5194
    },
    {
      "epoch": 6.85,
      "grad_norm": 19.75,
      "learning_rate": 4.719656992084432e-05,
      "loss": 0.2363,
      "step": 5195
    },
    {
      "epoch": 6.85,
      "grad_norm": 118.0,
      "learning_rate": 4.717678100263852e-05,
      "loss": 3.0312,
      "step": 5196
    },
    {
      "epoch": 6.86,
      "grad_norm": 14.9375,
      "learning_rate": 4.715699208443271e-05,
      "loss": 0.1367,
      "step": 5197
    },
    {
      "epoch": 6.86,
      "grad_norm": 9.625,
      "learning_rate": 4.7137203166226904e-05,
      "loss": 0.0991,
      "step": 5198
    },
    {
      "epoch": 6.86,
      "grad_norm": 18.25,
      "learning_rate": 4.71174142480211e-05,
      "loss": 0.3984,
      "step": 5199
    },
    {
      "epoch": 6.86,
      "grad_norm": 11.5,
      "learning_rate": 4.70976253298153e-05,
      "loss": 0.1533,
      "step": 5200
    },
    {
      "epoch": 6.86,
      "grad_norm": 79.0,
      "learning_rate": 4.707783641160949e-05,
      "loss": 1.4219,
      "step": 5201
    },
    {
      "epoch": 6.86,
      "grad_norm": 5.34375,
      "learning_rate": 4.705804749340369e-05,
      "loss": 0.0859,
      "step": 5202
    },
    {
      "epoch": 6.86,
      "grad_norm": 33.75,
      "learning_rate": 4.703825857519789e-05,
      "loss": 0.4824,
      "step": 5203
    },
    {
      "epoch": 6.87,
      "grad_norm": 12.4375,
      "learning_rate": 4.701846965699208e-05,
      "loss": 0.1133,
      "step": 5204
    },
    {
      "epoch": 6.87,
      "grad_norm": 8.25,
      "learning_rate": 4.699868073878628e-05,
      "loss": 0.0815,
      "step": 5205
    },
    {
      "epoch": 6.87,
      "grad_norm": 185.0,
      "learning_rate": 4.6978891820580475e-05,
      "loss": 4.2188,
      "step": 5206
    },
    {
      "epoch": 6.87,
      "grad_norm": 90.5,
      "learning_rate": 4.6959102902374666e-05,
      "loss": 2.5,
      "step": 5207
    },
    {
      "epoch": 6.87,
      "grad_norm": 110.0,
      "learning_rate": 4.6939313984168864e-05,
      "loss": 2.2031,
      "step": 5208
    },
    {
      "epoch": 6.87,
      "grad_norm": 89.5,
      "learning_rate": 4.691952506596306e-05,
      "loss": 2.1875,
      "step": 5209
    },
    {
      "epoch": 6.87,
      "grad_norm": 111.5,
      "learning_rate": 4.6899736147757253e-05,
      "loss": 1.5938,
      "step": 5210
    },
    {
      "epoch": 6.87,
      "grad_norm": 23.125,
      "learning_rate": 4.687994722955145e-05,
      "loss": 0.6641,
      "step": 5211
    },
    {
      "epoch": 6.88,
      "grad_norm": 28.375,
      "learning_rate": 4.6860158311345636e-05,
      "loss": 0.3125,
      "step": 5212
    },
    {
      "epoch": 6.88,
      "grad_norm": 8.1875,
      "learning_rate": 4.6840369393139834e-05,
      "loss": 0.083,
      "step": 5213
    },
    {
      "epoch": 6.88,
      "grad_norm": 88.5,
      "learning_rate": 4.682058047493403e-05,
      "loss": 1.7969,
      "step": 5214
    },
    {
      "epoch": 6.88,
      "grad_norm": 96.5,
      "learning_rate": 4.680079155672822e-05,
      "loss": 2.0625,
      "step": 5215
    },
    {
      "epoch": 6.88,
      "grad_norm": 149.0,
      "learning_rate": 4.678100263852242e-05,
      "loss": 4.3125,
      "step": 5216
    },
    {
      "epoch": 6.88,
      "grad_norm": 8.1875,
      "learning_rate": 4.676121372031662e-05,
      "loss": 0.0742,
      "step": 5217
    },
    {
      "epoch": 6.88,
      "grad_norm": 136.0,
      "learning_rate": 4.674142480211081e-05,
      "loss": 1.3359,
      "step": 5218
    },
    {
      "epoch": 6.89,
      "grad_norm": 10.375,
      "learning_rate": 4.672163588390501e-05,
      "loss": 0.1494,
      "step": 5219
    },
    {
      "epoch": 6.89,
      "grad_norm": 14.625,
      "learning_rate": 4.670184696569921e-05,
      "loss": 0.168,
      "step": 5220
    },
    {
      "epoch": 6.89,
      "grad_norm": 85.0,
      "learning_rate": 4.66820580474934e-05,
      "loss": 1.4453,
      "step": 5221
    },
    {
      "epoch": 6.89,
      "grad_norm": 124.0,
      "learning_rate": 4.6662269129287596e-05,
      "loss": 3.875,
      "step": 5222
    },
    {
      "epoch": 6.89,
      "grad_norm": 65.0,
      "learning_rate": 4.6642480211081794e-05,
      "loss": 0.8828,
      "step": 5223
    },
    {
      "epoch": 6.89,
      "grad_norm": 88.0,
      "learning_rate": 4.6622691292875986e-05,
      "loss": 1.6719,
      "step": 5224
    },
    {
      "epoch": 6.89,
      "grad_norm": 76.5,
      "learning_rate": 4.6602902374670184e-05,
      "loss": 1.7188,
      "step": 5225
    },
    {
      "epoch": 6.89,
      "grad_norm": 8.3125,
      "learning_rate": 4.658311345646438e-05,
      "loss": 0.0806,
      "step": 5226
    },
    {
      "epoch": 6.9,
      "grad_norm": 19.0,
      "learning_rate": 4.6563324538258566e-05,
      "loss": 0.2402,
      "step": 5227
    },
    {
      "epoch": 6.9,
      "grad_norm": 12.375,
      "learning_rate": 4.6543535620052764e-05,
      "loss": 0.1504,
      "step": 5228
    },
    {
      "epoch": 6.9,
      "grad_norm": 12.125,
      "learning_rate": 4.652374670184696e-05,
      "loss": 0.1895,
      "step": 5229
    },
    {
      "epoch": 6.9,
      "grad_norm": 11.25,
      "learning_rate": 4.6503957783641154e-05,
      "loss": 0.1348,
      "step": 5230
    },
    {
      "epoch": 6.9,
      "grad_norm": 82.0,
      "learning_rate": 4.648416886543535e-05,
      "loss": 1.1094,
      "step": 5231
    },
    {
      "epoch": 6.9,
      "grad_norm": 130.0,
      "learning_rate": 4.646437994722955e-05,
      "loss": 3.3438,
      "step": 5232
    },
    {
      "epoch": 6.9,
      "grad_norm": 129.0,
      "learning_rate": 4.644459102902374e-05,
      "loss": 3.375,
      "step": 5233
    },
    {
      "epoch": 6.91,
      "grad_norm": 111.0,
      "learning_rate": 4.642480211081794e-05,
      "loss": 1.4062,
      "step": 5234
    },
    {
      "epoch": 6.91,
      "grad_norm": 4.84375,
      "learning_rate": 4.640501319261214e-05,
      "loss": 0.0518,
      "step": 5235
    },
    {
      "epoch": 6.91,
      "grad_norm": 164.0,
      "learning_rate": 4.638522427440633e-05,
      "loss": 7.75,
      "step": 5236
    },
    {
      "epoch": 6.91,
      "grad_norm": 37.0,
      "learning_rate": 4.6365435356200526e-05,
      "loss": 0.4746,
      "step": 5237
    },
    {
      "epoch": 6.91,
      "grad_norm": 39.0,
      "learning_rate": 4.6345646437994725e-05,
      "loss": 0.3145,
      "step": 5238
    },
    {
      "epoch": 6.91,
      "grad_norm": 163.0,
      "learning_rate": 4.6325857519788916e-05,
      "loss": 2.2031,
      "step": 5239
    },
    {
      "epoch": 6.91,
      "grad_norm": 171.0,
      "learning_rate": 4.6306068601583114e-05,
      "loss": 4.8125,
      "step": 5240
    },
    {
      "epoch": 6.91,
      "grad_norm": 92.0,
      "learning_rate": 4.628627968337731e-05,
      "loss": 1.3438,
      "step": 5241
    },
    {
      "epoch": 6.92,
      "grad_norm": 125.0,
      "learning_rate": 4.6266490765171496e-05,
      "loss": 3.6562,
      "step": 5242
    },
    {
      "epoch": 6.92,
      "grad_norm": 13.875,
      "learning_rate": 4.6246701846965694e-05,
      "loss": 0.1592,
      "step": 5243
    },
    {
      "epoch": 6.92,
      "grad_norm": 171.0,
      "learning_rate": 4.6226912928759886e-05,
      "loss": 5.0938,
      "step": 5244
    },
    {
      "epoch": 6.92,
      "grad_norm": 58.75,
      "learning_rate": 4.6207124010554084e-05,
      "loss": 0.7891,
      "step": 5245
    },
    {
      "epoch": 6.92,
      "grad_norm": 45.5,
      "learning_rate": 4.618733509234828e-05,
      "loss": 0.4258,
      "step": 5246
    },
    {
      "epoch": 6.92,
      "grad_norm": 167.0,
      "learning_rate": 4.616754617414247e-05,
      "loss": 2.9844,
      "step": 5247
    },
    {
      "epoch": 6.92,
      "grad_norm": 190.0,
      "learning_rate": 4.614775725593667e-05,
      "loss": 3.8125,
      "step": 5248
    },
    {
      "epoch": 6.92,
      "grad_norm": 73.5,
      "learning_rate": 4.612796833773087e-05,
      "loss": 1.2656,
      "step": 5249
    },
    {
      "epoch": 6.93,
      "grad_norm": 122.5,
      "learning_rate": 4.610817941952506e-05,
      "loss": 2.2031,
      "step": 5250
    },
    {
      "epoch": 6.93,
      "grad_norm": 128.0,
      "learning_rate": 4.608839050131926e-05,
      "loss": 2.7031,
      "step": 5251
    },
    {
      "epoch": 6.93,
      "grad_norm": 22.125,
      "learning_rate": 4.606860158311346e-05,
      "loss": 0.5234,
      "step": 5252
    },
    {
      "epoch": 6.93,
      "grad_norm": 9.1875,
      "learning_rate": 4.604881266490765e-05,
      "loss": 0.1172,
      "step": 5253
    },
    {
      "epoch": 6.93,
      "grad_norm": 12.0625,
      "learning_rate": 4.6029023746701846e-05,
      "loss": 0.1729,
      "step": 5254
    },
    {
      "epoch": 6.93,
      "grad_norm": 157.0,
      "learning_rate": 4.6009234828496044e-05,
      "loss": 4.1562,
      "step": 5255
    },
    {
      "epoch": 6.93,
      "grad_norm": 20.875,
      "learning_rate": 4.5989445910290235e-05,
      "loss": 0.291,
      "step": 5256
    },
    {
      "epoch": 6.94,
      "grad_norm": 24.875,
      "learning_rate": 4.596965699208443e-05,
      "loss": 0.8906,
      "step": 5257
    },
    {
      "epoch": 6.94,
      "grad_norm": 126.5,
      "learning_rate": 4.594986807387862e-05,
      "loss": 3.0312,
      "step": 5258
    },
    {
      "epoch": 6.94,
      "grad_norm": 9.5,
      "learning_rate": 4.5930079155672816e-05,
      "loss": 0.1055,
      "step": 5259
    },
    {
      "epoch": 6.94,
      "grad_norm": 135.0,
      "learning_rate": 4.5910290237467014e-05,
      "loss": 2.0469,
      "step": 5260
    },
    {
      "epoch": 6.94,
      "grad_norm": 156.0,
      "learning_rate": 4.5890501319261205e-05,
      "loss": 5.0625,
      "step": 5261
    },
    {
      "epoch": 6.94,
      "grad_norm": 129.0,
      "learning_rate": 4.5870712401055403e-05,
      "loss": 3.5781,
      "step": 5262
    },
    {
      "epoch": 6.94,
      "grad_norm": 21.0,
      "learning_rate": 4.58509234828496e-05,
      "loss": 0.2344,
      "step": 5263
    },
    {
      "epoch": 6.94,
      "grad_norm": 68.0,
      "learning_rate": 4.583113456464379e-05,
      "loss": 1.2891,
      "step": 5264
    },
    {
      "epoch": 6.95,
      "grad_norm": 49.25,
      "learning_rate": 4.581134564643799e-05,
      "loss": 0.8086,
      "step": 5265
    },
    {
      "epoch": 6.95,
      "grad_norm": 17.75,
      "learning_rate": 4.579155672823219e-05,
      "loss": 0.3145,
      "step": 5266
    },
    {
      "epoch": 6.95,
      "grad_norm": 128.0,
      "learning_rate": 4.577176781002638e-05,
      "loss": 2.9844,
      "step": 5267
    },
    {
      "epoch": 6.95,
      "grad_norm": 11.4375,
      "learning_rate": 4.575197889182058e-05,
      "loss": 0.127,
      "step": 5268
    },
    {
      "epoch": 6.95,
      "grad_norm": 16.625,
      "learning_rate": 4.5732189973614776e-05,
      "loss": 0.1846,
      "step": 5269
    },
    {
      "epoch": 6.95,
      "grad_norm": 11.9375,
      "learning_rate": 4.571240105540897e-05,
      "loss": 0.1406,
      "step": 5270
    },
    {
      "epoch": 6.95,
      "grad_norm": 59.0,
      "learning_rate": 4.5692612137203166e-05,
      "loss": 0.8867,
      "step": 5271
    },
    {
      "epoch": 6.96,
      "grad_norm": 84.5,
      "learning_rate": 4.567282321899736e-05,
      "loss": 1.9297,
      "step": 5272
    },
    {
      "epoch": 6.96,
      "grad_norm": 23.625,
      "learning_rate": 4.565303430079155e-05,
      "loss": 0.6133,
      "step": 5273
    },
    {
      "epoch": 6.96,
      "grad_norm": 38.5,
      "learning_rate": 4.5633245382585746e-05,
      "loss": 0.6445,
      "step": 5274
    },
    {
      "epoch": 6.96,
      "grad_norm": 39.5,
      "learning_rate": 4.5613456464379944e-05,
      "loss": 0.8164,
      "step": 5275
    },
    {
      "epoch": 6.96,
      "grad_norm": 182.0,
      "learning_rate": 4.5593667546174136e-05,
      "loss": 3.6719,
      "step": 5276
    },
    {
      "epoch": 6.96,
      "grad_norm": 26.875,
      "learning_rate": 4.5573878627968334e-05,
      "loss": 0.3457,
      "step": 5277
    },
    {
      "epoch": 6.96,
      "grad_norm": 93.5,
      "learning_rate": 4.555408970976253e-05,
      "loss": 2.2812,
      "step": 5278
    },
    {
      "epoch": 6.96,
      "grad_norm": 13.0,
      "learning_rate": 4.553430079155672e-05,
      "loss": 0.2246,
      "step": 5279
    },
    {
      "epoch": 6.97,
      "grad_norm": 55.25,
      "learning_rate": 4.551451187335092e-05,
      "loss": 1.5234,
      "step": 5280
    },
    {
      "epoch": 6.97,
      "grad_norm": 17.875,
      "learning_rate": 4.549472295514512e-05,
      "loss": 0.377,
      "step": 5281
    },
    {
      "epoch": 6.97,
      "grad_norm": 29.125,
      "learning_rate": 4.547493403693931e-05,
      "loss": 0.5195,
      "step": 5282
    },
    {
      "epoch": 6.97,
      "grad_norm": 8.3125,
      "learning_rate": 4.545514511873351e-05,
      "loss": 0.1465,
      "step": 5283
    },
    {
      "epoch": 6.97,
      "grad_norm": 42.75,
      "learning_rate": 4.5435356200527707e-05,
      "loss": 0.8125,
      "step": 5284
    },
    {
      "epoch": 6.97,
      "grad_norm": 23.875,
      "learning_rate": 4.54155672823219e-05,
      "loss": 0.7578,
      "step": 5285
    },
    {
      "epoch": 6.97,
      "grad_norm": 22.875,
      "learning_rate": 4.5395778364116096e-05,
      "loss": 0.9336,
      "step": 5286
    },
    {
      "epoch": 6.97,
      "grad_norm": 132.0,
      "learning_rate": 4.537598944591028e-05,
      "loss": 3.4531,
      "step": 5287
    },
    {
      "epoch": 6.98,
      "grad_norm": 18.75,
      "learning_rate": 4.535620052770448e-05,
      "loss": 0.4492,
      "step": 5288
    },
    {
      "epoch": 6.98,
      "grad_norm": 102.0,
      "learning_rate": 4.5336411609498676e-05,
      "loss": 2.4531,
      "step": 5289
    },
    {
      "epoch": 6.98,
      "grad_norm": 16.75,
      "learning_rate": 4.531662269129287e-05,
      "loss": 0.209,
      "step": 5290
    },
    {
      "epoch": 6.98,
      "grad_norm": 13.875,
      "learning_rate": 4.5296833773087066e-05,
      "loss": 0.2207,
      "step": 5291
    },
    {
      "epoch": 6.98,
      "grad_norm": 69.0,
      "learning_rate": 4.5277044854881264e-05,
      "loss": 1.6641,
      "step": 5292
    },
    {
      "epoch": 6.98,
      "grad_norm": 18.875,
      "learning_rate": 4.5257255936675455e-05,
      "loss": 0.3574,
      "step": 5293
    },
    {
      "epoch": 6.98,
      "grad_norm": 19.125,
      "learning_rate": 4.523746701846965e-05,
      "loss": 0.2344,
      "step": 5294
    },
    {
      "epoch": 6.99,
      "grad_norm": 66.0,
      "learning_rate": 4.521767810026385e-05,
      "loss": 1.6172,
      "step": 5295
    },
    {
      "epoch": 6.99,
      "grad_norm": 19.5,
      "learning_rate": 4.519788918205804e-05,
      "loss": 0.252,
      "step": 5296
    },
    {
      "epoch": 6.99,
      "grad_norm": 37.0,
      "learning_rate": 4.517810026385224e-05,
      "loss": 0.707,
      "step": 5297
    },
    {
      "epoch": 6.99,
      "grad_norm": 18.75,
      "learning_rate": 4.515831134564644e-05,
      "loss": 0.2256,
      "step": 5298
    },
    {
      "epoch": 6.99,
      "grad_norm": 23.75,
      "learning_rate": 4.513852242744063e-05,
      "loss": 0.5664,
      "step": 5299
    },
    {
      "epoch": 6.99,
      "grad_norm": 107.5,
      "learning_rate": 4.511873350923483e-05,
      "loss": 2.375,
      "step": 5300
    },
    {
      "epoch": 6.99,
      "grad_norm": 25.125,
      "learning_rate": 4.5098944591029026e-05,
      "loss": 0.6914,
      "step": 5301
    },
    {
      "epoch": 6.99,
      "grad_norm": 20.25,
      "learning_rate": 4.507915567282321e-05,
      "loss": 0.3965,
      "step": 5302
    },
    {
      "epoch": 7.0,
      "grad_norm": 99.5,
      "learning_rate": 4.505936675461741e-05,
      "loss": 2.9844,
      "step": 5303
    },
    {
      "epoch": 7.0,
      "grad_norm": 82.0,
      "learning_rate": 4.50395778364116e-05,
      "loss": 1.5547,
      "step": 5304
    },
    {
      "epoch": 7.0,
      "grad_norm": 16.125,
      "learning_rate": 4.50197889182058e-05,
      "loss": 0.166,
      "step": 5305
    },
    {
      "epoch": 7.0,
      "grad_norm": 21.0,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 0.1357,
      "step": 5306
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.5329121351242065,
      "eval_runtime": 18.2783,
      "eval_samples_per_second": 42.783,
      "eval_steps_per_second": 10.723,
      "step": 5306
    },
    {
      "epoch": 7.0,
      "grad_norm": 7.53125,
      "learning_rate": 4.498021108179419e-05,
      "loss": 0.1289,
      "step": 5307
    },
    {
      "epoch": 7.0,
      "grad_norm": 7.25,
      "learning_rate": 4.4960422163588385e-05,
      "loss": 0.0845,
      "step": 5308
    },
    {
      "epoch": 7.0,
      "grad_norm": 91.5,
      "learning_rate": 4.4940633245382583e-05,
      "loss": 1.9609,
      "step": 5309
    },
    {
      "epoch": 7.01,
      "grad_norm": 3.171875,
      "learning_rate": 4.4920844327176775e-05,
      "loss": 0.0471,
      "step": 5310
    },
    {
      "epoch": 7.01,
      "grad_norm": 41.0,
      "learning_rate": 4.490105540897097e-05,
      "loss": 0.5938,
      "step": 5311
    },
    {
      "epoch": 7.01,
      "grad_norm": 137.0,
      "learning_rate": 4.488126649076517e-05,
      "loss": 3.4219,
      "step": 5312
    },
    {
      "epoch": 7.01,
      "grad_norm": 82.5,
      "learning_rate": 4.486147757255936e-05,
      "loss": 2.0625,
      "step": 5313
    },
    {
      "epoch": 7.01,
      "grad_norm": 15.625,
      "learning_rate": 4.484168865435356e-05,
      "loss": 0.4023,
      "step": 5314
    },
    {
      "epoch": 7.01,
      "grad_norm": 90.5,
      "learning_rate": 4.482189973614776e-05,
      "loss": 3.2656,
      "step": 5315
    },
    {
      "epoch": 7.01,
      "grad_norm": 80.0,
      "learning_rate": 4.480211081794195e-05,
      "loss": 1.8672,
      "step": 5316
    },
    {
      "epoch": 7.01,
      "grad_norm": 143.0,
      "learning_rate": 4.478232189973614e-05,
      "loss": 3.5312,
      "step": 5317
    },
    {
      "epoch": 7.02,
      "grad_norm": 131.0,
      "learning_rate": 4.476253298153034e-05,
      "loss": 3.4844,
      "step": 5318
    },
    {
      "epoch": 7.02,
      "grad_norm": 18.25,
      "learning_rate": 4.474274406332453e-05,
      "loss": 0.6953,
      "step": 5319
    },
    {
      "epoch": 7.02,
      "grad_norm": 176.0,
      "learning_rate": 4.472295514511873e-05,
      "loss": 3.5312,
      "step": 5320
    },
    {
      "epoch": 7.02,
      "grad_norm": 197.0,
      "learning_rate": 4.4703166226912926e-05,
      "loss": 6.2812,
      "step": 5321
    },
    {
      "epoch": 7.02,
      "grad_norm": 157.0,
      "learning_rate": 4.468337730870712e-05,
      "loss": 3.0469,
      "step": 5322
    },
    {
      "epoch": 7.02,
      "grad_norm": 77.5,
      "learning_rate": 4.4663588390501316e-05,
      "loss": 1.4688,
      "step": 5323
    },
    {
      "epoch": 7.02,
      "grad_norm": 6.5,
      "learning_rate": 4.4643799472295514e-05,
      "loss": 0.0771,
      "step": 5324
    },
    {
      "epoch": 7.03,
      "grad_norm": 14.125,
      "learning_rate": 4.4624010554089705e-05,
      "loss": 0.9453,
      "step": 5325
    },
    {
      "epoch": 7.03,
      "grad_norm": 121.0,
      "learning_rate": 4.46042216358839e-05,
      "loss": 3.1719,
      "step": 5326
    },
    {
      "epoch": 7.03,
      "grad_norm": 249.0,
      "learning_rate": 4.45844327176781e-05,
      "loss": 5.2812,
      "step": 5327
    },
    {
      "epoch": 7.03,
      "grad_norm": 91.0,
      "learning_rate": 4.456464379947229e-05,
      "loss": 1.8047,
      "step": 5328
    },
    {
      "epoch": 7.03,
      "grad_norm": 124.0,
      "learning_rate": 4.454485488126649e-05,
      "loss": 2.8125,
      "step": 5329
    },
    {
      "epoch": 7.03,
      "grad_norm": 14.375,
      "learning_rate": 4.452506596306069e-05,
      "loss": 0.2578,
      "step": 5330
    },
    {
      "epoch": 7.03,
      "grad_norm": 12.5625,
      "learning_rate": 4.450527704485488e-05,
      "loss": 0.1426,
      "step": 5331
    },
    {
      "epoch": 7.03,
      "grad_norm": 65.5,
      "learning_rate": 4.448548812664907e-05,
      "loss": 1.4297,
      "step": 5332
    },
    {
      "epoch": 7.04,
      "grad_norm": 28.0,
      "learning_rate": 4.446569920844326e-05,
      "loss": 0.252,
      "step": 5333
    },
    {
      "epoch": 7.04,
      "grad_norm": 67.0,
      "learning_rate": 4.444591029023746e-05,
      "loss": 1.1562,
      "step": 5334
    },
    {
      "epoch": 7.04,
      "grad_norm": 16.875,
      "learning_rate": 4.442612137203166e-05,
      "loss": 0.1836,
      "step": 5335
    },
    {
      "epoch": 7.04,
      "grad_norm": 142.0,
      "learning_rate": 4.440633245382585e-05,
      "loss": 3.6719,
      "step": 5336
    },
    {
      "epoch": 7.04,
      "grad_norm": 31.75,
      "learning_rate": 4.438654353562005e-05,
      "loss": 0.3535,
      "step": 5337
    },
    {
      "epoch": 7.04,
      "grad_norm": 6.5,
      "learning_rate": 4.4366754617414246e-05,
      "loss": 0.1045,
      "step": 5338
    },
    {
      "epoch": 7.04,
      "grad_norm": 9.625,
      "learning_rate": 4.434696569920844e-05,
      "loss": 0.1377,
      "step": 5339
    },
    {
      "epoch": 7.04,
      "grad_norm": 62.25,
      "learning_rate": 4.4327176781002635e-05,
      "loss": 1.2109,
      "step": 5340
    },
    {
      "epoch": 7.05,
      "grad_norm": 14.125,
      "learning_rate": 4.430738786279683e-05,
      "loss": 0.5156,
      "step": 5341
    },
    {
      "epoch": 7.05,
      "grad_norm": 38.75,
      "learning_rate": 4.4287598944591025e-05,
      "loss": 0.7422,
      "step": 5342
    },
    {
      "epoch": 7.05,
      "grad_norm": 36.25,
      "learning_rate": 4.426781002638522e-05,
      "loss": 0.498,
      "step": 5343
    },
    {
      "epoch": 7.05,
      "grad_norm": 324.0,
      "learning_rate": 4.424802110817942e-05,
      "loss": 2.5781,
      "step": 5344
    },
    {
      "epoch": 7.05,
      "grad_norm": 18.5,
      "learning_rate": 4.422823218997361e-05,
      "loss": 0.2656,
      "step": 5345
    },
    {
      "epoch": 7.05,
      "grad_norm": 19.5,
      "learning_rate": 4.420844327176781e-05,
      "loss": 0.5547,
      "step": 5346
    },
    {
      "epoch": 7.05,
      "grad_norm": 16.125,
      "learning_rate": 4.4188654353561995e-05,
      "loss": 0.3105,
      "step": 5347
    },
    {
      "epoch": 7.06,
      "grad_norm": 131.0,
      "learning_rate": 4.416886543535619e-05,
      "loss": 3.4531,
      "step": 5348
    },
    {
      "epoch": 7.06,
      "grad_norm": 70.0,
      "learning_rate": 4.414907651715039e-05,
      "loss": 1.3672,
      "step": 5349
    },
    {
      "epoch": 7.06,
      "grad_norm": 69.5,
      "learning_rate": 4.412928759894458e-05,
      "loss": 1.2422,
      "step": 5350
    },
    {
      "epoch": 7.06,
      "grad_norm": 127.0,
      "learning_rate": 4.410949868073878e-05,
      "loss": 2.6562,
      "step": 5351
    },
    {
      "epoch": 7.06,
      "grad_norm": 140.0,
      "learning_rate": 4.408970976253298e-05,
      "loss": 2.625,
      "step": 5352
    },
    {
      "epoch": 7.06,
      "grad_norm": 13.8125,
      "learning_rate": 4.406992084432717e-05,
      "loss": 0.208,
      "step": 5353
    },
    {
      "epoch": 7.06,
      "grad_norm": 18.625,
      "learning_rate": 4.405013192612137e-05,
      "loss": 0.2266,
      "step": 5354
    },
    {
      "epoch": 7.06,
      "grad_norm": 11.5,
      "learning_rate": 4.4030343007915565e-05,
      "loss": 0.1738,
      "step": 5355
    },
    {
      "epoch": 7.07,
      "grad_norm": 46.5,
      "learning_rate": 4.401055408970976e-05,
      "loss": 0.8242,
      "step": 5356
    },
    {
      "epoch": 7.07,
      "grad_norm": 119.0,
      "learning_rate": 4.3990765171503955e-05,
      "loss": 2.8438,
      "step": 5357
    },
    {
      "epoch": 7.07,
      "grad_norm": 60.75,
      "learning_rate": 4.397097625329815e-05,
      "loss": 1.0547,
      "step": 5358
    },
    {
      "epoch": 7.07,
      "grad_norm": 13.625,
      "learning_rate": 4.3951187335092344e-05,
      "loss": 0.2188,
      "step": 5359
    },
    {
      "epoch": 7.07,
      "grad_norm": 55.0,
      "learning_rate": 4.393139841688654e-05,
      "loss": 0.8984,
      "step": 5360
    },
    {
      "epoch": 7.07,
      "grad_norm": 17.0,
      "learning_rate": 4.391160949868074e-05,
      "loss": 0.3105,
      "step": 5361
    },
    {
      "epoch": 7.07,
      "grad_norm": 17.375,
      "learning_rate": 4.3891820580474925e-05,
      "loss": 0.1992,
      "step": 5362
    },
    {
      "epoch": 7.08,
      "grad_norm": 40.5,
      "learning_rate": 4.387203166226912e-05,
      "loss": 0.6172,
      "step": 5363
    },
    {
      "epoch": 7.08,
      "grad_norm": 89.0,
      "learning_rate": 4.385224274406332e-05,
      "loss": 1.3594,
      "step": 5364
    },
    {
      "epoch": 7.08,
      "grad_norm": 11.4375,
      "learning_rate": 4.383245382585751e-05,
      "loss": 0.126,
      "step": 5365
    },
    {
      "epoch": 7.08,
      "grad_norm": 152.0,
      "learning_rate": 4.381266490765171e-05,
      "loss": 2.5938,
      "step": 5366
    },
    {
      "epoch": 7.08,
      "grad_norm": 22.75,
      "learning_rate": 4.379287598944591e-05,
      "loss": 0.4746,
      "step": 5367
    },
    {
      "epoch": 7.08,
      "grad_norm": 130.0,
      "learning_rate": 4.37730870712401e-05,
      "loss": 1.7422,
      "step": 5368
    },
    {
      "epoch": 7.08,
      "grad_norm": 16.625,
      "learning_rate": 4.37532981530343e-05,
      "loss": 0.6484,
      "step": 5369
    },
    {
      "epoch": 7.08,
      "grad_norm": 13.0625,
      "learning_rate": 4.3733509234828496e-05,
      "loss": 0.0889,
      "step": 5370
    },
    {
      "epoch": 7.09,
      "grad_norm": 19.125,
      "learning_rate": 4.371372031662269e-05,
      "loss": 0.6719,
      "step": 5371
    },
    {
      "epoch": 7.09,
      "grad_norm": 28.0,
      "learning_rate": 4.3693931398416885e-05,
      "loss": 0.4863,
      "step": 5372
    },
    {
      "epoch": 7.09,
      "grad_norm": 25.125,
      "learning_rate": 4.367414248021108e-05,
      "loss": 0.332,
      "step": 5373
    },
    {
      "epoch": 7.09,
      "grad_norm": 6.25,
      "learning_rate": 4.3654353562005274e-05,
      "loss": 0.0732,
      "step": 5374
    },
    {
      "epoch": 7.09,
      "grad_norm": 113.0,
      "learning_rate": 4.363456464379947e-05,
      "loss": 2.7656,
      "step": 5375
    },
    {
      "epoch": 7.09,
      "grad_norm": 31.25,
      "learning_rate": 4.361477572559367e-05,
      "loss": 0.4668,
      "step": 5376
    },
    {
      "epoch": 7.09,
      "grad_norm": 18.25,
      "learning_rate": 4.3594986807387855e-05,
      "loss": 0.25,
      "step": 5377
    },
    {
      "epoch": 7.09,
      "grad_norm": 21.25,
      "learning_rate": 4.357519788918205e-05,
      "loss": 0.2559,
      "step": 5378
    },
    {
      "epoch": 7.1,
      "grad_norm": 132.0,
      "learning_rate": 4.3555408970976244e-05,
      "loss": 3.5312,
      "step": 5379
    },
    {
      "epoch": 7.1,
      "grad_norm": 130.0,
      "learning_rate": 4.353562005277044e-05,
      "loss": 2.25,
      "step": 5380
    },
    {
      "epoch": 7.1,
      "grad_norm": 233.0,
      "learning_rate": 4.351583113456464e-05,
      "loss": 5.8438,
      "step": 5381
    },
    {
      "epoch": 7.1,
      "grad_norm": 83.5,
      "learning_rate": 4.349604221635883e-05,
      "loss": 1.5938,
      "step": 5382
    },
    {
      "epoch": 7.1,
      "grad_norm": 26.375,
      "learning_rate": 4.347625329815303e-05,
      "loss": 0.418,
      "step": 5383
    },
    {
      "epoch": 7.1,
      "grad_norm": 48.0,
      "learning_rate": 4.345646437994723e-05,
      "loss": 0.6914,
      "step": 5384
    },
    {
      "epoch": 7.1,
      "grad_norm": 12.1875,
      "learning_rate": 4.343667546174142e-05,
      "loss": 0.2031,
      "step": 5385
    },
    {
      "epoch": 7.11,
      "grad_norm": 17.375,
      "learning_rate": 4.341688654353562e-05,
      "loss": 0.248,
      "step": 5386
    },
    {
      "epoch": 7.11,
      "grad_norm": 104.5,
      "learning_rate": 4.3397097625329815e-05,
      "loss": 3.3125,
      "step": 5387
    },
    {
      "epoch": 7.11,
      "grad_norm": 18.5,
      "learning_rate": 4.3377308707124007e-05,
      "loss": 0.4883,
      "step": 5388
    },
    {
      "epoch": 7.11,
      "grad_norm": 74.0,
      "learning_rate": 4.3357519788918205e-05,
      "loss": 1.4375,
      "step": 5389
    },
    {
      "epoch": 7.11,
      "grad_norm": 21.75,
      "learning_rate": 4.33377308707124e-05,
      "loss": 0.167,
      "step": 5390
    },
    {
      "epoch": 7.11,
      "grad_norm": 16.5,
      "learning_rate": 4.3317941952506594e-05,
      "loss": 0.4355,
      "step": 5391
    },
    {
      "epoch": 7.11,
      "grad_norm": 102.5,
      "learning_rate": 4.3298153034300785e-05,
      "loss": 2.5312,
      "step": 5392
    },
    {
      "epoch": 7.11,
      "grad_norm": 13.75,
      "learning_rate": 4.3278364116094977e-05,
      "loss": 0.1777,
      "step": 5393
    },
    {
      "epoch": 7.12,
      "grad_norm": 72.0,
      "learning_rate": 4.3258575197889175e-05,
      "loss": 1.2266,
      "step": 5394
    },
    {
      "epoch": 7.12,
      "grad_norm": 16.25,
      "learning_rate": 4.323878627968337e-05,
      "loss": 0.2734,
      "step": 5395
    },
    {
      "epoch": 7.12,
      "grad_norm": 16.375,
      "learning_rate": 4.3218997361477564e-05,
      "loss": 0.4844,
      "step": 5396
    },
    {
      "epoch": 7.12,
      "grad_norm": 113.5,
      "learning_rate": 4.319920844327176e-05,
      "loss": 2.9219,
      "step": 5397
    },
    {
      "epoch": 7.12,
      "grad_norm": 130.0,
      "learning_rate": 4.317941952506596e-05,
      "loss": 3.1562,
      "step": 5398
    },
    {
      "epoch": 7.12,
      "grad_norm": 10.6875,
      "learning_rate": 4.315963060686015e-05,
      "loss": 0.2285,
      "step": 5399
    },
    {
      "epoch": 7.12,
      "grad_norm": 85.5,
      "learning_rate": 4.313984168865435e-05,
      "loss": 1.5781,
      "step": 5400
    },
    {
      "epoch": 7.13,
      "grad_norm": 17.25,
      "learning_rate": 4.312005277044855e-05,
      "loss": 0.2324,
      "step": 5401
    },
    {
      "epoch": 7.13,
      "grad_norm": 23.875,
      "learning_rate": 4.310026385224274e-05,
      "loss": 0.5859,
      "step": 5402
    },
    {
      "epoch": 7.13,
      "grad_norm": 316.0,
      "learning_rate": 4.308047493403694e-05,
      "loss": 8.5,
      "step": 5403
    },
    {
      "epoch": 7.13,
      "grad_norm": 14.9375,
      "learning_rate": 4.3060686015831135e-05,
      "loss": 0.2402,
      "step": 5404
    },
    {
      "epoch": 7.13,
      "grad_norm": 94.0,
      "learning_rate": 4.3040897097625326e-05,
      "loss": 1.5,
      "step": 5405
    },
    {
      "epoch": 7.13,
      "grad_norm": 61.75,
      "learning_rate": 4.3021108179419524e-05,
      "loss": 0.9805,
      "step": 5406
    },
    {
      "epoch": 7.13,
      "grad_norm": 25.125,
      "learning_rate": 4.3001319261213715e-05,
      "loss": 0.5781,
      "step": 5407
    },
    {
      "epoch": 7.13,
      "grad_norm": 57.25,
      "learning_rate": 4.298153034300791e-05,
      "loss": 0.9297,
      "step": 5408
    },
    {
      "epoch": 7.14,
      "grad_norm": 24.75,
      "learning_rate": 4.2961741424802105e-05,
      "loss": 0.3516,
      "step": 5409
    },
    {
      "epoch": 7.14,
      "grad_norm": 16.875,
      "learning_rate": 4.29419525065963e-05,
      "loss": 0.4453,
      "step": 5410
    },
    {
      "epoch": 7.14,
      "grad_norm": 141.0,
      "learning_rate": 4.2922163588390494e-05,
      "loss": 3.4688,
      "step": 5411
    },
    {
      "epoch": 7.14,
      "grad_norm": 6.5,
      "learning_rate": 4.290237467018469e-05,
      "loss": 0.0962,
      "step": 5412
    },
    {
      "epoch": 7.14,
      "grad_norm": 13.125,
      "learning_rate": 4.288258575197889e-05,
      "loss": 0.1582,
      "step": 5413
    },
    {
      "epoch": 7.14,
      "grad_norm": 81.5,
      "learning_rate": 4.286279683377308e-05,
      "loss": 4.0625,
      "step": 5414
    },
    {
      "epoch": 7.14,
      "grad_norm": 17.0,
      "learning_rate": 4.284300791556728e-05,
      "loss": 0.1875,
      "step": 5415
    },
    {
      "epoch": 7.15,
      "grad_norm": 63.25,
      "learning_rate": 4.282321899736148e-05,
      "loss": 0.7031,
      "step": 5416
    },
    {
      "epoch": 7.15,
      "grad_norm": 10.8125,
      "learning_rate": 4.280343007915567e-05,
      "loss": 0.123,
      "step": 5417
    },
    {
      "epoch": 7.15,
      "grad_norm": 7.78125,
      "learning_rate": 4.278364116094987e-05,
      "loss": 0.0874,
      "step": 5418
    },
    {
      "epoch": 7.15,
      "grad_norm": 120.5,
      "learning_rate": 4.2763852242744065e-05,
      "loss": 3.2656,
      "step": 5419
    },
    {
      "epoch": 7.15,
      "grad_norm": 20.125,
      "learning_rate": 4.2744063324538256e-05,
      "loss": 0.6523,
      "step": 5420
    },
    {
      "epoch": 7.15,
      "grad_norm": 10.6875,
      "learning_rate": 4.2724274406332454e-05,
      "loss": 0.1885,
      "step": 5421
    },
    {
      "epoch": 7.15,
      "grad_norm": 205.0,
      "learning_rate": 4.270448548812664e-05,
      "loss": 4.2812,
      "step": 5422
    },
    {
      "epoch": 7.15,
      "grad_norm": 77.5,
      "learning_rate": 4.268469656992084e-05,
      "loss": 1.3594,
      "step": 5423
    },
    {
      "epoch": 7.16,
      "grad_norm": 16.0,
      "learning_rate": 4.2664907651715035e-05,
      "loss": 0.2275,
      "step": 5424
    },
    {
      "epoch": 7.16,
      "grad_norm": 13.5,
      "learning_rate": 4.2645118733509226e-05,
      "loss": 0.1846,
      "step": 5425
    },
    {
      "epoch": 7.16,
      "grad_norm": 22.5,
      "learning_rate": 4.2625329815303424e-05,
      "loss": 0.6016,
      "step": 5426
    },
    {
      "epoch": 7.16,
      "grad_norm": 194.0,
      "learning_rate": 4.260554089709762e-05,
      "loss": 5.0,
      "step": 5427
    },
    {
      "epoch": 7.16,
      "grad_norm": 132.0,
      "learning_rate": 4.2585751978891814e-05,
      "loss": 3.3438,
      "step": 5428
    },
    {
      "epoch": 7.16,
      "grad_norm": 25.5,
      "learning_rate": 4.256596306068601e-05,
      "loss": 0.3516,
      "step": 5429
    },
    {
      "epoch": 7.16,
      "grad_norm": 245.0,
      "learning_rate": 4.254617414248021e-05,
      "loss": 5.375,
      "step": 5430
    },
    {
      "epoch": 7.16,
      "grad_norm": 115.5,
      "learning_rate": 4.25263852242744e-05,
      "loss": 3.2656,
      "step": 5431
    },
    {
      "epoch": 7.17,
      "grad_norm": 18.875,
      "learning_rate": 4.25065963060686e-05,
      "loss": 0.1875,
      "step": 5432
    },
    {
      "epoch": 7.17,
      "grad_norm": 81.5,
      "learning_rate": 4.24868073878628e-05,
      "loss": 1.5703,
      "step": 5433
    },
    {
      "epoch": 7.17,
      "grad_norm": 18.0,
      "learning_rate": 4.246701846965699e-05,
      "loss": 0.2148,
      "step": 5434
    },
    {
      "epoch": 7.17,
      "grad_norm": 99.0,
      "learning_rate": 4.2447229551451187e-05,
      "loss": 2.375,
      "step": 5435
    },
    {
      "epoch": 7.17,
      "grad_norm": 5.96875,
      "learning_rate": 4.2427440633245385e-05,
      "loss": 0.0703,
      "step": 5436
    },
    {
      "epoch": 7.17,
      "grad_norm": 123.0,
      "learning_rate": 4.240765171503957e-05,
      "loss": 3.0312,
      "step": 5437
    },
    {
      "epoch": 7.17,
      "grad_norm": 41.25,
      "learning_rate": 4.238786279683377e-05,
      "loss": 0.6484,
      "step": 5438
    },
    {
      "epoch": 7.18,
      "grad_norm": 110.5,
      "learning_rate": 4.236807387862796e-05,
      "loss": 2.7344,
      "step": 5439
    },
    {
      "epoch": 7.18,
      "grad_norm": 166.0,
      "learning_rate": 4.2348284960422157e-05,
      "loss": 4.4375,
      "step": 5440
    },
    {
      "epoch": 7.18,
      "grad_norm": 3.609375,
      "learning_rate": 4.2328496042216355e-05,
      "loss": 0.0737,
      "step": 5441
    },
    {
      "epoch": 7.18,
      "grad_norm": 77.0,
      "learning_rate": 4.2308707124010546e-05,
      "loss": 2.875,
      "step": 5442
    },
    {
      "epoch": 7.18,
      "grad_norm": 112.0,
      "learning_rate": 4.2288918205804744e-05,
      "loss": 2.75,
      "step": 5443
    },
    {
      "epoch": 7.18,
      "grad_norm": 73.5,
      "learning_rate": 4.226912928759894e-05,
      "loss": 1.7812,
      "step": 5444
    },
    {
      "epoch": 7.18,
      "grad_norm": 7.46875,
      "learning_rate": 4.224934036939313e-05,
      "loss": 0.0786,
      "step": 5445
    },
    {
      "epoch": 7.18,
      "grad_norm": 130.0,
      "learning_rate": 4.222955145118733e-05,
      "loss": 2.0312,
      "step": 5446
    },
    {
      "epoch": 7.19,
      "grad_norm": 16.5,
      "learning_rate": 4.220976253298153e-05,
      "loss": 0.1787,
      "step": 5447
    },
    {
      "epoch": 7.19,
      "grad_norm": 10.25,
      "learning_rate": 4.218997361477572e-05,
      "loss": 0.1211,
      "step": 5448
    },
    {
      "epoch": 7.19,
      "grad_norm": 7.46875,
      "learning_rate": 4.217018469656992e-05,
      "loss": 0.1235,
      "step": 5449
    },
    {
      "epoch": 7.19,
      "grad_norm": 21.625,
      "learning_rate": 4.215039577836412e-05,
      "loss": 0.3555,
      "step": 5450
    },
    {
      "epoch": 7.19,
      "grad_norm": 23.75,
      "learning_rate": 4.213060686015831e-05,
      "loss": 0.1904,
      "step": 5451
    },
    {
      "epoch": 7.19,
      "grad_norm": 116.0,
      "learning_rate": 4.21108179419525e-05,
      "loss": 2.2344,
      "step": 5452
    },
    {
      "epoch": 7.19,
      "grad_norm": 75.5,
      "learning_rate": 4.20910290237467e-05,
      "loss": 1.6719,
      "step": 5453
    },
    {
      "epoch": 7.2,
      "grad_norm": 76.5,
      "learning_rate": 4.207124010554089e-05,
      "loss": 1.9062,
      "step": 5454
    },
    {
      "epoch": 7.2,
      "grad_norm": 11.75,
      "learning_rate": 4.205145118733509e-05,
      "loss": 0.0894,
      "step": 5455
    },
    {
      "epoch": 7.2,
      "grad_norm": 76.0,
      "learning_rate": 4.2031662269129285e-05,
      "loss": 1.0625,
      "step": 5456
    },
    {
      "epoch": 7.2,
      "grad_norm": 20.25,
      "learning_rate": 4.2011873350923476e-05,
      "loss": 0.3613,
      "step": 5457
    },
    {
      "epoch": 7.2,
      "grad_norm": 11.625,
      "learning_rate": 4.1992084432717674e-05,
      "loss": 0.1543,
      "step": 5458
    },
    {
      "epoch": 7.2,
      "grad_norm": 15.4375,
      "learning_rate": 4.197229551451187e-05,
      "loss": 0.2207,
      "step": 5459
    },
    {
      "epoch": 7.2,
      "grad_norm": 102.0,
      "learning_rate": 4.1952506596306064e-05,
      "loss": 2.2344,
      "step": 5460
    },
    {
      "epoch": 7.2,
      "grad_norm": 4.09375,
      "learning_rate": 4.193271767810026e-05,
      "loss": 0.0544,
      "step": 5461
    },
    {
      "epoch": 7.21,
      "grad_norm": 75.0,
      "learning_rate": 4.191292875989446e-05,
      "loss": 1.0156,
      "step": 5462
    },
    {
      "epoch": 7.21,
      "grad_norm": 157.0,
      "learning_rate": 4.189313984168865e-05,
      "loss": 3.9531,
      "step": 5463
    },
    {
      "epoch": 7.21,
      "grad_norm": 18.375,
      "learning_rate": 4.187335092348285e-05,
      "loss": 0.2949,
      "step": 5464
    },
    {
      "epoch": 7.21,
      "grad_norm": 102.0,
      "learning_rate": 4.185356200527705e-05,
      "loss": 2.0938,
      "step": 5465
    },
    {
      "epoch": 7.21,
      "grad_norm": 105.5,
      "learning_rate": 4.183377308707124e-05,
      "loss": 2.9375,
      "step": 5466
    },
    {
      "epoch": 7.21,
      "grad_norm": 22.625,
      "learning_rate": 4.181398416886543e-05,
      "loss": 0.4824,
      "step": 5467
    },
    {
      "epoch": 7.21,
      "grad_norm": 44.75,
      "learning_rate": 4.179419525065962e-05,
      "loss": 0.1865,
      "step": 5468
    },
    {
      "epoch": 7.22,
      "grad_norm": 66.5,
      "learning_rate": 4.177440633245382e-05,
      "loss": 1.6875,
      "step": 5469
    },
    {
      "epoch": 7.22,
      "grad_norm": 26.625,
      "learning_rate": 4.175461741424802e-05,
      "loss": 0.3066,
      "step": 5470
    },
    {
      "epoch": 7.22,
      "grad_norm": 9.0625,
      "learning_rate": 4.173482849604221e-05,
      "loss": 0.1021,
      "step": 5471
    },
    {
      "epoch": 7.22,
      "grad_norm": 544.0,
      "learning_rate": 4.1715039577836406e-05,
      "loss": 5.6562,
      "step": 5472
    },
    {
      "epoch": 7.22,
      "grad_norm": 13.4375,
      "learning_rate": 4.1695250659630604e-05,
      "loss": 0.1426,
      "step": 5473
    },
    {
      "epoch": 7.22,
      "grad_norm": 129.0,
      "learning_rate": 4.1675461741424796e-05,
      "loss": 3.5,
      "step": 5474
    },
    {
      "epoch": 7.22,
      "grad_norm": 88.5,
      "learning_rate": 4.1655672823218994e-05,
      "loss": 1.6562,
      "step": 5475
    },
    {
      "epoch": 7.22,
      "grad_norm": 17.125,
      "learning_rate": 4.163588390501319e-05,
      "loss": 0.2109,
      "step": 5476
    },
    {
      "epoch": 7.23,
      "grad_norm": 11.75,
      "learning_rate": 4.161609498680738e-05,
      "loss": 0.1885,
      "step": 5477
    },
    {
      "epoch": 7.23,
      "grad_norm": 12.5,
      "learning_rate": 4.159630606860158e-05,
      "loss": 0.1953,
      "step": 5478
    },
    {
      "epoch": 7.23,
      "grad_norm": 75.0,
      "learning_rate": 4.157651715039578e-05,
      "loss": 1.9453,
      "step": 5479
    },
    {
      "epoch": 7.23,
      "grad_norm": 8.25,
      "learning_rate": 4.155672823218997e-05,
      "loss": 0.0547,
      "step": 5480
    },
    {
      "epoch": 7.23,
      "grad_norm": 110.0,
      "learning_rate": 4.153693931398417e-05,
      "loss": 2.1719,
      "step": 5481
    },
    {
      "epoch": 7.23,
      "grad_norm": 76.0,
      "learning_rate": 4.151715039577835e-05,
      "loss": 1.2578,
      "step": 5482
    },
    {
      "epoch": 7.23,
      "grad_norm": 114.0,
      "learning_rate": 4.149736147757255e-05,
      "loss": 2.125,
      "step": 5483
    },
    {
      "epoch": 7.23,
      "grad_norm": 85.5,
      "learning_rate": 4.147757255936675e-05,
      "loss": 0.5664,
      "step": 5484
    },
    {
      "epoch": 7.24,
      "grad_norm": 12.5,
      "learning_rate": 4.145778364116094e-05,
      "loss": 0.1982,
      "step": 5485
    },
    {
      "epoch": 7.24,
      "grad_norm": 166.0,
      "learning_rate": 4.143799472295514e-05,
      "loss": 4.625,
      "step": 5486
    },
    {
      "epoch": 7.24,
      "grad_norm": 3.09375,
      "learning_rate": 4.1418205804749337e-05,
      "loss": 0.0374,
      "step": 5487
    },
    {
      "epoch": 7.24,
      "grad_norm": 6.9375,
      "learning_rate": 4.139841688654353e-05,
      "loss": 0.0991,
      "step": 5488
    },
    {
      "epoch": 7.24,
      "grad_norm": 86.5,
      "learning_rate": 4.1378627968337726e-05,
      "loss": 1.9453,
      "step": 5489
    },
    {
      "epoch": 7.24,
      "grad_norm": 320.0,
      "learning_rate": 4.1358839050131924e-05,
      "loss": 4.625,
      "step": 5490
    },
    {
      "epoch": 7.24,
      "grad_norm": 7.15625,
      "learning_rate": 4.1339050131926115e-05,
      "loss": 0.1113,
      "step": 5491
    },
    {
      "epoch": 7.25,
      "grad_norm": 5.6875,
      "learning_rate": 4.131926121372031e-05,
      "loss": 0.0669,
      "step": 5492
    },
    {
      "epoch": 7.25,
      "grad_norm": 86.0,
      "learning_rate": 4.129947229551451e-05,
      "loss": 1.8203,
      "step": 5493
    },
    {
      "epoch": 7.25,
      "grad_norm": 8.375,
      "learning_rate": 4.12796833773087e-05,
      "loss": 0.0439,
      "step": 5494
    },
    {
      "epoch": 7.25,
      "grad_norm": 77.0,
      "learning_rate": 4.12598944591029e-05,
      "loss": 1.7812,
      "step": 5495
    },
    {
      "epoch": 7.25,
      "grad_norm": 232.0,
      "learning_rate": 4.12401055408971e-05,
      "loss": 5.9688,
      "step": 5496
    },
    {
      "epoch": 7.25,
      "grad_norm": 10.0625,
      "learning_rate": 4.122031662269129e-05,
      "loss": 0.126,
      "step": 5497
    },
    {
      "epoch": 7.25,
      "grad_norm": 106.5,
      "learning_rate": 4.120052770448548e-05,
      "loss": 0.7891,
      "step": 5498
    },
    {
      "epoch": 7.25,
      "grad_norm": 106.5,
      "learning_rate": 4.118073878627968e-05,
      "loss": 2.4844,
      "step": 5499
    },
    {
      "epoch": 7.26,
      "grad_norm": 86.0,
      "learning_rate": 4.116094986807387e-05,
      "loss": 1.4453,
      "step": 5500
    },
    {
      "epoch": 7.26,
      "grad_norm": 92.0,
      "learning_rate": 4.114116094986807e-05,
      "loss": 2.8906,
      "step": 5501
    },
    {
      "epoch": 7.26,
      "grad_norm": 15.0,
      "learning_rate": 4.112137203166227e-05,
      "loss": 0.1719,
      "step": 5502
    },
    {
      "epoch": 7.26,
      "grad_norm": 11.75,
      "learning_rate": 4.110158311345646e-05,
      "loss": 0.1816,
      "step": 5503
    },
    {
      "epoch": 7.26,
      "grad_norm": 129.0,
      "learning_rate": 4.1081794195250656e-05,
      "loss": 3.4531,
      "step": 5504
    },
    {
      "epoch": 7.26,
      "grad_norm": 27.5,
      "learning_rate": 4.1062005277044854e-05,
      "loss": 0.2061,
      "step": 5505
    },
    {
      "epoch": 7.26,
      "grad_norm": 26.25,
      "learning_rate": 4.1042216358839046e-05,
      "loss": 0.7461,
      "step": 5506
    },
    {
      "epoch": 7.27,
      "grad_norm": 109.0,
      "learning_rate": 4.1022427440633244e-05,
      "loss": 3.0312,
      "step": 5507
    },
    {
      "epoch": 7.27,
      "grad_norm": 4.625,
      "learning_rate": 4.100263852242744e-05,
      "loss": 0.0427,
      "step": 5508
    },
    {
      "epoch": 7.27,
      "grad_norm": 40.75,
      "learning_rate": 4.098284960422163e-05,
      "loss": 0.4414,
      "step": 5509
    },
    {
      "epoch": 7.27,
      "grad_norm": 60.0,
      "learning_rate": 4.096306068601583e-05,
      "loss": 0.8398,
      "step": 5510
    },
    {
      "epoch": 7.27,
      "grad_norm": 304.0,
      "learning_rate": 4.094327176781003e-05,
      "loss": 4.875,
      "step": 5511
    },
    {
      "epoch": 7.27,
      "grad_norm": 62.5,
      "learning_rate": 4.092348284960422e-05,
      "loss": 0.8594,
      "step": 5512
    },
    {
      "epoch": 7.27,
      "grad_norm": 20.625,
      "learning_rate": 4.090369393139841e-05,
      "loss": 0.8516,
      "step": 5513
    },
    {
      "epoch": 7.27,
      "grad_norm": 118.0,
      "learning_rate": 4.08839050131926e-05,
      "loss": 1.9219,
      "step": 5514
    },
    {
      "epoch": 7.28,
      "grad_norm": 122.0,
      "learning_rate": 4.08641160949868e-05,
      "loss": 0.5078,
      "step": 5515
    },
    {
      "epoch": 7.28,
      "grad_norm": 8.875,
      "learning_rate": 4.0844327176781e-05,
      "loss": 0.1055,
      "step": 5516
    },
    {
      "epoch": 7.28,
      "grad_norm": 133.0,
      "learning_rate": 4.082453825857519e-05,
      "loss": 4.9375,
      "step": 5517
    },
    {
      "epoch": 7.28,
      "grad_norm": 14.875,
      "learning_rate": 4.080474934036939e-05,
      "loss": 0.2344,
      "step": 5518
    },
    {
      "epoch": 7.28,
      "grad_norm": 9.8125,
      "learning_rate": 4.0784960422163586e-05,
      "loss": 0.1406,
      "step": 5519
    },
    {
      "epoch": 7.28,
      "grad_norm": 159.0,
      "learning_rate": 4.076517150395778e-05,
      "loss": 3.6094,
      "step": 5520
    },
    {
      "epoch": 7.28,
      "grad_norm": 77.0,
      "learning_rate": 4.0745382585751976e-05,
      "loss": 2.0312,
      "step": 5521
    },
    {
      "epoch": 7.28,
      "grad_norm": 57.75,
      "learning_rate": 4.0725593667546174e-05,
      "loss": 1.0938,
      "step": 5522
    },
    {
      "epoch": 7.29,
      "grad_norm": 20.125,
      "learning_rate": 4.0705804749340365e-05,
      "loss": 0.1099,
      "step": 5523
    },
    {
      "epoch": 7.29,
      "grad_norm": 24.25,
      "learning_rate": 4.068601583113456e-05,
      "loss": 0.1465,
      "step": 5524
    },
    {
      "epoch": 7.29,
      "grad_norm": 14.125,
      "learning_rate": 4.066622691292876e-05,
      "loss": 0.1943,
      "step": 5525
    },
    {
      "epoch": 7.29,
      "grad_norm": 264.0,
      "learning_rate": 4.064643799472295e-05,
      "loss": 1.5781,
      "step": 5526
    },
    {
      "epoch": 7.29,
      "grad_norm": 7.8125,
      "learning_rate": 4.062664907651715e-05,
      "loss": 0.0933,
      "step": 5527
    },
    {
      "epoch": 7.29,
      "grad_norm": 58.25,
      "learning_rate": 4.0606860158311335e-05,
      "loss": 0.3594,
      "step": 5528
    },
    {
      "epoch": 7.29,
      "grad_norm": 130.0,
      "learning_rate": 4.058707124010553e-05,
      "loss": 2.4531,
      "step": 5529
    },
    {
      "epoch": 7.3,
      "grad_norm": 12.875,
      "learning_rate": 4.056728232189973e-05,
      "loss": 0.1377,
      "step": 5530
    },
    {
      "epoch": 7.3,
      "grad_norm": 43.75,
      "learning_rate": 4.054749340369392e-05,
      "loss": 0.291,
      "step": 5531
    },
    {
      "epoch": 7.3,
      "grad_norm": 141.0,
      "learning_rate": 4.052770448548812e-05,
      "loss": 2.2656,
      "step": 5532
    },
    {
      "epoch": 7.3,
      "grad_norm": 9.8125,
      "learning_rate": 4.050791556728232e-05,
      "loss": 0.1455,
      "step": 5533
    },
    {
      "epoch": 7.3,
      "grad_norm": 20.0,
      "learning_rate": 4.048812664907652e-05,
      "loss": 0.6484,
      "step": 5534
    },
    {
      "epoch": 7.3,
      "grad_norm": 15.6875,
      "learning_rate": 4.046833773087071e-05,
      "loss": 0.7148,
      "step": 5535
    },
    {
      "epoch": 7.3,
      "grad_norm": 136.0,
      "learning_rate": 4.0448548812664906e-05,
      "loss": 3.0469,
      "step": 5536
    },
    {
      "epoch": 7.3,
      "grad_norm": 34.25,
      "learning_rate": 4.0428759894459104e-05,
      "loss": 0.418,
      "step": 5537
    },
    {
      "epoch": 7.31,
      "grad_norm": 1.59375,
      "learning_rate": 4.0408970976253295e-05,
      "loss": 0.0125,
      "step": 5538
    },
    {
      "epoch": 7.31,
      "grad_norm": 6.46875,
      "learning_rate": 4.038918205804749e-05,
      "loss": 0.084,
      "step": 5539
    },
    {
      "epoch": 7.31,
      "grad_norm": 1.796875,
      "learning_rate": 4.036939313984169e-05,
      "loss": 0.0232,
      "step": 5540
    },
    {
      "epoch": 7.31,
      "grad_norm": 90.5,
      "learning_rate": 4.034960422163588e-05,
      "loss": 1.5078,
      "step": 5541
    },
    {
      "epoch": 7.31,
      "grad_norm": 196.0,
      "learning_rate": 4.032981530343008e-05,
      "loss": 5.0938,
      "step": 5542
    },
    {
      "epoch": 7.31,
      "grad_norm": 37.0,
      "learning_rate": 4.0310026385224265e-05,
      "loss": 0.2656,
      "step": 5543
    },
    {
      "epoch": 7.31,
      "grad_norm": 138.0,
      "learning_rate": 4.029023746701846e-05,
      "loss": 2.8125,
      "step": 5544
    },
    {
      "epoch": 7.32,
      "grad_norm": 7.96875,
      "learning_rate": 4.027044854881266e-05,
      "loss": 0.0518,
      "step": 5545
    },
    {
      "epoch": 7.32,
      "grad_norm": 544.0,
      "learning_rate": 4.025065963060685e-05,
      "loss": 3.1094,
      "step": 5546
    },
    {
      "epoch": 7.32,
      "grad_norm": 34.0,
      "learning_rate": 4.023087071240105e-05,
      "loss": 0.3086,
      "step": 5547
    },
    {
      "epoch": 7.32,
      "grad_norm": 60.25,
      "learning_rate": 4.021108179419525e-05,
      "loss": 0.7734,
      "step": 5548
    },
    {
      "epoch": 7.32,
      "grad_norm": 141.0,
      "learning_rate": 4.019129287598944e-05,
      "loss": 3.4062,
      "step": 5549
    },
    {
      "epoch": 7.32,
      "grad_norm": 19.375,
      "learning_rate": 4.017150395778364e-05,
      "loss": 0.6289,
      "step": 5550
    },
    {
      "epoch": 7.32,
      "grad_norm": 3.0625,
      "learning_rate": 4.0151715039577836e-05,
      "loss": 0.0427,
      "step": 5551
    },
    {
      "epoch": 7.32,
      "grad_norm": 131.0,
      "learning_rate": 4.013192612137203e-05,
      "loss": 1.5469,
      "step": 5552
    },
    {
      "epoch": 7.33,
      "grad_norm": 4.34375,
      "learning_rate": 4.0112137203166226e-05,
      "loss": 0.0369,
      "step": 5553
    },
    {
      "epoch": 7.33,
      "grad_norm": 88.0,
      "learning_rate": 4.0092348284960424e-05,
      "loss": 1.625,
      "step": 5554
    },
    {
      "epoch": 7.33,
      "grad_norm": 27.0,
      "learning_rate": 4.0072559366754615e-05,
      "loss": 0.3594,
      "step": 5555
    },
    {
      "epoch": 7.33,
      "grad_norm": 130.0,
      "learning_rate": 4.005277044854881e-05,
      "loss": 2.3281,
      "step": 5556
    },
    {
      "epoch": 7.33,
      "grad_norm": 93.0,
      "learning_rate": 4.003298153034301e-05,
      "loss": 0.8828,
      "step": 5557
    },
    {
      "epoch": 7.33,
      "grad_norm": 46.75,
      "learning_rate": 4.0013192612137196e-05,
      "loss": 0.8984,
      "step": 5558
    },
    {
      "epoch": 7.33,
      "grad_norm": 25.375,
      "learning_rate": 3.9993403693931394e-05,
      "loss": 0.6836,
      "step": 5559
    },
    {
      "epoch": 7.34,
      "grad_norm": 86.0,
      "learning_rate": 3.9973614775725585e-05,
      "loss": 1.9688,
      "step": 5560
    },
    {
      "epoch": 7.34,
      "grad_norm": 39.25,
      "learning_rate": 3.995382585751978e-05,
      "loss": 0.2354,
      "step": 5561
    },
    {
      "epoch": 7.34,
      "grad_norm": 90.0,
      "learning_rate": 3.993403693931398e-05,
      "loss": 0.8594,
      "step": 5562
    },
    {
      "epoch": 7.34,
      "grad_norm": 30.625,
      "learning_rate": 3.991424802110817e-05,
      "loss": 0.5352,
      "step": 5563
    },
    {
      "epoch": 7.34,
      "grad_norm": 13.9375,
      "learning_rate": 3.989445910290237e-05,
      "loss": 0.168,
      "step": 5564
    },
    {
      "epoch": 7.34,
      "grad_norm": 136.0,
      "learning_rate": 3.987467018469657e-05,
      "loss": 2.9062,
      "step": 5565
    },
    {
      "epoch": 7.34,
      "grad_norm": 145.0,
      "learning_rate": 3.985488126649076e-05,
      "loss": 5.3125,
      "step": 5566
    },
    {
      "epoch": 7.34,
      "grad_norm": 16.25,
      "learning_rate": 3.983509234828496e-05,
      "loss": 0.1377,
      "step": 5567
    },
    {
      "epoch": 7.35,
      "grad_norm": 27.625,
      "learning_rate": 3.9815303430079156e-05,
      "loss": 0.4746,
      "step": 5568
    },
    {
      "epoch": 7.35,
      "grad_norm": 16.5,
      "learning_rate": 3.979551451187335e-05,
      "loss": 0.1523,
      "step": 5569
    },
    {
      "epoch": 7.35,
      "grad_norm": 36.75,
      "learning_rate": 3.9775725593667545e-05,
      "loss": 0.165,
      "step": 5570
    },
    {
      "epoch": 7.35,
      "grad_norm": 11.0,
      "learning_rate": 3.975593667546174e-05,
      "loss": 0.1367,
      "step": 5571
    },
    {
      "epoch": 7.35,
      "grad_norm": 13.0,
      "learning_rate": 3.9736147757255934e-05,
      "loss": 0.2188,
      "step": 5572
    },
    {
      "epoch": 7.35,
      "grad_norm": 15.1875,
      "learning_rate": 3.9716358839050126e-05,
      "loss": 0.1602,
      "step": 5573
    },
    {
      "epoch": 7.35,
      "grad_norm": 13.0,
      "learning_rate": 3.9696569920844324e-05,
      "loss": 0.0791,
      "step": 5574
    },
    {
      "epoch": 7.35,
      "grad_norm": 24.625,
      "learning_rate": 3.9676781002638515e-05,
      "loss": 0.5586,
      "step": 5575
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.5859375,
      "learning_rate": 3.965699208443271e-05,
      "loss": 0.0171,
      "step": 5576
    },
    {
      "epoch": 7.36,
      "grad_norm": 115.5,
      "learning_rate": 3.963720316622691e-05,
      "loss": 2.4531,
      "step": 5577
    },
    {
      "epoch": 7.36,
      "grad_norm": 5.125,
      "learning_rate": 3.96174142480211e-05,
      "loss": 0.0732,
      "step": 5578
    },
    {
      "epoch": 7.36,
      "grad_norm": 59.75,
      "learning_rate": 3.95976253298153e-05,
      "loss": 1.2891,
      "step": 5579
    },
    {
      "epoch": 7.36,
      "grad_norm": 143.0,
      "learning_rate": 3.95778364116095e-05,
      "loss": 2.6875,
      "step": 5580
    },
    {
      "epoch": 7.36,
      "grad_norm": 30.0,
      "learning_rate": 3.955804749340369e-05,
      "loss": 0.4062,
      "step": 5581
    },
    {
      "epoch": 7.36,
      "grad_norm": 10.6875,
      "learning_rate": 3.953825857519789e-05,
      "loss": 0.0854,
      "step": 5582
    },
    {
      "epoch": 7.37,
      "grad_norm": 3.90625,
      "learning_rate": 3.9518469656992086e-05,
      "loss": 0.0493,
      "step": 5583
    },
    {
      "epoch": 7.37,
      "grad_norm": 123.5,
      "learning_rate": 3.949868073878628e-05,
      "loss": 1.9219,
      "step": 5584
    },
    {
      "epoch": 7.37,
      "grad_norm": 13.3125,
      "learning_rate": 3.9478891820580475e-05,
      "loss": 0.1348,
      "step": 5585
    },
    {
      "epoch": 7.37,
      "grad_norm": 85.0,
      "learning_rate": 3.9459102902374673e-05,
      "loss": 2.1719,
      "step": 5586
    },
    {
      "epoch": 7.37,
      "grad_norm": 136.0,
      "learning_rate": 3.9439313984168865e-05,
      "loss": 3.9375,
      "step": 5587
    },
    {
      "epoch": 7.37,
      "grad_norm": 7.0625,
      "learning_rate": 3.9419525065963056e-05,
      "loss": 0.0786,
      "step": 5588
    },
    {
      "epoch": 7.37,
      "grad_norm": 61.75,
      "learning_rate": 3.939973614775725e-05,
      "loss": 0.1885,
      "step": 5589
    },
    {
      "epoch": 7.37,
      "grad_norm": 84.0,
      "learning_rate": 3.9379947229551445e-05,
      "loss": 2.0,
      "step": 5590
    },
    {
      "epoch": 7.38,
      "grad_norm": 1.2890625,
      "learning_rate": 3.9360158311345643e-05,
      "loss": 0.0176,
      "step": 5591
    },
    {
      "epoch": 7.38,
      "grad_norm": 3.171875,
      "learning_rate": 3.9340369393139835e-05,
      "loss": 0.0289,
      "step": 5592
    },
    {
      "epoch": 7.38,
      "grad_norm": 4.40625,
      "learning_rate": 3.932058047493403e-05,
      "loss": 0.04,
      "step": 5593
    },
    {
      "epoch": 7.38,
      "grad_norm": 24.125,
      "learning_rate": 3.930079155672823e-05,
      "loss": 0.375,
      "step": 5594
    },
    {
      "epoch": 7.38,
      "grad_norm": 71.0,
      "learning_rate": 3.928100263852242e-05,
      "loss": 0.1426,
      "step": 5595
    },
    {
      "epoch": 7.38,
      "grad_norm": 164.0,
      "learning_rate": 3.926121372031662e-05,
      "loss": 5.625,
      "step": 5596
    },
    {
      "epoch": 7.38,
      "grad_norm": 186.0,
      "learning_rate": 3.924142480211082e-05,
      "loss": 2.6875,
      "step": 5597
    },
    {
      "epoch": 7.39,
      "grad_norm": 4.875,
      "learning_rate": 3.922163588390501e-05,
      "loss": 0.04,
      "step": 5598
    },
    {
      "epoch": 7.39,
      "grad_norm": 155.0,
      "learning_rate": 3.920184696569921e-05,
      "loss": 4.25,
      "step": 5599
    },
    {
      "epoch": 7.39,
      "grad_norm": 206.0,
      "learning_rate": 3.9182058047493406e-05,
      "loss": 4.2188,
      "step": 5600
    },
    {
      "epoch": 7.39,
      "grad_norm": 159.0,
      "learning_rate": 3.91622691292876e-05,
      "loss": 3.7656,
      "step": 5601
    },
    {
      "epoch": 7.39,
      "grad_norm": 239.0,
      "learning_rate": 3.9142480211081795e-05,
      "loss": 9.0625,
      "step": 5602
    },
    {
      "epoch": 7.39,
      "grad_norm": 10.375,
      "learning_rate": 3.912269129287598e-05,
      "loss": 0.0786,
      "step": 5603
    },
    {
      "epoch": 7.39,
      "grad_norm": 2.75,
      "learning_rate": 3.910290237467018e-05,
      "loss": 0.017,
      "step": 5604
    },
    {
      "epoch": 7.39,
      "grad_norm": 109.0,
      "learning_rate": 3.9083113456464376e-05,
      "loss": 2.3125,
      "step": 5605
    },
    {
      "epoch": 7.4,
      "grad_norm": 115.5,
      "learning_rate": 3.906332453825857e-05,
      "loss": 3.0938,
      "step": 5606
    },
    {
      "epoch": 7.4,
      "grad_norm": 134.0,
      "learning_rate": 3.9043535620052765e-05,
      "loss": 2.9688,
      "step": 5607
    },
    {
      "epoch": 7.4,
      "grad_norm": 23.875,
      "learning_rate": 3.902374670184696e-05,
      "loss": 0.3125,
      "step": 5608
    },
    {
      "epoch": 7.4,
      "grad_norm": 47.5,
      "learning_rate": 3.9003957783641154e-05,
      "loss": 0.9023,
      "step": 5609
    },
    {
      "epoch": 7.4,
      "grad_norm": 26.625,
      "learning_rate": 3.898416886543535e-05,
      "loss": 0.6523,
      "step": 5610
    },
    {
      "epoch": 7.4,
      "grad_norm": 3.140625,
      "learning_rate": 3.896437994722955e-05,
      "loss": 0.0376,
      "step": 5611
    },
    {
      "epoch": 7.4,
      "grad_norm": 109.0,
      "learning_rate": 3.894459102902374e-05,
      "loss": 2.5156,
      "step": 5612
    },
    {
      "epoch": 7.41,
      "grad_norm": 89.0,
      "learning_rate": 3.892480211081794e-05,
      "loss": 2.125,
      "step": 5613
    },
    {
      "epoch": 7.41,
      "grad_norm": 42.0,
      "learning_rate": 3.890501319261214e-05,
      "loss": 0.3652,
      "step": 5614
    },
    {
      "epoch": 7.41,
      "grad_norm": 5.5625,
      "learning_rate": 3.888522427440633e-05,
      "loss": 0.0684,
      "step": 5615
    },
    {
      "epoch": 7.41,
      "grad_norm": 3.625,
      "learning_rate": 3.886543535620053e-05,
      "loss": 0.0486,
      "step": 5616
    },
    {
      "epoch": 7.41,
      "grad_norm": 7.28125,
      "learning_rate": 3.8845646437994725e-05,
      "loss": 0.0864,
      "step": 5617
    },
    {
      "epoch": 7.41,
      "grad_norm": 5.9375,
      "learning_rate": 3.882585751978891e-05,
      "loss": 0.064,
      "step": 5618
    },
    {
      "epoch": 7.41,
      "grad_norm": 1.8046875,
      "learning_rate": 3.880606860158311e-05,
      "loss": 0.0188,
      "step": 5619
    },
    {
      "epoch": 7.41,
      "grad_norm": 144.0,
      "learning_rate": 3.8786279683377306e-05,
      "loss": 2.5781,
      "step": 5620
    },
    {
      "epoch": 7.42,
      "grad_norm": 47.5,
      "learning_rate": 3.87664907651715e-05,
      "loss": 1.1719,
      "step": 5621
    },
    {
      "epoch": 7.42,
      "grad_norm": 65.5,
      "learning_rate": 3.8746701846965695e-05,
      "loss": 0.332,
      "step": 5622
    },
    {
      "epoch": 7.42,
      "grad_norm": 5.71875,
      "learning_rate": 3.872691292875989e-05,
      "loss": 0.0571,
      "step": 5623
    },
    {
      "epoch": 7.42,
      "grad_norm": 33.0,
      "learning_rate": 3.8707124010554084e-05,
      "loss": 0.2031,
      "step": 5624
    },
    {
      "epoch": 7.42,
      "grad_norm": 91.0,
      "learning_rate": 3.868733509234828e-05,
      "loss": 2.25,
      "step": 5625
    },
    {
      "epoch": 7.42,
      "grad_norm": 20.75,
      "learning_rate": 3.866754617414248e-05,
      "loss": 0.4062,
      "step": 5626
    },
    {
      "epoch": 7.42,
      "grad_norm": 5.21875,
      "learning_rate": 3.864775725593667e-05,
      "loss": 0.0649,
      "step": 5627
    },
    {
      "epoch": 7.42,
      "grad_norm": 300.0,
      "learning_rate": 3.862796833773087e-05,
      "loss": 5.5938,
      "step": 5628
    },
    {
      "epoch": 7.43,
      "grad_norm": 112.5,
      "learning_rate": 3.860817941952507e-05,
      "loss": 4.0,
      "step": 5629
    },
    {
      "epoch": 7.43,
      "grad_norm": 6.25,
      "learning_rate": 3.858839050131926e-05,
      "loss": 0.0923,
      "step": 5630
    },
    {
      "epoch": 7.43,
      "grad_norm": 27.75,
      "learning_rate": 3.856860158311346e-05,
      "loss": 0.4941,
      "step": 5631
    },
    {
      "epoch": 7.43,
      "grad_norm": 163.0,
      "learning_rate": 3.8548812664907655e-05,
      "loss": 3.875,
      "step": 5632
    },
    {
      "epoch": 7.43,
      "grad_norm": 74.5,
      "learning_rate": 3.852902374670184e-05,
      "loss": 1.1797,
      "step": 5633
    },
    {
      "epoch": 7.43,
      "grad_norm": 2.5,
      "learning_rate": 3.850923482849604e-05,
      "loss": 0.0223,
      "step": 5634
    },
    {
      "epoch": 7.43,
      "grad_norm": 104.0,
      "learning_rate": 3.848944591029023e-05,
      "loss": 2.8281,
      "step": 5635
    },
    {
      "epoch": 7.44,
      "grad_norm": 24.0,
      "learning_rate": 3.846965699208443e-05,
      "loss": 0.4375,
      "step": 5636
    },
    {
      "epoch": 7.44,
      "grad_norm": 22.375,
      "learning_rate": 3.8449868073878625e-05,
      "loss": 0.1011,
      "step": 5637
    },
    {
      "epoch": 7.44,
      "grad_norm": 87.5,
      "learning_rate": 3.843007915567282e-05,
      "loss": 2.2812,
      "step": 5638
    },
    {
      "epoch": 7.44,
      "grad_norm": 158.0,
      "learning_rate": 3.8410290237467015e-05,
      "loss": 3.5469,
      "step": 5639
    },
    {
      "epoch": 7.44,
      "grad_norm": 5.25,
      "learning_rate": 3.839050131926121e-05,
      "loss": 0.0635,
      "step": 5640
    },
    {
      "epoch": 7.44,
      "grad_norm": 63.5,
      "learning_rate": 3.8370712401055404e-05,
      "loss": 0.4395,
      "step": 5641
    },
    {
      "epoch": 7.44,
      "grad_norm": 59.75,
      "learning_rate": 3.83509234828496e-05,
      "loss": 0.8555,
      "step": 5642
    },
    {
      "epoch": 7.44,
      "grad_norm": 111.0,
      "learning_rate": 3.83311345646438e-05,
      "loss": 2.6406,
      "step": 5643
    },
    {
      "epoch": 7.45,
      "grad_norm": 20.875,
      "learning_rate": 3.831134564643799e-05,
      "loss": 1.125,
      "step": 5644
    },
    {
      "epoch": 7.45,
      "grad_norm": 118.5,
      "learning_rate": 3.829155672823219e-05,
      "loss": 1.0781,
      "step": 5645
    },
    {
      "epoch": 7.45,
      "grad_norm": 6.09375,
      "learning_rate": 3.827176781002639e-05,
      "loss": 0.0552,
      "step": 5646
    },
    {
      "epoch": 7.45,
      "grad_norm": 54.5,
      "learning_rate": 3.825197889182058e-05,
      "loss": 0.7109,
      "step": 5647
    },
    {
      "epoch": 7.45,
      "grad_norm": 5.75,
      "learning_rate": 3.823218997361477e-05,
      "loss": 0.0525,
      "step": 5648
    },
    {
      "epoch": 7.45,
      "grad_norm": 108.5,
      "learning_rate": 3.821240105540896e-05,
      "loss": 4.7188,
      "step": 5649
    },
    {
      "epoch": 7.45,
      "grad_norm": 326.0,
      "learning_rate": 3.819261213720316e-05,
      "loss": 2.5781,
      "step": 5650
    },
    {
      "epoch": 7.46,
      "grad_norm": 10.8125,
      "learning_rate": 3.817282321899736e-05,
      "loss": 0.1641,
      "step": 5651
    },
    {
      "epoch": 7.46,
      "grad_norm": 20.625,
      "learning_rate": 3.815303430079155e-05,
      "loss": 0.4414,
      "step": 5652
    },
    {
      "epoch": 7.46,
      "grad_norm": 8.8125,
      "learning_rate": 3.813324538258575e-05,
      "loss": 0.1123,
      "step": 5653
    },
    {
      "epoch": 7.46,
      "grad_norm": 4.75,
      "learning_rate": 3.8113456464379945e-05,
      "loss": 0.0295,
      "step": 5654
    },
    {
      "epoch": 7.46,
      "grad_norm": 89.0,
      "learning_rate": 3.8093667546174136e-05,
      "loss": 1.1719,
      "step": 5655
    },
    {
      "epoch": 7.46,
      "grad_norm": 30.0,
      "learning_rate": 3.8073878627968334e-05,
      "loss": 0.6758,
      "step": 5656
    },
    {
      "epoch": 7.46,
      "grad_norm": 5.25,
      "learning_rate": 3.805408970976253e-05,
      "loss": 0.0586,
      "step": 5657
    },
    {
      "epoch": 7.46,
      "grad_norm": 101.5,
      "learning_rate": 3.8034300791556724e-05,
      "loss": 2.8906,
      "step": 5658
    },
    {
      "epoch": 7.47,
      "grad_norm": 114.5,
      "learning_rate": 3.801451187335092e-05,
      "loss": 3.0156,
      "step": 5659
    },
    {
      "epoch": 7.47,
      "grad_norm": 91.5,
      "learning_rate": 3.799472295514512e-05,
      "loss": 2.1406,
      "step": 5660
    },
    {
      "epoch": 7.47,
      "grad_norm": 119.0,
      "learning_rate": 3.797493403693931e-05,
      "loss": 3.0938,
      "step": 5661
    },
    {
      "epoch": 7.47,
      "grad_norm": 80.0,
      "learning_rate": 3.795514511873351e-05,
      "loss": 1.7266,
      "step": 5662
    },
    {
      "epoch": 7.47,
      "grad_norm": 115.5,
      "learning_rate": 3.79353562005277e-05,
      "loss": 3.0938,
      "step": 5663
    },
    {
      "epoch": 7.47,
      "grad_norm": 16.125,
      "learning_rate": 3.791556728232189e-05,
      "loss": 0.5547,
      "step": 5664
    },
    {
      "epoch": 7.47,
      "grad_norm": 39.25,
      "learning_rate": 3.789577836411609e-05,
      "loss": 0.2812,
      "step": 5665
    },
    {
      "epoch": 7.47,
      "grad_norm": 86.0,
      "learning_rate": 3.787598944591029e-05,
      "loss": 1.8047,
      "step": 5666
    },
    {
      "epoch": 7.48,
      "grad_norm": 5.5,
      "learning_rate": 3.785620052770448e-05,
      "loss": 0.0557,
      "step": 5667
    },
    {
      "epoch": 7.48,
      "grad_norm": 6.625,
      "learning_rate": 3.783641160949868e-05,
      "loss": 0.0869,
      "step": 5668
    },
    {
      "epoch": 7.48,
      "grad_norm": 54.75,
      "learning_rate": 3.7816622691292875e-05,
      "loss": 0.7812,
      "step": 5669
    },
    {
      "epoch": 7.48,
      "grad_norm": 152.0,
      "learning_rate": 3.7796833773087066e-05,
      "loss": 2.5312,
      "step": 5670
    },
    {
      "epoch": 7.48,
      "grad_norm": 78.0,
      "learning_rate": 3.7777044854881265e-05,
      "loss": 2.0156,
      "step": 5671
    },
    {
      "epoch": 7.48,
      "grad_norm": 89.5,
      "learning_rate": 3.775725593667546e-05,
      "loss": 1.6719,
      "step": 5672
    },
    {
      "epoch": 7.48,
      "grad_norm": 152.0,
      "learning_rate": 3.7737467018469654e-05,
      "loss": 3.1875,
      "step": 5673
    },
    {
      "epoch": 7.49,
      "grad_norm": 11.375,
      "learning_rate": 3.771767810026385e-05,
      "loss": 0.1494,
      "step": 5674
    },
    {
      "epoch": 7.49,
      "grad_norm": 126.0,
      "learning_rate": 3.769788918205805e-05,
      "loss": 4.6562,
      "step": 5675
    },
    {
      "epoch": 7.49,
      "grad_norm": 39.5,
      "learning_rate": 3.767810026385224e-05,
      "loss": 0.4648,
      "step": 5676
    },
    {
      "epoch": 7.49,
      "grad_norm": 54.5,
      "learning_rate": 3.765831134564644e-05,
      "loss": 1.0547,
      "step": 5677
    },
    {
      "epoch": 7.49,
      "grad_norm": 21.0,
      "learning_rate": 3.7638522427440624e-05,
      "loss": 0.1475,
      "step": 5678
    },
    {
      "epoch": 7.49,
      "grad_norm": 31.125,
      "learning_rate": 3.761873350923482e-05,
      "loss": 0.3438,
      "step": 5679
    },
    {
      "epoch": 7.49,
      "grad_norm": 30.375,
      "learning_rate": 3.759894459102902e-05,
      "loss": 0.4453,
      "step": 5680
    },
    {
      "epoch": 7.49,
      "grad_norm": 149.0,
      "learning_rate": 3.757915567282321e-05,
      "loss": 2.7188,
      "step": 5681
    },
    {
      "epoch": 7.5,
      "grad_norm": 5.90625,
      "learning_rate": 3.755936675461741e-05,
      "loss": 0.0664,
      "step": 5682
    },
    {
      "epoch": 7.5,
      "grad_norm": 100.0,
      "learning_rate": 3.753957783641161e-05,
      "loss": 1.6094,
      "step": 5683
    },
    {
      "epoch": 7.5,
      "grad_norm": 19.0,
      "learning_rate": 3.75197889182058e-05,
      "loss": 0.2217,
      "step": 5684
    },
    {
      "epoch": 7.5,
      "grad_norm": 86.5,
      "learning_rate": 3.75e-05,
      "loss": 1.2734,
      "step": 5685
    },
    {
      "epoch": 7.5,
      "grad_norm": 19.25,
      "learning_rate": 3.7480211081794195e-05,
      "loss": 0.2021,
      "step": 5686
    },
    {
      "epoch": 7.5,
      "grad_norm": 28.5,
      "learning_rate": 3.7460422163588386e-05,
      "loss": 0.7305,
      "step": 5687
    },
    {
      "epoch": 7.5,
      "grad_norm": 71.5,
      "learning_rate": 3.7440633245382584e-05,
      "loss": 0.8945,
      "step": 5688
    },
    {
      "epoch": 7.51,
      "grad_norm": 1.4921875,
      "learning_rate": 3.7420844327176775e-05,
      "loss": 0.0201,
      "step": 5689
    },
    {
      "epoch": 7.51,
      "grad_norm": 10.8125,
      "learning_rate": 3.7401055408970973e-05,
      "loss": 0.0898,
      "step": 5690
    },
    {
      "epoch": 7.51,
      "grad_norm": 57.25,
      "learning_rate": 3.7381266490765165e-05,
      "loss": 1.5,
      "step": 5691
    },
    {
      "epoch": 7.51,
      "grad_norm": 13.875,
      "learning_rate": 3.736147757255936e-05,
      "loss": 0.2031,
      "step": 5692
    },
    {
      "epoch": 7.51,
      "grad_norm": 49.5,
      "learning_rate": 3.734168865435356e-05,
      "loss": 0.5664,
      "step": 5693
    },
    {
      "epoch": 7.51,
      "grad_norm": 158.0,
      "learning_rate": 3.732189973614775e-05,
      "loss": 4.5938,
      "step": 5694
    },
    {
      "epoch": 7.51,
      "grad_norm": 129.0,
      "learning_rate": 3.730211081794195e-05,
      "loss": 3.5156,
      "step": 5695
    },
    {
      "epoch": 7.51,
      "grad_norm": 15.3125,
      "learning_rate": 3.728232189973615e-05,
      "loss": 0.1758,
      "step": 5696
    },
    {
      "epoch": 7.52,
      "grad_norm": 21.0,
      "learning_rate": 3.726253298153034e-05,
      "loss": 0.2021,
      "step": 5697
    },
    {
      "epoch": 7.52,
      "grad_norm": 94.0,
      "learning_rate": 3.724274406332453e-05,
      "loss": 1.5312,
      "step": 5698
    },
    {
      "epoch": 7.52,
      "grad_norm": 13.375,
      "learning_rate": 3.722295514511873e-05,
      "loss": 0.165,
      "step": 5699
    },
    {
      "epoch": 7.52,
      "grad_norm": 24.125,
      "learning_rate": 3.720316622691293e-05,
      "loss": 0.4727,
      "step": 5700
    },
    {
      "epoch": 7.52,
      "grad_norm": 84.5,
      "learning_rate": 3.718337730870712e-05,
      "loss": 1.8438,
      "step": 5701
    },
    {
      "epoch": 7.52,
      "grad_norm": 3.03125,
      "learning_rate": 3.7163588390501316e-05,
      "loss": 0.0359,
      "step": 5702
    },
    {
      "epoch": 7.52,
      "grad_norm": 83.0,
      "learning_rate": 3.7143799472295514e-05,
      "loss": 1.7812,
      "step": 5703
    },
    {
      "epoch": 7.53,
      "grad_norm": 31.25,
      "learning_rate": 3.7124010554089706e-05,
      "loss": 0.2246,
      "step": 5704
    },
    {
      "epoch": 7.53,
      "grad_norm": 11.625,
      "learning_rate": 3.7104221635883904e-05,
      "loss": 0.1226,
      "step": 5705
    },
    {
      "epoch": 7.53,
      "grad_norm": 156.0,
      "learning_rate": 3.7084432717678095e-05,
      "loss": 4.375,
      "step": 5706
    },
    {
      "epoch": 7.53,
      "grad_norm": 11.0,
      "learning_rate": 3.706464379947229e-05,
      "loss": 0.1621,
      "step": 5707
    },
    {
      "epoch": 7.53,
      "grad_norm": 52.25,
      "learning_rate": 3.704485488126649e-05,
      "loss": 0.1338,
      "step": 5708
    },
    {
      "epoch": 7.53,
      "grad_norm": 253.0,
      "learning_rate": 3.702506596306068e-05,
      "loss": 7.5938,
      "step": 5709
    },
    {
      "epoch": 7.53,
      "grad_norm": 52.5,
      "learning_rate": 3.700527704485488e-05,
      "loss": 0.6562,
      "step": 5710
    },
    {
      "epoch": 7.53,
      "grad_norm": 144.0,
      "learning_rate": 3.698548812664908e-05,
      "loss": 3.1094,
      "step": 5711
    },
    {
      "epoch": 7.54,
      "grad_norm": 12.5625,
      "learning_rate": 3.696569920844327e-05,
      "loss": 0.126,
      "step": 5712
    },
    {
      "epoch": 7.54,
      "grad_norm": 334.0,
      "learning_rate": 3.694591029023746e-05,
      "loss": 5.0,
      "step": 5713
    },
    {
      "epoch": 7.54,
      "grad_norm": 32.5,
      "learning_rate": 3.692612137203166e-05,
      "loss": 0.4844,
      "step": 5714
    },
    {
      "epoch": 7.54,
      "grad_norm": 165.0,
      "learning_rate": 3.690633245382586e-05,
      "loss": 2.7656,
      "step": 5715
    },
    {
      "epoch": 7.54,
      "grad_norm": 3.703125,
      "learning_rate": 3.688654353562005e-05,
      "loss": 0.0564,
      "step": 5716
    },
    {
      "epoch": 7.54,
      "grad_norm": 480.0,
      "learning_rate": 3.6866754617414247e-05,
      "loss": 3.0781,
      "step": 5717
    },
    {
      "epoch": 7.54,
      "grad_norm": 2.9375,
      "learning_rate": 3.6846965699208445e-05,
      "loss": 0.0369,
      "step": 5718
    },
    {
      "epoch": 7.54,
      "grad_norm": 2.859375,
      "learning_rate": 3.6827176781002636e-05,
      "loss": 0.0317,
      "step": 5719
    },
    {
      "epoch": 7.55,
      "grad_norm": 214.0,
      "learning_rate": 3.680738786279683e-05,
      "loss": 3.3594,
      "step": 5720
    },
    {
      "epoch": 7.55,
      "grad_norm": 66.5,
      "learning_rate": 3.6787598944591025e-05,
      "loss": 0.5117,
      "step": 5721
    },
    {
      "epoch": 7.55,
      "grad_norm": 102.5,
      "learning_rate": 3.676781002638522e-05,
      "loss": 1.8203,
      "step": 5722
    },
    {
      "epoch": 7.55,
      "grad_norm": 26.5,
      "learning_rate": 3.6748021108179415e-05,
      "loss": 0.4062,
      "step": 5723
    },
    {
      "epoch": 7.55,
      "grad_norm": 127.0,
      "learning_rate": 3.672823218997361e-05,
      "loss": 3.3125,
      "step": 5724
    },
    {
      "epoch": 7.55,
      "grad_norm": 13.4375,
      "learning_rate": 3.670844327176781e-05,
      "loss": 0.1011,
      "step": 5725
    },
    {
      "epoch": 7.55,
      "grad_norm": 7.1875,
      "learning_rate": 3.6688654353562e-05,
      "loss": 0.0742,
      "step": 5726
    },
    {
      "epoch": 7.56,
      "grad_norm": 38.25,
      "learning_rate": 3.666886543535619e-05,
      "loss": 0.293,
      "step": 5727
    },
    {
      "epoch": 7.56,
      "grad_norm": 56.0,
      "learning_rate": 3.664907651715039e-05,
      "loss": 0.7578,
      "step": 5728
    },
    {
      "epoch": 7.56,
      "grad_norm": 39.5,
      "learning_rate": 3.662928759894459e-05,
      "loss": 0.6016,
      "step": 5729
    },
    {
      "epoch": 7.56,
      "grad_norm": 79.0,
      "learning_rate": 3.660949868073878e-05,
      "loss": 2.7344,
      "step": 5730
    },
    {
      "epoch": 7.56,
      "grad_norm": 176.0,
      "learning_rate": 3.658970976253298e-05,
      "loss": 3.2812,
      "step": 5731
    },
    {
      "epoch": 7.56,
      "grad_norm": 26.5,
      "learning_rate": 3.656992084432718e-05,
      "loss": 0.6719,
      "step": 5732
    },
    {
      "epoch": 7.56,
      "grad_norm": 8.125,
      "learning_rate": 3.655013192612137e-05,
      "loss": 0.0957,
      "step": 5733
    },
    {
      "epoch": 7.56,
      "grad_norm": 12.8125,
      "learning_rate": 3.653034300791556e-05,
      "loss": 0.1553,
      "step": 5734
    },
    {
      "epoch": 7.57,
      "grad_norm": 177.0,
      "learning_rate": 3.651055408970976e-05,
      "loss": 3.1094,
      "step": 5735
    },
    {
      "epoch": 7.57,
      "grad_norm": 3.53125,
      "learning_rate": 3.6490765171503955e-05,
      "loss": 0.0337,
      "step": 5736
    },
    {
      "epoch": 7.57,
      "grad_norm": 107.5,
      "learning_rate": 3.647097625329815e-05,
      "loss": 1.6406,
      "step": 5737
    },
    {
      "epoch": 7.57,
      "grad_norm": 222.0,
      "learning_rate": 3.6451187335092345e-05,
      "loss": 5.4688,
      "step": 5738
    },
    {
      "epoch": 7.57,
      "grad_norm": 8.5,
      "learning_rate": 3.643139841688654e-05,
      "loss": 0.0664,
      "step": 5739
    },
    {
      "epoch": 7.57,
      "grad_norm": 42.5,
      "learning_rate": 3.6411609498680734e-05,
      "loss": 0.5195,
      "step": 5740
    },
    {
      "epoch": 7.57,
      "grad_norm": 170.0,
      "learning_rate": 3.639182058047493e-05,
      "loss": 4.9062,
      "step": 5741
    },
    {
      "epoch": 7.58,
      "grad_norm": 107.5,
      "learning_rate": 3.6372031662269123e-05,
      "loss": 2.125,
      "step": 5742
    },
    {
      "epoch": 7.58,
      "grad_norm": 45.75,
      "learning_rate": 3.635224274406332e-05,
      "loss": 1.2344,
      "step": 5743
    },
    {
      "epoch": 7.58,
      "grad_norm": 3.28125,
      "learning_rate": 3.633245382585751e-05,
      "loss": 0.0452,
      "step": 5744
    },
    {
      "epoch": 7.58,
      "grad_norm": 6.21875,
      "learning_rate": 3.631266490765171e-05,
      "loss": 0.0723,
      "step": 5745
    },
    {
      "epoch": 7.58,
      "grad_norm": 66.5,
      "learning_rate": 3.629287598944591e-05,
      "loss": 0.9375,
      "step": 5746
    },
    {
      "epoch": 7.58,
      "grad_norm": 45.75,
      "learning_rate": 3.62730870712401e-05,
      "loss": 0.7773,
      "step": 5747
    },
    {
      "epoch": 7.58,
      "grad_norm": 23.375,
      "learning_rate": 3.62532981530343e-05,
      "loss": 0.8672,
      "step": 5748
    },
    {
      "epoch": 7.58,
      "grad_norm": 139.0,
      "learning_rate": 3.623350923482849e-05,
      "loss": 4.0938,
      "step": 5749
    },
    {
      "epoch": 7.59,
      "grad_norm": 98.5,
      "learning_rate": 3.621372031662269e-05,
      "loss": 2.7812,
      "step": 5750
    },
    {
      "epoch": 7.59,
      "grad_norm": 26.875,
      "learning_rate": 3.6193931398416886e-05,
      "loss": 0.3848,
      "step": 5751
    },
    {
      "epoch": 7.59,
      "grad_norm": 2.171875,
      "learning_rate": 3.617414248021108e-05,
      "loss": 0.0281,
      "step": 5752
    },
    {
      "epoch": 7.59,
      "grad_norm": 95.5,
      "learning_rate": 3.6154353562005275e-05,
      "loss": 1.0781,
      "step": 5753
    },
    {
      "epoch": 7.59,
      "grad_norm": 78.5,
      "learning_rate": 3.613456464379947e-05,
      "loss": 1.4844,
      "step": 5754
    },
    {
      "epoch": 7.59,
      "grad_norm": 51.25,
      "learning_rate": 3.6114775725593664e-05,
      "loss": 0.5547,
      "step": 5755
    },
    {
      "epoch": 7.59,
      "grad_norm": 18.5,
      "learning_rate": 3.609498680738786e-05,
      "loss": 0.1748,
      "step": 5756
    },
    {
      "epoch": 7.59,
      "grad_norm": 10.75,
      "learning_rate": 3.6075197889182054e-05,
      "loss": 0.0981,
      "step": 5757
    },
    {
      "epoch": 7.6,
      "grad_norm": 234.0,
      "learning_rate": 3.605540897097625e-05,
      "loss": 3.5625,
      "step": 5758
    },
    {
      "epoch": 7.6,
      "grad_norm": 6.0,
      "learning_rate": 3.603562005277044e-05,
      "loss": 0.0566,
      "step": 5759
    },
    {
      "epoch": 7.6,
      "grad_norm": 25.875,
      "learning_rate": 3.601583113456464e-05,
      "loss": 0.2852,
      "step": 5760
    },
    {
      "epoch": 7.6,
      "grad_norm": 70.0,
      "learning_rate": 3.599604221635884e-05,
      "loss": 1.6562,
      "step": 5761
    },
    {
      "epoch": 7.6,
      "grad_norm": 33.5,
      "learning_rate": 3.597625329815303e-05,
      "loss": 0.2832,
      "step": 5762
    },
    {
      "epoch": 7.6,
      "grad_norm": 29.375,
      "learning_rate": 3.595646437994723e-05,
      "loss": 0.3789,
      "step": 5763
    },
    {
      "epoch": 7.6,
      "grad_norm": 3.609375,
      "learning_rate": 3.593667546174142e-05,
      "loss": 0.0393,
      "step": 5764
    },
    {
      "epoch": 7.61,
      "grad_norm": 53.5,
      "learning_rate": 3.591688654353562e-05,
      "loss": 0.7031,
      "step": 5765
    },
    {
      "epoch": 7.61,
      "grad_norm": 174.0,
      "learning_rate": 3.589709762532981e-05,
      "loss": 3.5781,
      "step": 5766
    },
    {
      "epoch": 7.61,
      "grad_norm": 4.9375,
      "learning_rate": 3.587730870712401e-05,
      "loss": 0.0547,
      "step": 5767
    },
    {
      "epoch": 7.61,
      "grad_norm": 94.5,
      "learning_rate": 3.5857519788918205e-05,
      "loss": 3.1094,
      "step": 5768
    },
    {
      "epoch": 7.61,
      "grad_norm": 80.0,
      "learning_rate": 3.5837730870712397e-05,
      "loss": 2.0781,
      "step": 5769
    },
    {
      "epoch": 7.61,
      "grad_norm": 119.5,
      "learning_rate": 3.5817941952506595e-05,
      "loss": 1.4141,
      "step": 5770
    },
    {
      "epoch": 7.61,
      "grad_norm": 253.0,
      "learning_rate": 3.579815303430079e-05,
      "loss": 2.9844,
      "step": 5771
    },
    {
      "epoch": 7.61,
      "grad_norm": 4.8125,
      "learning_rate": 3.5778364116094984e-05,
      "loss": 0.04,
      "step": 5772
    },
    {
      "epoch": 7.62,
      "grad_norm": 121.5,
      "learning_rate": 3.5758575197889175e-05,
      "loss": 6.25,
      "step": 5773
    },
    {
      "epoch": 7.62,
      "grad_norm": 6.0625,
      "learning_rate": 3.573878627968337e-05,
      "loss": 0.0586,
      "step": 5774
    },
    {
      "epoch": 7.62,
      "grad_norm": 120.0,
      "learning_rate": 3.571899736147757e-05,
      "loss": 2.5312,
      "step": 5775
    },
    {
      "epoch": 7.62,
      "grad_norm": 13.6875,
      "learning_rate": 3.569920844327176e-05,
      "loss": 0.0303,
      "step": 5776
    },
    {
      "epoch": 7.62,
      "grad_norm": 89.5,
      "learning_rate": 3.567941952506596e-05,
      "loss": 1.5078,
      "step": 5777
    },
    {
      "epoch": 7.62,
      "grad_norm": 149.0,
      "learning_rate": 3.565963060686016e-05,
      "loss": 4.1875,
      "step": 5778
    },
    {
      "epoch": 7.62,
      "grad_norm": 81.5,
      "learning_rate": 3.563984168865435e-05,
      "loss": 1.6094,
      "step": 5779
    },
    {
      "epoch": 7.63,
      "grad_norm": 112.5,
      "learning_rate": 3.562005277044854e-05,
      "loss": 4.4375,
      "step": 5780
    },
    {
      "epoch": 7.63,
      "grad_norm": 56.75,
      "learning_rate": 3.560026385224274e-05,
      "loss": 0.6602,
      "step": 5781
    },
    {
      "epoch": 7.63,
      "grad_norm": 4.625,
      "learning_rate": 3.558047493403694e-05,
      "loss": 0.0515,
      "step": 5782
    },
    {
      "epoch": 7.63,
      "grad_norm": 1.8125,
      "learning_rate": 3.556068601583113e-05,
      "loss": 0.0197,
      "step": 5783
    },
    {
      "epoch": 7.63,
      "grad_norm": 24.375,
      "learning_rate": 3.554089709762533e-05,
      "loss": 0.252,
      "step": 5784
    },
    {
      "epoch": 7.63,
      "grad_norm": 4.84375,
      "learning_rate": 3.5521108179419525e-05,
      "loss": 0.0386,
      "step": 5785
    },
    {
      "epoch": 7.63,
      "grad_norm": 55.75,
      "learning_rate": 3.5501319261213716e-05,
      "loss": 0.7109,
      "step": 5786
    },
    {
      "epoch": 7.63,
      "grad_norm": 144.0,
      "learning_rate": 3.548153034300791e-05,
      "loss": 1.8672,
      "step": 5787
    },
    {
      "epoch": 7.64,
      "grad_norm": 88.0,
      "learning_rate": 3.5461741424802105e-05,
      "loss": 1.3125,
      "step": 5788
    },
    {
      "epoch": 7.64,
      "grad_norm": 9.375,
      "learning_rate": 3.5441952506596304e-05,
      "loss": 0.085,
      "step": 5789
    },
    {
      "epoch": 7.64,
      "grad_norm": 33.0,
      "learning_rate": 3.5422163588390495e-05,
      "loss": 0.4355,
      "step": 5790
    },
    {
      "epoch": 7.64,
      "grad_norm": 85.0,
      "learning_rate": 3.540237467018469e-05,
      "loss": 1.7656,
      "step": 5791
    },
    {
      "epoch": 7.64,
      "grad_norm": 420.0,
      "learning_rate": 3.538258575197889e-05,
      "loss": 5.8438,
      "step": 5792
    },
    {
      "epoch": 7.64,
      "grad_norm": 129.0,
      "learning_rate": 3.536279683377308e-05,
      "loss": 1.0703,
      "step": 5793
    },
    {
      "epoch": 7.64,
      "grad_norm": 11.125,
      "learning_rate": 3.534300791556728e-05,
      "loss": 0.1387,
      "step": 5794
    },
    {
      "epoch": 7.65,
      "grad_norm": 1.640625,
      "learning_rate": 3.532321899736147e-05,
      "loss": 0.0089,
      "step": 5795
    },
    {
      "epoch": 7.65,
      "grad_norm": 42.5,
      "learning_rate": 3.530343007915567e-05,
      "loss": 0.457,
      "step": 5796
    },
    {
      "epoch": 7.65,
      "grad_norm": 180.0,
      "learning_rate": 3.528364116094987e-05,
      "loss": 0.8398,
      "step": 5797
    },
    {
      "epoch": 7.65,
      "grad_norm": 145.0,
      "learning_rate": 3.526385224274406e-05,
      "loss": 3.8594,
      "step": 5798
    },
    {
      "epoch": 7.65,
      "grad_norm": 159.0,
      "learning_rate": 3.524406332453826e-05,
      "loss": 4.1562,
      "step": 5799
    },
    {
      "epoch": 7.65,
      "grad_norm": 98.0,
      "learning_rate": 3.5224274406332455e-05,
      "loss": 1.75,
      "step": 5800
    },
    {
      "epoch": 7.65,
      "grad_norm": 124.5,
      "learning_rate": 3.5204485488126646e-05,
      "loss": 3.4375,
      "step": 5801
    },
    {
      "epoch": 7.65,
      "grad_norm": 59.0,
      "learning_rate": 3.518469656992084e-05,
      "loss": 0.4824,
      "step": 5802
    },
    {
      "epoch": 7.66,
      "grad_norm": 9.0625,
      "learning_rate": 3.5164907651715036e-05,
      "loss": 0.0645,
      "step": 5803
    },
    {
      "epoch": 7.66,
      "grad_norm": 61.0,
      "learning_rate": 3.5145118733509234e-05,
      "loss": 0.3555,
      "step": 5804
    },
    {
      "epoch": 7.66,
      "grad_norm": 17.875,
      "learning_rate": 3.5125329815303425e-05,
      "loss": 0.104,
      "step": 5805
    },
    {
      "epoch": 7.66,
      "grad_norm": 185.0,
      "learning_rate": 3.510554089709762e-05,
      "loss": 2.9219,
      "step": 5806
    },
    {
      "epoch": 7.66,
      "grad_norm": 9.5625,
      "learning_rate": 3.508575197889182e-05,
      "loss": 0.1631,
      "step": 5807
    },
    {
      "epoch": 7.66,
      "grad_norm": 190.0,
      "learning_rate": 3.506596306068601e-05,
      "loss": 4.0625,
      "step": 5808
    },
    {
      "epoch": 7.66,
      "grad_norm": 25.5,
      "learning_rate": 3.504617414248021e-05,
      "loss": 0.2275,
      "step": 5809
    },
    {
      "epoch": 7.66,
      "grad_norm": 227.0,
      "learning_rate": 3.50263852242744e-05,
      "loss": 4.1562,
      "step": 5810
    },
    {
      "epoch": 7.67,
      "grad_norm": 13.25,
      "learning_rate": 3.50065963060686e-05,
      "loss": 0.1089,
      "step": 5811
    },
    {
      "epoch": 7.67,
      "grad_norm": 237.0,
      "learning_rate": 3.498680738786279e-05,
      "loss": 4.1875,
      "step": 5812
    },
    {
      "epoch": 7.67,
      "grad_norm": 31.375,
      "learning_rate": 3.496701846965699e-05,
      "loss": 0.4629,
      "step": 5813
    },
    {
      "epoch": 7.67,
      "grad_norm": 130.0,
      "learning_rate": 3.494722955145119e-05,
      "loss": 3.4844,
      "step": 5814
    },
    {
      "epoch": 7.67,
      "grad_norm": 14.75,
      "learning_rate": 3.492744063324538e-05,
      "loss": 0.2168,
      "step": 5815
    },
    {
      "epoch": 7.67,
      "grad_norm": 48.5,
      "learning_rate": 3.4907651715039577e-05,
      "loss": 0.4727,
      "step": 5816
    },
    {
      "epoch": 7.67,
      "grad_norm": 27.75,
      "learning_rate": 3.488786279683377e-05,
      "loss": 0.75,
      "step": 5817
    },
    {
      "epoch": 7.68,
      "grad_norm": 133.0,
      "learning_rate": 3.4868073878627966e-05,
      "loss": 2.6406,
      "step": 5818
    },
    {
      "epoch": 7.68,
      "grad_norm": 288.0,
      "learning_rate": 3.484828496042216e-05,
      "loss": 3.9844,
      "step": 5819
    },
    {
      "epoch": 7.68,
      "grad_norm": 25.5,
      "learning_rate": 3.4828496042216355e-05,
      "loss": 0.8125,
      "step": 5820
    },
    {
      "epoch": 7.68,
      "grad_norm": 124.0,
      "learning_rate": 3.480870712401055e-05,
      "loss": 1.0469,
      "step": 5821
    },
    {
      "epoch": 7.68,
      "grad_norm": 179.0,
      "learning_rate": 3.4788918205804745e-05,
      "loss": 3.8594,
      "step": 5822
    },
    {
      "epoch": 7.68,
      "grad_norm": 47.5,
      "learning_rate": 3.476912928759894e-05,
      "loss": 0.6406,
      "step": 5823
    },
    {
      "epoch": 7.68,
      "grad_norm": 73.5,
      "learning_rate": 3.474934036939314e-05,
      "loss": 1.3672,
      "step": 5824
    },
    {
      "epoch": 7.68,
      "grad_norm": 197.0,
      "learning_rate": 3.472955145118733e-05,
      "loss": 3.1719,
      "step": 5825
    },
    {
      "epoch": 7.69,
      "grad_norm": 20.5,
      "learning_rate": 3.470976253298152e-05,
      "loss": 0.6133,
      "step": 5826
    },
    {
      "epoch": 7.69,
      "grad_norm": 32.25,
      "learning_rate": 3.468997361477572e-05,
      "loss": 0.1562,
      "step": 5827
    },
    {
      "epoch": 7.69,
      "grad_norm": 37.0,
      "learning_rate": 3.467018469656992e-05,
      "loss": 0.5039,
      "step": 5828
    },
    {
      "epoch": 7.69,
      "grad_norm": 16.625,
      "learning_rate": 3.465039577836411e-05,
      "loss": 0.2031,
      "step": 5829
    },
    {
      "epoch": 7.69,
      "grad_norm": 38.0,
      "learning_rate": 3.463060686015831e-05,
      "loss": 0.3535,
      "step": 5830
    },
    {
      "epoch": 7.69,
      "grad_norm": 159.0,
      "learning_rate": 3.461081794195251e-05,
      "loss": 3.3594,
      "step": 5831
    },
    {
      "epoch": 7.69,
      "grad_norm": 25.375,
      "learning_rate": 3.45910290237467e-05,
      "loss": 0.2402,
      "step": 5832
    },
    {
      "epoch": 7.7,
      "grad_norm": 101.0,
      "learning_rate": 3.457124010554089e-05,
      "loss": 2.6875,
      "step": 5833
    },
    {
      "epoch": 7.7,
      "grad_norm": 23.375,
      "learning_rate": 3.455145118733509e-05,
      "loss": 0.6016,
      "step": 5834
    },
    {
      "epoch": 7.7,
      "grad_norm": 43.25,
      "learning_rate": 3.4531662269129286e-05,
      "loss": 0.4492,
      "step": 5835
    },
    {
      "epoch": 7.7,
      "grad_norm": 25.0,
      "learning_rate": 3.451187335092348e-05,
      "loss": 0.4512,
      "step": 5836
    },
    {
      "epoch": 7.7,
      "grad_norm": 34.5,
      "learning_rate": 3.4492084432717675e-05,
      "loss": 0.252,
      "step": 5837
    },
    {
      "epoch": 7.7,
      "grad_norm": 115.0,
      "learning_rate": 3.447229551451187e-05,
      "loss": 1.8281,
      "step": 5838
    },
    {
      "epoch": 7.7,
      "grad_norm": 126.5,
      "learning_rate": 3.445250659630607e-05,
      "loss": 2.4844,
      "step": 5839
    },
    {
      "epoch": 7.7,
      "grad_norm": 36.75,
      "learning_rate": 3.443271767810026e-05,
      "loss": 0.3359,
      "step": 5840
    },
    {
      "epoch": 7.71,
      "grad_norm": 84.5,
      "learning_rate": 3.4412928759894454e-05,
      "loss": 0.3301,
      "step": 5841
    },
    {
      "epoch": 7.71,
      "grad_norm": 26.125,
      "learning_rate": 3.439313984168865e-05,
      "loss": 1.0156,
      "step": 5842
    },
    {
      "epoch": 7.71,
      "grad_norm": 2.84375,
      "learning_rate": 3.437335092348285e-05,
      "loss": 0.0165,
      "step": 5843
    },
    {
      "epoch": 7.71,
      "grad_norm": 40.0,
      "learning_rate": 3.435356200527704e-05,
      "loss": 0.8867,
      "step": 5844
    },
    {
      "epoch": 7.71,
      "grad_norm": 41.75,
      "learning_rate": 3.433377308707124e-05,
      "loss": 0.5664,
      "step": 5845
    },
    {
      "epoch": 7.71,
      "grad_norm": 284.0,
      "learning_rate": 3.431398416886544e-05,
      "loss": 4.625,
      "step": 5846
    },
    {
      "epoch": 7.71,
      "grad_norm": 148.0,
      "learning_rate": 3.429419525065963e-05,
      "loss": 2.5781,
      "step": 5847
    },
    {
      "epoch": 7.72,
      "grad_norm": 43.25,
      "learning_rate": 3.427440633245382e-05,
      "loss": 0.5508,
      "step": 5848
    },
    {
      "epoch": 7.72,
      "grad_norm": 34.75,
      "learning_rate": 3.425461741424802e-05,
      "loss": 0.291,
      "step": 5849
    },
    {
      "epoch": 7.72,
      "grad_norm": 25.875,
      "learning_rate": 3.4234828496042216e-05,
      "loss": 0.332,
      "step": 5850
    },
    {
      "epoch": 7.72,
      "grad_norm": 34.5,
      "learning_rate": 3.421503957783641e-05,
      "loss": 0.6445,
      "step": 5851
    },
    {
      "epoch": 7.72,
      "grad_norm": 101.0,
      "learning_rate": 3.4195250659630605e-05,
      "loss": 1.375,
      "step": 5852
    },
    {
      "epoch": 7.72,
      "grad_norm": 97.5,
      "learning_rate": 3.41754617414248e-05,
      "loss": 1.6016,
      "step": 5853
    },
    {
      "epoch": 7.72,
      "grad_norm": 75.0,
      "learning_rate": 3.4155672823218994e-05,
      "loss": 0.9844,
      "step": 5854
    },
    {
      "epoch": 7.72,
      "grad_norm": 47.25,
      "learning_rate": 3.4135883905013186e-05,
      "loss": 0.6875,
      "step": 5855
    },
    {
      "epoch": 7.73,
      "grad_norm": 40.25,
      "learning_rate": 3.4116094986807384e-05,
      "loss": 0.4141,
      "step": 5856
    },
    {
      "epoch": 7.73,
      "grad_norm": 55.25,
      "learning_rate": 3.409630606860158e-05,
      "loss": 0.2539,
      "step": 5857
    },
    {
      "epoch": 7.73,
      "grad_norm": 98.5,
      "learning_rate": 3.407651715039577e-05,
      "loss": 1.8125,
      "step": 5858
    },
    {
      "epoch": 7.73,
      "grad_norm": 41.5,
      "learning_rate": 3.405672823218997e-05,
      "loss": 0.4766,
      "step": 5859
    },
    {
      "epoch": 7.73,
      "grad_norm": 15.0,
      "learning_rate": 3.403693931398417e-05,
      "loss": 0.1523,
      "step": 5860
    },
    {
      "epoch": 7.73,
      "grad_norm": 71.0,
      "learning_rate": 3.401715039577836e-05,
      "loss": 0.5859,
      "step": 5861
    },
    {
      "epoch": 7.73,
      "grad_norm": 296.0,
      "learning_rate": 3.399736147757255e-05,
      "loss": 6.375,
      "step": 5862
    },
    {
      "epoch": 7.73,
      "grad_norm": 150.0,
      "learning_rate": 3.397757255936675e-05,
      "loss": 1.4297,
      "step": 5863
    },
    {
      "epoch": 7.74,
      "grad_norm": 19.5,
      "learning_rate": 3.395778364116095e-05,
      "loss": 0.2168,
      "step": 5864
    },
    {
      "epoch": 7.74,
      "grad_norm": 10.9375,
      "learning_rate": 3.393799472295514e-05,
      "loss": 0.1631,
      "step": 5865
    },
    {
      "epoch": 7.74,
      "grad_norm": 334.0,
      "learning_rate": 3.391820580474934e-05,
      "loss": 8.375,
      "step": 5866
    },
    {
      "epoch": 7.74,
      "grad_norm": 64.0,
      "learning_rate": 3.3898416886543535e-05,
      "loss": 1.2422,
      "step": 5867
    },
    {
      "epoch": 7.74,
      "grad_norm": 10.875,
      "learning_rate": 3.3878627968337727e-05,
      "loss": 0.1357,
      "step": 5868
    },
    {
      "epoch": 7.74,
      "grad_norm": 71.0,
      "learning_rate": 3.3858839050131925e-05,
      "loss": 0.4551,
      "step": 5869
    },
    {
      "epoch": 7.74,
      "grad_norm": 253.0,
      "learning_rate": 3.3839050131926116e-05,
      "loss": 3.5312,
      "step": 5870
    },
    {
      "epoch": 7.75,
      "grad_norm": 136.0,
      "learning_rate": 3.3819261213720314e-05,
      "loss": 2.7969,
      "step": 5871
    },
    {
      "epoch": 7.75,
      "grad_norm": 85.5,
      "learning_rate": 3.3799472295514505e-05,
      "loss": 0.6445,
      "step": 5872
    },
    {
      "epoch": 7.75,
      "grad_norm": 19.75,
      "learning_rate": 3.37796833773087e-05,
      "loss": 0.252,
      "step": 5873
    },
    {
      "epoch": 7.75,
      "grad_norm": 20.25,
      "learning_rate": 3.37598944591029e-05,
      "loss": 0.2344,
      "step": 5874
    },
    {
      "epoch": 7.75,
      "grad_norm": 36.25,
      "learning_rate": 3.374010554089709e-05,
      "loss": 0.832,
      "step": 5875
    },
    {
      "epoch": 7.75,
      "grad_norm": 24.375,
      "learning_rate": 3.372031662269129e-05,
      "loss": 0.1689,
      "step": 5876
    },
    {
      "epoch": 7.75,
      "grad_norm": 14.3125,
      "learning_rate": 3.370052770448548e-05,
      "loss": 0.1465,
      "step": 5877
    },
    {
      "epoch": 7.75,
      "grad_norm": 112.0,
      "learning_rate": 3.368073878627968e-05,
      "loss": 2.5938,
      "step": 5878
    },
    {
      "epoch": 7.76,
      "grad_norm": 22.0,
      "learning_rate": 3.366094986807388e-05,
      "loss": 0.2695,
      "step": 5879
    },
    {
      "epoch": 7.76,
      "grad_norm": 26.75,
      "learning_rate": 3.364116094986807e-05,
      "loss": 0.3789,
      "step": 5880
    },
    {
      "epoch": 7.76,
      "grad_norm": 15.1875,
      "learning_rate": 3.362137203166227e-05,
      "loss": 0.1338,
      "step": 5881
    },
    {
      "epoch": 7.76,
      "grad_norm": 165.0,
      "learning_rate": 3.3601583113456466e-05,
      "loss": 2.4375,
      "step": 5882
    },
    {
      "epoch": 7.76,
      "grad_norm": 105.5,
      "learning_rate": 3.358179419525066e-05,
      "loss": 1.5078,
      "step": 5883
    },
    {
      "epoch": 7.76,
      "grad_norm": 24.625,
      "learning_rate": 3.3562005277044855e-05,
      "loss": 0.6953,
      "step": 5884
    },
    {
      "epoch": 7.76,
      "grad_norm": 177.0,
      "learning_rate": 3.3542216358839046e-05,
      "loss": 5.0,
      "step": 5885
    },
    {
      "epoch": 7.77,
      "grad_norm": 6.71875,
      "learning_rate": 3.3522427440633244e-05,
      "loss": 0.0608,
      "step": 5886
    },
    {
      "epoch": 7.77,
      "grad_norm": 23.5,
      "learning_rate": 3.3502638522427436e-05,
      "loss": 0.7148,
      "step": 5887
    },
    {
      "epoch": 7.77,
      "grad_norm": 147.0,
      "learning_rate": 3.3482849604221634e-05,
      "loss": 2.6875,
      "step": 5888
    },
    {
      "epoch": 7.77,
      "grad_norm": 101.5,
      "learning_rate": 3.346306068601583e-05,
      "loss": 1.3594,
      "step": 5889
    },
    {
      "epoch": 7.77,
      "grad_norm": 21.25,
      "learning_rate": 3.344327176781002e-05,
      "loss": 0.3965,
      "step": 5890
    },
    {
      "epoch": 7.77,
      "grad_norm": 131.0,
      "learning_rate": 3.342348284960422e-05,
      "loss": 2.0312,
      "step": 5891
    },
    {
      "epoch": 7.77,
      "grad_norm": 10.0625,
      "learning_rate": 3.340369393139841e-05,
      "loss": 0.1084,
      "step": 5892
    },
    {
      "epoch": 7.77,
      "grad_norm": 29.875,
      "learning_rate": 3.338390501319261e-05,
      "loss": 0.498,
      "step": 5893
    },
    {
      "epoch": 7.78,
      "grad_norm": 63.75,
      "learning_rate": 3.33641160949868e-05,
      "loss": 0.8008,
      "step": 5894
    },
    {
      "epoch": 7.78,
      "grad_norm": 97.5,
      "learning_rate": 3.3344327176781e-05,
      "loss": 1.5234,
      "step": 5895
    },
    {
      "epoch": 7.78,
      "grad_norm": 216.0,
      "learning_rate": 3.33245382585752e-05,
      "loss": 5.4062,
      "step": 5896
    },
    {
      "epoch": 7.78,
      "grad_norm": 174.0,
      "learning_rate": 3.330474934036939e-05,
      "loss": 3.3125,
      "step": 5897
    },
    {
      "epoch": 7.78,
      "grad_norm": 7.0,
      "learning_rate": 3.328496042216359e-05,
      "loss": 0.0718,
      "step": 5898
    },
    {
      "epoch": 7.78,
      "grad_norm": 10.5625,
      "learning_rate": 3.3265171503957785e-05,
      "loss": 0.0967,
      "step": 5899
    },
    {
      "epoch": 7.78,
      "grad_norm": 15.4375,
      "learning_rate": 3.3245382585751976e-05,
      "loss": 0.1699,
      "step": 5900
    },
    {
      "epoch": 7.78,
      "grad_norm": 35.75,
      "learning_rate": 3.322559366754617e-05,
      "loss": 0.8008,
      "step": 5901
    },
    {
      "epoch": 7.79,
      "grad_norm": 85.0,
      "learning_rate": 3.3205804749340366e-05,
      "loss": 2.1406,
      "step": 5902
    },
    {
      "epoch": 7.79,
      "grad_norm": 24.875,
      "learning_rate": 3.3186015831134564e-05,
      "loss": 0.498,
      "step": 5903
    },
    {
      "epoch": 7.79,
      "grad_norm": 102.5,
      "learning_rate": 3.3166226912928755e-05,
      "loss": 1.0312,
      "step": 5904
    },
    {
      "epoch": 7.79,
      "grad_norm": 103.0,
      "learning_rate": 3.314643799472295e-05,
      "loss": 2.0312,
      "step": 5905
    },
    {
      "epoch": 7.79,
      "grad_norm": 38.0,
      "learning_rate": 3.312664907651715e-05,
      "loss": 0.5781,
      "step": 5906
    },
    {
      "epoch": 7.79,
      "grad_norm": 42.5,
      "learning_rate": 3.310686015831134e-05,
      "loss": 0.6133,
      "step": 5907
    },
    {
      "epoch": 7.79,
      "grad_norm": 87.5,
      "learning_rate": 3.3087071240105534e-05,
      "loss": 1.3125,
      "step": 5908
    },
    {
      "epoch": 7.8,
      "grad_norm": 168.0,
      "learning_rate": 3.306728232189973e-05,
      "loss": 1.7812,
      "step": 5909
    },
    {
      "epoch": 7.8,
      "grad_norm": 13.5625,
      "learning_rate": 3.304749340369393e-05,
      "loss": 0.1182,
      "step": 5910
    },
    {
      "epoch": 7.8,
      "grad_norm": 132.0,
      "learning_rate": 3.302770448548812e-05,
      "loss": 2.6406,
      "step": 5911
    },
    {
      "epoch": 7.8,
      "grad_norm": 73.5,
      "learning_rate": 3.300791556728232e-05,
      "loss": 0.6719,
      "step": 5912
    },
    {
      "epoch": 7.8,
      "grad_norm": 7.78125,
      "learning_rate": 3.298812664907652e-05,
      "loss": 0.0742,
      "step": 5913
    },
    {
      "epoch": 7.8,
      "grad_norm": 12.8125,
      "learning_rate": 3.296833773087071e-05,
      "loss": 0.1328,
      "step": 5914
    },
    {
      "epoch": 7.8,
      "grad_norm": 106.5,
      "learning_rate": 3.29485488126649e-05,
      "loss": 1.3125,
      "step": 5915
    },
    {
      "epoch": 7.8,
      "grad_norm": 10.0,
      "learning_rate": 3.29287598944591e-05,
      "loss": 0.0889,
      "step": 5916
    },
    {
      "epoch": 7.81,
      "grad_norm": 149.0,
      "learning_rate": 3.2908970976253296e-05,
      "loss": 3.7188,
      "step": 5917
    },
    {
      "epoch": 7.81,
      "grad_norm": 118.0,
      "learning_rate": 3.288918205804749e-05,
      "loss": 2.5156,
      "step": 5918
    },
    {
      "epoch": 7.81,
      "grad_norm": 59.25,
      "learning_rate": 3.2869393139841685e-05,
      "loss": 0.8828,
      "step": 5919
    },
    {
      "epoch": 7.81,
      "grad_norm": 179.0,
      "learning_rate": 3.284960422163588e-05,
      "loss": 2.8281,
      "step": 5920
    },
    {
      "epoch": 7.81,
      "grad_norm": 12.25,
      "learning_rate": 3.2829815303430075e-05,
      "loss": 0.1328,
      "step": 5921
    },
    {
      "epoch": 7.81,
      "grad_norm": 158.0,
      "learning_rate": 3.281002638522427e-05,
      "loss": 3.6094,
      "step": 5922
    },
    {
      "epoch": 7.81,
      "grad_norm": 102.0,
      "learning_rate": 3.2790237467018464e-05,
      "loss": 2.0,
      "step": 5923
    },
    {
      "epoch": 7.82,
      "grad_norm": 44.5,
      "learning_rate": 3.277044854881266e-05,
      "loss": 0.6055,
      "step": 5924
    },
    {
      "epoch": 7.82,
      "grad_norm": 39.0,
      "learning_rate": 3.275065963060686e-05,
      "loss": 0.4473,
      "step": 5925
    },
    {
      "epoch": 7.82,
      "grad_norm": 25.125,
      "learning_rate": 3.273087071240105e-05,
      "loss": 0.332,
      "step": 5926
    },
    {
      "epoch": 7.82,
      "grad_norm": 27.125,
      "learning_rate": 3.271108179419525e-05,
      "loss": 0.6211,
      "step": 5927
    },
    {
      "epoch": 7.82,
      "grad_norm": 19.125,
      "learning_rate": 3.269129287598945e-05,
      "loss": 0.4707,
      "step": 5928
    },
    {
      "epoch": 7.82,
      "grad_norm": 24.25,
      "learning_rate": 3.267150395778364e-05,
      "loss": 0.4219,
      "step": 5929
    },
    {
      "epoch": 7.82,
      "grad_norm": 32.75,
      "learning_rate": 3.265171503957783e-05,
      "loss": 0.4824,
      "step": 5930
    },
    {
      "epoch": 7.82,
      "grad_norm": 146.0,
      "learning_rate": 3.263192612137203e-05,
      "loss": 3.8906,
      "step": 5931
    },
    {
      "epoch": 7.83,
      "grad_norm": 25.125,
      "learning_rate": 3.2612137203166226e-05,
      "loss": 0.7422,
      "step": 5932
    },
    {
      "epoch": 7.83,
      "grad_norm": 85.5,
      "learning_rate": 3.259234828496042e-05,
      "loss": 1.8828,
      "step": 5933
    },
    {
      "epoch": 7.83,
      "grad_norm": 21.875,
      "learning_rate": 3.2572559366754616e-05,
      "loss": 0.2324,
      "step": 5934
    },
    {
      "epoch": 7.83,
      "grad_norm": 84.0,
      "learning_rate": 3.2552770448548814e-05,
      "loss": 1.3906,
      "step": 5935
    },
    {
      "epoch": 7.83,
      "grad_norm": 8.625,
      "learning_rate": 3.2532981530343005e-05,
      "loss": 0.0486,
      "step": 5936
    },
    {
      "epoch": 7.83,
      "grad_norm": 3.203125,
      "learning_rate": 3.2513192612137196e-05,
      "loss": 0.0322,
      "step": 5937
    },
    {
      "epoch": 7.83,
      "grad_norm": 97.0,
      "learning_rate": 3.2493403693931394e-05,
      "loss": 1.7344,
      "step": 5938
    },
    {
      "epoch": 7.84,
      "grad_norm": 26.625,
      "learning_rate": 3.247361477572559e-05,
      "loss": 0.4785,
      "step": 5939
    },
    {
      "epoch": 7.84,
      "grad_norm": 20.625,
      "learning_rate": 3.2453825857519784e-05,
      "loss": 0.2119,
      "step": 5940
    },
    {
      "epoch": 7.84,
      "grad_norm": 52.0,
      "learning_rate": 3.243403693931398e-05,
      "loss": 0.4707,
      "step": 5941
    },
    {
      "epoch": 7.84,
      "grad_norm": 8.9375,
      "learning_rate": 3.241424802110818e-05,
      "loss": 0.0728,
      "step": 5942
    },
    {
      "epoch": 7.84,
      "grad_norm": 6.6875,
      "learning_rate": 3.239445910290237e-05,
      "loss": 0.0811,
      "step": 5943
    },
    {
      "epoch": 7.84,
      "grad_norm": 26.875,
      "learning_rate": 3.237467018469657e-05,
      "loss": 0.4199,
      "step": 5944
    },
    {
      "epoch": 7.84,
      "grad_norm": 19.5,
      "learning_rate": 3.235488126649076e-05,
      "loss": 0.3203,
      "step": 5945
    },
    {
      "epoch": 7.84,
      "grad_norm": 12.75,
      "learning_rate": 3.233509234828496e-05,
      "loss": 0.1152,
      "step": 5946
    },
    {
      "epoch": 7.85,
      "grad_norm": 43.25,
      "learning_rate": 3.231530343007915e-05,
      "loss": 0.2617,
      "step": 5947
    },
    {
      "epoch": 7.85,
      "grad_norm": 175.0,
      "learning_rate": 3.229551451187335e-05,
      "loss": 5.8125,
      "step": 5948
    },
    {
      "epoch": 7.85,
      "grad_norm": 111.5,
      "learning_rate": 3.2275725593667546e-05,
      "loss": 2.3594,
      "step": 5949
    },
    {
      "epoch": 7.85,
      "grad_norm": 20.125,
      "learning_rate": 3.225593667546174e-05,
      "loss": 0.832,
      "step": 5950
    },
    {
      "epoch": 7.85,
      "grad_norm": 5.25,
      "learning_rate": 3.2236147757255935e-05,
      "loss": 0.0615,
      "step": 5951
    },
    {
      "epoch": 7.85,
      "grad_norm": 117.5,
      "learning_rate": 3.2216358839050126e-05,
      "loss": 3.1094,
      "step": 5952
    },
    {
      "epoch": 7.85,
      "grad_norm": 22.5,
      "learning_rate": 3.2196569920844324e-05,
      "loss": 0.209,
      "step": 5953
    },
    {
      "epoch": 7.85,
      "grad_norm": 27.125,
      "learning_rate": 3.2176781002638516e-05,
      "loss": 0.4453,
      "step": 5954
    },
    {
      "epoch": 7.86,
      "grad_norm": 14.5,
      "learning_rate": 3.2156992084432714e-05,
      "loss": 0.1934,
      "step": 5955
    },
    {
      "epoch": 7.86,
      "grad_norm": 4.3125,
      "learning_rate": 3.213720316622691e-05,
      "loss": 0.0393,
      "step": 5956
    },
    {
      "epoch": 7.86,
      "grad_norm": 7.5625,
      "learning_rate": 3.21174142480211e-05,
      "loss": 0.0679,
      "step": 5957
    },
    {
      "epoch": 7.86,
      "grad_norm": 91.0,
      "learning_rate": 3.20976253298153e-05,
      "loss": 1.1562,
      "step": 5958
    },
    {
      "epoch": 7.86,
      "grad_norm": 22.5,
      "learning_rate": 3.20778364116095e-05,
      "loss": 0.1758,
      "step": 5959
    },
    {
      "epoch": 7.86,
      "grad_norm": 136.0,
      "learning_rate": 3.205804749340369e-05,
      "loss": 3.9844,
      "step": 5960
    },
    {
      "epoch": 7.86,
      "grad_norm": 9.4375,
      "learning_rate": 3.203825857519788e-05,
      "loss": 0.0781,
      "step": 5961
    },
    {
      "epoch": 7.87,
      "grad_norm": 28.0,
      "learning_rate": 3.201846965699208e-05,
      "loss": 0.7656,
      "step": 5962
    },
    {
      "epoch": 7.87,
      "grad_norm": 52.75,
      "learning_rate": 3.199868073878628e-05,
      "loss": 0.8008,
      "step": 5963
    },
    {
      "epoch": 7.87,
      "grad_norm": 7.40625,
      "learning_rate": 3.197889182058047e-05,
      "loss": 0.0522,
      "step": 5964
    },
    {
      "epoch": 7.87,
      "grad_norm": 10.5,
      "learning_rate": 3.195910290237467e-05,
      "loss": 0.0894,
      "step": 5965
    },
    {
      "epoch": 7.87,
      "grad_norm": 3.921875,
      "learning_rate": 3.1939313984168865e-05,
      "loss": 0.0339,
      "step": 5966
    },
    {
      "epoch": 7.87,
      "grad_norm": 3.390625,
      "learning_rate": 3.191952506596306e-05,
      "loss": 0.0391,
      "step": 5967
    },
    {
      "epoch": 7.87,
      "grad_norm": 4.6875,
      "learning_rate": 3.1899736147757255e-05,
      "loss": 0.0474,
      "step": 5968
    },
    {
      "epoch": 7.87,
      "grad_norm": 102.5,
      "learning_rate": 3.1879947229551446e-05,
      "loss": 1.8594,
      "step": 5969
    },
    {
      "epoch": 7.88,
      "grad_norm": 32.25,
      "learning_rate": 3.1860158311345644e-05,
      "loss": 0.1206,
      "step": 5970
    },
    {
      "epoch": 7.88,
      "grad_norm": 27.75,
      "learning_rate": 3.184036939313984e-05,
      "loss": 0.8086,
      "step": 5971
    },
    {
      "epoch": 7.88,
      "grad_norm": 13.25,
      "learning_rate": 3.1820580474934033e-05,
      "loss": 0.1235,
      "step": 5972
    },
    {
      "epoch": 7.88,
      "grad_norm": 115.0,
      "learning_rate": 3.180079155672823e-05,
      "loss": 2.9531,
      "step": 5973
    },
    {
      "epoch": 7.88,
      "grad_norm": 31.875,
      "learning_rate": 3.178100263852243e-05,
      "loss": 0.2129,
      "step": 5974
    },
    {
      "epoch": 7.88,
      "grad_norm": 26.375,
      "learning_rate": 3.176121372031662e-05,
      "loss": 0.3867,
      "step": 5975
    },
    {
      "epoch": 7.88,
      "grad_norm": 24.0,
      "learning_rate": 3.174142480211081e-05,
      "loss": 0.543,
      "step": 5976
    },
    {
      "epoch": 7.89,
      "grad_norm": 5.1875,
      "learning_rate": 3.172163588390501e-05,
      "loss": 0.0457,
      "step": 5977
    },
    {
      "epoch": 7.89,
      "grad_norm": 4.625,
      "learning_rate": 3.170184696569921e-05,
      "loss": 0.0522,
      "step": 5978
    },
    {
      "epoch": 7.89,
      "grad_norm": 112.5,
      "learning_rate": 3.16820580474934e-05,
      "loss": 2.4219,
      "step": 5979
    },
    {
      "epoch": 7.89,
      "grad_norm": 24.375,
      "learning_rate": 3.16622691292876e-05,
      "loss": 0.126,
      "step": 5980
    },
    {
      "epoch": 7.89,
      "grad_norm": 30.5,
      "learning_rate": 3.1642480211081796e-05,
      "loss": 0.3945,
      "step": 5981
    },
    {
      "epoch": 7.89,
      "grad_norm": 4.15625,
      "learning_rate": 3.162269129287599e-05,
      "loss": 0.042,
      "step": 5982
    },
    {
      "epoch": 7.89,
      "grad_norm": 162.0,
      "learning_rate": 3.160290237467018e-05,
      "loss": 2.2656,
      "step": 5983
    },
    {
      "epoch": 7.89,
      "grad_norm": 52.5,
      "learning_rate": 3.1583113456464376e-05,
      "loss": 0.5664,
      "step": 5984
    },
    {
      "epoch": 7.9,
      "grad_norm": 155.0,
      "learning_rate": 3.1563324538258574e-05,
      "loss": 6.4375,
      "step": 5985
    },
    {
      "epoch": 7.9,
      "grad_norm": 137.0,
      "learning_rate": 3.1543535620052766e-05,
      "loss": 1.5547,
      "step": 5986
    },
    {
      "epoch": 7.9,
      "grad_norm": 21.75,
      "learning_rate": 3.1523746701846964e-05,
      "loss": 0.0693,
      "step": 5987
    },
    {
      "epoch": 7.9,
      "grad_norm": 163.0,
      "learning_rate": 3.150395778364116e-05,
      "loss": 4.5938,
      "step": 5988
    },
    {
      "epoch": 7.9,
      "grad_norm": 2.4375,
      "learning_rate": 3.148416886543535e-05,
      "loss": 0.0266,
      "step": 5989
    },
    {
      "epoch": 7.9,
      "grad_norm": 4.1875,
      "learning_rate": 3.1464379947229544e-05,
      "loss": 0.0344,
      "step": 5990
    },
    {
      "epoch": 7.9,
      "grad_norm": 3.5625,
      "learning_rate": 3.144459102902374e-05,
      "loss": 0.0361,
      "step": 5991
    },
    {
      "epoch": 7.91,
      "grad_norm": 0.94921875,
      "learning_rate": 3.142480211081794e-05,
      "loss": 0.0126,
      "step": 5992
    },
    {
      "epoch": 7.91,
      "grad_norm": 8.875,
      "learning_rate": 3.140501319261213e-05,
      "loss": 0.0522,
      "step": 5993
    },
    {
      "epoch": 7.91,
      "grad_norm": 52.75,
      "learning_rate": 3.138522427440633e-05,
      "loss": 0.1992,
      "step": 5994
    },
    {
      "epoch": 7.91,
      "grad_norm": 160.0,
      "learning_rate": 3.136543535620053e-05,
      "loss": 4.2812,
      "step": 5995
    },
    {
      "epoch": 7.91,
      "grad_norm": 221.0,
      "learning_rate": 3.134564643799472e-05,
      "loss": 5.7812,
      "step": 5996
    },
    {
      "epoch": 7.91,
      "grad_norm": 177.0,
      "learning_rate": 3.132585751978892e-05,
      "loss": 6.5938,
      "step": 5997
    },
    {
      "epoch": 7.91,
      "grad_norm": 2.15625,
      "learning_rate": 3.130606860158311e-05,
      "loss": 0.0137,
      "step": 5998
    },
    {
      "epoch": 7.91,
      "grad_norm": 38.25,
      "learning_rate": 3.1286279683377306e-05,
      "loss": 0.1973,
      "step": 5999
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.71875,
      "learning_rate": 3.12664907651715e-05,
      "loss": 0.0045,
      "step": 6000
    },
    {
      "epoch": 7.92,
      "grad_norm": 34.25,
      "learning_rate": 3.1246701846965696e-05,
      "loss": 0.5781,
      "step": 6001
    },
    {
      "epoch": 7.92,
      "grad_norm": 133.0,
      "learning_rate": 3.1226912928759894e-05,
      "loss": 2.5469,
      "step": 6002
    },
    {
      "epoch": 7.92,
      "grad_norm": 212.0,
      "learning_rate": 3.1207124010554085e-05,
      "loss": 1.9531,
      "step": 6003
    },
    {
      "epoch": 7.92,
      "grad_norm": 52.0,
      "learning_rate": 3.118733509234828e-05,
      "loss": 0.4492,
      "step": 6004
    },
    {
      "epoch": 7.92,
      "grad_norm": 312.0,
      "learning_rate": 3.1167546174142474e-05,
      "loss": 10.4375,
      "step": 6005
    },
    {
      "epoch": 7.92,
      "grad_norm": 2.171875,
      "learning_rate": 3.114775725593667e-05,
      "loss": 0.0178,
      "step": 6006
    },
    {
      "epoch": 7.92,
      "grad_norm": 237.0,
      "learning_rate": 3.112796833773087e-05,
      "loss": 8.875,
      "step": 6007
    },
    {
      "epoch": 7.93,
      "grad_norm": 111.0,
      "learning_rate": 3.110817941952506e-05,
      "loss": 2.5156,
      "step": 6008
    },
    {
      "epoch": 7.93,
      "grad_norm": 110.5,
      "learning_rate": 3.108839050131926e-05,
      "loss": 4.9688,
      "step": 6009
    },
    {
      "epoch": 7.93,
      "grad_norm": 113.5,
      "learning_rate": 3.106860158311346e-05,
      "loss": 1.0078,
      "step": 6010
    },
    {
      "epoch": 7.93,
      "grad_norm": 59.75,
      "learning_rate": 3.104881266490765e-05,
      "loss": 0.3359,
      "step": 6011
    },
    {
      "epoch": 7.93,
      "grad_norm": 1.390625,
      "learning_rate": 3.102902374670185e-05,
      "loss": 0.016,
      "step": 6012
    },
    {
      "epoch": 7.93,
      "grad_norm": 184.0,
      "learning_rate": 3.100923482849604e-05,
      "loss": 1.2344,
      "step": 6013
    },
    {
      "epoch": 7.93,
      "grad_norm": 10.8125,
      "learning_rate": 3.098944591029024e-05,
      "loss": 0.0752,
      "step": 6014
    },
    {
      "epoch": 7.94,
      "grad_norm": 33.25,
      "learning_rate": 3.096965699208443e-05,
      "loss": 0.1504,
      "step": 6015
    },
    {
      "epoch": 7.94,
      "grad_norm": 46.25,
      "learning_rate": 3.0949868073878626e-05,
      "loss": 0.7773,
      "step": 6016
    },
    {
      "epoch": 7.94,
      "grad_norm": 26.625,
      "learning_rate": 3.0930079155672824e-05,
      "loss": 0.9219,
      "step": 6017
    },
    {
      "epoch": 7.94,
      "grad_norm": 288.0,
      "learning_rate": 3.0910290237467015e-05,
      "loss": 3.8906,
      "step": 6018
    },
    {
      "epoch": 7.94,
      "grad_norm": 107.0,
      "learning_rate": 3.0890501319261213e-05,
      "loss": 1.1719,
      "step": 6019
    },
    {
      "epoch": 7.94,
      "grad_norm": 40.0,
      "learning_rate": 3.0870712401055405e-05,
      "loss": 0.0986,
      "step": 6020
    },
    {
      "epoch": 7.94,
      "grad_norm": 175.0,
      "learning_rate": 3.08509234828496e-05,
      "loss": 1.1641,
      "step": 6021
    },
    {
      "epoch": 7.94,
      "grad_norm": 1.1328125,
      "learning_rate": 3.0831134564643794e-05,
      "loss": 0.0126,
      "step": 6022
    },
    {
      "epoch": 7.95,
      "grad_norm": 5.15625,
      "learning_rate": 3.081134564643799e-05,
      "loss": 0.0277,
      "step": 6023
    },
    {
      "epoch": 7.95,
      "grad_norm": 21.75,
      "learning_rate": 3.079155672823219e-05,
      "loss": 0.3047,
      "step": 6024
    },
    {
      "epoch": 7.95,
      "grad_norm": 23.5,
      "learning_rate": 3.077176781002638e-05,
      "loss": 0.6797,
      "step": 6025
    },
    {
      "epoch": 7.95,
      "grad_norm": 141.0,
      "learning_rate": 3.075197889182058e-05,
      "loss": 3.25,
      "step": 6026
    },
    {
      "epoch": 7.95,
      "grad_norm": 108.0,
      "learning_rate": 3.073218997361478e-05,
      "loss": 2.3438,
      "step": 6027
    },
    {
      "epoch": 7.95,
      "grad_norm": 22.125,
      "learning_rate": 3.071240105540897e-05,
      "loss": 0.0898,
      "step": 6028
    },
    {
      "epoch": 7.95,
      "grad_norm": 206.0,
      "learning_rate": 3.069261213720316e-05,
      "loss": 1.2969,
      "step": 6029
    },
    {
      "epoch": 7.96,
      "grad_norm": 20.0,
      "learning_rate": 3.067282321899736e-05,
      "loss": 0.0952,
      "step": 6030
    },
    {
      "epoch": 7.96,
      "grad_norm": 372.0,
      "learning_rate": 3.0653034300791556e-05,
      "loss": 8.1875,
      "step": 6031
    },
    {
      "epoch": 7.96,
      "grad_norm": 179.0,
      "learning_rate": 3.063324538258575e-05,
      "loss": 4.5625,
      "step": 6032
    },
    {
      "epoch": 7.96,
      "grad_norm": 22.25,
      "learning_rate": 3.0613456464379946e-05,
      "loss": 0.1738,
      "step": 6033
    },
    {
      "epoch": 7.96,
      "grad_norm": 150.0,
      "learning_rate": 3.0593667546174144e-05,
      "loss": 2.6875,
      "step": 6034
    },
    {
      "epoch": 7.96,
      "grad_norm": 2.78125,
      "learning_rate": 3.0573878627968335e-05,
      "loss": 0.0199,
      "step": 6035
    },
    {
      "epoch": 7.96,
      "grad_norm": 38.5,
      "learning_rate": 3.0554089709762526e-05,
      "loss": 0.2773,
      "step": 6036
    },
    {
      "epoch": 7.96,
      "grad_norm": 14.4375,
      "learning_rate": 3.0534300791556724e-05,
      "loss": 0.1338,
      "step": 6037
    },
    {
      "epoch": 7.97,
      "grad_norm": 214.0,
      "learning_rate": 3.051451187335092e-05,
      "loss": 5.125,
      "step": 6038
    },
    {
      "epoch": 7.97,
      "grad_norm": 42.75,
      "learning_rate": 3.0494722955145117e-05,
      "loss": 0.7812,
      "step": 6039
    },
    {
      "epoch": 7.97,
      "grad_norm": 7.625,
      "learning_rate": 3.0474934036939312e-05,
      "loss": 0.0781,
      "step": 6040
    },
    {
      "epoch": 7.97,
      "grad_norm": 113.5,
      "learning_rate": 3.0455145118733506e-05,
      "loss": 2.5156,
      "step": 6041
    },
    {
      "epoch": 7.97,
      "grad_norm": 32.5,
      "learning_rate": 3.0435356200527704e-05,
      "loss": 0.2256,
      "step": 6042
    },
    {
      "epoch": 7.97,
      "grad_norm": 5.53125,
      "learning_rate": 3.0415567282321896e-05,
      "loss": 0.0171,
      "step": 6043
    },
    {
      "epoch": 7.97,
      "grad_norm": 13.875,
      "learning_rate": 3.039577836411609e-05,
      "loss": 0.0635,
      "step": 6044
    },
    {
      "epoch": 7.97,
      "grad_norm": 127.5,
      "learning_rate": 3.037598944591029e-05,
      "loss": 2.8906,
      "step": 6045
    },
    {
      "epoch": 7.98,
      "grad_norm": 145.0,
      "learning_rate": 3.0356200527704483e-05,
      "loss": 3.8438,
      "step": 6046
    },
    {
      "epoch": 7.98,
      "grad_norm": 25.5,
      "learning_rate": 3.0336411609498678e-05,
      "loss": 0.2158,
      "step": 6047
    },
    {
      "epoch": 7.98,
      "grad_norm": 12.25,
      "learning_rate": 3.0316622691292876e-05,
      "loss": 0.1934,
      "step": 6048
    },
    {
      "epoch": 7.98,
      "grad_norm": 37.75,
      "learning_rate": 3.029683377308707e-05,
      "loss": 0.7148,
      "step": 6049
    },
    {
      "epoch": 7.98,
      "grad_norm": 4.8125,
      "learning_rate": 3.0277044854881262e-05,
      "loss": 0.0369,
      "step": 6050
    },
    {
      "epoch": 7.98,
      "grad_norm": 38.25,
      "learning_rate": 3.0257255936675456e-05,
      "loss": 0.1846,
      "step": 6051
    },
    {
      "epoch": 7.98,
      "grad_norm": 14.1875,
      "learning_rate": 3.0237467018469655e-05,
      "loss": 0.1348,
      "step": 6052
    },
    {
      "epoch": 7.99,
      "grad_norm": 102.5,
      "learning_rate": 3.021767810026385e-05,
      "loss": 1.5312,
      "step": 6053
    },
    {
      "epoch": 7.99,
      "grad_norm": 20.25,
      "learning_rate": 3.0197889182058044e-05,
      "loss": 0.2598,
      "step": 6054
    },
    {
      "epoch": 7.99,
      "grad_norm": 228.0,
      "learning_rate": 3.0178100263852242e-05,
      "loss": 1.4531,
      "step": 6055
    },
    {
      "epoch": 7.99,
      "grad_norm": 137.0,
      "learning_rate": 3.0158311345646437e-05,
      "loss": 2.2344,
      "step": 6056
    },
    {
      "epoch": 7.99,
      "grad_norm": 83.5,
      "learning_rate": 3.013852242744063e-05,
      "loss": 1.9062,
      "step": 6057
    },
    {
      "epoch": 7.99,
      "grad_norm": 91.0,
      "learning_rate": 3.0118733509234823e-05,
      "loss": 1.4766,
      "step": 6058
    },
    {
      "epoch": 7.99,
      "grad_norm": 65.5,
      "learning_rate": 3.009894459102902e-05,
      "loss": 0.75,
      "step": 6059
    },
    {
      "epoch": 7.99,
      "grad_norm": 5.65625,
      "learning_rate": 3.0079155672823215e-05,
      "loss": 0.0625,
      "step": 6060
    },
    {
      "epoch": 8.0,
      "grad_norm": 18.625,
      "learning_rate": 3.005936675461741e-05,
      "loss": 0.2383,
      "step": 6061
    },
    {
      "epoch": 8.0,
      "grad_norm": 20.75,
      "learning_rate": 3.0039577836411608e-05,
      "loss": 0.1172,
      "step": 6062
    },
    {
      "epoch": 8.0,
      "grad_norm": 42.5,
      "learning_rate": 3.0019788918205803e-05,
      "loss": 0.1836,
      "step": 6063
    },
    {
      "epoch": 8.0,
      "grad_norm": 152.0,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 2.5469,
      "step": 6064
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.6379637718200684,
      "eval_runtime": 18.3251,
      "eval_samples_per_second": 42.674,
      "eval_steps_per_second": 10.696,
      "step": 6064
    },
    {
      "epoch": 8.0,
      "grad_norm": 39.0,
      "learning_rate": 2.9980211081794192e-05,
      "loss": 0.7578,
      "step": 6065
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.375,
      "learning_rate": 2.9960422163588387e-05,
      "loss": 0.0142,
      "step": 6066
    },
    {
      "epoch": 8.0,
      "grad_norm": 168.0,
      "learning_rate": 2.994063324538258e-05,
      "loss": 3.3125,
      "step": 6067
    },
    {
      "epoch": 8.01,
      "grad_norm": 21.375,
      "learning_rate": 2.992084432717678e-05,
      "loss": 0.2139,
      "step": 6068
    },
    {
      "epoch": 8.01,
      "grad_norm": 36.75,
      "learning_rate": 2.9901055408970974e-05,
      "loss": 0.6758,
      "step": 6069
    },
    {
      "epoch": 8.01,
      "grad_norm": 14.4375,
      "learning_rate": 2.988126649076517e-05,
      "loss": 0.1699,
      "step": 6070
    },
    {
      "epoch": 8.01,
      "grad_norm": 108.0,
      "learning_rate": 2.9861477572559367e-05,
      "loss": 2.0781,
      "step": 6071
    },
    {
      "epoch": 8.01,
      "grad_norm": 17.625,
      "learning_rate": 2.984168865435356e-05,
      "loss": 0.1455,
      "step": 6072
    },
    {
      "epoch": 8.01,
      "grad_norm": 54.75,
      "learning_rate": 2.9821899736147753e-05,
      "loss": 0.6953,
      "step": 6073
    },
    {
      "epoch": 8.01,
      "grad_norm": 65.5,
      "learning_rate": 2.9802110817941947e-05,
      "loss": 0.3809,
      "step": 6074
    },
    {
      "epoch": 8.01,
      "grad_norm": 187.0,
      "learning_rate": 2.9782321899736146e-05,
      "loss": 3.9062,
      "step": 6075
    },
    {
      "epoch": 8.02,
      "grad_norm": 156.0,
      "learning_rate": 2.976253298153034e-05,
      "loss": 2.6719,
      "step": 6076
    },
    {
      "epoch": 8.02,
      "grad_norm": 108.0,
      "learning_rate": 2.9742744063324535e-05,
      "loss": 2.4531,
      "step": 6077
    },
    {
      "epoch": 8.02,
      "grad_norm": 8.25,
      "learning_rate": 2.9722955145118733e-05,
      "loss": 0.0654,
      "step": 6078
    },
    {
      "epoch": 8.02,
      "grad_norm": 7.53125,
      "learning_rate": 2.9703166226912928e-05,
      "loss": 0.0618,
      "step": 6079
    },
    {
      "epoch": 8.02,
      "grad_norm": 110.0,
      "learning_rate": 2.968337730870712e-05,
      "loss": 0.957,
      "step": 6080
    },
    {
      "epoch": 8.02,
      "grad_norm": 60.75,
      "learning_rate": 2.9663588390501314e-05,
      "loss": 1.3984,
      "step": 6081
    },
    {
      "epoch": 8.02,
      "grad_norm": 154.0,
      "learning_rate": 2.964379947229551e-05,
      "loss": 2.0312,
      "step": 6082
    },
    {
      "epoch": 8.03,
      "grad_norm": 99.5,
      "learning_rate": 2.9624010554089706e-05,
      "loss": 2.9531,
      "step": 6083
    },
    {
      "epoch": 8.03,
      "grad_norm": 85.5,
      "learning_rate": 2.9604221635883904e-05,
      "loss": 2.9062,
      "step": 6084
    },
    {
      "epoch": 8.03,
      "grad_norm": 40.25,
      "learning_rate": 2.95844327176781e-05,
      "loss": 1.1641,
      "step": 6085
    },
    {
      "epoch": 8.03,
      "grad_norm": 115.0,
      "learning_rate": 2.9564643799472294e-05,
      "loss": 2.2188,
      "step": 6086
    },
    {
      "epoch": 8.03,
      "grad_norm": 113.5,
      "learning_rate": 2.9544854881266492e-05,
      "loss": 2.5781,
      "step": 6087
    },
    {
      "epoch": 8.03,
      "grad_norm": 49.25,
      "learning_rate": 2.9525065963060683e-05,
      "loss": 1.6641,
      "step": 6088
    },
    {
      "epoch": 8.03,
      "grad_norm": 29.125,
      "learning_rate": 2.9505277044854878e-05,
      "loss": 0.1846,
      "step": 6089
    },
    {
      "epoch": 8.03,
      "grad_norm": 115.0,
      "learning_rate": 2.9485488126649072e-05,
      "loss": 2.2031,
      "step": 6090
    },
    {
      "epoch": 8.04,
      "grad_norm": 244.0,
      "learning_rate": 2.946569920844327e-05,
      "loss": 4.25,
      "step": 6091
    },
    {
      "epoch": 8.04,
      "grad_norm": 3.015625,
      "learning_rate": 2.9445910290237465e-05,
      "loss": 0.0254,
      "step": 6092
    },
    {
      "epoch": 8.04,
      "grad_norm": 37.5,
      "learning_rate": 2.942612137203166e-05,
      "loss": 0.6055,
      "step": 6093
    },
    {
      "epoch": 8.04,
      "grad_norm": 30.375,
      "learning_rate": 2.9406332453825858e-05,
      "loss": 0.4141,
      "step": 6094
    },
    {
      "epoch": 8.04,
      "grad_norm": 25.5,
      "learning_rate": 2.938654353562005e-05,
      "loss": 0.4824,
      "step": 6095
    },
    {
      "epoch": 8.04,
      "grad_norm": 12.4375,
      "learning_rate": 2.9366754617414244e-05,
      "loss": 0.0806,
      "step": 6096
    },
    {
      "epoch": 8.04,
      "grad_norm": 84.0,
      "learning_rate": 2.934696569920844e-05,
      "loss": 0.6406,
      "step": 6097
    },
    {
      "epoch": 8.04,
      "grad_norm": 30.125,
      "learning_rate": 2.9327176781002637e-05,
      "loss": 0.5117,
      "step": 6098
    },
    {
      "epoch": 8.05,
      "grad_norm": 34.5,
      "learning_rate": 2.930738786279683e-05,
      "loss": 0.2656,
      "step": 6099
    },
    {
      "epoch": 8.05,
      "grad_norm": 124.5,
      "learning_rate": 2.9287598944591026e-05,
      "loss": 2.6719,
      "step": 6100
    },
    {
      "epoch": 8.05,
      "grad_norm": 57.5,
      "learning_rate": 2.9267810026385224e-05,
      "loss": 0.1484,
      "step": 6101
    },
    {
      "epoch": 8.05,
      "grad_norm": 54.75,
      "learning_rate": 2.924802110817942e-05,
      "loss": 0.668,
      "step": 6102
    },
    {
      "epoch": 8.05,
      "grad_norm": 20.375,
      "learning_rate": 2.922823218997361e-05,
      "loss": 0.6211,
      "step": 6103
    },
    {
      "epoch": 8.05,
      "grad_norm": 133.0,
      "learning_rate": 2.9208443271767808e-05,
      "loss": 2.8594,
      "step": 6104
    },
    {
      "epoch": 8.05,
      "grad_norm": 44.75,
      "learning_rate": 2.9188654353562003e-05,
      "loss": 1.1797,
      "step": 6105
    },
    {
      "epoch": 8.06,
      "grad_norm": 31.625,
      "learning_rate": 2.9168865435356197e-05,
      "loss": 0.2061,
      "step": 6106
    },
    {
      "epoch": 8.06,
      "grad_norm": 4.125,
      "learning_rate": 2.9149076517150395e-05,
      "loss": 0.0342,
      "step": 6107
    },
    {
      "epoch": 8.06,
      "grad_norm": 79.0,
      "learning_rate": 2.912928759894459e-05,
      "loss": 1.3047,
      "step": 6108
    },
    {
      "epoch": 8.06,
      "grad_norm": 152.0,
      "learning_rate": 2.9109498680738785e-05,
      "loss": 4.5938,
      "step": 6109
    },
    {
      "epoch": 8.06,
      "grad_norm": 27.375,
      "learning_rate": 2.9089709762532976e-05,
      "loss": 0.7578,
      "step": 6110
    },
    {
      "epoch": 8.06,
      "grad_norm": 54.25,
      "learning_rate": 2.9069920844327174e-05,
      "loss": 1.3359,
      "step": 6111
    },
    {
      "epoch": 8.06,
      "grad_norm": 294.0,
      "learning_rate": 2.905013192612137e-05,
      "loss": 2.9531,
      "step": 6112
    },
    {
      "epoch": 8.06,
      "grad_norm": 22.125,
      "learning_rate": 2.9030343007915563e-05,
      "loss": 0.2949,
      "step": 6113
    },
    {
      "epoch": 8.07,
      "grad_norm": 36.25,
      "learning_rate": 2.901055408970976e-05,
      "loss": 0.7539,
      "step": 6114
    },
    {
      "epoch": 8.07,
      "grad_norm": 8.9375,
      "learning_rate": 2.8990765171503956e-05,
      "loss": 0.1807,
      "step": 6115
    },
    {
      "epoch": 8.07,
      "grad_norm": 85.5,
      "learning_rate": 2.897097625329815e-05,
      "loss": 0.6641,
      "step": 6116
    },
    {
      "epoch": 8.07,
      "grad_norm": 67.0,
      "learning_rate": 2.895118733509235e-05,
      "loss": 0.8164,
      "step": 6117
    },
    {
      "epoch": 8.07,
      "grad_norm": 123.5,
      "learning_rate": 2.893139841688654e-05,
      "loss": 2.8125,
      "step": 6118
    },
    {
      "epoch": 8.07,
      "grad_norm": 11.1875,
      "learning_rate": 2.8911609498680735e-05,
      "loss": 0.1475,
      "step": 6119
    },
    {
      "epoch": 8.07,
      "grad_norm": 48.75,
      "learning_rate": 2.889182058047493e-05,
      "loss": 0.8164,
      "step": 6120
    },
    {
      "epoch": 8.08,
      "grad_norm": 18.75,
      "learning_rate": 2.8872031662269128e-05,
      "loss": 0.1943,
      "step": 6121
    },
    {
      "epoch": 8.08,
      "grad_norm": 34.5,
      "learning_rate": 2.8852242744063322e-05,
      "loss": 0.2754,
      "step": 6122
    },
    {
      "epoch": 8.08,
      "grad_norm": 33.75,
      "learning_rate": 2.8832453825857517e-05,
      "loss": 0.957,
      "step": 6123
    },
    {
      "epoch": 8.08,
      "grad_norm": 30.875,
      "learning_rate": 2.8812664907651715e-05,
      "loss": 0.209,
      "step": 6124
    },
    {
      "epoch": 8.08,
      "grad_norm": 13.4375,
      "learning_rate": 2.8792875989445906e-05,
      "loss": 0.1182,
      "step": 6125
    },
    {
      "epoch": 8.08,
      "grad_norm": 15.875,
      "learning_rate": 2.87730870712401e-05,
      "loss": 0.2451,
      "step": 6126
    },
    {
      "epoch": 8.08,
      "grad_norm": 7.28125,
      "learning_rate": 2.87532981530343e-05,
      "loss": 0.0593,
      "step": 6127
    },
    {
      "epoch": 8.08,
      "grad_norm": 25.875,
      "learning_rate": 2.8733509234828494e-05,
      "loss": 1.2422,
      "step": 6128
    },
    {
      "epoch": 8.09,
      "grad_norm": 47.25,
      "learning_rate": 2.8713720316622688e-05,
      "loss": 0.8477,
      "step": 6129
    },
    {
      "epoch": 8.09,
      "grad_norm": 38.75,
      "learning_rate": 2.8693931398416886e-05,
      "loss": 0.6016,
      "step": 6130
    },
    {
      "epoch": 8.09,
      "grad_norm": 20.0,
      "learning_rate": 2.867414248021108e-05,
      "loss": 0.25,
      "step": 6131
    },
    {
      "epoch": 8.09,
      "grad_norm": 3.90625,
      "learning_rate": 2.8654353562005276e-05,
      "loss": 0.0381,
      "step": 6132
    },
    {
      "epoch": 8.09,
      "grad_norm": 98.5,
      "learning_rate": 2.8634564643799467e-05,
      "loss": 1.9062,
      "step": 6133
    },
    {
      "epoch": 8.09,
      "grad_norm": 87.5,
      "learning_rate": 2.8614775725593665e-05,
      "loss": 1.1953,
      "step": 6134
    },
    {
      "epoch": 8.09,
      "grad_norm": 46.25,
      "learning_rate": 2.859498680738786e-05,
      "loss": 0.6641,
      "step": 6135
    },
    {
      "epoch": 8.09,
      "grad_norm": 13.8125,
      "learning_rate": 2.8575197889182054e-05,
      "loss": 0.1719,
      "step": 6136
    },
    {
      "epoch": 8.1,
      "grad_norm": 126.5,
      "learning_rate": 2.8555408970976252e-05,
      "loss": 2.5781,
      "step": 6137
    },
    {
      "epoch": 8.1,
      "grad_norm": 122.0,
      "learning_rate": 2.8535620052770447e-05,
      "loss": 1.9766,
      "step": 6138
    },
    {
      "epoch": 8.1,
      "grad_norm": 206.0,
      "learning_rate": 2.8515831134564642e-05,
      "loss": 5.4062,
      "step": 6139
    },
    {
      "epoch": 8.1,
      "grad_norm": 5.125,
      "learning_rate": 2.8496042216358833e-05,
      "loss": 0.0525,
      "step": 6140
    },
    {
      "epoch": 8.1,
      "grad_norm": 25.0,
      "learning_rate": 2.847625329815303e-05,
      "loss": 0.8398,
      "step": 6141
    },
    {
      "epoch": 8.1,
      "grad_norm": 28.25,
      "learning_rate": 2.8456464379947226e-05,
      "loss": 0.1699,
      "step": 6142
    },
    {
      "epoch": 8.1,
      "grad_norm": 25.25,
      "learning_rate": 2.843667546174142e-05,
      "loss": 0.3652,
      "step": 6143
    },
    {
      "epoch": 8.11,
      "grad_norm": 23.875,
      "learning_rate": 2.841688654353562e-05,
      "loss": 0.4238,
      "step": 6144
    },
    {
      "epoch": 8.11,
      "grad_norm": 85.5,
      "learning_rate": 2.8397097625329813e-05,
      "loss": 1.1016,
      "step": 6145
    },
    {
      "epoch": 8.11,
      "grad_norm": 23.75,
      "learning_rate": 2.8377308707124008e-05,
      "loss": 0.3613,
      "step": 6146
    },
    {
      "epoch": 8.11,
      "grad_norm": 3.21875,
      "learning_rate": 2.8357519788918206e-05,
      "loss": 0.0388,
      "step": 6147
    },
    {
      "epoch": 8.11,
      "grad_norm": 38.0,
      "learning_rate": 2.8337730870712397e-05,
      "loss": 0.457,
      "step": 6148
    },
    {
      "epoch": 8.11,
      "grad_norm": 13.4375,
      "learning_rate": 2.8317941952506592e-05,
      "loss": 0.1436,
      "step": 6149
    },
    {
      "epoch": 8.11,
      "grad_norm": 152.0,
      "learning_rate": 2.829815303430079e-05,
      "loss": 7.75,
      "step": 6150
    },
    {
      "epoch": 8.11,
      "grad_norm": 43.25,
      "learning_rate": 2.8278364116094985e-05,
      "loss": 0.3828,
      "step": 6151
    },
    {
      "epoch": 8.12,
      "grad_norm": 15.625,
      "learning_rate": 2.825857519788918e-05,
      "loss": 0.1367,
      "step": 6152
    },
    {
      "epoch": 8.12,
      "grad_norm": 178.0,
      "learning_rate": 2.8238786279683377e-05,
      "loss": 2.0156,
      "step": 6153
    },
    {
      "epoch": 8.12,
      "grad_norm": 11.3125,
      "learning_rate": 2.8218997361477572e-05,
      "loss": 0.1245,
      "step": 6154
    },
    {
      "epoch": 8.12,
      "grad_norm": 4.96875,
      "learning_rate": 2.8199208443271763e-05,
      "loss": 0.0376,
      "step": 6155
    },
    {
      "epoch": 8.12,
      "grad_norm": 48.75,
      "learning_rate": 2.8179419525065958e-05,
      "loss": 0.1074,
      "step": 6156
    },
    {
      "epoch": 8.12,
      "grad_norm": 138.0,
      "learning_rate": 2.8159630606860156e-05,
      "loss": 2.5625,
      "step": 6157
    },
    {
      "epoch": 8.12,
      "grad_norm": 30.0,
      "learning_rate": 2.813984168865435e-05,
      "loss": 0.3047,
      "step": 6158
    },
    {
      "epoch": 8.13,
      "grad_norm": 71.5,
      "learning_rate": 2.8120052770448545e-05,
      "loss": 1.0156,
      "step": 6159
    },
    {
      "epoch": 8.13,
      "grad_norm": 24.625,
      "learning_rate": 2.8100263852242743e-05,
      "loss": 0.5664,
      "step": 6160
    },
    {
      "epoch": 8.13,
      "grad_norm": 278.0,
      "learning_rate": 2.8080474934036938e-05,
      "loss": 3.8125,
      "step": 6161
    },
    {
      "epoch": 8.13,
      "grad_norm": 92.0,
      "learning_rate": 2.8060686015831133e-05,
      "loss": 1.9297,
      "step": 6162
    },
    {
      "epoch": 8.13,
      "grad_norm": 56.0,
      "learning_rate": 2.8040897097625324e-05,
      "loss": 0.4531,
      "step": 6163
    },
    {
      "epoch": 8.13,
      "grad_norm": 36.75,
      "learning_rate": 2.8021108179419522e-05,
      "loss": 0.418,
      "step": 6164
    },
    {
      "epoch": 8.13,
      "grad_norm": 42.75,
      "learning_rate": 2.8001319261213717e-05,
      "loss": 0.3613,
      "step": 6165
    },
    {
      "epoch": 8.13,
      "grad_norm": 141.0,
      "learning_rate": 2.798153034300791e-05,
      "loss": 3.0312,
      "step": 6166
    },
    {
      "epoch": 8.14,
      "grad_norm": 10.625,
      "learning_rate": 2.796174142480211e-05,
      "loss": 0.1206,
      "step": 6167
    },
    {
      "epoch": 8.14,
      "grad_norm": 6.1875,
      "learning_rate": 2.7941952506596304e-05,
      "loss": 0.0503,
      "step": 6168
    },
    {
      "epoch": 8.14,
      "grad_norm": 5.5625,
      "learning_rate": 2.79221635883905e-05,
      "loss": 0.0361,
      "step": 6169
    },
    {
      "epoch": 8.14,
      "grad_norm": 18.125,
      "learning_rate": 2.7902374670184697e-05,
      "loss": 0.4746,
      "step": 6170
    },
    {
      "epoch": 8.14,
      "grad_norm": 111.0,
      "learning_rate": 2.7882585751978888e-05,
      "loss": 1.0703,
      "step": 6171
    },
    {
      "epoch": 8.14,
      "grad_norm": 6.40625,
      "learning_rate": 2.7862796833773083e-05,
      "loss": 0.0486,
      "step": 6172
    },
    {
      "epoch": 8.14,
      "grad_norm": 90.0,
      "learning_rate": 2.784300791556728e-05,
      "loss": 1.9375,
      "step": 6173
    },
    {
      "epoch": 8.15,
      "grad_norm": 11.375,
      "learning_rate": 2.7823218997361476e-05,
      "loss": 0.0554,
      "step": 6174
    },
    {
      "epoch": 8.15,
      "grad_norm": 64.5,
      "learning_rate": 2.780343007915567e-05,
      "loss": 3.4688,
      "step": 6175
    },
    {
      "epoch": 8.15,
      "grad_norm": 24.0,
      "learning_rate": 2.778364116094987e-05,
      "loss": 0.2734,
      "step": 6176
    },
    {
      "epoch": 8.15,
      "grad_norm": 10.0,
      "learning_rate": 2.7763852242744063e-05,
      "loss": 0.052,
      "step": 6177
    },
    {
      "epoch": 8.15,
      "grad_norm": 97.0,
      "learning_rate": 2.7744063324538254e-05,
      "loss": 0.6797,
      "step": 6178
    },
    {
      "epoch": 8.15,
      "grad_norm": 142.0,
      "learning_rate": 2.772427440633245e-05,
      "loss": 1.4219,
      "step": 6179
    },
    {
      "epoch": 8.15,
      "grad_norm": 9.0,
      "learning_rate": 2.7704485488126647e-05,
      "loss": 0.1113,
      "step": 6180
    },
    {
      "epoch": 8.15,
      "grad_norm": 24.375,
      "learning_rate": 2.768469656992084e-05,
      "loss": 0.3672,
      "step": 6181
    },
    {
      "epoch": 8.16,
      "grad_norm": 61.0,
      "learning_rate": 2.7664907651715036e-05,
      "loss": 0.8359,
      "step": 6182
    },
    {
      "epoch": 8.16,
      "grad_norm": 6.46875,
      "learning_rate": 2.7645118733509234e-05,
      "loss": 0.0645,
      "step": 6183
    },
    {
      "epoch": 8.16,
      "grad_norm": 42.75,
      "learning_rate": 2.762532981530343e-05,
      "loss": 0.3359,
      "step": 6184
    },
    {
      "epoch": 8.16,
      "grad_norm": 18.375,
      "learning_rate": 2.7605540897097624e-05,
      "loss": 0.2236,
      "step": 6185
    },
    {
      "epoch": 8.16,
      "grad_norm": 380.0,
      "learning_rate": 2.7585751978891815e-05,
      "loss": 5.75,
      "step": 6186
    },
    {
      "epoch": 8.16,
      "grad_norm": 0.7734375,
      "learning_rate": 2.7565963060686013e-05,
      "loss": 0.0106,
      "step": 6187
    },
    {
      "epoch": 8.16,
      "grad_norm": 11.6875,
      "learning_rate": 2.7546174142480208e-05,
      "loss": 0.1035,
      "step": 6188
    },
    {
      "epoch": 8.16,
      "grad_norm": 8.9375,
      "learning_rate": 2.7526385224274402e-05,
      "loss": 0.0884,
      "step": 6189
    },
    {
      "epoch": 8.17,
      "grad_norm": 11.3125,
      "learning_rate": 2.75065963060686e-05,
      "loss": 0.1582,
      "step": 6190
    },
    {
      "epoch": 8.17,
      "grad_norm": 4.5,
      "learning_rate": 2.7486807387862795e-05,
      "loss": 0.0554,
      "step": 6191
    },
    {
      "epoch": 8.17,
      "grad_norm": 189.0,
      "learning_rate": 2.746701846965699e-05,
      "loss": 4.5938,
      "step": 6192
    },
    {
      "epoch": 8.17,
      "grad_norm": 0.53515625,
      "learning_rate": 2.7447229551451185e-05,
      "loss": 0.0056,
      "step": 6193
    },
    {
      "epoch": 8.17,
      "grad_norm": 21.625,
      "learning_rate": 2.742744063324538e-05,
      "loss": 0.457,
      "step": 6194
    },
    {
      "epoch": 8.17,
      "grad_norm": 62.75,
      "learning_rate": 2.7407651715039574e-05,
      "loss": 0.668,
      "step": 6195
    },
    {
      "epoch": 8.17,
      "grad_norm": 5.25,
      "learning_rate": 2.7387862796833772e-05,
      "loss": 0.0342,
      "step": 6196
    },
    {
      "epoch": 8.18,
      "grad_norm": 120.0,
      "learning_rate": 2.7368073878627967e-05,
      "loss": 2.2969,
      "step": 6197
    },
    {
      "epoch": 8.18,
      "grad_norm": 64.0,
      "learning_rate": 2.734828496042216e-05,
      "loss": 0.4102,
      "step": 6198
    },
    {
      "epoch": 8.18,
      "grad_norm": 42.0,
      "learning_rate": 2.732849604221636e-05,
      "loss": 0.543,
      "step": 6199
    },
    {
      "epoch": 8.18,
      "grad_norm": 9.25,
      "learning_rate": 2.7308707124010554e-05,
      "loss": 0.0635,
      "step": 6200
    },
    {
      "epoch": 8.18,
      "grad_norm": 12.875,
      "learning_rate": 2.7288918205804745e-05,
      "loss": 0.041,
      "step": 6201
    },
    {
      "epoch": 8.18,
      "grad_norm": 8.375,
      "learning_rate": 2.726912928759894e-05,
      "loss": 0.0442,
      "step": 6202
    },
    {
      "epoch": 8.18,
      "grad_norm": 35.0,
      "learning_rate": 2.7249340369393138e-05,
      "loss": 0.5547,
      "step": 6203
    },
    {
      "epoch": 8.18,
      "grad_norm": 266.0,
      "learning_rate": 2.7229551451187333e-05,
      "loss": 4.2812,
      "step": 6204
    },
    {
      "epoch": 8.19,
      "grad_norm": 35.5,
      "learning_rate": 2.7209762532981527e-05,
      "loss": 1.0703,
      "step": 6205
    },
    {
      "epoch": 8.19,
      "grad_norm": 85.0,
      "learning_rate": 2.7189973614775725e-05,
      "loss": 1.1953,
      "step": 6206
    },
    {
      "epoch": 8.19,
      "grad_norm": 210.0,
      "learning_rate": 2.717018469656992e-05,
      "loss": 6.3438,
      "step": 6207
    },
    {
      "epoch": 8.19,
      "grad_norm": 42.25,
      "learning_rate": 2.715039577836411e-05,
      "loss": 0.75,
      "step": 6208
    },
    {
      "epoch": 8.19,
      "grad_norm": 178.0,
      "learning_rate": 2.7130606860158306e-05,
      "loss": 2.9062,
      "step": 6209
    },
    {
      "epoch": 8.19,
      "grad_norm": 15.9375,
      "learning_rate": 2.7110817941952504e-05,
      "loss": 0.0742,
      "step": 6210
    },
    {
      "epoch": 8.19,
      "grad_norm": 4.375,
      "learning_rate": 2.70910290237467e-05,
      "loss": 0.0505,
      "step": 6211
    },
    {
      "epoch": 8.2,
      "grad_norm": 11.4375,
      "learning_rate": 2.7071240105540893e-05,
      "loss": 0.0645,
      "step": 6212
    },
    {
      "epoch": 8.2,
      "grad_norm": 30.0,
      "learning_rate": 2.705145118733509e-05,
      "loss": 0.3164,
      "step": 6213
    },
    {
      "epoch": 8.2,
      "grad_norm": 1.8828125,
      "learning_rate": 2.7031662269129286e-05,
      "loss": 0.0179,
      "step": 6214
    },
    {
      "epoch": 8.2,
      "grad_norm": 1.9453125,
      "learning_rate": 2.701187335092348e-05,
      "loss": 0.0175,
      "step": 6215
    },
    {
      "epoch": 8.2,
      "grad_norm": 98.5,
      "learning_rate": 2.6992084432717676e-05,
      "loss": 0.5078,
      "step": 6216
    },
    {
      "epoch": 8.2,
      "grad_norm": 55.25,
      "learning_rate": 2.697229551451187e-05,
      "loss": 0.6445,
      "step": 6217
    },
    {
      "epoch": 8.2,
      "grad_norm": 15.875,
      "learning_rate": 2.6952506596306065e-05,
      "loss": 0.126,
      "step": 6218
    },
    {
      "epoch": 8.2,
      "grad_norm": 28.75,
      "learning_rate": 2.6932717678100263e-05,
      "loss": 1.1016,
      "step": 6219
    },
    {
      "epoch": 8.21,
      "grad_norm": 34.25,
      "learning_rate": 2.6912928759894458e-05,
      "loss": 0.1338,
      "step": 6220
    },
    {
      "epoch": 8.21,
      "grad_norm": 141.0,
      "learning_rate": 2.6893139841688652e-05,
      "loss": 3.3906,
      "step": 6221
    },
    {
      "epoch": 8.21,
      "grad_norm": 22.625,
      "learning_rate": 2.687335092348285e-05,
      "loss": 0.6055,
      "step": 6222
    },
    {
      "epoch": 8.21,
      "grad_norm": 10.9375,
      "learning_rate": 2.685356200527704e-05,
      "loss": 0.0762,
      "step": 6223
    },
    {
      "epoch": 8.21,
      "grad_norm": 54.0,
      "learning_rate": 2.6833773087071236e-05,
      "loss": 0.334,
      "step": 6224
    },
    {
      "epoch": 8.21,
      "grad_norm": 186.0,
      "learning_rate": 2.681398416886543e-05,
      "loss": 5.75,
      "step": 6225
    },
    {
      "epoch": 8.21,
      "grad_norm": 132.0,
      "learning_rate": 2.679419525065963e-05,
      "loss": 3.625,
      "step": 6226
    },
    {
      "epoch": 8.22,
      "grad_norm": 178.0,
      "learning_rate": 2.6774406332453824e-05,
      "loss": 6.0312,
      "step": 6227
    },
    {
      "epoch": 8.22,
      "grad_norm": 300.0,
      "learning_rate": 2.675461741424802e-05,
      "loss": 3.2969,
      "step": 6228
    },
    {
      "epoch": 8.22,
      "grad_norm": 2.609375,
      "learning_rate": 2.6734828496042216e-05,
      "loss": 0.0159,
      "step": 6229
    },
    {
      "epoch": 8.22,
      "grad_norm": 190.0,
      "learning_rate": 2.671503957783641e-05,
      "loss": 1.6875,
      "step": 6230
    },
    {
      "epoch": 8.22,
      "grad_norm": 177.0,
      "learning_rate": 2.6695250659630602e-05,
      "loss": 3.6094,
      "step": 6231
    },
    {
      "epoch": 8.22,
      "grad_norm": 28.75,
      "learning_rate": 2.6675461741424797e-05,
      "loss": 0.8789,
      "step": 6232
    },
    {
      "epoch": 8.22,
      "grad_norm": 31.375,
      "learning_rate": 2.6655672823218995e-05,
      "loss": 0.5039,
      "step": 6233
    },
    {
      "epoch": 8.22,
      "grad_norm": 9.6875,
      "learning_rate": 2.663588390501319e-05,
      "loss": 0.0542,
      "step": 6234
    },
    {
      "epoch": 8.23,
      "grad_norm": 15.6875,
      "learning_rate": 2.6616094986807384e-05,
      "loss": 0.0747,
      "step": 6235
    },
    {
      "epoch": 8.23,
      "grad_norm": 135.0,
      "learning_rate": 2.6596306068601582e-05,
      "loss": 2.7188,
      "step": 6236
    },
    {
      "epoch": 8.23,
      "grad_norm": 564.0,
      "learning_rate": 2.6576517150395777e-05,
      "loss": 10.25,
      "step": 6237
    },
    {
      "epoch": 8.23,
      "grad_norm": 1.390625,
      "learning_rate": 2.655672823218997e-05,
      "loss": 0.0095,
      "step": 6238
    },
    {
      "epoch": 8.23,
      "grad_norm": 45.5,
      "learning_rate": 2.6536939313984166e-05,
      "loss": 0.4492,
      "step": 6239
    },
    {
      "epoch": 8.23,
      "grad_norm": 41.0,
      "learning_rate": 2.651715039577836e-05,
      "loss": 0.9062,
      "step": 6240
    },
    {
      "epoch": 8.23,
      "grad_norm": 32.5,
      "learning_rate": 2.6497361477572556e-05,
      "loss": 0.7773,
      "step": 6241
    },
    {
      "epoch": 8.23,
      "grad_norm": 298.0,
      "learning_rate": 2.6477572559366754e-05,
      "loss": 6.0625,
      "step": 6242
    },
    {
      "epoch": 8.24,
      "grad_norm": 3.109375,
      "learning_rate": 2.645778364116095e-05,
      "loss": 0.0278,
      "step": 6243
    },
    {
      "epoch": 8.24,
      "grad_norm": 33.25,
      "learning_rate": 2.6437994722955143e-05,
      "loss": 0.209,
      "step": 6244
    },
    {
      "epoch": 8.24,
      "grad_norm": 110.0,
      "learning_rate": 2.641820580474934e-05,
      "loss": 2.1406,
      "step": 6245
    },
    {
      "epoch": 8.24,
      "grad_norm": 189.0,
      "learning_rate": 2.6398416886543533e-05,
      "loss": 2.3594,
      "step": 6246
    },
    {
      "epoch": 8.24,
      "grad_norm": 79.5,
      "learning_rate": 2.6378627968337727e-05,
      "loss": 0.6094,
      "step": 6247
    },
    {
      "epoch": 8.24,
      "grad_norm": 124.0,
      "learning_rate": 2.6358839050131922e-05,
      "loss": 1.875,
      "step": 6248
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.0625,
      "learning_rate": 2.633905013192612e-05,
      "loss": 0.0099,
      "step": 6249
    },
    {
      "epoch": 8.25,
      "grad_norm": 155.0,
      "learning_rate": 2.6319261213720315e-05,
      "loss": 5.5,
      "step": 6250
    },
    {
      "epoch": 8.25,
      "grad_norm": 4.84375,
      "learning_rate": 2.629947229551451e-05,
      "loss": 0.0596,
      "step": 6251
    },
    {
      "epoch": 8.25,
      "grad_norm": 37.5,
      "learning_rate": 2.6279683377308707e-05,
      "loss": 0.1729,
      "step": 6252
    },
    {
      "epoch": 8.25,
      "grad_norm": 2.0625,
      "learning_rate": 2.62598944591029e-05,
      "loss": 0.0229,
      "step": 6253
    },
    {
      "epoch": 8.25,
      "grad_norm": 39.0,
      "learning_rate": 2.6240105540897093e-05,
      "loss": 0.4824,
      "step": 6254
    },
    {
      "epoch": 8.25,
      "grad_norm": 241.0,
      "learning_rate": 2.622031662269129e-05,
      "loss": 3.0938,
      "step": 6255
    },
    {
      "epoch": 8.25,
      "grad_norm": 31.0,
      "learning_rate": 2.6200527704485486e-05,
      "loss": 0.3594,
      "step": 6256
    },
    {
      "epoch": 8.25,
      "grad_norm": 25.875,
      "learning_rate": 2.618073878627968e-05,
      "loss": 0.0962,
      "step": 6257
    },
    {
      "epoch": 8.26,
      "grad_norm": 83.0,
      "learning_rate": 2.616094986807388e-05,
      "loss": 0.4395,
      "step": 6258
    },
    {
      "epoch": 8.26,
      "grad_norm": 3.21875,
      "learning_rate": 2.6141160949868073e-05,
      "loss": 0.0225,
      "step": 6259
    },
    {
      "epoch": 8.26,
      "grad_norm": 134.0,
      "learning_rate": 2.6121372031662268e-05,
      "loss": 3.0781,
      "step": 6260
    },
    {
      "epoch": 8.26,
      "grad_norm": 162.0,
      "learning_rate": 2.610158311345646e-05,
      "loss": 4.6562,
      "step": 6261
    },
    {
      "epoch": 8.26,
      "grad_norm": 6.34375,
      "learning_rate": 2.6081794195250657e-05,
      "loss": 0.042,
      "step": 6262
    },
    {
      "epoch": 8.26,
      "grad_norm": 218.0,
      "learning_rate": 2.6062005277044852e-05,
      "loss": 4.5312,
      "step": 6263
    },
    {
      "epoch": 8.26,
      "grad_norm": 16.5,
      "learning_rate": 2.6042216358839047e-05,
      "loss": 0.0889,
      "step": 6264
    },
    {
      "epoch": 8.27,
      "grad_norm": 25.625,
      "learning_rate": 2.6022427440633245e-05,
      "loss": 0.1719,
      "step": 6265
    },
    {
      "epoch": 8.27,
      "grad_norm": 346.0,
      "learning_rate": 2.600263852242744e-05,
      "loss": 1.5781,
      "step": 6266
    },
    {
      "epoch": 8.27,
      "grad_norm": 189.0,
      "learning_rate": 2.5982849604221634e-05,
      "loss": 3.4062,
      "step": 6267
    },
    {
      "epoch": 8.27,
      "grad_norm": 1.2109375,
      "learning_rate": 2.5963060686015826e-05,
      "loss": 0.0084,
      "step": 6268
    },
    {
      "epoch": 8.27,
      "grad_norm": 31.75,
      "learning_rate": 2.5943271767810024e-05,
      "loss": 1.1875,
      "step": 6269
    },
    {
      "epoch": 8.27,
      "grad_norm": 103.5,
      "learning_rate": 2.5923482849604218e-05,
      "loss": 2.4844,
      "step": 6270
    },
    {
      "epoch": 8.27,
      "grad_norm": 15.3125,
      "learning_rate": 2.5903693931398413e-05,
      "loss": 0.1846,
      "step": 6271
    },
    {
      "epoch": 8.27,
      "grad_norm": 7.46875,
      "learning_rate": 2.588390501319261e-05,
      "loss": 0.0596,
      "step": 6272
    },
    {
      "epoch": 8.28,
      "grad_norm": 107.5,
      "learning_rate": 2.5864116094986806e-05,
      "loss": 1.8828,
      "step": 6273
    },
    {
      "epoch": 8.28,
      "grad_norm": 163.0,
      "learning_rate": 2.5844327176781e-05,
      "loss": 3.3438,
      "step": 6274
    },
    {
      "epoch": 8.28,
      "grad_norm": 112.0,
      "learning_rate": 2.58245382585752e-05,
      "loss": 3.8438,
      "step": 6275
    },
    {
      "epoch": 8.28,
      "grad_norm": 41.0,
      "learning_rate": 2.580474934036939e-05,
      "loss": 0.3027,
      "step": 6276
    },
    {
      "epoch": 8.28,
      "grad_norm": 56.5,
      "learning_rate": 2.5784960422163584e-05,
      "loss": 0.793,
      "step": 6277
    },
    {
      "epoch": 8.28,
      "grad_norm": 8.625,
      "learning_rate": 2.5765171503957782e-05,
      "loss": 0.0967,
      "step": 6278
    },
    {
      "epoch": 8.28,
      "grad_norm": 150.0,
      "learning_rate": 2.5745382585751977e-05,
      "loss": 4.5312,
      "step": 6279
    },
    {
      "epoch": 8.28,
      "grad_norm": 44.75,
      "learning_rate": 2.5725593667546172e-05,
      "loss": 0.2314,
      "step": 6280
    },
    {
      "epoch": 8.29,
      "grad_norm": 21.75,
      "learning_rate": 2.570580474934037e-05,
      "loss": 0.1348,
      "step": 6281
    },
    {
      "epoch": 8.29,
      "grad_norm": 3.578125,
      "learning_rate": 2.5686015831134564e-05,
      "loss": 0.0298,
      "step": 6282
    },
    {
      "epoch": 8.29,
      "grad_norm": 151.0,
      "learning_rate": 2.5666226912928756e-05,
      "loss": 2.4219,
      "step": 6283
    },
    {
      "epoch": 8.29,
      "grad_norm": 109.5,
      "learning_rate": 2.564643799472295e-05,
      "loss": 1.7969,
      "step": 6284
    },
    {
      "epoch": 8.29,
      "grad_norm": 33.25,
      "learning_rate": 2.562664907651715e-05,
      "loss": 0.5117,
      "step": 6285
    },
    {
      "epoch": 8.29,
      "grad_norm": 157.0,
      "learning_rate": 2.5606860158311343e-05,
      "loss": 3.8281,
      "step": 6286
    },
    {
      "epoch": 8.29,
      "grad_norm": 135.0,
      "learning_rate": 2.5587071240105538e-05,
      "loss": 1.1016,
      "step": 6287
    },
    {
      "epoch": 8.3,
      "grad_norm": 272.0,
      "learning_rate": 2.5567282321899736e-05,
      "loss": 2.9531,
      "step": 6288
    },
    {
      "epoch": 8.3,
      "grad_norm": 380.0,
      "learning_rate": 2.554749340369393e-05,
      "loss": 1.75,
      "step": 6289
    },
    {
      "epoch": 8.3,
      "grad_norm": 23.0,
      "learning_rate": 2.5527704485488125e-05,
      "loss": 0.2207,
      "step": 6290
    },
    {
      "epoch": 8.3,
      "grad_norm": 30.75,
      "learning_rate": 2.5507915567282317e-05,
      "loss": 1.0938,
      "step": 6291
    },
    {
      "epoch": 8.3,
      "grad_norm": 21.5,
      "learning_rate": 2.5488126649076515e-05,
      "loss": 0.6016,
      "step": 6292
    },
    {
      "epoch": 8.3,
      "grad_norm": 103.5,
      "learning_rate": 2.546833773087071e-05,
      "loss": 1.7031,
      "step": 6293
    },
    {
      "epoch": 8.3,
      "grad_norm": 115.0,
      "learning_rate": 2.5448548812664904e-05,
      "loss": 2.9688,
      "step": 6294
    },
    {
      "epoch": 8.3,
      "grad_norm": 152.0,
      "learning_rate": 2.5428759894459102e-05,
      "loss": 2.5,
      "step": 6295
    },
    {
      "epoch": 8.31,
      "grad_norm": 16.0,
      "learning_rate": 2.5408970976253297e-05,
      "loss": 0.1543,
      "step": 6296
    },
    {
      "epoch": 8.31,
      "grad_norm": 162.0,
      "learning_rate": 2.538918205804749e-05,
      "loss": 1.6172,
      "step": 6297
    },
    {
      "epoch": 8.31,
      "grad_norm": 26.0,
      "learning_rate": 2.5369393139841686e-05,
      "loss": 0.4238,
      "step": 6298
    },
    {
      "epoch": 8.31,
      "grad_norm": 135.0,
      "learning_rate": 2.534960422163588e-05,
      "loss": 2.8906,
      "step": 6299
    },
    {
      "epoch": 8.31,
      "grad_norm": 117.0,
      "learning_rate": 2.5329815303430075e-05,
      "loss": 2.5781,
      "step": 6300
    },
    {
      "epoch": 8.31,
      "grad_norm": 217.0,
      "learning_rate": 2.5310026385224273e-05,
      "loss": 2.6719,
      "step": 6301
    },
    {
      "epoch": 8.31,
      "grad_norm": 86.5,
      "learning_rate": 2.5290237467018468e-05,
      "loss": 0.2812,
      "step": 6302
    },
    {
      "epoch": 8.32,
      "grad_norm": 0.640625,
      "learning_rate": 2.5270448548812663e-05,
      "loss": 0.0062,
      "step": 6303
    },
    {
      "epoch": 8.32,
      "grad_norm": 30.375,
      "learning_rate": 2.525065963060686e-05,
      "loss": 1.0312,
      "step": 6304
    },
    {
      "epoch": 8.32,
      "grad_norm": 16.0,
      "learning_rate": 2.5230870712401055e-05,
      "loss": 0.2275,
      "step": 6305
    },
    {
      "epoch": 8.32,
      "grad_norm": 272.0,
      "learning_rate": 2.5211081794195247e-05,
      "loss": 3.6562,
      "step": 6306
    },
    {
      "epoch": 8.32,
      "grad_norm": 50.75,
      "learning_rate": 2.519129287598944e-05,
      "loss": 0.7148,
      "step": 6307
    },
    {
      "epoch": 8.32,
      "grad_norm": 34.25,
      "learning_rate": 2.517150395778364e-05,
      "loss": 0.6641,
      "step": 6308
    },
    {
      "epoch": 8.32,
      "grad_norm": 25.125,
      "learning_rate": 2.5151715039577834e-05,
      "loss": 0.2617,
      "step": 6309
    },
    {
      "epoch": 8.32,
      "grad_norm": 53.25,
      "learning_rate": 2.513192612137203e-05,
      "loss": 0.6445,
      "step": 6310
    },
    {
      "epoch": 8.33,
      "grad_norm": 133.0,
      "learning_rate": 2.5112137203166227e-05,
      "loss": 2.5469,
      "step": 6311
    },
    {
      "epoch": 8.33,
      "grad_norm": 103.5,
      "learning_rate": 2.509234828496042e-05,
      "loss": 2.0469,
      "step": 6312
    },
    {
      "epoch": 8.33,
      "grad_norm": 179.0,
      "learning_rate": 2.5072559366754613e-05,
      "loss": 4.2812,
      "step": 6313
    },
    {
      "epoch": 8.33,
      "grad_norm": 1.984375,
      "learning_rate": 2.5052770448548808e-05,
      "loss": 0.0131,
      "step": 6314
    },
    {
      "epoch": 8.33,
      "grad_norm": 7.4375,
      "learning_rate": 2.5032981530343006e-05,
      "loss": 0.0664,
      "step": 6315
    },
    {
      "epoch": 8.33,
      "grad_norm": 160.0,
      "learning_rate": 2.50131926121372e-05,
      "loss": 2.2344,
      "step": 6316
    },
    {
      "epoch": 8.33,
      "grad_norm": 5.75,
      "learning_rate": 2.4993403693931395e-05,
      "loss": 0.0334,
      "step": 6317
    },
    {
      "epoch": 8.34,
      "grad_norm": 19.375,
      "learning_rate": 2.4973614775725593e-05,
      "loss": 0.1621,
      "step": 6318
    },
    {
      "epoch": 8.34,
      "grad_norm": 26.75,
      "learning_rate": 2.4953825857519788e-05,
      "loss": 0.3809,
      "step": 6319
    },
    {
      "epoch": 8.34,
      "grad_norm": 27.375,
      "learning_rate": 2.4934036939313982e-05,
      "loss": 0.1543,
      "step": 6320
    },
    {
      "epoch": 8.34,
      "grad_norm": 32.75,
      "learning_rate": 2.4914248021108177e-05,
      "loss": 0.1973,
      "step": 6321
    },
    {
      "epoch": 8.34,
      "grad_norm": 22.75,
      "learning_rate": 2.489445910290237e-05,
      "loss": 0.1289,
      "step": 6322
    },
    {
      "epoch": 8.34,
      "grad_norm": 32.0,
      "learning_rate": 2.4874670184696566e-05,
      "loss": 0.1191,
      "step": 6323
    },
    {
      "epoch": 8.34,
      "grad_norm": 2.78125,
      "learning_rate": 2.4854881266490764e-05,
      "loss": 0.0244,
      "step": 6324
    },
    {
      "epoch": 8.34,
      "grad_norm": 11.8125,
      "learning_rate": 2.483509234828496e-05,
      "loss": 0.0771,
      "step": 6325
    },
    {
      "epoch": 8.35,
      "grad_norm": 3.953125,
      "learning_rate": 2.4815303430079154e-05,
      "loss": 0.028,
      "step": 6326
    },
    {
      "epoch": 8.35,
      "grad_norm": 16.75,
      "learning_rate": 2.4795514511873352e-05,
      "loss": 0.1079,
      "step": 6327
    },
    {
      "epoch": 8.35,
      "grad_norm": 103.0,
      "learning_rate": 2.4775725593667543e-05,
      "loss": 1.4766,
      "step": 6328
    },
    {
      "epoch": 8.35,
      "grad_norm": 145.0,
      "learning_rate": 2.4755936675461738e-05,
      "loss": 2.9531,
      "step": 6329
    },
    {
      "epoch": 8.35,
      "grad_norm": 56.5,
      "learning_rate": 2.4736147757255932e-05,
      "loss": 0.7539,
      "step": 6330
    },
    {
      "epoch": 8.35,
      "grad_norm": 1.1875,
      "learning_rate": 2.471635883905013e-05,
      "loss": 0.0121,
      "step": 6331
    },
    {
      "epoch": 8.35,
      "grad_norm": 3.25,
      "learning_rate": 2.4696569920844325e-05,
      "loss": 0.026,
      "step": 6332
    },
    {
      "epoch": 8.35,
      "grad_norm": 33.25,
      "learning_rate": 2.467678100263852e-05,
      "loss": 0.4961,
      "step": 6333
    },
    {
      "epoch": 8.36,
      "grad_norm": 160.0,
      "learning_rate": 2.4656992084432718e-05,
      "loss": 4.5938,
      "step": 6334
    },
    {
      "epoch": 8.36,
      "grad_norm": 139.0,
      "learning_rate": 2.4637203166226913e-05,
      "loss": 3.4219,
      "step": 6335
    },
    {
      "epoch": 8.36,
      "grad_norm": 232.0,
      "learning_rate": 2.4617414248021104e-05,
      "loss": 4.7812,
      "step": 6336
    },
    {
      "epoch": 8.36,
      "grad_norm": 10.0625,
      "learning_rate": 2.45976253298153e-05,
      "loss": 0.0415,
      "step": 6337
    },
    {
      "epoch": 8.36,
      "grad_norm": 20.0,
      "learning_rate": 2.4577836411609497e-05,
      "loss": 0.1416,
      "step": 6338
    },
    {
      "epoch": 8.36,
      "grad_norm": 28.5,
      "learning_rate": 2.455804749340369e-05,
      "loss": 0.7422,
      "step": 6339
    },
    {
      "epoch": 8.36,
      "grad_norm": 568.0,
      "learning_rate": 2.4538258575197886e-05,
      "loss": 4.5625,
      "step": 6340
    },
    {
      "epoch": 8.37,
      "grad_norm": 128.0,
      "learning_rate": 2.4518469656992084e-05,
      "loss": 2.875,
      "step": 6341
    },
    {
      "epoch": 8.37,
      "grad_norm": 174.0,
      "learning_rate": 2.449868073878628e-05,
      "loss": 1.6953,
      "step": 6342
    },
    {
      "epoch": 8.37,
      "grad_norm": 2.234375,
      "learning_rate": 2.447889182058047e-05,
      "loss": 0.0193,
      "step": 6343
    },
    {
      "epoch": 8.37,
      "grad_norm": 33.75,
      "learning_rate": 2.4459102902374668e-05,
      "loss": 0.7656,
      "step": 6344
    },
    {
      "epoch": 8.37,
      "grad_norm": 103.5,
      "learning_rate": 2.4439313984168863e-05,
      "loss": 2.7344,
      "step": 6345
    },
    {
      "epoch": 8.37,
      "grad_norm": 3.15625,
      "learning_rate": 2.4419525065963057e-05,
      "loss": 0.0291,
      "step": 6346
    },
    {
      "epoch": 8.37,
      "grad_norm": 120.0,
      "learning_rate": 2.4399736147757255e-05,
      "loss": 2.4219,
      "step": 6347
    },
    {
      "epoch": 8.37,
      "grad_norm": 7.46875,
      "learning_rate": 2.437994722955145e-05,
      "loss": 0.0388,
      "step": 6348
    },
    {
      "epoch": 8.38,
      "grad_norm": 3.5625,
      "learning_rate": 2.4360158311345645e-05,
      "loss": 0.0306,
      "step": 6349
    },
    {
      "epoch": 8.38,
      "grad_norm": 27.0,
      "learning_rate": 2.4340369393139843e-05,
      "loss": 0.625,
      "step": 6350
    },
    {
      "epoch": 8.38,
      "grad_norm": 45.0,
      "learning_rate": 2.4320580474934034e-05,
      "loss": 0.1768,
      "step": 6351
    },
    {
      "epoch": 8.38,
      "grad_norm": 12.25,
      "learning_rate": 2.430079155672823e-05,
      "loss": 0.0654,
      "step": 6352
    },
    {
      "epoch": 8.38,
      "grad_norm": 111.0,
      "learning_rate": 2.4281002638522423e-05,
      "loss": 1.6797,
      "step": 6353
    },
    {
      "epoch": 8.38,
      "grad_norm": 65.0,
      "learning_rate": 2.426121372031662e-05,
      "loss": 0.5273,
      "step": 6354
    },
    {
      "epoch": 8.38,
      "grad_norm": 165.0,
      "learning_rate": 2.4241424802110816e-05,
      "loss": 3.8281,
      "step": 6355
    },
    {
      "epoch": 8.39,
      "grad_norm": 124.5,
      "learning_rate": 2.422163588390501e-05,
      "loss": 3.5,
      "step": 6356
    },
    {
      "epoch": 8.39,
      "grad_norm": 174.0,
      "learning_rate": 2.420184696569921e-05,
      "loss": 2.4062,
      "step": 6357
    },
    {
      "epoch": 8.39,
      "grad_norm": 109.0,
      "learning_rate": 2.4182058047493404e-05,
      "loss": 0.7266,
      "step": 6358
    },
    {
      "epoch": 8.39,
      "grad_norm": 109.5,
      "learning_rate": 2.4162269129287595e-05,
      "loss": 1.3516,
      "step": 6359
    },
    {
      "epoch": 8.39,
      "grad_norm": 48.5,
      "learning_rate": 2.414248021108179e-05,
      "loss": 0.5078,
      "step": 6360
    },
    {
      "epoch": 8.39,
      "grad_norm": 6.15625,
      "learning_rate": 2.4122691292875988e-05,
      "loss": 0.0559,
      "step": 6361
    },
    {
      "epoch": 8.39,
      "grad_norm": 110.0,
      "learning_rate": 2.4102902374670182e-05,
      "loss": 3.3594,
      "step": 6362
    },
    {
      "epoch": 8.39,
      "grad_norm": 26.625,
      "learning_rate": 2.4083113456464377e-05,
      "loss": 0.4941,
      "step": 6363
    },
    {
      "epoch": 8.4,
      "grad_norm": 82.5,
      "learning_rate": 2.4063324538258575e-05,
      "loss": 0.5234,
      "step": 6364
    },
    {
      "epoch": 8.4,
      "grad_norm": 151.0,
      "learning_rate": 2.404353562005277e-05,
      "loss": 2.8906,
      "step": 6365
    },
    {
      "epoch": 8.4,
      "grad_norm": 5.625,
      "learning_rate": 2.402374670184696e-05,
      "loss": 0.0173,
      "step": 6366
    },
    {
      "epoch": 8.4,
      "grad_norm": 65.5,
      "learning_rate": 2.400395778364116e-05,
      "loss": 0.8867,
      "step": 6367
    },
    {
      "epoch": 8.4,
      "grad_norm": 34.0,
      "learning_rate": 2.3984168865435354e-05,
      "loss": 0.8594,
      "step": 6368
    },
    {
      "epoch": 8.4,
      "grad_norm": 33.25,
      "learning_rate": 2.3964379947229548e-05,
      "loss": 0.2383,
      "step": 6369
    },
    {
      "epoch": 8.4,
      "grad_norm": 137.0,
      "learning_rate": 2.3944591029023746e-05,
      "loss": 0.8828,
      "step": 6370
    },
    {
      "epoch": 8.41,
      "grad_norm": 14.3125,
      "learning_rate": 2.392480211081794e-05,
      "loss": 0.0903,
      "step": 6371
    },
    {
      "epoch": 8.41,
      "grad_norm": 18.25,
      "learning_rate": 2.3905013192612136e-05,
      "loss": 0.1611,
      "step": 6372
    },
    {
      "epoch": 8.41,
      "grad_norm": 59.75,
      "learning_rate": 2.3885224274406334e-05,
      "loss": 0.4492,
      "step": 6373
    },
    {
      "epoch": 8.41,
      "grad_norm": 3.640625,
      "learning_rate": 2.3865435356200525e-05,
      "loss": 0.0269,
      "step": 6374
    },
    {
      "epoch": 8.41,
      "grad_norm": 35.25,
      "learning_rate": 2.384564643799472e-05,
      "loss": 0.4902,
      "step": 6375
    },
    {
      "epoch": 8.41,
      "grad_norm": 25.625,
      "learning_rate": 2.3825857519788914e-05,
      "loss": 0.3613,
      "step": 6376
    },
    {
      "epoch": 8.41,
      "grad_norm": 42.5,
      "learning_rate": 2.3806068601583112e-05,
      "loss": 0.3281,
      "step": 6377
    },
    {
      "epoch": 8.41,
      "grad_norm": 27.5,
      "learning_rate": 2.3786279683377307e-05,
      "loss": 0.6758,
      "step": 6378
    },
    {
      "epoch": 8.42,
      "grad_norm": 21.125,
      "learning_rate": 2.3766490765171502e-05,
      "loss": 0.7031,
      "step": 6379
    },
    {
      "epoch": 8.42,
      "grad_norm": 27.75,
      "learning_rate": 2.37467018469657e-05,
      "loss": 0.8867,
      "step": 6380
    },
    {
      "epoch": 8.42,
      "grad_norm": 57.75,
      "learning_rate": 2.372691292875989e-05,
      "loss": 0.7773,
      "step": 6381
    },
    {
      "epoch": 8.42,
      "grad_norm": 34.0,
      "learning_rate": 2.3707124010554086e-05,
      "loss": 0.2891,
      "step": 6382
    },
    {
      "epoch": 8.42,
      "grad_norm": 222.0,
      "learning_rate": 2.368733509234828e-05,
      "loss": 4.8125,
      "step": 6383
    },
    {
      "epoch": 8.42,
      "grad_norm": 13.8125,
      "learning_rate": 2.366754617414248e-05,
      "loss": 0.2041,
      "step": 6384
    },
    {
      "epoch": 8.42,
      "grad_norm": 179.0,
      "learning_rate": 2.3647757255936673e-05,
      "loss": 2.5,
      "step": 6385
    },
    {
      "epoch": 8.42,
      "grad_norm": 110.5,
      "learning_rate": 2.3627968337730868e-05,
      "loss": 2.125,
      "step": 6386
    },
    {
      "epoch": 8.43,
      "grad_norm": 30.375,
      "learning_rate": 2.3608179419525066e-05,
      "loss": 0.3867,
      "step": 6387
    },
    {
      "epoch": 8.43,
      "grad_norm": 124.0,
      "learning_rate": 2.358839050131926e-05,
      "loss": 2.2812,
      "step": 6388
    },
    {
      "epoch": 8.43,
      "grad_norm": 47.75,
      "learning_rate": 2.3568601583113452e-05,
      "loss": 0.4727,
      "step": 6389
    },
    {
      "epoch": 8.43,
      "grad_norm": 37.75,
      "learning_rate": 2.354881266490765e-05,
      "loss": 0.2852,
      "step": 6390
    },
    {
      "epoch": 8.43,
      "grad_norm": 9.0625,
      "learning_rate": 2.3529023746701845e-05,
      "loss": 0.0767,
      "step": 6391
    },
    {
      "epoch": 8.43,
      "grad_norm": 45.5,
      "learning_rate": 2.350923482849604e-05,
      "loss": 0.2852,
      "step": 6392
    },
    {
      "epoch": 8.43,
      "grad_norm": 1.453125,
      "learning_rate": 2.3489445910290237e-05,
      "loss": 0.009,
      "step": 6393
    },
    {
      "epoch": 8.44,
      "grad_norm": 169.0,
      "learning_rate": 2.3469656992084432e-05,
      "loss": 2.5938,
      "step": 6394
    },
    {
      "epoch": 8.44,
      "grad_norm": 181.0,
      "learning_rate": 2.3449868073878627e-05,
      "loss": 2.7656,
      "step": 6395
    },
    {
      "epoch": 8.44,
      "grad_norm": 6.375,
      "learning_rate": 2.3430079155672818e-05,
      "loss": 0.0488,
      "step": 6396
    },
    {
      "epoch": 8.44,
      "grad_norm": 44.0,
      "learning_rate": 2.3410290237467016e-05,
      "loss": 0.6797,
      "step": 6397
    },
    {
      "epoch": 8.44,
      "grad_norm": 109.5,
      "learning_rate": 2.339050131926121e-05,
      "loss": 2.5,
      "step": 6398
    },
    {
      "epoch": 8.44,
      "grad_norm": 11.5,
      "learning_rate": 2.3370712401055405e-05,
      "loss": 0.1621,
      "step": 6399
    },
    {
      "epoch": 8.44,
      "grad_norm": 24.25,
      "learning_rate": 2.3350923482849603e-05,
      "loss": 0.2617,
      "step": 6400
    },
    {
      "epoch": 8.44,
      "grad_norm": 6.40625,
      "learning_rate": 2.3331134564643798e-05,
      "loss": 0.0684,
      "step": 6401
    },
    {
      "epoch": 8.45,
      "grad_norm": 130.0,
      "learning_rate": 2.3311345646437993e-05,
      "loss": 3.3594,
      "step": 6402
    },
    {
      "epoch": 8.45,
      "grad_norm": 46.5,
      "learning_rate": 2.329155672823219e-05,
      "loss": 0.7969,
      "step": 6403
    },
    {
      "epoch": 8.45,
      "grad_norm": 36.75,
      "learning_rate": 2.3271767810026382e-05,
      "loss": 0.4453,
      "step": 6404
    },
    {
      "epoch": 8.45,
      "grad_norm": 70.5,
      "learning_rate": 2.3251978891820577e-05,
      "loss": 0.5547,
      "step": 6405
    },
    {
      "epoch": 8.45,
      "grad_norm": 21.375,
      "learning_rate": 2.3232189973614775e-05,
      "loss": 0.8516,
      "step": 6406
    },
    {
      "epoch": 8.45,
      "grad_norm": 6.25,
      "learning_rate": 2.321240105540897e-05,
      "loss": 0.0703,
      "step": 6407
    },
    {
      "epoch": 8.45,
      "grad_norm": 2.828125,
      "learning_rate": 2.3192612137203164e-05,
      "loss": 0.0254,
      "step": 6408
    },
    {
      "epoch": 8.46,
      "grad_norm": 87.5,
      "learning_rate": 2.3172823218997362e-05,
      "loss": 0.7148,
      "step": 6409
    },
    {
      "epoch": 8.46,
      "grad_norm": 204.0,
      "learning_rate": 2.3153034300791557e-05,
      "loss": 3.75,
      "step": 6410
    },
    {
      "epoch": 8.46,
      "grad_norm": 129.0,
      "learning_rate": 2.3133245382585748e-05,
      "loss": 3.0312,
      "step": 6411
    },
    {
      "epoch": 8.46,
      "grad_norm": 29.875,
      "learning_rate": 2.3113456464379943e-05,
      "loss": 0.7383,
      "step": 6412
    },
    {
      "epoch": 8.46,
      "grad_norm": 33.25,
      "learning_rate": 2.309366754617414e-05,
      "loss": 0.3379,
      "step": 6413
    },
    {
      "epoch": 8.46,
      "grad_norm": 197.0,
      "learning_rate": 2.3073878627968336e-05,
      "loss": 1.2031,
      "step": 6414
    },
    {
      "epoch": 8.46,
      "grad_norm": 23.375,
      "learning_rate": 2.305408970976253e-05,
      "loss": 0.625,
      "step": 6415
    },
    {
      "epoch": 8.46,
      "grad_norm": 29.125,
      "learning_rate": 2.303430079155673e-05,
      "loss": 0.4473,
      "step": 6416
    },
    {
      "epoch": 8.47,
      "grad_norm": 122.5,
      "learning_rate": 2.3014511873350923e-05,
      "loss": 2.3594,
      "step": 6417
    },
    {
      "epoch": 8.47,
      "grad_norm": 31.25,
      "learning_rate": 2.2994722955145118e-05,
      "loss": 0.498,
      "step": 6418
    },
    {
      "epoch": 8.47,
      "grad_norm": 6.875,
      "learning_rate": 2.297493403693931e-05,
      "loss": 0.0422,
      "step": 6419
    },
    {
      "epoch": 8.47,
      "grad_norm": 119.5,
      "learning_rate": 2.2955145118733507e-05,
      "loss": 3.75,
      "step": 6420
    },
    {
      "epoch": 8.47,
      "grad_norm": 19.75,
      "learning_rate": 2.2935356200527702e-05,
      "loss": 0.1895,
      "step": 6421
    },
    {
      "epoch": 8.47,
      "grad_norm": 184.0,
      "learning_rate": 2.2915567282321896e-05,
      "loss": 2.4062,
      "step": 6422
    },
    {
      "epoch": 8.47,
      "grad_norm": 127.0,
      "learning_rate": 2.2895778364116094e-05,
      "loss": 1.3203,
      "step": 6423
    },
    {
      "epoch": 8.47,
      "grad_norm": 27.125,
      "learning_rate": 2.287598944591029e-05,
      "loss": 0.1963,
      "step": 6424
    },
    {
      "epoch": 8.48,
      "grad_norm": 1.9140625,
      "learning_rate": 2.2856200527704484e-05,
      "loss": 0.021,
      "step": 6425
    },
    {
      "epoch": 8.48,
      "grad_norm": 268.0,
      "learning_rate": 2.283641160949868e-05,
      "loss": 5.4375,
      "step": 6426
    },
    {
      "epoch": 8.48,
      "grad_norm": 36.0,
      "learning_rate": 2.2816622691292873e-05,
      "loss": 0.5625,
      "step": 6427
    },
    {
      "epoch": 8.48,
      "grad_norm": 152.0,
      "learning_rate": 2.2796833773087068e-05,
      "loss": 3.0781,
      "step": 6428
    },
    {
      "epoch": 8.48,
      "grad_norm": 20.0,
      "learning_rate": 2.2777044854881266e-05,
      "loss": 0.0752,
      "step": 6429
    },
    {
      "epoch": 8.48,
      "grad_norm": 0.734375,
      "learning_rate": 2.275725593667546e-05,
      "loss": 0.0061,
      "step": 6430
    },
    {
      "epoch": 8.48,
      "grad_norm": 53.75,
      "learning_rate": 2.2737467018469655e-05,
      "loss": 1.4375,
      "step": 6431
    },
    {
      "epoch": 8.49,
      "grad_norm": 31.875,
      "learning_rate": 2.2717678100263853e-05,
      "loss": 0.9258,
      "step": 6432
    },
    {
      "epoch": 8.49,
      "grad_norm": 149.0,
      "learning_rate": 2.2697889182058048e-05,
      "loss": 3.5156,
      "step": 6433
    },
    {
      "epoch": 8.49,
      "grad_norm": 260.0,
      "learning_rate": 2.267810026385224e-05,
      "loss": 7.3125,
      "step": 6434
    },
    {
      "epoch": 8.49,
      "grad_norm": 350.0,
      "learning_rate": 2.2658311345646434e-05,
      "loss": 9.25,
      "step": 6435
    },
    {
      "epoch": 8.49,
      "grad_norm": 45.75,
      "learning_rate": 2.2638522427440632e-05,
      "loss": 0.6719,
      "step": 6436
    },
    {
      "epoch": 8.49,
      "grad_norm": 0.91796875,
      "learning_rate": 2.2618733509234827e-05,
      "loss": 0.0059,
      "step": 6437
    },
    {
      "epoch": 8.49,
      "grad_norm": 32.75,
      "learning_rate": 2.259894459102902e-05,
      "loss": 0.375,
      "step": 6438
    },
    {
      "epoch": 8.49,
      "grad_norm": 176.0,
      "learning_rate": 2.257915567282322e-05,
      "loss": 3.8594,
      "step": 6439
    },
    {
      "epoch": 8.5,
      "grad_norm": 4.625,
      "learning_rate": 2.2559366754617414e-05,
      "loss": 0.0554,
      "step": 6440
    },
    {
      "epoch": 8.5,
      "grad_norm": 149.0,
      "learning_rate": 2.2539577836411605e-05,
      "loss": 2.2344,
      "step": 6441
    },
    {
      "epoch": 8.5,
      "grad_norm": 152.0,
      "learning_rate": 2.25197889182058e-05,
      "loss": 3.9844,
      "step": 6442
    },
    {
      "epoch": 8.5,
      "grad_norm": 4.625,
      "learning_rate": 2.2499999999999998e-05,
      "loss": 0.0272,
      "step": 6443
    },
    {
      "epoch": 8.5,
      "grad_norm": 26.875,
      "learning_rate": 2.2480211081794193e-05,
      "loss": 0.332,
      "step": 6444
    },
    {
      "epoch": 8.5,
      "grad_norm": 15.25,
      "learning_rate": 2.2460422163588387e-05,
      "loss": 0.2559,
      "step": 6445
    },
    {
      "epoch": 8.5,
      "grad_norm": 184.0,
      "learning_rate": 2.2440633245382585e-05,
      "loss": 3.0312,
      "step": 6446
    },
    {
      "epoch": 8.51,
      "grad_norm": 17.5,
      "learning_rate": 2.242084432717678e-05,
      "loss": 0.1035,
      "step": 6447
    },
    {
      "epoch": 8.51,
      "grad_norm": 8.875,
      "learning_rate": 2.2401055408970975e-05,
      "loss": 0.0679,
      "step": 6448
    },
    {
      "epoch": 8.51,
      "grad_norm": 34.0,
      "learning_rate": 2.238126649076517e-05,
      "loss": 0.7656,
      "step": 6449
    },
    {
      "epoch": 8.51,
      "grad_norm": 40.25,
      "learning_rate": 2.2361477572559364e-05,
      "loss": 0.5508,
      "step": 6450
    },
    {
      "epoch": 8.51,
      "grad_norm": 7.375,
      "learning_rate": 2.234168865435356e-05,
      "loss": 0.0786,
      "step": 6451
    },
    {
      "epoch": 8.51,
      "grad_norm": 37.75,
      "learning_rate": 2.2321899736147757e-05,
      "loss": 0.8008,
      "step": 6452
    },
    {
      "epoch": 8.51,
      "grad_norm": 7.125,
      "learning_rate": 2.230211081794195e-05,
      "loss": 0.0718,
      "step": 6453
    },
    {
      "epoch": 8.51,
      "grad_norm": 72.5,
      "learning_rate": 2.2282321899736146e-05,
      "loss": 0.6094,
      "step": 6454
    },
    {
      "epoch": 8.52,
      "grad_norm": 30.25,
      "learning_rate": 2.2262532981530344e-05,
      "loss": 0.7109,
      "step": 6455
    },
    {
      "epoch": 8.52,
      "grad_norm": 72.5,
      "learning_rate": 2.2242744063324536e-05,
      "loss": 1.5703,
      "step": 6456
    },
    {
      "epoch": 8.52,
      "grad_norm": 44.5,
      "learning_rate": 2.222295514511873e-05,
      "loss": 0.1523,
      "step": 6457
    },
    {
      "epoch": 8.52,
      "grad_norm": 46.75,
      "learning_rate": 2.2203166226912925e-05,
      "loss": 0.1533,
      "step": 6458
    },
    {
      "epoch": 8.52,
      "grad_norm": 104.5,
      "learning_rate": 2.2183377308707123e-05,
      "loss": 0.9648,
      "step": 6459
    },
    {
      "epoch": 8.52,
      "grad_norm": 4.0625,
      "learning_rate": 2.2163588390501318e-05,
      "loss": 0.0486,
      "step": 6460
    },
    {
      "epoch": 8.52,
      "grad_norm": 16.0,
      "learning_rate": 2.2143799472295512e-05,
      "loss": 0.0942,
      "step": 6461
    },
    {
      "epoch": 8.53,
      "grad_norm": 236.0,
      "learning_rate": 2.212401055408971e-05,
      "loss": 2.875,
      "step": 6462
    },
    {
      "epoch": 8.53,
      "grad_norm": 21.0,
      "learning_rate": 2.2104221635883905e-05,
      "loss": 0.1963,
      "step": 6463
    },
    {
      "epoch": 8.53,
      "grad_norm": 33.0,
      "learning_rate": 2.2084432717678096e-05,
      "loss": 0.7539,
      "step": 6464
    },
    {
      "epoch": 8.53,
      "grad_norm": 111.5,
      "learning_rate": 2.206464379947229e-05,
      "loss": 0.8008,
      "step": 6465
    },
    {
      "epoch": 8.53,
      "grad_norm": 6.34375,
      "learning_rate": 2.204485488126649e-05,
      "loss": 0.0564,
      "step": 6466
    },
    {
      "epoch": 8.53,
      "grad_norm": 96.0,
      "learning_rate": 2.2025065963060684e-05,
      "loss": 1.9609,
      "step": 6467
    },
    {
      "epoch": 8.53,
      "grad_norm": 6.25,
      "learning_rate": 2.200527704485488e-05,
      "loss": 0.0532,
      "step": 6468
    },
    {
      "epoch": 8.53,
      "grad_norm": 185.0,
      "learning_rate": 2.1985488126649076e-05,
      "loss": 2.9375,
      "step": 6469
    },
    {
      "epoch": 8.54,
      "grad_norm": 418.0,
      "learning_rate": 2.196569920844327e-05,
      "loss": 3.0625,
      "step": 6470
    },
    {
      "epoch": 8.54,
      "grad_norm": 27.75,
      "learning_rate": 2.1945910290237462e-05,
      "loss": 0.0977,
      "step": 6471
    },
    {
      "epoch": 8.54,
      "grad_norm": 306.0,
      "learning_rate": 2.192612137203166e-05,
      "loss": 4.3125,
      "step": 6472
    },
    {
      "epoch": 8.54,
      "grad_norm": 126.5,
      "learning_rate": 2.1906332453825855e-05,
      "loss": 5.1562,
      "step": 6473
    },
    {
      "epoch": 8.54,
      "grad_norm": 21.375,
      "learning_rate": 2.188654353562005e-05,
      "loss": 0.3477,
      "step": 6474
    },
    {
      "epoch": 8.54,
      "grad_norm": 49.25,
      "learning_rate": 2.1866754617414248e-05,
      "loss": 0.4316,
      "step": 6475
    },
    {
      "epoch": 8.54,
      "grad_norm": 56.5,
      "learning_rate": 2.1846965699208443e-05,
      "loss": 0.291,
      "step": 6476
    },
    {
      "epoch": 8.54,
      "grad_norm": 201.0,
      "learning_rate": 2.1827176781002637e-05,
      "loss": 4.8438,
      "step": 6477
    },
    {
      "epoch": 8.55,
      "grad_norm": 5.71875,
      "learning_rate": 2.1807387862796835e-05,
      "loss": 0.0361,
      "step": 6478
    },
    {
      "epoch": 8.55,
      "grad_norm": 152.0,
      "learning_rate": 2.1787598944591027e-05,
      "loss": 7.0312,
      "step": 6479
    },
    {
      "epoch": 8.55,
      "grad_norm": 12.375,
      "learning_rate": 2.176781002638522e-05,
      "loss": 0.1729,
      "step": 6480
    },
    {
      "epoch": 8.55,
      "grad_norm": 2.625,
      "learning_rate": 2.1748021108179416e-05,
      "loss": 0.0156,
      "step": 6481
    },
    {
      "epoch": 8.55,
      "grad_norm": 140.0,
      "learning_rate": 2.1728232189973614e-05,
      "loss": 3.6406,
      "step": 6482
    },
    {
      "epoch": 8.55,
      "grad_norm": 61.0,
      "learning_rate": 2.170844327176781e-05,
      "loss": 0.5234,
      "step": 6483
    },
    {
      "epoch": 8.55,
      "grad_norm": 107.5,
      "learning_rate": 2.1688654353562003e-05,
      "loss": 2.2031,
      "step": 6484
    },
    {
      "epoch": 8.56,
      "grad_norm": 45.5,
      "learning_rate": 2.16688654353562e-05,
      "loss": 0.4336,
      "step": 6485
    },
    {
      "epoch": 8.56,
      "grad_norm": 3.625,
      "learning_rate": 2.1649076517150393e-05,
      "loss": 0.0359,
      "step": 6486
    },
    {
      "epoch": 8.56,
      "grad_norm": 4.71875,
      "learning_rate": 2.1629287598944587e-05,
      "loss": 0.051,
      "step": 6487
    },
    {
      "epoch": 8.56,
      "grad_norm": 258.0,
      "learning_rate": 2.1609498680738782e-05,
      "loss": 3.6875,
      "step": 6488
    },
    {
      "epoch": 8.56,
      "grad_norm": 115.5,
      "learning_rate": 2.158970976253298e-05,
      "loss": 2.2969,
      "step": 6489
    },
    {
      "epoch": 8.56,
      "grad_norm": 56.5,
      "learning_rate": 2.1569920844327175e-05,
      "loss": 0.4395,
      "step": 6490
    },
    {
      "epoch": 8.56,
      "grad_norm": 42.25,
      "learning_rate": 2.155013192612137e-05,
      "loss": 0.4219,
      "step": 6491
    },
    {
      "epoch": 8.56,
      "grad_norm": 2.421875,
      "learning_rate": 2.1530343007915567e-05,
      "loss": 0.0261,
      "step": 6492
    },
    {
      "epoch": 8.57,
      "grad_norm": 5.34375,
      "learning_rate": 2.1510554089709762e-05,
      "loss": 0.054,
      "step": 6493
    },
    {
      "epoch": 8.57,
      "grad_norm": 25.875,
      "learning_rate": 2.1490765171503953e-05,
      "loss": 0.0713,
      "step": 6494
    },
    {
      "epoch": 8.57,
      "grad_norm": 220.0,
      "learning_rate": 2.147097625329815e-05,
      "loss": 4.6562,
      "step": 6495
    },
    {
      "epoch": 8.57,
      "grad_norm": 26.625,
      "learning_rate": 2.1451187335092346e-05,
      "loss": 0.3516,
      "step": 6496
    },
    {
      "epoch": 8.57,
      "grad_norm": 4.34375,
      "learning_rate": 2.143139841688654e-05,
      "loss": 0.0469,
      "step": 6497
    },
    {
      "epoch": 8.57,
      "grad_norm": 57.0,
      "learning_rate": 2.141160949868074e-05,
      "loss": 0.7383,
      "step": 6498
    },
    {
      "epoch": 8.57,
      "grad_norm": 32.0,
      "learning_rate": 2.1391820580474934e-05,
      "loss": 0.2559,
      "step": 6499
    },
    {
      "epoch": 8.58,
      "grad_norm": 197.0,
      "learning_rate": 2.1372031662269128e-05,
      "loss": 4.25,
      "step": 6500
    },
    {
      "epoch": 8.58,
      "grad_norm": 6.03125,
      "learning_rate": 2.135224274406332e-05,
      "loss": 0.0483,
      "step": 6501
    },
    {
      "epoch": 8.58,
      "grad_norm": 18.75,
      "learning_rate": 2.1332453825857518e-05,
      "loss": 0.1084,
      "step": 6502
    },
    {
      "epoch": 8.58,
      "grad_norm": 20.25,
      "learning_rate": 2.1312664907651712e-05,
      "loss": 0.5703,
      "step": 6503
    },
    {
      "epoch": 8.58,
      "grad_norm": 175.0,
      "learning_rate": 2.1292875989445907e-05,
      "loss": 1.6328,
      "step": 6504
    },
    {
      "epoch": 8.58,
      "grad_norm": 75.0,
      "learning_rate": 2.1273087071240105e-05,
      "loss": 0.3359,
      "step": 6505
    },
    {
      "epoch": 8.58,
      "grad_norm": 78.5,
      "learning_rate": 2.12532981530343e-05,
      "loss": 1.6953,
      "step": 6506
    },
    {
      "epoch": 8.58,
      "grad_norm": 280.0,
      "learning_rate": 2.1233509234828494e-05,
      "loss": 8.25,
      "step": 6507
    },
    {
      "epoch": 8.59,
      "grad_norm": 135.0,
      "learning_rate": 2.1213720316622692e-05,
      "loss": 1.1328,
      "step": 6508
    },
    {
      "epoch": 8.59,
      "grad_norm": 126.0,
      "learning_rate": 2.1193931398416884e-05,
      "loss": 3.375,
      "step": 6509
    },
    {
      "epoch": 8.59,
      "grad_norm": 88.0,
      "learning_rate": 2.1174142480211078e-05,
      "loss": 2.125,
      "step": 6510
    },
    {
      "epoch": 8.59,
      "grad_norm": 11.3125,
      "learning_rate": 2.1154353562005273e-05,
      "loss": 0.0796,
      "step": 6511
    },
    {
      "epoch": 8.59,
      "grad_norm": 3.21875,
      "learning_rate": 2.113456464379947e-05,
      "loss": 0.0125,
      "step": 6512
    },
    {
      "epoch": 8.59,
      "grad_norm": 135.0,
      "learning_rate": 2.1114775725593666e-05,
      "loss": 2.7188,
      "step": 6513
    },
    {
      "epoch": 8.59,
      "grad_norm": 215.0,
      "learning_rate": 2.109498680738786e-05,
      "loss": 2.375,
      "step": 6514
    },
    {
      "epoch": 8.59,
      "grad_norm": 1.1015625,
      "learning_rate": 2.107519788918206e-05,
      "loss": 0.0074,
      "step": 6515
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.279296875,
      "learning_rate": 2.105540897097625e-05,
      "loss": 0.0017,
      "step": 6516
    },
    {
      "epoch": 8.6,
      "grad_norm": 20.875,
      "learning_rate": 2.1035620052770444e-05,
      "loss": 0.4258,
      "step": 6517
    },
    {
      "epoch": 8.6,
      "grad_norm": 41.25,
      "learning_rate": 2.1015831134564642e-05,
      "loss": 0.8125,
      "step": 6518
    },
    {
      "epoch": 8.6,
      "grad_norm": 137.0,
      "learning_rate": 2.0996042216358837e-05,
      "loss": 3.3125,
      "step": 6519
    },
    {
      "epoch": 8.6,
      "grad_norm": 3.71875,
      "learning_rate": 2.0976253298153032e-05,
      "loss": 0.0371,
      "step": 6520
    },
    {
      "epoch": 8.6,
      "grad_norm": 21.875,
      "learning_rate": 2.095646437994723e-05,
      "loss": 0.1162,
      "step": 6521
    },
    {
      "epoch": 8.6,
      "grad_norm": 55.5,
      "learning_rate": 2.0936675461741424e-05,
      "loss": 0.7109,
      "step": 6522
    },
    {
      "epoch": 8.61,
      "grad_norm": 103.5,
      "learning_rate": 2.091688654353562e-05,
      "loss": 0.9219,
      "step": 6523
    },
    {
      "epoch": 8.61,
      "grad_norm": 5.15625,
      "learning_rate": 2.089709762532981e-05,
      "loss": 0.043,
      "step": 6524
    },
    {
      "epoch": 8.61,
      "grad_norm": 18.0,
      "learning_rate": 2.087730870712401e-05,
      "loss": 0.1328,
      "step": 6525
    },
    {
      "epoch": 8.61,
      "grad_norm": 154.0,
      "learning_rate": 2.0857519788918203e-05,
      "loss": 1.0859,
      "step": 6526
    },
    {
      "epoch": 8.61,
      "grad_norm": 28.0,
      "learning_rate": 2.0837730870712398e-05,
      "loss": 1.2891,
      "step": 6527
    },
    {
      "epoch": 8.61,
      "grad_norm": 29.125,
      "learning_rate": 2.0817941952506596e-05,
      "loss": 0.5117,
      "step": 6528
    },
    {
      "epoch": 8.61,
      "grad_norm": 6.375,
      "learning_rate": 2.079815303430079e-05,
      "loss": 0.0488,
      "step": 6529
    },
    {
      "epoch": 8.61,
      "grad_norm": 43.0,
      "learning_rate": 2.0778364116094985e-05,
      "loss": 1.2344,
      "step": 6530
    },
    {
      "epoch": 8.62,
      "grad_norm": 29.0,
      "learning_rate": 2.0758575197889177e-05,
      "loss": 0.2637,
      "step": 6531
    },
    {
      "epoch": 8.62,
      "grad_norm": 34.0,
      "learning_rate": 2.0738786279683375e-05,
      "loss": 0.2793,
      "step": 6532
    },
    {
      "epoch": 8.62,
      "grad_norm": 182.0,
      "learning_rate": 2.071899736147757e-05,
      "loss": 2.7969,
      "step": 6533
    },
    {
      "epoch": 8.62,
      "grad_norm": 20.0,
      "learning_rate": 2.0699208443271764e-05,
      "loss": 0.3848,
      "step": 6534
    },
    {
      "epoch": 8.62,
      "grad_norm": 270.0,
      "learning_rate": 2.0679419525065962e-05,
      "loss": 6.3438,
      "step": 6535
    },
    {
      "epoch": 8.62,
      "grad_norm": 27.625,
      "learning_rate": 2.0659630606860157e-05,
      "loss": 0.1045,
      "step": 6536
    },
    {
      "epoch": 8.62,
      "grad_norm": 17.625,
      "learning_rate": 2.063984168865435e-05,
      "loss": 0.0537,
      "step": 6537
    },
    {
      "epoch": 8.63,
      "grad_norm": 31.375,
      "learning_rate": 2.062005277044855e-05,
      "loss": 0.6875,
      "step": 6538
    },
    {
      "epoch": 8.63,
      "grad_norm": 524.0,
      "learning_rate": 2.060026385224274e-05,
      "loss": 2.4531,
      "step": 6539
    },
    {
      "epoch": 8.63,
      "grad_norm": 14.1875,
      "learning_rate": 2.0580474934036935e-05,
      "loss": 0.0684,
      "step": 6540
    },
    {
      "epoch": 8.63,
      "grad_norm": 17.875,
      "learning_rate": 2.0560686015831133e-05,
      "loss": 0.7227,
      "step": 6541
    },
    {
      "epoch": 8.63,
      "grad_norm": 6.40625,
      "learning_rate": 2.0540897097625328e-05,
      "loss": 0.0466,
      "step": 6542
    },
    {
      "epoch": 8.63,
      "grad_norm": 46.0,
      "learning_rate": 2.0521108179419523e-05,
      "loss": 0.4551,
      "step": 6543
    },
    {
      "epoch": 8.63,
      "grad_norm": 4.75,
      "learning_rate": 2.050131926121372e-05,
      "loss": 0.0361,
      "step": 6544
    },
    {
      "epoch": 8.63,
      "grad_norm": 32.5,
      "learning_rate": 2.0481530343007915e-05,
      "loss": 0.1943,
      "step": 6545
    },
    {
      "epoch": 8.64,
      "grad_norm": 6.28125,
      "learning_rate": 2.046174142480211e-05,
      "loss": 0.0615,
      "step": 6546
    },
    {
      "epoch": 8.64,
      "grad_norm": 114.5,
      "learning_rate": 2.04419525065963e-05,
      "loss": 1.8672,
      "step": 6547
    },
    {
      "epoch": 8.64,
      "grad_norm": 9.5625,
      "learning_rate": 2.04221635883905e-05,
      "loss": 0.0669,
      "step": 6548
    },
    {
      "epoch": 8.64,
      "grad_norm": 238.0,
      "learning_rate": 2.0402374670184694e-05,
      "loss": 6.0312,
      "step": 6549
    },
    {
      "epoch": 8.64,
      "grad_norm": 45.75,
      "learning_rate": 2.038258575197889e-05,
      "loss": 0.209,
      "step": 6550
    },
    {
      "epoch": 8.64,
      "grad_norm": 5.1875,
      "learning_rate": 2.0362796833773087e-05,
      "loss": 0.0304,
      "step": 6551
    },
    {
      "epoch": 8.64,
      "grad_norm": 6.625,
      "learning_rate": 2.034300791556728e-05,
      "loss": 0.0505,
      "step": 6552
    },
    {
      "epoch": 8.65,
      "grad_norm": 171.0,
      "learning_rate": 2.0323218997361476e-05,
      "loss": 2.9844,
      "step": 6553
    },
    {
      "epoch": 8.65,
      "grad_norm": 118.0,
      "learning_rate": 2.0303430079155668e-05,
      "loss": 2.5938,
      "step": 6554
    },
    {
      "epoch": 8.65,
      "grad_norm": 11.0,
      "learning_rate": 2.0283641160949866e-05,
      "loss": 0.1582,
      "step": 6555
    },
    {
      "epoch": 8.65,
      "grad_norm": 70.5,
      "learning_rate": 2.026385224274406e-05,
      "loss": 1.0312,
      "step": 6556
    },
    {
      "epoch": 8.65,
      "grad_norm": 544.0,
      "learning_rate": 2.024406332453826e-05,
      "loss": 5.8125,
      "step": 6557
    },
    {
      "epoch": 8.65,
      "grad_norm": 187.0,
      "learning_rate": 2.0224274406332453e-05,
      "loss": 5.8438,
      "step": 6558
    },
    {
      "epoch": 8.65,
      "grad_norm": 62.5,
      "learning_rate": 2.0204485488126648e-05,
      "loss": 0.3145,
      "step": 6559
    },
    {
      "epoch": 8.65,
      "grad_norm": 203.0,
      "learning_rate": 2.0184696569920846e-05,
      "loss": 1.8516,
      "step": 6560
    },
    {
      "epoch": 8.66,
      "grad_norm": 296.0,
      "learning_rate": 2.016490765171504e-05,
      "loss": 2.25,
      "step": 6561
    },
    {
      "epoch": 8.66,
      "grad_norm": 7.90625,
      "learning_rate": 2.014511873350923e-05,
      "loss": 0.0586,
      "step": 6562
    },
    {
      "epoch": 8.66,
      "grad_norm": 98.5,
      "learning_rate": 2.0125329815303426e-05,
      "loss": 2.1875,
      "step": 6563
    },
    {
      "epoch": 8.66,
      "grad_norm": 38.0,
      "learning_rate": 2.0105540897097624e-05,
      "loss": 0.7031,
      "step": 6564
    },
    {
      "epoch": 8.66,
      "grad_norm": 1.9609375,
      "learning_rate": 2.008575197889182e-05,
      "loss": 0.0143,
      "step": 6565
    },
    {
      "epoch": 8.66,
      "grad_norm": 152.0,
      "learning_rate": 2.0065963060686014e-05,
      "loss": 0.209,
      "step": 6566
    },
    {
      "epoch": 8.66,
      "grad_norm": 141.0,
      "learning_rate": 2.0046174142480212e-05,
      "loss": 1.0,
      "step": 6567
    },
    {
      "epoch": 8.66,
      "grad_norm": 19.5,
      "learning_rate": 2.0026385224274406e-05,
      "loss": 0.7812,
      "step": 6568
    },
    {
      "epoch": 8.67,
      "grad_norm": 43.5,
      "learning_rate": 2.0006596306068598e-05,
      "loss": 0.3906,
      "step": 6569
    },
    {
      "epoch": 8.67,
      "grad_norm": 122.0,
      "learning_rate": 1.9986807387862792e-05,
      "loss": 2.1875,
      "step": 6570
    },
    {
      "epoch": 8.67,
      "grad_norm": 225.0,
      "learning_rate": 1.996701846965699e-05,
      "loss": 1.7031,
      "step": 6571
    },
    {
      "epoch": 8.67,
      "grad_norm": 3.609375,
      "learning_rate": 1.9947229551451185e-05,
      "loss": 0.0359,
      "step": 6572
    },
    {
      "epoch": 8.67,
      "grad_norm": 46.5,
      "learning_rate": 1.992744063324538e-05,
      "loss": 0.2178,
      "step": 6573
    },
    {
      "epoch": 8.67,
      "grad_norm": 4.4375,
      "learning_rate": 1.9907651715039578e-05,
      "loss": 0.0342,
      "step": 6574
    },
    {
      "epoch": 8.67,
      "grad_norm": 62.75,
      "learning_rate": 1.9887862796833773e-05,
      "loss": 0.334,
      "step": 6575
    },
    {
      "epoch": 8.68,
      "grad_norm": 247.0,
      "learning_rate": 1.9868073878627967e-05,
      "loss": 3.9219,
      "step": 6576
    },
    {
      "epoch": 8.68,
      "grad_norm": 96.5,
      "learning_rate": 1.9848284960422162e-05,
      "loss": 1.9219,
      "step": 6577
    },
    {
      "epoch": 8.68,
      "grad_norm": 55.75,
      "learning_rate": 1.9828496042216357e-05,
      "loss": 0.3027,
      "step": 6578
    },
    {
      "epoch": 8.68,
      "grad_norm": 5.40625,
      "learning_rate": 1.980870712401055e-05,
      "loss": 0.0469,
      "step": 6579
    },
    {
      "epoch": 8.68,
      "grad_norm": 38.25,
      "learning_rate": 1.978891820580475e-05,
      "loss": 0.5898,
      "step": 6580
    },
    {
      "epoch": 8.68,
      "grad_norm": 7.5,
      "learning_rate": 1.9769129287598944e-05,
      "loss": 0.0532,
      "step": 6581
    },
    {
      "epoch": 8.68,
      "grad_norm": 43.0,
      "learning_rate": 1.974934036939314e-05,
      "loss": 0.252,
      "step": 6582
    },
    {
      "epoch": 8.68,
      "grad_norm": 40.25,
      "learning_rate": 1.9729551451187337e-05,
      "loss": 0.6211,
      "step": 6583
    },
    {
      "epoch": 8.69,
      "grad_norm": 4.03125,
      "learning_rate": 1.9709762532981528e-05,
      "loss": 0.0312,
      "step": 6584
    },
    {
      "epoch": 8.69,
      "grad_norm": 133.0,
      "learning_rate": 1.9689973614775723e-05,
      "loss": 2.5938,
      "step": 6585
    },
    {
      "epoch": 8.69,
      "grad_norm": 35.25,
      "learning_rate": 1.9670184696569917e-05,
      "loss": 0.25,
      "step": 6586
    },
    {
      "epoch": 8.69,
      "grad_norm": 336.0,
      "learning_rate": 1.9650395778364115e-05,
      "loss": 3.0625,
      "step": 6587
    },
    {
      "epoch": 8.69,
      "grad_norm": 48.0,
      "learning_rate": 1.963060686015831e-05,
      "loss": 0.1953,
      "step": 6588
    },
    {
      "epoch": 8.69,
      "grad_norm": 29.375,
      "learning_rate": 1.9610817941952505e-05,
      "loss": 0.918,
      "step": 6589
    },
    {
      "epoch": 8.69,
      "grad_norm": 31.125,
      "learning_rate": 1.9591029023746703e-05,
      "loss": 0.2383,
      "step": 6590
    },
    {
      "epoch": 8.7,
      "grad_norm": 130.0,
      "learning_rate": 1.9571240105540897e-05,
      "loss": 2.3594,
      "step": 6591
    },
    {
      "epoch": 8.7,
      "grad_norm": 2.546875,
      "learning_rate": 1.955145118733509e-05,
      "loss": 0.0129,
      "step": 6592
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.267578125,
      "learning_rate": 1.9531662269129283e-05,
      "loss": 0.0013,
      "step": 6593
    },
    {
      "epoch": 8.7,
      "grad_norm": 29.0,
      "learning_rate": 1.951187335092348e-05,
      "loss": 0.2734,
      "step": 6594
    },
    {
      "epoch": 8.7,
      "grad_norm": 6.5625,
      "learning_rate": 1.9492084432717676e-05,
      "loss": 0.054,
      "step": 6595
    },
    {
      "epoch": 8.7,
      "grad_norm": 142.0,
      "learning_rate": 1.947229551451187e-05,
      "loss": 2.1406,
      "step": 6596
    },
    {
      "epoch": 8.7,
      "grad_norm": 5.25,
      "learning_rate": 1.945250659630607e-05,
      "loss": 0.0342,
      "step": 6597
    },
    {
      "epoch": 8.7,
      "grad_norm": 44.75,
      "learning_rate": 1.9432717678100264e-05,
      "loss": 0.9609,
      "step": 6598
    },
    {
      "epoch": 8.71,
      "grad_norm": 24.375,
      "learning_rate": 1.9412928759894455e-05,
      "loss": 0.75,
      "step": 6599
    },
    {
      "epoch": 8.71,
      "grad_norm": 127.0,
      "learning_rate": 1.9393139841688653e-05,
      "loss": 1.1016,
      "step": 6600
    },
    {
      "epoch": 8.71,
      "grad_norm": 9.3125,
      "learning_rate": 1.9373350923482848e-05,
      "loss": 0.0408,
      "step": 6601
    },
    {
      "epoch": 8.71,
      "grad_norm": 116.5,
      "learning_rate": 1.9353562005277042e-05,
      "loss": 0.3047,
      "step": 6602
    },
    {
      "epoch": 8.71,
      "grad_norm": 7.46875,
      "learning_rate": 1.933377308707124e-05,
      "loss": 0.0496,
      "step": 6603
    },
    {
      "epoch": 8.71,
      "grad_norm": 34.25,
      "learning_rate": 1.9313984168865435e-05,
      "loss": 0.3594,
      "step": 6604
    },
    {
      "epoch": 8.71,
      "grad_norm": 138.0,
      "learning_rate": 1.929419525065963e-05,
      "loss": 4.0938,
      "step": 6605
    },
    {
      "epoch": 8.72,
      "grad_norm": 75.5,
      "learning_rate": 1.9274406332453828e-05,
      "loss": 0.9805,
      "step": 6606
    },
    {
      "epoch": 8.72,
      "grad_norm": 16.25,
      "learning_rate": 1.925461741424802e-05,
      "loss": 0.1895,
      "step": 6607
    },
    {
      "epoch": 8.72,
      "grad_norm": 127.5,
      "learning_rate": 1.9234828496042214e-05,
      "loss": 1.0234,
      "step": 6608
    },
    {
      "epoch": 8.72,
      "grad_norm": 36.25,
      "learning_rate": 1.921503957783641e-05,
      "loss": 0.6445,
      "step": 6609
    },
    {
      "epoch": 8.72,
      "grad_norm": 284.0,
      "learning_rate": 1.9195250659630606e-05,
      "loss": 3.8594,
      "step": 6610
    },
    {
      "epoch": 8.72,
      "grad_norm": 26.75,
      "learning_rate": 1.91754617414248e-05,
      "loss": 0.6328,
      "step": 6611
    },
    {
      "epoch": 8.72,
      "grad_norm": 83.5,
      "learning_rate": 1.9155672823218996e-05,
      "loss": 0.4121,
      "step": 6612
    },
    {
      "epoch": 8.72,
      "grad_norm": 6.3125,
      "learning_rate": 1.9135883905013194e-05,
      "loss": 0.0344,
      "step": 6613
    },
    {
      "epoch": 8.73,
      "grad_norm": 10.8125,
      "learning_rate": 1.9116094986807385e-05,
      "loss": 0.0659,
      "step": 6614
    },
    {
      "epoch": 8.73,
      "grad_norm": 2.234375,
      "learning_rate": 1.909630606860158e-05,
      "loss": 0.02,
      "step": 6615
    },
    {
      "epoch": 8.73,
      "grad_norm": 125.5,
      "learning_rate": 1.9076517150395774e-05,
      "loss": 2.0469,
      "step": 6616
    },
    {
      "epoch": 8.73,
      "grad_norm": 39.5,
      "learning_rate": 1.9056728232189972e-05,
      "loss": 0.3008,
      "step": 6617
    },
    {
      "epoch": 8.73,
      "grad_norm": 243.0,
      "learning_rate": 1.9036939313984167e-05,
      "loss": 7.2812,
      "step": 6618
    },
    {
      "epoch": 8.73,
      "grad_norm": 49.0,
      "learning_rate": 1.9017150395778362e-05,
      "loss": 0.4199,
      "step": 6619
    },
    {
      "epoch": 8.73,
      "grad_norm": 160.0,
      "learning_rate": 1.899736147757256e-05,
      "loss": 3.8594,
      "step": 6620
    },
    {
      "epoch": 8.73,
      "grad_norm": 20.0,
      "learning_rate": 1.8977572559366755e-05,
      "loss": 0.1768,
      "step": 6621
    },
    {
      "epoch": 8.74,
      "grad_norm": 62.25,
      "learning_rate": 1.8957783641160946e-05,
      "loss": 1.0547,
      "step": 6622
    },
    {
      "epoch": 8.74,
      "grad_norm": 7.15625,
      "learning_rate": 1.8937994722955144e-05,
      "loss": 0.0542,
      "step": 6623
    },
    {
      "epoch": 8.74,
      "grad_norm": 37.5,
      "learning_rate": 1.891820580474934e-05,
      "loss": 0.7188,
      "step": 6624
    },
    {
      "epoch": 8.74,
      "grad_norm": 241.0,
      "learning_rate": 1.8898416886543533e-05,
      "loss": 5.6562,
      "step": 6625
    },
    {
      "epoch": 8.74,
      "grad_norm": 34.0,
      "learning_rate": 1.887862796833773e-05,
      "loss": 0.207,
      "step": 6626
    },
    {
      "epoch": 8.74,
      "grad_norm": 239.0,
      "learning_rate": 1.8858839050131926e-05,
      "loss": 2.9062,
      "step": 6627
    },
    {
      "epoch": 8.74,
      "grad_norm": 93.0,
      "learning_rate": 1.883905013192612e-05,
      "loss": 0.3867,
      "step": 6628
    },
    {
      "epoch": 8.75,
      "grad_norm": 148.0,
      "learning_rate": 1.8819261213720312e-05,
      "loss": 2.9844,
      "step": 6629
    },
    {
      "epoch": 8.75,
      "grad_norm": 20.0,
      "learning_rate": 1.879947229551451e-05,
      "loss": 0.1895,
      "step": 6630
    },
    {
      "epoch": 8.75,
      "grad_norm": 1.5703125,
      "learning_rate": 1.8779683377308705e-05,
      "loss": 0.0193,
      "step": 6631
    },
    {
      "epoch": 8.75,
      "grad_norm": 556.0,
      "learning_rate": 1.87598944591029e-05,
      "loss": 3.3906,
      "step": 6632
    },
    {
      "epoch": 8.75,
      "grad_norm": 18.625,
      "learning_rate": 1.8740105540897097e-05,
      "loss": 0.3125,
      "step": 6633
    },
    {
      "epoch": 8.75,
      "grad_norm": 212.0,
      "learning_rate": 1.8720316622691292e-05,
      "loss": 2.3438,
      "step": 6634
    },
    {
      "epoch": 8.75,
      "grad_norm": 26.625,
      "learning_rate": 1.8700527704485487e-05,
      "loss": 0.4473,
      "step": 6635
    },
    {
      "epoch": 8.75,
      "grad_norm": 45.25,
      "learning_rate": 1.868073878627968e-05,
      "loss": 0.3242,
      "step": 6636
    },
    {
      "epoch": 8.76,
      "grad_norm": 10.6875,
      "learning_rate": 1.8660949868073876e-05,
      "loss": 0.0776,
      "step": 6637
    },
    {
      "epoch": 8.76,
      "grad_norm": 37.0,
      "learning_rate": 1.8641160949868074e-05,
      "loss": 0.6094,
      "step": 6638
    },
    {
      "epoch": 8.76,
      "grad_norm": 26.375,
      "learning_rate": 1.8621372031662265e-05,
      "loss": 0.9102,
      "step": 6639
    },
    {
      "epoch": 8.76,
      "grad_norm": 17.875,
      "learning_rate": 1.8601583113456463e-05,
      "loss": 0.1484,
      "step": 6640
    },
    {
      "epoch": 8.76,
      "grad_norm": 127.5,
      "learning_rate": 1.8581794195250658e-05,
      "loss": 2.2969,
      "step": 6641
    },
    {
      "epoch": 8.76,
      "grad_norm": 13.8125,
      "learning_rate": 1.8562005277044853e-05,
      "loss": 0.1543,
      "step": 6642
    },
    {
      "epoch": 8.76,
      "grad_norm": 314.0,
      "learning_rate": 1.8542216358839047e-05,
      "loss": 7.0938,
      "step": 6643
    },
    {
      "epoch": 8.77,
      "grad_norm": 16.5,
      "learning_rate": 1.8522427440633246e-05,
      "loss": 0.209,
      "step": 6644
    },
    {
      "epoch": 8.77,
      "grad_norm": 175.0,
      "learning_rate": 1.850263852242744e-05,
      "loss": 3.7969,
      "step": 6645
    },
    {
      "epoch": 8.77,
      "grad_norm": 22.875,
      "learning_rate": 1.8482849604221635e-05,
      "loss": 0.3047,
      "step": 6646
    },
    {
      "epoch": 8.77,
      "grad_norm": 200.0,
      "learning_rate": 1.846306068601583e-05,
      "loss": 3.2812,
      "step": 6647
    },
    {
      "epoch": 8.77,
      "grad_norm": 28.875,
      "learning_rate": 1.8443271767810024e-05,
      "loss": 0.7773,
      "step": 6648
    },
    {
      "epoch": 8.77,
      "grad_norm": 179.0,
      "learning_rate": 1.8423482849604222e-05,
      "loss": 2.2344,
      "step": 6649
    },
    {
      "epoch": 8.77,
      "grad_norm": 17.125,
      "learning_rate": 1.8403693931398414e-05,
      "loss": 0.0952,
      "step": 6650
    },
    {
      "epoch": 8.77,
      "grad_norm": 31.0,
      "learning_rate": 1.838390501319261e-05,
      "loss": 0.4902,
      "step": 6651
    },
    {
      "epoch": 8.78,
      "grad_norm": 43.5,
      "learning_rate": 1.8364116094986806e-05,
      "loss": 0.1992,
      "step": 6652
    },
    {
      "epoch": 8.78,
      "grad_norm": 127.5,
      "learning_rate": 1.8344327176781e-05,
      "loss": 2.4844,
      "step": 6653
    },
    {
      "epoch": 8.78,
      "grad_norm": 141.0,
      "learning_rate": 1.8324538258575196e-05,
      "loss": 0.8281,
      "step": 6654
    },
    {
      "epoch": 8.78,
      "grad_norm": 31.375,
      "learning_rate": 1.830474934036939e-05,
      "loss": 0.4199,
      "step": 6655
    },
    {
      "epoch": 8.78,
      "grad_norm": 20.0,
      "learning_rate": 1.828496042216359e-05,
      "loss": 0.5039,
      "step": 6656
    },
    {
      "epoch": 8.78,
      "grad_norm": 155.0,
      "learning_rate": 1.826517150395778e-05,
      "loss": 1.0938,
      "step": 6657
    },
    {
      "epoch": 8.78,
      "grad_norm": 109.5,
      "learning_rate": 1.8245382585751978e-05,
      "loss": 1.1797,
      "step": 6658
    },
    {
      "epoch": 8.78,
      "grad_norm": 4.4375,
      "learning_rate": 1.8225593667546172e-05,
      "loss": 0.0391,
      "step": 6659
    },
    {
      "epoch": 8.79,
      "grad_norm": 32.25,
      "learning_rate": 1.8205804749340367e-05,
      "loss": 0.7227,
      "step": 6660
    },
    {
      "epoch": 8.79,
      "grad_norm": 36.75,
      "learning_rate": 1.8186015831134562e-05,
      "loss": 0.1533,
      "step": 6661
    },
    {
      "epoch": 8.79,
      "grad_norm": 20.375,
      "learning_rate": 1.8166226912928756e-05,
      "loss": 0.6094,
      "step": 6662
    },
    {
      "epoch": 8.79,
      "grad_norm": 17.875,
      "learning_rate": 1.8146437994722954e-05,
      "loss": 0.6719,
      "step": 6663
    },
    {
      "epoch": 8.79,
      "grad_norm": 21.375,
      "learning_rate": 1.812664907651715e-05,
      "loss": 0.1738,
      "step": 6664
    },
    {
      "epoch": 8.79,
      "grad_norm": 141.0,
      "learning_rate": 1.8106860158311344e-05,
      "loss": 3.6562,
      "step": 6665
    },
    {
      "epoch": 8.79,
      "grad_norm": 6.0625,
      "learning_rate": 1.808707124010554e-05,
      "loss": 0.0598,
      "step": 6666
    },
    {
      "epoch": 8.8,
      "grad_norm": 82.0,
      "learning_rate": 1.8067282321899737e-05,
      "loss": 1.7422,
      "step": 6667
    },
    {
      "epoch": 8.8,
      "grad_norm": 120.5,
      "learning_rate": 1.804749340369393e-05,
      "loss": 0.8398,
      "step": 6668
    },
    {
      "epoch": 8.8,
      "grad_norm": 92.0,
      "learning_rate": 1.8027704485488126e-05,
      "loss": 1.7578,
      "step": 6669
    },
    {
      "epoch": 8.8,
      "grad_norm": 174.0,
      "learning_rate": 1.800791556728232e-05,
      "loss": 1.4375,
      "step": 6670
    },
    {
      "epoch": 8.8,
      "grad_norm": 167.0,
      "learning_rate": 1.7988126649076515e-05,
      "loss": 3.4375,
      "step": 6671
    },
    {
      "epoch": 8.8,
      "grad_norm": 37.75,
      "learning_rate": 1.796833773087071e-05,
      "loss": 0.8711,
      "step": 6672
    },
    {
      "epoch": 8.8,
      "grad_norm": 318.0,
      "learning_rate": 1.7948548812664905e-05,
      "loss": 8.0625,
      "step": 6673
    },
    {
      "epoch": 8.8,
      "grad_norm": 4.21875,
      "learning_rate": 1.7928759894459103e-05,
      "loss": 0.0376,
      "step": 6674
    },
    {
      "epoch": 8.81,
      "grad_norm": 157.0,
      "learning_rate": 1.7908970976253297e-05,
      "loss": 2.3906,
      "step": 6675
    },
    {
      "epoch": 8.81,
      "grad_norm": 14.3125,
      "learning_rate": 1.7889182058047492e-05,
      "loss": 0.3027,
      "step": 6676
    },
    {
      "epoch": 8.81,
      "grad_norm": 720.0,
      "learning_rate": 1.7869393139841687e-05,
      "loss": 3.7188,
      "step": 6677
    },
    {
      "epoch": 8.81,
      "grad_norm": 111.0,
      "learning_rate": 1.784960422163588e-05,
      "loss": 2.5625,
      "step": 6678
    },
    {
      "epoch": 8.81,
      "grad_norm": 24.5,
      "learning_rate": 1.782981530343008e-05,
      "loss": 0.4473,
      "step": 6679
    },
    {
      "epoch": 8.81,
      "grad_norm": 28.75,
      "learning_rate": 1.781002638522427e-05,
      "loss": 0.4043,
      "step": 6680
    },
    {
      "epoch": 8.81,
      "grad_norm": 145.0,
      "learning_rate": 1.779023746701847e-05,
      "loss": 4.5938,
      "step": 6681
    },
    {
      "epoch": 8.82,
      "grad_norm": 75.5,
      "learning_rate": 1.7770448548812663e-05,
      "loss": 0.8125,
      "step": 6682
    },
    {
      "epoch": 8.82,
      "grad_norm": 100.5,
      "learning_rate": 1.7750659630606858e-05,
      "loss": 2.2031,
      "step": 6683
    },
    {
      "epoch": 8.82,
      "grad_norm": 123.5,
      "learning_rate": 1.7730870712401053e-05,
      "loss": 3.3125,
      "step": 6684
    },
    {
      "epoch": 8.82,
      "grad_norm": 23.625,
      "learning_rate": 1.7711081794195247e-05,
      "loss": 0.4316,
      "step": 6685
    },
    {
      "epoch": 8.82,
      "grad_norm": 138.0,
      "learning_rate": 1.7691292875989445e-05,
      "loss": 1.9453,
      "step": 6686
    },
    {
      "epoch": 8.82,
      "grad_norm": 10.5625,
      "learning_rate": 1.767150395778364e-05,
      "loss": 0.0791,
      "step": 6687
    },
    {
      "epoch": 8.82,
      "grad_norm": 262.0,
      "learning_rate": 1.7651715039577835e-05,
      "loss": 1.3125,
      "step": 6688
    },
    {
      "epoch": 8.82,
      "grad_norm": 428.0,
      "learning_rate": 1.763192612137203e-05,
      "loss": 3.0,
      "step": 6689
    },
    {
      "epoch": 8.83,
      "grad_norm": 75.5,
      "learning_rate": 1.7612137203166228e-05,
      "loss": 0.5664,
      "step": 6690
    },
    {
      "epoch": 8.83,
      "grad_norm": 35.75,
      "learning_rate": 1.759234828496042e-05,
      "loss": 0.4746,
      "step": 6691
    },
    {
      "epoch": 8.83,
      "grad_norm": 224.0,
      "learning_rate": 1.7572559366754617e-05,
      "loss": 4.75,
      "step": 6692
    },
    {
      "epoch": 8.83,
      "grad_norm": 49.75,
      "learning_rate": 1.755277044854881e-05,
      "loss": 0.5781,
      "step": 6693
    },
    {
      "epoch": 8.83,
      "grad_norm": 232.0,
      "learning_rate": 1.7532981530343006e-05,
      "loss": 3.5938,
      "step": 6694
    },
    {
      "epoch": 8.83,
      "grad_norm": 36.25,
      "learning_rate": 1.75131926121372e-05,
      "loss": 0.2344,
      "step": 6695
    },
    {
      "epoch": 8.83,
      "grad_norm": 46.25,
      "learning_rate": 1.7493403693931396e-05,
      "loss": 1.2188,
      "step": 6696
    },
    {
      "epoch": 8.84,
      "grad_norm": 38.75,
      "learning_rate": 1.7473614775725594e-05,
      "loss": 0.0688,
      "step": 6697
    },
    {
      "epoch": 8.84,
      "grad_norm": 25.625,
      "learning_rate": 1.7453825857519788e-05,
      "loss": 0.4316,
      "step": 6698
    },
    {
      "epoch": 8.84,
      "grad_norm": 6.0,
      "learning_rate": 1.7434036939313983e-05,
      "loss": 0.0688,
      "step": 6699
    },
    {
      "epoch": 8.84,
      "grad_norm": 53.5,
      "learning_rate": 1.7414248021108178e-05,
      "loss": 0.5391,
      "step": 6700
    },
    {
      "epoch": 8.84,
      "grad_norm": 27.0,
      "learning_rate": 1.7394459102902372e-05,
      "loss": 0.6562,
      "step": 6701
    },
    {
      "epoch": 8.84,
      "grad_norm": 58.0,
      "learning_rate": 1.737467018469657e-05,
      "loss": 0.6406,
      "step": 6702
    },
    {
      "epoch": 8.84,
      "grad_norm": 116.0,
      "learning_rate": 1.735488126649076e-05,
      "loss": 1.2031,
      "step": 6703
    },
    {
      "epoch": 8.84,
      "grad_norm": 43.25,
      "learning_rate": 1.733509234828496e-05,
      "loss": 0.3809,
      "step": 6704
    },
    {
      "epoch": 8.85,
      "grad_norm": 70.5,
      "learning_rate": 1.7315303430079154e-05,
      "loss": 0.9844,
      "step": 6705
    },
    {
      "epoch": 8.85,
      "grad_norm": 8.75,
      "learning_rate": 1.729551451187335e-05,
      "loss": 0.0623,
      "step": 6706
    },
    {
      "epoch": 8.85,
      "grad_norm": 4.84375,
      "learning_rate": 1.7275725593667544e-05,
      "loss": 0.0403,
      "step": 6707
    },
    {
      "epoch": 8.85,
      "grad_norm": 141.0,
      "learning_rate": 1.725593667546174e-05,
      "loss": 4.5312,
      "step": 6708
    },
    {
      "epoch": 8.85,
      "grad_norm": 84.0,
      "learning_rate": 1.7236147757255936e-05,
      "loss": 2.1094,
      "step": 6709
    },
    {
      "epoch": 8.85,
      "grad_norm": 3.078125,
      "learning_rate": 1.721635883905013e-05,
      "loss": 0.0256,
      "step": 6710
    },
    {
      "epoch": 8.85,
      "grad_norm": 26.0,
      "learning_rate": 1.7196569920844326e-05,
      "loss": 0.2891,
      "step": 6711
    },
    {
      "epoch": 8.85,
      "grad_norm": 6.65625,
      "learning_rate": 1.717678100263852e-05,
      "loss": 0.0535,
      "step": 6712
    },
    {
      "epoch": 8.86,
      "grad_norm": 43.0,
      "learning_rate": 1.715699208443272e-05,
      "loss": 0.6445,
      "step": 6713
    },
    {
      "epoch": 8.86,
      "grad_norm": 13.0625,
      "learning_rate": 1.713720316622691e-05,
      "loss": 0.1572,
      "step": 6714
    },
    {
      "epoch": 8.86,
      "grad_norm": 27.375,
      "learning_rate": 1.7117414248021108e-05,
      "loss": 0.3711,
      "step": 6715
    },
    {
      "epoch": 8.86,
      "grad_norm": 166.0,
      "learning_rate": 1.7097625329815303e-05,
      "loss": 3.4688,
      "step": 6716
    },
    {
      "epoch": 8.86,
      "grad_norm": 4.9375,
      "learning_rate": 1.7077836411609497e-05,
      "loss": 0.0347,
      "step": 6717
    },
    {
      "epoch": 8.86,
      "grad_norm": 39.25,
      "learning_rate": 1.7058047493403692e-05,
      "loss": 0.3418,
      "step": 6718
    },
    {
      "epoch": 8.86,
      "grad_norm": 48.25,
      "learning_rate": 1.7038258575197887e-05,
      "loss": 0.2695,
      "step": 6719
    },
    {
      "epoch": 8.87,
      "grad_norm": 7.5625,
      "learning_rate": 1.7018469656992085e-05,
      "loss": 0.0679,
      "step": 6720
    },
    {
      "epoch": 8.87,
      "grad_norm": 119.5,
      "learning_rate": 1.6998680738786276e-05,
      "loss": 4.125,
      "step": 6721
    },
    {
      "epoch": 8.87,
      "grad_norm": 576.0,
      "learning_rate": 1.6978891820580474e-05,
      "loss": 5.4062,
      "step": 6722
    },
    {
      "epoch": 8.87,
      "grad_norm": 51.75,
      "learning_rate": 1.695910290237467e-05,
      "loss": 0.2344,
      "step": 6723
    },
    {
      "epoch": 8.87,
      "grad_norm": 74.0,
      "learning_rate": 1.6939313984168863e-05,
      "loss": 0.5352,
      "step": 6724
    },
    {
      "epoch": 8.87,
      "grad_norm": 23.75,
      "learning_rate": 1.6919525065963058e-05,
      "loss": 0.1729,
      "step": 6725
    },
    {
      "epoch": 8.87,
      "grad_norm": 14.1875,
      "learning_rate": 1.6899736147757253e-05,
      "loss": 0.1318,
      "step": 6726
    },
    {
      "epoch": 8.87,
      "grad_norm": 3.890625,
      "learning_rate": 1.687994722955145e-05,
      "loss": 0.0347,
      "step": 6727
    },
    {
      "epoch": 8.88,
      "grad_norm": 217.0,
      "learning_rate": 1.6860158311345645e-05,
      "loss": 2.4844,
      "step": 6728
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.79296875,
      "learning_rate": 1.684036939313984e-05,
      "loss": 0.0078,
      "step": 6729
    },
    {
      "epoch": 8.88,
      "grad_norm": 62.5,
      "learning_rate": 1.6820580474934035e-05,
      "loss": 0.625,
      "step": 6730
    },
    {
      "epoch": 8.88,
      "grad_norm": 120.0,
      "learning_rate": 1.6800791556728233e-05,
      "loss": 4.0625,
      "step": 6731
    },
    {
      "epoch": 8.88,
      "grad_norm": 7.4375,
      "learning_rate": 1.6781002638522427e-05,
      "loss": 0.0476,
      "step": 6732
    },
    {
      "epoch": 8.88,
      "grad_norm": 27.0,
      "learning_rate": 1.6761213720316622e-05,
      "loss": 0.1021,
      "step": 6733
    },
    {
      "epoch": 8.88,
      "grad_norm": 92.5,
      "learning_rate": 1.6741424802110817e-05,
      "loss": 1.3594,
      "step": 6734
    },
    {
      "epoch": 8.89,
      "grad_norm": 25.25,
      "learning_rate": 1.672163588390501e-05,
      "loss": 0.4277,
      "step": 6735
    },
    {
      "epoch": 8.89,
      "grad_norm": 231.0,
      "learning_rate": 1.6701846965699206e-05,
      "loss": 2.0938,
      "step": 6736
    },
    {
      "epoch": 8.89,
      "grad_norm": 161.0,
      "learning_rate": 1.66820580474934e-05,
      "loss": 3.0312,
      "step": 6737
    },
    {
      "epoch": 8.89,
      "grad_norm": 23.625,
      "learning_rate": 1.66622691292876e-05,
      "loss": 0.3789,
      "step": 6738
    },
    {
      "epoch": 8.89,
      "grad_norm": 89.0,
      "learning_rate": 1.6642480211081794e-05,
      "loss": 2.7344,
      "step": 6739
    },
    {
      "epoch": 8.89,
      "grad_norm": 280.0,
      "learning_rate": 1.6622691292875988e-05,
      "loss": 3.9062,
      "step": 6740
    },
    {
      "epoch": 8.89,
      "grad_norm": 28.0,
      "learning_rate": 1.6602902374670183e-05,
      "loss": 1.1328,
      "step": 6741
    },
    {
      "epoch": 8.89,
      "grad_norm": 20.625,
      "learning_rate": 1.6583113456464378e-05,
      "loss": 0.2227,
      "step": 6742
    },
    {
      "epoch": 8.9,
      "grad_norm": 25.875,
      "learning_rate": 1.6563324538258576e-05,
      "loss": 1.0078,
      "step": 6743
    },
    {
      "epoch": 8.9,
      "grad_norm": 45.75,
      "learning_rate": 1.6543535620052767e-05,
      "loss": 0.2812,
      "step": 6744
    },
    {
      "epoch": 8.9,
      "grad_norm": 20.625,
      "learning_rate": 1.6523746701846965e-05,
      "loss": 0.1963,
      "step": 6745
    },
    {
      "epoch": 8.9,
      "grad_norm": 30.625,
      "learning_rate": 1.650395778364116e-05,
      "loss": 0.8672,
      "step": 6746
    },
    {
      "epoch": 8.9,
      "grad_norm": 422.0,
      "learning_rate": 1.6484168865435354e-05,
      "loss": 1.4297,
      "step": 6747
    },
    {
      "epoch": 8.9,
      "grad_norm": 235.0,
      "learning_rate": 1.646437994722955e-05,
      "loss": 4.75,
      "step": 6748
    },
    {
      "epoch": 8.9,
      "grad_norm": 5.46875,
      "learning_rate": 1.6444591029023744e-05,
      "loss": 0.0415,
      "step": 6749
    },
    {
      "epoch": 8.91,
      "grad_norm": 101.5,
      "learning_rate": 1.642480211081794e-05,
      "loss": 3.0625,
      "step": 6750
    },
    {
      "epoch": 8.91,
      "grad_norm": 44.75,
      "learning_rate": 1.6405013192612136e-05,
      "loss": 0.543,
      "step": 6751
    },
    {
      "epoch": 8.91,
      "grad_norm": 32.5,
      "learning_rate": 1.638522427440633e-05,
      "loss": 0.7383,
      "step": 6752
    },
    {
      "epoch": 8.91,
      "grad_norm": 130.0,
      "learning_rate": 1.6365435356200526e-05,
      "loss": 1.0781,
      "step": 6753
    },
    {
      "epoch": 8.91,
      "grad_norm": 3.984375,
      "learning_rate": 1.6345646437994724e-05,
      "loss": 0.0344,
      "step": 6754
    },
    {
      "epoch": 8.91,
      "grad_norm": 21.0,
      "learning_rate": 1.6325857519788915e-05,
      "loss": 0.3086,
      "step": 6755
    },
    {
      "epoch": 8.91,
      "grad_norm": 162.0,
      "learning_rate": 1.6306068601583113e-05,
      "loss": 2.2344,
      "step": 6756
    },
    {
      "epoch": 8.91,
      "grad_norm": 123.5,
      "learning_rate": 1.6286279683377308e-05,
      "loss": 2.2656,
      "step": 6757
    },
    {
      "epoch": 8.92,
      "grad_norm": 162.0,
      "learning_rate": 1.6266490765171502e-05,
      "loss": 2.7344,
      "step": 6758
    },
    {
      "epoch": 8.92,
      "grad_norm": 29.5,
      "learning_rate": 1.6246701846965697e-05,
      "loss": 0.5586,
      "step": 6759
    },
    {
      "epoch": 8.92,
      "grad_norm": 8.5,
      "learning_rate": 1.6226912928759892e-05,
      "loss": 0.0554,
      "step": 6760
    },
    {
      "epoch": 8.92,
      "grad_norm": 146.0,
      "learning_rate": 1.620712401055409e-05,
      "loss": 2.2031,
      "step": 6761
    },
    {
      "epoch": 8.92,
      "grad_norm": 3.8125,
      "learning_rate": 1.6187335092348285e-05,
      "loss": 0.0315,
      "step": 6762
    },
    {
      "epoch": 8.92,
      "grad_norm": 21.0,
      "learning_rate": 1.616754617414248e-05,
      "loss": 0.1104,
      "step": 6763
    },
    {
      "epoch": 8.92,
      "grad_norm": 29.75,
      "learning_rate": 1.6147757255936674e-05,
      "loss": 0.2734,
      "step": 6764
    },
    {
      "epoch": 8.92,
      "grad_norm": 69.0,
      "learning_rate": 1.612796833773087e-05,
      "loss": 0.2314,
      "step": 6765
    },
    {
      "epoch": 8.93,
      "grad_norm": 22.875,
      "learning_rate": 1.6108179419525063e-05,
      "loss": 0.4414,
      "step": 6766
    },
    {
      "epoch": 8.93,
      "grad_norm": 164.0,
      "learning_rate": 1.6088390501319258e-05,
      "loss": 1.9375,
      "step": 6767
    },
    {
      "epoch": 8.93,
      "grad_norm": 86.5,
      "learning_rate": 1.6068601583113456e-05,
      "loss": 0.8086,
      "step": 6768
    },
    {
      "epoch": 8.93,
      "grad_norm": 69.0,
      "learning_rate": 1.604881266490765e-05,
      "loss": 1.1172,
      "step": 6769
    },
    {
      "epoch": 8.93,
      "grad_norm": 194.0,
      "learning_rate": 1.6029023746701845e-05,
      "loss": 4.0,
      "step": 6770
    },
    {
      "epoch": 8.93,
      "grad_norm": 114.5,
      "learning_rate": 1.600923482849604e-05,
      "loss": 4.25,
      "step": 6771
    },
    {
      "epoch": 8.93,
      "grad_norm": 294.0,
      "learning_rate": 1.5989445910290235e-05,
      "loss": 2.1094,
      "step": 6772
    },
    {
      "epoch": 8.94,
      "grad_norm": 163.0,
      "learning_rate": 1.5969656992084433e-05,
      "loss": 1.25,
      "step": 6773
    },
    {
      "epoch": 8.94,
      "grad_norm": 3.96875,
      "learning_rate": 1.5949868073878627e-05,
      "loss": 0.0378,
      "step": 6774
    },
    {
      "epoch": 8.94,
      "grad_norm": 27.75,
      "learning_rate": 1.5930079155672822e-05,
      "loss": 0.3457,
      "step": 6775
    },
    {
      "epoch": 8.94,
      "grad_norm": 10.6875,
      "learning_rate": 1.5910290237467017e-05,
      "loss": 0.0659,
      "step": 6776
    },
    {
      "epoch": 8.94,
      "grad_norm": 29.375,
      "learning_rate": 1.5890501319261215e-05,
      "loss": 0.3555,
      "step": 6777
    },
    {
      "epoch": 8.94,
      "grad_norm": 5.21875,
      "learning_rate": 1.5870712401055406e-05,
      "loss": 0.0571,
      "step": 6778
    },
    {
      "epoch": 8.94,
      "grad_norm": 37.0,
      "learning_rate": 1.5850923482849604e-05,
      "loss": 0.3379,
      "step": 6779
    },
    {
      "epoch": 8.94,
      "grad_norm": 7.78125,
      "learning_rate": 1.58311345646438e-05,
      "loss": 0.0625,
      "step": 6780
    },
    {
      "epoch": 8.95,
      "grad_norm": 142.0,
      "learning_rate": 1.5811345646437993e-05,
      "loss": 2.3281,
      "step": 6781
    },
    {
      "epoch": 8.95,
      "grad_norm": 52.25,
      "learning_rate": 1.5791556728232188e-05,
      "loss": 0.4199,
      "step": 6782
    },
    {
      "epoch": 8.95,
      "grad_norm": 89.0,
      "learning_rate": 1.5771767810026383e-05,
      "loss": 0.2637,
      "step": 6783
    },
    {
      "epoch": 8.95,
      "grad_norm": 12.5,
      "learning_rate": 1.575197889182058e-05,
      "loss": 0.063,
      "step": 6784
    },
    {
      "epoch": 8.95,
      "grad_norm": 2.15625,
      "learning_rate": 1.5732189973614772e-05,
      "loss": 0.0206,
      "step": 6785
    },
    {
      "epoch": 8.95,
      "grad_norm": 7.5,
      "learning_rate": 1.571240105540897e-05,
      "loss": 0.0598,
      "step": 6786
    },
    {
      "epoch": 8.95,
      "grad_norm": 3.84375,
      "learning_rate": 1.5692612137203165e-05,
      "loss": 0.0376,
      "step": 6787
    },
    {
      "epoch": 8.96,
      "grad_norm": 20.75,
      "learning_rate": 1.567282321899736e-05,
      "loss": 0.5664,
      "step": 6788
    },
    {
      "epoch": 8.96,
      "grad_norm": 200.0,
      "learning_rate": 1.5653034300791554e-05,
      "loss": 2.2031,
      "step": 6789
    },
    {
      "epoch": 8.96,
      "grad_norm": 63.75,
      "learning_rate": 1.563324538258575e-05,
      "loss": 0.7891,
      "step": 6790
    },
    {
      "epoch": 8.96,
      "grad_norm": 19.25,
      "learning_rate": 1.5613456464379947e-05,
      "loss": 0.2305,
      "step": 6791
    },
    {
      "epoch": 8.96,
      "grad_norm": 254.0,
      "learning_rate": 1.559366754617414e-05,
      "loss": 2.1875,
      "step": 6792
    },
    {
      "epoch": 8.96,
      "grad_norm": 32.25,
      "learning_rate": 1.5573878627968336e-05,
      "loss": 0.1377,
      "step": 6793
    },
    {
      "epoch": 8.96,
      "grad_norm": 9.0625,
      "learning_rate": 1.555408970976253e-05,
      "loss": 0.0603,
      "step": 6794
    },
    {
      "epoch": 8.96,
      "grad_norm": 47.5,
      "learning_rate": 1.553430079155673e-05,
      "loss": 0.957,
      "step": 6795
    },
    {
      "epoch": 8.97,
      "grad_norm": 368.0,
      "learning_rate": 1.5514511873350924e-05,
      "loss": 1.2422,
      "step": 6796
    },
    {
      "epoch": 8.97,
      "grad_norm": 6.09375,
      "learning_rate": 1.549472295514512e-05,
      "loss": 0.0452,
      "step": 6797
    },
    {
      "epoch": 8.97,
      "grad_norm": 13.6875,
      "learning_rate": 1.5474934036939313e-05,
      "loss": 0.0908,
      "step": 6798
    },
    {
      "epoch": 8.97,
      "grad_norm": 4.25,
      "learning_rate": 1.5455145118733508e-05,
      "loss": 0.0344,
      "step": 6799
    },
    {
      "epoch": 8.97,
      "grad_norm": 46.25,
      "learning_rate": 1.5435356200527702e-05,
      "loss": 0.5234,
      "step": 6800
    },
    {
      "epoch": 8.97,
      "grad_norm": 121.0,
      "learning_rate": 1.5415567282321897e-05,
      "loss": 2.3594,
      "step": 6801
    },
    {
      "epoch": 8.97,
      "grad_norm": 21.75,
      "learning_rate": 1.5395778364116095e-05,
      "loss": 0.3418,
      "step": 6802
    },
    {
      "epoch": 8.97,
      "grad_norm": 121.0,
      "learning_rate": 1.537598944591029e-05,
      "loss": 0.6016,
      "step": 6803
    },
    {
      "epoch": 8.98,
      "grad_norm": 114.5,
      "learning_rate": 1.5356200527704484e-05,
      "loss": 4.1562,
      "step": 6804
    },
    {
      "epoch": 8.98,
      "grad_norm": 390.0,
      "learning_rate": 1.533641160949868e-05,
      "loss": 6.7188,
      "step": 6805
    },
    {
      "epoch": 8.98,
      "grad_norm": 38.0,
      "learning_rate": 1.5316622691292874e-05,
      "loss": 0.2617,
      "step": 6806
    },
    {
      "epoch": 8.98,
      "grad_norm": 46.5,
      "learning_rate": 1.5296833773087072e-05,
      "loss": 0.4199,
      "step": 6807
    },
    {
      "epoch": 8.98,
      "grad_norm": 45.25,
      "learning_rate": 1.5277044854881263e-05,
      "loss": 0.2305,
      "step": 6808
    },
    {
      "epoch": 8.98,
      "grad_norm": 9.9375,
      "learning_rate": 1.525725593667546e-05,
      "loss": 0.0864,
      "step": 6809
    },
    {
      "epoch": 8.98,
      "grad_norm": 131.0,
      "learning_rate": 1.5237467018469656e-05,
      "loss": 1.6797,
      "step": 6810
    },
    {
      "epoch": 8.99,
      "grad_norm": 62.25,
      "learning_rate": 1.5217678100263852e-05,
      "loss": 0.7344,
      "step": 6811
    },
    {
      "epoch": 8.99,
      "grad_norm": 44.0,
      "learning_rate": 1.5197889182058045e-05,
      "loss": 0.2539,
      "step": 6812
    },
    {
      "epoch": 8.99,
      "grad_norm": 380.0,
      "learning_rate": 1.5178100263852242e-05,
      "loss": 8.1875,
      "step": 6813
    },
    {
      "epoch": 8.99,
      "grad_norm": 7.875,
      "learning_rate": 1.5158311345646438e-05,
      "loss": 0.0522,
      "step": 6814
    },
    {
      "epoch": 8.99,
      "grad_norm": 143.0,
      "learning_rate": 1.5138522427440631e-05,
      "loss": 1.0156,
      "step": 6815
    },
    {
      "epoch": 8.99,
      "grad_norm": 21.5,
      "learning_rate": 1.5118733509234827e-05,
      "loss": 0.3379,
      "step": 6816
    },
    {
      "epoch": 8.99,
      "grad_norm": 42.5,
      "learning_rate": 1.5098944591029022e-05,
      "loss": 0.4668,
      "step": 6817
    },
    {
      "epoch": 8.99,
      "grad_norm": 13.0,
      "learning_rate": 1.5079155672823218e-05,
      "loss": 0.1406,
      "step": 6818
    },
    {
      "epoch": 9.0,
      "grad_norm": 37.5,
      "learning_rate": 1.5059366754617411e-05,
      "loss": 0.4395,
      "step": 6819
    },
    {
      "epoch": 9.0,
      "grad_norm": 53.25,
      "learning_rate": 1.5039577836411608e-05,
      "loss": 0.3418,
      "step": 6820
    },
    {
      "epoch": 9.0,
      "grad_norm": 90.0,
      "learning_rate": 1.5019788918205804e-05,
      "loss": 2.4531,
      "step": 6821
    },
    {
      "epoch": 9.0,
      "grad_norm": 60.0,
      "learning_rate": 1.4999999999999999e-05,
      "loss": 0.5273,
      "step": 6822
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.7047334909439087,
      "eval_runtime": 18.347,
      "eval_samples_per_second": 42.623,
      "eval_steps_per_second": 10.683,
      "step": 6822
    },
    {
      "epoch": 9.0,
      "grad_norm": 110.0,
      "learning_rate": 1.4980211081794193e-05,
      "loss": 2.0312,
      "step": 6823
    },
    {
      "epoch": 9.0,
      "grad_norm": 14.0625,
      "learning_rate": 1.496042216358839e-05,
      "loss": 0.2041,
      "step": 6824
    },
    {
      "epoch": 9.0,
      "grad_norm": 24.25,
      "learning_rate": 1.4940633245382584e-05,
      "loss": 0.3281,
      "step": 6825
    },
    {
      "epoch": 9.01,
      "grad_norm": 22.75,
      "learning_rate": 1.492084432717678e-05,
      "loss": 0.4473,
      "step": 6826
    },
    {
      "epoch": 9.01,
      "grad_norm": 40.25,
      "learning_rate": 1.4901055408970974e-05,
      "loss": 1.1953,
      "step": 6827
    },
    {
      "epoch": 9.01,
      "grad_norm": 6.75,
      "learning_rate": 1.488126649076517e-05,
      "loss": 0.053,
      "step": 6828
    },
    {
      "epoch": 9.01,
      "grad_norm": 3.078125,
      "learning_rate": 1.4861477572559366e-05,
      "loss": 0.024,
      "step": 6829
    },
    {
      "epoch": 9.01,
      "grad_norm": 16.625,
      "learning_rate": 1.484168865435356e-05,
      "loss": 0.1816,
      "step": 6830
    },
    {
      "epoch": 9.01,
      "grad_norm": 294.0,
      "learning_rate": 1.4821899736147756e-05,
      "loss": 2.4688,
      "step": 6831
    },
    {
      "epoch": 9.01,
      "grad_norm": 192.0,
      "learning_rate": 1.4802110817941952e-05,
      "loss": 1.5625,
      "step": 6832
    },
    {
      "epoch": 9.01,
      "grad_norm": 48.5,
      "learning_rate": 1.4782321899736147e-05,
      "loss": 1.8125,
      "step": 6833
    },
    {
      "epoch": 9.02,
      "grad_norm": 28.75,
      "learning_rate": 1.4762532981530342e-05,
      "loss": 0.6914,
      "step": 6834
    },
    {
      "epoch": 9.02,
      "grad_norm": 8.1875,
      "learning_rate": 1.4742744063324536e-05,
      "loss": 0.1143,
      "step": 6835
    },
    {
      "epoch": 9.02,
      "grad_norm": 141.0,
      "learning_rate": 1.4722955145118733e-05,
      "loss": 4.0,
      "step": 6836
    },
    {
      "epoch": 9.02,
      "grad_norm": 18.375,
      "learning_rate": 1.4703166226912929e-05,
      "loss": 0.0522,
      "step": 6837
    },
    {
      "epoch": 9.02,
      "grad_norm": 21.875,
      "learning_rate": 1.4683377308707122e-05,
      "loss": 0.1367,
      "step": 6838
    },
    {
      "epoch": 9.02,
      "grad_norm": 382.0,
      "learning_rate": 1.4663588390501318e-05,
      "loss": 4.6875,
      "step": 6839
    },
    {
      "epoch": 9.02,
      "grad_norm": 18.125,
      "learning_rate": 1.4643799472295513e-05,
      "loss": 0.1543,
      "step": 6840
    },
    {
      "epoch": 9.03,
      "grad_norm": 1.4453125,
      "learning_rate": 1.462401055408971e-05,
      "loss": 0.0103,
      "step": 6841
    },
    {
      "epoch": 9.03,
      "grad_norm": 36.25,
      "learning_rate": 1.4604221635883904e-05,
      "loss": 1.1484,
      "step": 6842
    },
    {
      "epoch": 9.03,
      "grad_norm": 11.9375,
      "learning_rate": 1.4584432717678099e-05,
      "loss": 0.0781,
      "step": 6843
    },
    {
      "epoch": 9.03,
      "grad_norm": 18.875,
      "learning_rate": 1.4564643799472295e-05,
      "loss": 0.0645,
      "step": 6844
    },
    {
      "epoch": 9.03,
      "grad_norm": 3.21875,
      "learning_rate": 1.4544854881266488e-05,
      "loss": 0.0317,
      "step": 6845
    },
    {
      "epoch": 9.03,
      "grad_norm": 18.25,
      "learning_rate": 1.4525065963060684e-05,
      "loss": 0.208,
      "step": 6846
    },
    {
      "epoch": 9.03,
      "grad_norm": 79.0,
      "learning_rate": 1.450527704485488e-05,
      "loss": 1.7734,
      "step": 6847
    },
    {
      "epoch": 9.03,
      "grad_norm": 76.0,
      "learning_rate": 1.4485488126649075e-05,
      "loss": 0.416,
      "step": 6848
    },
    {
      "epoch": 9.04,
      "grad_norm": 28.625,
      "learning_rate": 1.446569920844327e-05,
      "loss": 0.9648,
      "step": 6849
    },
    {
      "epoch": 9.04,
      "grad_norm": 20.375,
      "learning_rate": 1.4445910290237465e-05,
      "loss": 0.5078,
      "step": 6850
    },
    {
      "epoch": 9.04,
      "grad_norm": 123.0,
      "learning_rate": 1.4426121372031661e-05,
      "loss": 2.1875,
      "step": 6851
    },
    {
      "epoch": 9.04,
      "grad_norm": 1.9921875,
      "learning_rate": 1.4406332453825857e-05,
      "loss": 0.0226,
      "step": 6852
    },
    {
      "epoch": 9.04,
      "grad_norm": 17.5,
      "learning_rate": 1.438654353562005e-05,
      "loss": 0.0825,
      "step": 6853
    },
    {
      "epoch": 9.04,
      "grad_norm": 24.875,
      "learning_rate": 1.4366754617414247e-05,
      "loss": 0.5977,
      "step": 6854
    },
    {
      "epoch": 9.04,
      "grad_norm": 88.0,
      "learning_rate": 1.4346965699208443e-05,
      "loss": 0.8125,
      "step": 6855
    },
    {
      "epoch": 9.04,
      "grad_norm": 175.0,
      "learning_rate": 1.4327176781002638e-05,
      "loss": 1.9844,
      "step": 6856
    },
    {
      "epoch": 9.05,
      "grad_norm": 29.625,
      "learning_rate": 1.4307387862796833e-05,
      "loss": 0.7266,
      "step": 6857
    },
    {
      "epoch": 9.05,
      "grad_norm": 98.5,
      "learning_rate": 1.4287598944591027e-05,
      "loss": 1.875,
      "step": 6858
    },
    {
      "epoch": 9.05,
      "grad_norm": 130.0,
      "learning_rate": 1.4267810026385224e-05,
      "loss": 3.8125,
      "step": 6859
    },
    {
      "epoch": 9.05,
      "grad_norm": 218.0,
      "learning_rate": 1.4248021108179417e-05,
      "loss": 4.0312,
      "step": 6860
    },
    {
      "epoch": 9.05,
      "grad_norm": 156.0,
      "learning_rate": 1.4228232189973613e-05,
      "loss": 3.6719,
      "step": 6861
    },
    {
      "epoch": 9.05,
      "grad_norm": 47.5,
      "learning_rate": 1.420844327176781e-05,
      "loss": 1.0703,
      "step": 6862
    },
    {
      "epoch": 9.05,
      "grad_norm": 25.125,
      "learning_rate": 1.4188654353562004e-05,
      "loss": 0.6719,
      "step": 6863
    },
    {
      "epoch": 9.06,
      "grad_norm": 119.5,
      "learning_rate": 1.4168865435356199e-05,
      "loss": 2.4844,
      "step": 6864
    },
    {
      "epoch": 9.06,
      "grad_norm": 34.25,
      "learning_rate": 1.4149076517150395e-05,
      "loss": 0.4805,
      "step": 6865
    },
    {
      "epoch": 9.06,
      "grad_norm": 17.5,
      "learning_rate": 1.412928759894459e-05,
      "loss": 0.4062,
      "step": 6866
    },
    {
      "epoch": 9.06,
      "grad_norm": 34.0,
      "learning_rate": 1.4109498680738786e-05,
      "loss": 0.2041,
      "step": 6867
    },
    {
      "epoch": 9.06,
      "grad_norm": 1.6953125,
      "learning_rate": 1.4089709762532979e-05,
      "loss": 0.0079,
      "step": 6868
    },
    {
      "epoch": 9.06,
      "grad_norm": 360.0,
      "learning_rate": 1.4069920844327175e-05,
      "loss": 4.9062,
      "step": 6869
    },
    {
      "epoch": 9.06,
      "grad_norm": 0.58984375,
      "learning_rate": 1.4050131926121372e-05,
      "loss": 0.0081,
      "step": 6870
    },
    {
      "epoch": 9.06,
      "grad_norm": 79.5,
      "learning_rate": 1.4030343007915566e-05,
      "loss": 3.25,
      "step": 6871
    },
    {
      "epoch": 9.07,
      "grad_norm": 170.0,
      "learning_rate": 1.4010554089709761e-05,
      "loss": 2.9375,
      "step": 6872
    },
    {
      "epoch": 9.07,
      "grad_norm": 104.0,
      "learning_rate": 1.3990765171503956e-05,
      "loss": 1.2344,
      "step": 6873
    },
    {
      "epoch": 9.07,
      "grad_norm": 12.6875,
      "learning_rate": 1.3970976253298152e-05,
      "loss": 0.2314,
      "step": 6874
    },
    {
      "epoch": 9.07,
      "grad_norm": 7.78125,
      "learning_rate": 1.3951187335092348e-05,
      "loss": 0.0688,
      "step": 6875
    },
    {
      "epoch": 9.07,
      "grad_norm": 139.0,
      "learning_rate": 1.3931398416886541e-05,
      "loss": 0.9688,
      "step": 6876
    },
    {
      "epoch": 9.07,
      "grad_norm": 6.40625,
      "learning_rate": 1.3911609498680738e-05,
      "loss": 0.0613,
      "step": 6877
    },
    {
      "epoch": 9.07,
      "grad_norm": 233.0,
      "learning_rate": 1.3891820580474934e-05,
      "loss": 3.0312,
      "step": 6878
    },
    {
      "epoch": 9.08,
      "grad_norm": 110.0,
      "learning_rate": 1.3872031662269127e-05,
      "loss": 2.2344,
      "step": 6879
    },
    {
      "epoch": 9.08,
      "grad_norm": 2.53125,
      "learning_rate": 1.3852242744063324e-05,
      "loss": 0.017,
      "step": 6880
    },
    {
      "epoch": 9.08,
      "grad_norm": 50.0,
      "learning_rate": 1.3832453825857518e-05,
      "loss": 0.4551,
      "step": 6881
    },
    {
      "epoch": 9.08,
      "grad_norm": 115.5,
      "learning_rate": 1.3812664907651715e-05,
      "loss": 3.2969,
      "step": 6882
    },
    {
      "epoch": 9.08,
      "grad_norm": 0.60546875,
      "learning_rate": 1.3792875989445908e-05,
      "loss": 0.0081,
      "step": 6883
    },
    {
      "epoch": 9.08,
      "grad_norm": 5.71875,
      "learning_rate": 1.3773087071240104e-05,
      "loss": 0.0327,
      "step": 6884
    },
    {
      "epoch": 9.08,
      "grad_norm": 113.0,
      "learning_rate": 1.37532981530343e-05,
      "loss": 2.1875,
      "step": 6885
    },
    {
      "epoch": 9.08,
      "grad_norm": 5.71875,
      "learning_rate": 1.3733509234828495e-05,
      "loss": 0.0452,
      "step": 6886
    },
    {
      "epoch": 9.09,
      "grad_norm": 189.0,
      "learning_rate": 1.371372031662269e-05,
      "loss": 1.7734,
      "step": 6887
    },
    {
      "epoch": 9.09,
      "grad_norm": 196.0,
      "learning_rate": 1.3693931398416886e-05,
      "loss": 2.5625,
      "step": 6888
    },
    {
      "epoch": 9.09,
      "grad_norm": 13.625,
      "learning_rate": 1.367414248021108e-05,
      "loss": 0.0703,
      "step": 6889
    },
    {
      "epoch": 9.09,
      "grad_norm": 131.0,
      "learning_rate": 1.3654353562005277e-05,
      "loss": 1.4141,
      "step": 6890
    },
    {
      "epoch": 9.09,
      "grad_norm": 4.65625,
      "learning_rate": 1.363456464379947e-05,
      "loss": 0.0291,
      "step": 6891
    },
    {
      "epoch": 9.09,
      "grad_norm": 44.75,
      "learning_rate": 1.3614775725593666e-05,
      "loss": 0.106,
      "step": 6892
    },
    {
      "epoch": 9.09,
      "grad_norm": 3.5625,
      "learning_rate": 1.3594986807387863e-05,
      "loss": 0.0359,
      "step": 6893
    },
    {
      "epoch": 9.09,
      "grad_norm": 59.5,
      "learning_rate": 1.3575197889182056e-05,
      "loss": 0.3359,
      "step": 6894
    },
    {
      "epoch": 9.1,
      "grad_norm": 318.0,
      "learning_rate": 1.3555408970976252e-05,
      "loss": 2.7344,
      "step": 6895
    },
    {
      "epoch": 9.1,
      "grad_norm": 2.296875,
      "learning_rate": 1.3535620052770447e-05,
      "loss": 0.0228,
      "step": 6896
    },
    {
      "epoch": 9.1,
      "grad_norm": 127.0,
      "learning_rate": 1.3515831134564643e-05,
      "loss": 4.1875,
      "step": 6897
    },
    {
      "epoch": 9.1,
      "grad_norm": 49.25,
      "learning_rate": 1.3496042216358838e-05,
      "loss": 0.5195,
      "step": 6898
    },
    {
      "epoch": 9.1,
      "grad_norm": 64.5,
      "learning_rate": 1.3476253298153032e-05,
      "loss": 1.0078,
      "step": 6899
    },
    {
      "epoch": 9.1,
      "grad_norm": 23.5,
      "learning_rate": 1.3456464379947229e-05,
      "loss": 0.0981,
      "step": 6900
    },
    {
      "epoch": 9.1,
      "grad_norm": 58.5,
      "learning_rate": 1.3436675461741425e-05,
      "loss": 0.7227,
      "step": 6901
    },
    {
      "epoch": 9.11,
      "grad_norm": 32.25,
      "learning_rate": 1.3416886543535618e-05,
      "loss": 0.2148,
      "step": 6902
    },
    {
      "epoch": 9.11,
      "grad_norm": 420.0,
      "learning_rate": 1.3397097625329814e-05,
      "loss": 1.9766,
      "step": 6903
    },
    {
      "epoch": 9.11,
      "grad_norm": 123.0,
      "learning_rate": 1.337730870712401e-05,
      "loss": 4.0625,
      "step": 6904
    },
    {
      "epoch": 9.11,
      "grad_norm": 9.0,
      "learning_rate": 1.3357519788918206e-05,
      "loss": 0.0554,
      "step": 6905
    },
    {
      "epoch": 9.11,
      "grad_norm": 25.25,
      "learning_rate": 1.3337730870712399e-05,
      "loss": 0.8477,
      "step": 6906
    },
    {
      "epoch": 9.11,
      "grad_norm": 22.5,
      "learning_rate": 1.3317941952506595e-05,
      "loss": 0.7461,
      "step": 6907
    },
    {
      "epoch": 9.11,
      "grad_norm": 118.5,
      "learning_rate": 1.3298153034300791e-05,
      "loss": 1.9219,
      "step": 6908
    },
    {
      "epoch": 9.11,
      "grad_norm": 4.53125,
      "learning_rate": 1.3278364116094984e-05,
      "loss": 0.0408,
      "step": 6909
    },
    {
      "epoch": 9.12,
      "grad_norm": 16.625,
      "learning_rate": 1.325857519788918e-05,
      "loss": 0.1836,
      "step": 6910
    },
    {
      "epoch": 9.12,
      "grad_norm": 3.65625,
      "learning_rate": 1.3238786279683377e-05,
      "loss": 0.0295,
      "step": 6911
    },
    {
      "epoch": 9.12,
      "grad_norm": 46.75,
      "learning_rate": 1.3218997361477572e-05,
      "loss": 0.373,
      "step": 6912
    },
    {
      "epoch": 9.12,
      "grad_norm": 24.375,
      "learning_rate": 1.3199208443271766e-05,
      "loss": 0.5156,
      "step": 6913
    },
    {
      "epoch": 9.12,
      "grad_norm": 2.640625,
      "learning_rate": 1.3179419525065961e-05,
      "loss": 0.0237,
      "step": 6914
    },
    {
      "epoch": 9.12,
      "grad_norm": 5.0,
      "learning_rate": 1.3159630606860157e-05,
      "loss": 0.0596,
      "step": 6915
    },
    {
      "epoch": 9.12,
      "grad_norm": 6.71875,
      "learning_rate": 1.3139841688654354e-05,
      "loss": 0.0249,
      "step": 6916
    },
    {
      "epoch": 9.13,
      "grad_norm": 127.0,
      "learning_rate": 1.3120052770448547e-05,
      "loss": 2.7188,
      "step": 6917
    },
    {
      "epoch": 9.13,
      "grad_norm": 38.0,
      "learning_rate": 1.3100263852242743e-05,
      "loss": 0.0835,
      "step": 6918
    },
    {
      "epoch": 9.13,
      "grad_norm": 27.0,
      "learning_rate": 1.308047493403694e-05,
      "loss": 0.2441,
      "step": 6919
    },
    {
      "epoch": 9.13,
      "grad_norm": 12.1875,
      "learning_rate": 1.3060686015831134e-05,
      "loss": 0.0781,
      "step": 6920
    },
    {
      "epoch": 9.13,
      "grad_norm": 28.0,
      "learning_rate": 1.3040897097625329e-05,
      "loss": 0.2754,
      "step": 6921
    },
    {
      "epoch": 9.13,
      "grad_norm": 3.0625,
      "learning_rate": 1.3021108179419523e-05,
      "loss": 0.0391,
      "step": 6922
    },
    {
      "epoch": 9.13,
      "grad_norm": 15.6875,
      "learning_rate": 1.300131926121372e-05,
      "loss": 0.1475,
      "step": 6923
    },
    {
      "epoch": 9.13,
      "grad_norm": 2.109375,
      "learning_rate": 1.2981530343007913e-05,
      "loss": 0.0167,
      "step": 6924
    },
    {
      "epoch": 9.14,
      "grad_norm": 17.125,
      "learning_rate": 1.2961741424802109e-05,
      "loss": 0.0938,
      "step": 6925
    },
    {
      "epoch": 9.14,
      "grad_norm": 173.0,
      "learning_rate": 1.2941952506596305e-05,
      "loss": 1.1641,
      "step": 6926
    },
    {
      "epoch": 9.14,
      "grad_norm": 8.3125,
      "learning_rate": 1.29221635883905e-05,
      "loss": 0.0913,
      "step": 6927
    },
    {
      "epoch": 9.14,
      "grad_norm": 28.25,
      "learning_rate": 1.2902374670184695e-05,
      "loss": 0.3438,
      "step": 6928
    },
    {
      "epoch": 9.14,
      "grad_norm": 19.5,
      "learning_rate": 1.2882585751978891e-05,
      "loss": 0.4062,
      "step": 6929
    },
    {
      "epoch": 9.14,
      "grad_norm": 54.5,
      "learning_rate": 1.2862796833773086e-05,
      "loss": 0.9609,
      "step": 6930
    },
    {
      "epoch": 9.14,
      "grad_norm": 199.0,
      "learning_rate": 1.2843007915567282e-05,
      "loss": 4.75,
      "step": 6931
    },
    {
      "epoch": 9.15,
      "grad_norm": 17.75,
      "learning_rate": 1.2823218997361475e-05,
      "loss": 0.1167,
      "step": 6932
    },
    {
      "epoch": 9.15,
      "grad_norm": 96.5,
      "learning_rate": 1.2803430079155672e-05,
      "loss": 1.9219,
      "step": 6933
    },
    {
      "epoch": 9.15,
      "grad_norm": 3.859375,
      "learning_rate": 1.2783641160949868e-05,
      "loss": 0.0393,
      "step": 6934
    },
    {
      "epoch": 9.15,
      "grad_norm": 22.875,
      "learning_rate": 1.2763852242744063e-05,
      "loss": 0.6328,
      "step": 6935
    },
    {
      "epoch": 9.15,
      "grad_norm": 30.125,
      "learning_rate": 1.2744063324538257e-05,
      "loss": 0.2637,
      "step": 6936
    },
    {
      "epoch": 9.15,
      "grad_norm": 36.5,
      "learning_rate": 1.2724274406332452e-05,
      "loss": 0.5859,
      "step": 6937
    },
    {
      "epoch": 9.15,
      "grad_norm": 183.0,
      "learning_rate": 1.2704485488126648e-05,
      "loss": 2.375,
      "step": 6938
    },
    {
      "epoch": 9.15,
      "grad_norm": 1.40625,
      "learning_rate": 1.2684696569920843e-05,
      "loss": 0.0123,
      "step": 6939
    },
    {
      "epoch": 9.16,
      "grad_norm": 59.25,
      "learning_rate": 1.2664907651715038e-05,
      "loss": 0.6289,
      "step": 6940
    },
    {
      "epoch": 9.16,
      "grad_norm": 133.0,
      "learning_rate": 1.2645118733509234e-05,
      "loss": 3.0938,
      "step": 6941
    },
    {
      "epoch": 9.16,
      "grad_norm": 17.875,
      "learning_rate": 1.262532981530343e-05,
      "loss": 0.0417,
      "step": 6942
    },
    {
      "epoch": 9.16,
      "grad_norm": 43.0,
      "learning_rate": 1.2605540897097623e-05,
      "loss": 0.3535,
      "step": 6943
    },
    {
      "epoch": 9.16,
      "grad_norm": 103.0,
      "learning_rate": 1.258575197889182e-05,
      "loss": 1.4688,
      "step": 6944
    },
    {
      "epoch": 9.16,
      "grad_norm": 2.5625,
      "learning_rate": 1.2565963060686014e-05,
      "loss": 0.027,
      "step": 6945
    },
    {
      "epoch": 9.16,
      "grad_norm": 157.0,
      "learning_rate": 1.254617414248021e-05,
      "loss": 5.9375,
      "step": 6946
    },
    {
      "epoch": 9.16,
      "grad_norm": 55.5,
      "learning_rate": 1.2526385224274404e-05,
      "loss": 0.4102,
      "step": 6947
    },
    {
      "epoch": 9.17,
      "grad_norm": 159.0,
      "learning_rate": 1.25065963060686e-05,
      "loss": 1.6172,
      "step": 6948
    },
    {
      "epoch": 9.17,
      "grad_norm": 37.75,
      "learning_rate": 1.2486807387862796e-05,
      "loss": 0.1719,
      "step": 6949
    },
    {
      "epoch": 9.17,
      "grad_norm": 209.0,
      "learning_rate": 1.2467018469656991e-05,
      "loss": 5.5938,
      "step": 6950
    },
    {
      "epoch": 9.17,
      "grad_norm": 18.0,
      "learning_rate": 1.2447229551451186e-05,
      "loss": 0.1504,
      "step": 6951
    },
    {
      "epoch": 9.17,
      "grad_norm": 193.0,
      "learning_rate": 1.2427440633245382e-05,
      "loss": 2.2188,
      "step": 6952
    },
    {
      "epoch": 9.17,
      "grad_norm": 2.53125,
      "learning_rate": 1.2407651715039577e-05,
      "loss": 0.0253,
      "step": 6953
    },
    {
      "epoch": 9.17,
      "grad_norm": 49.75,
      "learning_rate": 1.2387862796833772e-05,
      "loss": 0.3281,
      "step": 6954
    },
    {
      "epoch": 9.18,
      "grad_norm": 49.25,
      "learning_rate": 1.2368073878627966e-05,
      "loss": 0.4121,
      "step": 6955
    },
    {
      "epoch": 9.18,
      "grad_norm": 8.125,
      "learning_rate": 1.2348284960422163e-05,
      "loss": 0.0469,
      "step": 6956
    },
    {
      "epoch": 9.18,
      "grad_norm": 25.375,
      "learning_rate": 1.2328496042216359e-05,
      "loss": 0.3535,
      "step": 6957
    },
    {
      "epoch": 9.18,
      "grad_norm": 36.5,
      "learning_rate": 1.2308707124010552e-05,
      "loss": 0.3438,
      "step": 6958
    },
    {
      "epoch": 9.18,
      "grad_norm": 140.0,
      "learning_rate": 1.2288918205804748e-05,
      "loss": 1.3438,
      "step": 6959
    },
    {
      "epoch": 9.18,
      "grad_norm": 85.0,
      "learning_rate": 1.2269129287598943e-05,
      "loss": 1.3906,
      "step": 6960
    },
    {
      "epoch": 9.18,
      "grad_norm": 125.0,
      "learning_rate": 1.224934036939314e-05,
      "loss": 2.1094,
      "step": 6961
    },
    {
      "epoch": 9.18,
      "grad_norm": 45.75,
      "learning_rate": 1.2229551451187334e-05,
      "loss": 0.2988,
      "step": 6962
    },
    {
      "epoch": 9.19,
      "grad_norm": 144.0,
      "learning_rate": 1.2209762532981529e-05,
      "loss": 1.1406,
      "step": 6963
    },
    {
      "epoch": 9.19,
      "grad_norm": 68.0,
      "learning_rate": 1.2189973614775725e-05,
      "loss": 0.5,
      "step": 6964
    },
    {
      "epoch": 9.19,
      "grad_norm": 156.0,
      "learning_rate": 1.2170184696569921e-05,
      "loss": 2.5469,
      "step": 6965
    },
    {
      "epoch": 9.19,
      "grad_norm": 22.75,
      "learning_rate": 1.2150395778364114e-05,
      "loss": 0.1011,
      "step": 6966
    },
    {
      "epoch": 9.19,
      "grad_norm": 9.0,
      "learning_rate": 1.213060686015831e-05,
      "loss": 0.0806,
      "step": 6967
    },
    {
      "epoch": 9.19,
      "grad_norm": 55.5,
      "learning_rate": 1.2110817941952505e-05,
      "loss": 0.2041,
      "step": 6968
    },
    {
      "epoch": 9.19,
      "grad_norm": 14.25,
      "learning_rate": 1.2091029023746702e-05,
      "loss": 0.2656,
      "step": 6969
    },
    {
      "epoch": 9.2,
      "grad_norm": 55.0,
      "learning_rate": 1.2071240105540895e-05,
      "loss": 0.3828,
      "step": 6970
    },
    {
      "epoch": 9.2,
      "grad_norm": 24.75,
      "learning_rate": 1.2051451187335091e-05,
      "loss": 0.875,
      "step": 6971
    },
    {
      "epoch": 9.2,
      "grad_norm": 115.0,
      "learning_rate": 1.2031662269129287e-05,
      "loss": 2.0469,
      "step": 6972
    },
    {
      "epoch": 9.2,
      "grad_norm": 14.3125,
      "learning_rate": 1.201187335092348e-05,
      "loss": 0.1768,
      "step": 6973
    },
    {
      "epoch": 9.2,
      "grad_norm": 17.625,
      "learning_rate": 1.1992084432717677e-05,
      "loss": 0.082,
      "step": 6974
    },
    {
      "epoch": 9.2,
      "grad_norm": 46.75,
      "learning_rate": 1.1972295514511873e-05,
      "loss": 0.3574,
      "step": 6975
    },
    {
      "epoch": 9.2,
      "grad_norm": 111.5,
      "learning_rate": 1.1952506596306068e-05,
      "loss": 3.2031,
      "step": 6976
    },
    {
      "epoch": 9.2,
      "grad_norm": 21.875,
      "learning_rate": 1.1932717678100263e-05,
      "loss": 0.5625,
      "step": 6977
    },
    {
      "epoch": 9.21,
      "grad_norm": 21.125,
      "learning_rate": 1.1912928759894457e-05,
      "loss": 0.2227,
      "step": 6978
    },
    {
      "epoch": 9.21,
      "grad_norm": 147.0,
      "learning_rate": 1.1893139841688654e-05,
      "loss": 5.1875,
      "step": 6979
    },
    {
      "epoch": 9.21,
      "grad_norm": 109.0,
      "learning_rate": 1.187335092348285e-05,
      "loss": 2.6094,
      "step": 6980
    },
    {
      "epoch": 9.21,
      "grad_norm": 28.125,
      "learning_rate": 1.1853562005277043e-05,
      "loss": 0.4902,
      "step": 6981
    },
    {
      "epoch": 9.21,
      "grad_norm": 29.625,
      "learning_rate": 1.183377308707124e-05,
      "loss": 0.3496,
      "step": 6982
    },
    {
      "epoch": 9.21,
      "grad_norm": 130.0,
      "learning_rate": 1.1813984168865434e-05,
      "loss": 1.4062,
      "step": 6983
    },
    {
      "epoch": 9.21,
      "grad_norm": 116.0,
      "learning_rate": 1.179419525065963e-05,
      "loss": 2.4844,
      "step": 6984
    },
    {
      "epoch": 9.22,
      "grad_norm": 108.0,
      "learning_rate": 1.1774406332453825e-05,
      "loss": 1.8359,
      "step": 6985
    },
    {
      "epoch": 9.22,
      "grad_norm": 6.875,
      "learning_rate": 1.175461741424802e-05,
      "loss": 0.0688,
      "step": 6986
    },
    {
      "epoch": 9.22,
      "grad_norm": 129.0,
      "learning_rate": 1.1734828496042216e-05,
      "loss": 1.9609,
      "step": 6987
    },
    {
      "epoch": 9.22,
      "grad_norm": 22.25,
      "learning_rate": 1.1715039577836409e-05,
      "loss": 0.1816,
      "step": 6988
    },
    {
      "epoch": 9.22,
      "grad_norm": 46.5,
      "learning_rate": 1.1695250659630605e-05,
      "loss": 0.2383,
      "step": 6989
    },
    {
      "epoch": 9.22,
      "grad_norm": 221.0,
      "learning_rate": 1.1675461741424802e-05,
      "loss": 2.8594,
      "step": 6990
    },
    {
      "epoch": 9.22,
      "grad_norm": 5.59375,
      "learning_rate": 1.1655672823218996e-05,
      "loss": 0.0437,
      "step": 6991
    },
    {
      "epoch": 9.22,
      "grad_norm": 43.25,
      "learning_rate": 1.1635883905013191e-05,
      "loss": 0.1523,
      "step": 6992
    },
    {
      "epoch": 9.23,
      "grad_norm": 203.0,
      "learning_rate": 1.1616094986807387e-05,
      "loss": 4.25,
      "step": 6993
    },
    {
      "epoch": 9.23,
      "grad_norm": 153.0,
      "learning_rate": 1.1596306068601582e-05,
      "loss": 2.8438,
      "step": 6994
    },
    {
      "epoch": 9.23,
      "grad_norm": 50.25,
      "learning_rate": 1.1576517150395778e-05,
      "loss": 0.7578,
      "step": 6995
    },
    {
      "epoch": 9.23,
      "grad_norm": 165.0,
      "learning_rate": 1.1556728232189971e-05,
      "loss": 2.9531,
      "step": 6996
    },
    {
      "epoch": 9.23,
      "grad_norm": 350.0,
      "learning_rate": 1.1536939313984168e-05,
      "loss": 0.7422,
      "step": 6997
    },
    {
      "epoch": 9.23,
      "grad_norm": 12.5,
      "learning_rate": 1.1517150395778364e-05,
      "loss": 0.0544,
      "step": 6998
    },
    {
      "epoch": 9.23,
      "grad_norm": 38.5,
      "learning_rate": 1.1497361477572559e-05,
      "loss": 0.2715,
      "step": 6999
    },
    {
      "epoch": 9.23,
      "grad_norm": 2.859375,
      "learning_rate": 1.1477572559366754e-05,
      "loss": 0.0115,
      "step": 7000
    },
    {
      "epoch": 9.24,
      "grad_norm": 0.66015625,
      "learning_rate": 1.1457783641160948e-05,
      "loss": 0.0064,
      "step": 7001
    },
    {
      "epoch": 9.24,
      "grad_norm": 6.03125,
      "learning_rate": 1.1437994722955145e-05,
      "loss": 0.0461,
      "step": 7002
    },
    {
      "epoch": 9.24,
      "grad_norm": 112.5,
      "learning_rate": 1.141820580474934e-05,
      "loss": 3.5469,
      "step": 7003
    },
    {
      "epoch": 9.24,
      "grad_norm": 36.5,
      "learning_rate": 1.1398416886543534e-05,
      "loss": 0.6484,
      "step": 7004
    },
    {
      "epoch": 9.24,
      "grad_norm": 15.0,
      "learning_rate": 1.137862796833773e-05,
      "loss": 0.6953,
      "step": 7005
    },
    {
      "epoch": 9.24,
      "grad_norm": 186.0,
      "learning_rate": 1.1358839050131927e-05,
      "loss": 1.9141,
      "step": 7006
    },
    {
      "epoch": 9.24,
      "grad_norm": 3.4375,
      "learning_rate": 1.133905013192612e-05,
      "loss": 0.0339,
      "step": 7007
    },
    {
      "epoch": 9.25,
      "grad_norm": 11.375,
      "learning_rate": 1.1319261213720316e-05,
      "loss": 0.1514,
      "step": 7008
    },
    {
      "epoch": 9.25,
      "grad_norm": 324.0,
      "learning_rate": 1.129947229551451e-05,
      "loss": 3.625,
      "step": 7009
    },
    {
      "epoch": 9.25,
      "grad_norm": 195.0,
      "learning_rate": 1.1279683377308707e-05,
      "loss": 1.5859,
      "step": 7010
    },
    {
      "epoch": 9.25,
      "grad_norm": 130.0,
      "learning_rate": 1.12598944591029e-05,
      "loss": 1.5312,
      "step": 7011
    },
    {
      "epoch": 9.25,
      "grad_norm": 19.25,
      "learning_rate": 1.1240105540897096e-05,
      "loss": 0.1885,
      "step": 7012
    },
    {
      "epoch": 9.25,
      "grad_norm": 168.0,
      "learning_rate": 1.1220316622691293e-05,
      "loss": 4.3125,
      "step": 7013
    },
    {
      "epoch": 9.25,
      "grad_norm": 118.5,
      "learning_rate": 1.1200527704485487e-05,
      "loss": 1.2188,
      "step": 7014
    },
    {
      "epoch": 9.25,
      "grad_norm": 139.0,
      "learning_rate": 1.1180738786279682e-05,
      "loss": 3.3125,
      "step": 7015
    },
    {
      "epoch": 9.26,
      "grad_norm": 39.5,
      "learning_rate": 1.1160949868073878e-05,
      "loss": 0.2949,
      "step": 7016
    },
    {
      "epoch": 9.26,
      "grad_norm": 290.0,
      "learning_rate": 1.1141160949868073e-05,
      "loss": 1.2188,
      "step": 7017
    },
    {
      "epoch": 9.26,
      "grad_norm": 127.0,
      "learning_rate": 1.1121372031662268e-05,
      "loss": 4.7188,
      "step": 7018
    },
    {
      "epoch": 9.26,
      "grad_norm": 208.0,
      "learning_rate": 1.1101583113456462e-05,
      "loss": 9.0,
      "step": 7019
    },
    {
      "epoch": 9.26,
      "grad_norm": 197.0,
      "learning_rate": 1.1081794195250659e-05,
      "loss": 5.3438,
      "step": 7020
    },
    {
      "epoch": 9.26,
      "grad_norm": 103.5,
      "learning_rate": 1.1062005277044855e-05,
      "loss": 0.6016,
      "step": 7021
    },
    {
      "epoch": 9.26,
      "grad_norm": 127.0,
      "learning_rate": 1.1042216358839048e-05,
      "loss": 3.4219,
      "step": 7022
    },
    {
      "epoch": 9.27,
      "grad_norm": 119.5,
      "learning_rate": 1.1022427440633245e-05,
      "loss": 2.375,
      "step": 7023
    },
    {
      "epoch": 9.27,
      "grad_norm": 19.875,
      "learning_rate": 1.100263852242744e-05,
      "loss": 0.0266,
      "step": 7024
    },
    {
      "epoch": 9.27,
      "grad_norm": 10.1875,
      "learning_rate": 1.0982849604221636e-05,
      "loss": 0.0693,
      "step": 7025
    },
    {
      "epoch": 9.27,
      "grad_norm": 22.125,
      "learning_rate": 1.096306068601583e-05,
      "loss": 0.2891,
      "step": 7026
    },
    {
      "epoch": 9.27,
      "grad_norm": 22.375,
      "learning_rate": 1.0943271767810025e-05,
      "loss": 0.3379,
      "step": 7027
    },
    {
      "epoch": 9.27,
      "grad_norm": 250.0,
      "learning_rate": 1.0923482849604221e-05,
      "loss": 4.1562,
      "step": 7028
    },
    {
      "epoch": 9.27,
      "grad_norm": 13.75,
      "learning_rate": 1.0903693931398418e-05,
      "loss": 0.0869,
      "step": 7029
    },
    {
      "epoch": 9.27,
      "grad_norm": 1.9609375,
      "learning_rate": 1.088390501319261e-05,
      "loss": 0.0188,
      "step": 7030
    },
    {
      "epoch": 9.28,
      "grad_norm": 9.75,
      "learning_rate": 1.0864116094986807e-05,
      "loss": 0.0559,
      "step": 7031
    },
    {
      "epoch": 9.28,
      "grad_norm": 88.0,
      "learning_rate": 1.0844327176781002e-05,
      "loss": 1.2109,
      "step": 7032
    },
    {
      "epoch": 9.28,
      "grad_norm": 21.625,
      "learning_rate": 1.0824538258575196e-05,
      "loss": 0.8789,
      "step": 7033
    },
    {
      "epoch": 9.28,
      "grad_norm": 156.0,
      "learning_rate": 1.0804749340369391e-05,
      "loss": 0.2891,
      "step": 7034
    },
    {
      "epoch": 9.28,
      "grad_norm": 14.875,
      "learning_rate": 1.0784960422163587e-05,
      "loss": 0.0698,
      "step": 7035
    },
    {
      "epoch": 9.28,
      "grad_norm": 35.75,
      "learning_rate": 1.0765171503957784e-05,
      "loss": 0.1289,
      "step": 7036
    },
    {
      "epoch": 9.28,
      "grad_norm": 394.0,
      "learning_rate": 1.0745382585751977e-05,
      "loss": 5.125,
      "step": 7037
    },
    {
      "epoch": 9.28,
      "grad_norm": 7.75,
      "learning_rate": 1.0725593667546173e-05,
      "loss": 0.0693,
      "step": 7038
    },
    {
      "epoch": 9.29,
      "grad_norm": 78.5,
      "learning_rate": 1.070580474934037e-05,
      "loss": 0.7266,
      "step": 7039
    },
    {
      "epoch": 9.29,
      "grad_norm": 21.875,
      "learning_rate": 1.0686015831134564e-05,
      "loss": 0.2051,
      "step": 7040
    },
    {
      "epoch": 9.29,
      "grad_norm": 11.9375,
      "learning_rate": 1.0666226912928759e-05,
      "loss": 0.1494,
      "step": 7041
    },
    {
      "epoch": 9.29,
      "grad_norm": 12.4375,
      "learning_rate": 1.0646437994722953e-05,
      "loss": 0.0481,
      "step": 7042
    },
    {
      "epoch": 9.29,
      "grad_norm": 118.0,
      "learning_rate": 1.062664907651715e-05,
      "loss": 1.5859,
      "step": 7043
    },
    {
      "epoch": 9.29,
      "grad_norm": 10.25,
      "learning_rate": 1.0606860158311346e-05,
      "loss": 0.0811,
      "step": 7044
    },
    {
      "epoch": 9.29,
      "grad_norm": 8.0,
      "learning_rate": 1.0587071240105539e-05,
      "loss": 0.0393,
      "step": 7045
    },
    {
      "epoch": 9.3,
      "grad_norm": 12.6875,
      "learning_rate": 1.0567282321899736e-05,
      "loss": 0.0957,
      "step": 7046
    },
    {
      "epoch": 9.3,
      "grad_norm": 251.0,
      "learning_rate": 1.054749340369393e-05,
      "loss": 4.4062,
      "step": 7047
    },
    {
      "epoch": 9.3,
      "grad_norm": 31.5,
      "learning_rate": 1.0527704485488125e-05,
      "loss": 0.2539,
      "step": 7048
    },
    {
      "epoch": 9.3,
      "grad_norm": 23.25,
      "learning_rate": 1.0507915567282321e-05,
      "loss": 0.6367,
      "step": 7049
    },
    {
      "epoch": 9.3,
      "grad_norm": 125.5,
      "learning_rate": 1.0488126649076516e-05,
      "loss": 3.3906,
      "step": 7050
    },
    {
      "epoch": 9.3,
      "grad_norm": 6.90625,
      "learning_rate": 1.0468337730870712e-05,
      "loss": 0.0233,
      "step": 7051
    },
    {
      "epoch": 9.3,
      "grad_norm": 214.0,
      "learning_rate": 1.0448548812664905e-05,
      "loss": 5.3438,
      "step": 7052
    },
    {
      "epoch": 9.3,
      "grad_norm": 8.3125,
      "learning_rate": 1.0428759894459102e-05,
      "loss": 0.0481,
      "step": 7053
    },
    {
      "epoch": 9.31,
      "grad_norm": 225.0,
      "learning_rate": 1.0408970976253298e-05,
      "loss": 5.5,
      "step": 7054
    },
    {
      "epoch": 9.31,
      "grad_norm": 33.5,
      "learning_rate": 1.0389182058047493e-05,
      "loss": 0.4395,
      "step": 7055
    },
    {
      "epoch": 9.31,
      "grad_norm": 5.03125,
      "learning_rate": 1.0369393139841687e-05,
      "loss": 0.042,
      "step": 7056
    },
    {
      "epoch": 9.31,
      "grad_norm": 31.25,
      "learning_rate": 1.0349604221635882e-05,
      "loss": 0.2949,
      "step": 7057
    },
    {
      "epoch": 9.31,
      "grad_norm": 21.25,
      "learning_rate": 1.0329815303430078e-05,
      "loss": 0.6562,
      "step": 7058
    },
    {
      "epoch": 9.31,
      "grad_norm": 30.625,
      "learning_rate": 1.0310026385224275e-05,
      "loss": 0.7031,
      "step": 7059
    },
    {
      "epoch": 9.31,
      "grad_norm": 118.0,
      "learning_rate": 1.0290237467018468e-05,
      "loss": 4.3438,
      "step": 7060
    },
    {
      "epoch": 9.32,
      "grad_norm": 29.25,
      "learning_rate": 1.0270448548812664e-05,
      "loss": 0.3223,
      "step": 7061
    },
    {
      "epoch": 9.32,
      "grad_norm": 7.28125,
      "learning_rate": 1.025065963060686e-05,
      "loss": 0.0425,
      "step": 7062
    },
    {
      "epoch": 9.32,
      "grad_norm": 24.625,
      "learning_rate": 1.0230870712401055e-05,
      "loss": 0.4473,
      "step": 7063
    },
    {
      "epoch": 9.32,
      "grad_norm": 45.5,
      "learning_rate": 1.021108179419525e-05,
      "loss": 0.2344,
      "step": 7064
    },
    {
      "epoch": 9.32,
      "grad_norm": 36.25,
      "learning_rate": 1.0191292875989444e-05,
      "loss": 0.6641,
      "step": 7065
    },
    {
      "epoch": 9.32,
      "grad_norm": 294.0,
      "learning_rate": 1.017150395778364e-05,
      "loss": 5.0312,
      "step": 7066
    },
    {
      "epoch": 9.32,
      "grad_norm": 31.0,
      "learning_rate": 1.0151715039577834e-05,
      "loss": 0.6992,
      "step": 7067
    },
    {
      "epoch": 9.32,
      "grad_norm": 127.5,
      "learning_rate": 1.013192612137203e-05,
      "loss": 3.3906,
      "step": 7068
    },
    {
      "epoch": 9.33,
      "grad_norm": 0.75390625,
      "learning_rate": 1.0112137203166226e-05,
      "loss": 0.0076,
      "step": 7069
    },
    {
      "epoch": 9.33,
      "grad_norm": 4.71875,
      "learning_rate": 1.0092348284960423e-05,
      "loss": 0.0398,
      "step": 7070
    },
    {
      "epoch": 9.33,
      "grad_norm": 143.0,
      "learning_rate": 1.0072559366754616e-05,
      "loss": 2.8906,
      "step": 7071
    },
    {
      "epoch": 9.33,
      "grad_norm": 191.0,
      "learning_rate": 1.0052770448548812e-05,
      "loss": 1.1016,
      "step": 7072
    },
    {
      "epoch": 9.33,
      "grad_norm": 8.75,
      "learning_rate": 1.0032981530343007e-05,
      "loss": 0.0576,
      "step": 7073
    },
    {
      "epoch": 9.33,
      "grad_norm": 129.0,
      "learning_rate": 1.0013192612137203e-05,
      "loss": 1.7266,
      "step": 7074
    },
    {
      "epoch": 9.33,
      "grad_norm": 14.9375,
      "learning_rate": 9.993403693931396e-06,
      "loss": 0.1216,
      "step": 7075
    },
    {
      "epoch": 9.34,
      "grad_norm": 290.0,
      "learning_rate": 9.973614775725593e-06,
      "loss": 5.2188,
      "step": 7076
    },
    {
      "epoch": 9.34,
      "grad_norm": 23.875,
      "learning_rate": 9.953825857519789e-06,
      "loss": 0.165,
      "step": 7077
    },
    {
      "epoch": 9.34,
      "grad_norm": 13.75,
      "learning_rate": 9.934036939313984e-06,
      "loss": 0.1504,
      "step": 7078
    },
    {
      "epoch": 9.34,
      "grad_norm": 149.0,
      "learning_rate": 9.914248021108178e-06,
      "loss": 1.4453,
      "step": 7079
    },
    {
      "epoch": 9.34,
      "grad_norm": 123.5,
      "learning_rate": 9.894459102902375e-06,
      "loss": 2.7812,
      "step": 7080
    },
    {
      "epoch": 9.34,
      "grad_norm": 7.15625,
      "learning_rate": 9.87467018469657e-06,
      "loss": 0.051,
      "step": 7081
    },
    {
      "epoch": 9.34,
      "grad_norm": 238.0,
      "learning_rate": 9.854881266490764e-06,
      "loss": 2.5,
      "step": 7082
    },
    {
      "epoch": 9.34,
      "grad_norm": 10.8125,
      "learning_rate": 9.835092348284959e-06,
      "loss": 0.0845,
      "step": 7083
    },
    {
      "epoch": 9.35,
      "grad_norm": 128.0,
      "learning_rate": 9.815303430079155e-06,
      "loss": 2.0156,
      "step": 7084
    },
    {
      "epoch": 9.35,
      "grad_norm": 93.5,
      "learning_rate": 9.795514511873351e-06,
      "loss": 2.0312,
      "step": 7085
    },
    {
      "epoch": 9.35,
      "grad_norm": 85.0,
      "learning_rate": 9.775725593667544e-06,
      "loss": 1.7734,
      "step": 7086
    },
    {
      "epoch": 9.35,
      "grad_norm": 50.5,
      "learning_rate": 9.75593667546174e-06,
      "loss": 1.0234,
      "step": 7087
    },
    {
      "epoch": 9.35,
      "grad_norm": 94.5,
      "learning_rate": 9.736147757255935e-06,
      "loss": 1.0703,
      "step": 7088
    },
    {
      "epoch": 9.35,
      "grad_norm": 4.96875,
      "learning_rate": 9.716358839050132e-06,
      "loss": 0.0474,
      "step": 7089
    },
    {
      "epoch": 9.35,
      "grad_norm": 142.0,
      "learning_rate": 9.696569920844326e-06,
      "loss": 4.9062,
      "step": 7090
    },
    {
      "epoch": 9.35,
      "grad_norm": 30.375,
      "learning_rate": 9.676781002638521e-06,
      "loss": 0.6562,
      "step": 7091
    },
    {
      "epoch": 9.36,
      "grad_norm": 1.234375,
      "learning_rate": 9.656992084432717e-06,
      "loss": 0.0161,
      "step": 7092
    },
    {
      "epoch": 9.36,
      "grad_norm": 1.953125,
      "learning_rate": 9.637203166226914e-06,
      "loss": 0.0198,
      "step": 7093
    },
    {
      "epoch": 9.36,
      "grad_norm": 33.5,
      "learning_rate": 9.617414248021107e-06,
      "loss": 0.377,
      "step": 7094
    },
    {
      "epoch": 9.36,
      "grad_norm": 41.0,
      "learning_rate": 9.597625329815303e-06,
      "loss": 0.9258,
      "step": 7095
    },
    {
      "epoch": 9.36,
      "grad_norm": 28.25,
      "learning_rate": 9.577836411609498e-06,
      "loss": 0.8086,
      "step": 7096
    },
    {
      "epoch": 9.36,
      "grad_norm": 57.25,
      "learning_rate": 9.558047493403693e-06,
      "loss": 1.0156,
      "step": 7097
    },
    {
      "epoch": 9.36,
      "grad_norm": 199.0,
      "learning_rate": 9.538258575197887e-06,
      "loss": 2.3594,
      "step": 7098
    },
    {
      "epoch": 9.37,
      "grad_norm": 48.75,
      "learning_rate": 9.518469656992084e-06,
      "loss": 0.8047,
      "step": 7099
    },
    {
      "epoch": 9.37,
      "grad_norm": 17.75,
      "learning_rate": 9.49868073878628e-06,
      "loss": 0.1079,
      "step": 7100
    },
    {
      "epoch": 9.37,
      "grad_norm": 21.0,
      "learning_rate": 9.478891820580473e-06,
      "loss": 0.6797,
      "step": 7101
    },
    {
      "epoch": 9.37,
      "grad_norm": 9.0625,
      "learning_rate": 9.45910290237467e-06,
      "loss": 0.1328,
      "step": 7102
    },
    {
      "epoch": 9.37,
      "grad_norm": 16.5,
      "learning_rate": 9.439313984168866e-06,
      "loss": 0.0845,
      "step": 7103
    },
    {
      "epoch": 9.37,
      "grad_norm": 101.0,
      "learning_rate": 9.41952506596306e-06,
      "loss": 1.8281,
      "step": 7104
    },
    {
      "epoch": 9.37,
      "grad_norm": 318.0,
      "learning_rate": 9.399736147757255e-06,
      "loss": 5.7812,
      "step": 7105
    },
    {
      "epoch": 9.37,
      "grad_norm": 29.75,
      "learning_rate": 9.37994722955145e-06,
      "loss": 1.0234,
      "step": 7106
    },
    {
      "epoch": 9.38,
      "grad_norm": 113.5,
      "learning_rate": 9.360158311345646e-06,
      "loss": 2.7344,
      "step": 7107
    },
    {
      "epoch": 9.38,
      "grad_norm": 37.25,
      "learning_rate": 9.34036939313984e-06,
      "loss": 1.0078,
      "step": 7108
    },
    {
      "epoch": 9.38,
      "grad_norm": 96.0,
      "learning_rate": 9.320580474934037e-06,
      "loss": 1.1641,
      "step": 7109
    },
    {
      "epoch": 9.38,
      "grad_norm": 19.0,
      "learning_rate": 9.300791556728232e-06,
      "loss": 0.2988,
      "step": 7110
    },
    {
      "epoch": 9.38,
      "grad_norm": 34.75,
      "learning_rate": 9.281002638522426e-06,
      "loss": 0.5117,
      "step": 7111
    },
    {
      "epoch": 9.38,
      "grad_norm": 19.375,
      "learning_rate": 9.261213720316623e-06,
      "loss": 0.1357,
      "step": 7112
    },
    {
      "epoch": 9.38,
      "grad_norm": 28.25,
      "learning_rate": 9.241424802110817e-06,
      "loss": 0.1025,
      "step": 7113
    },
    {
      "epoch": 9.39,
      "grad_norm": 30.75,
      "learning_rate": 9.221635883905012e-06,
      "loss": 0.2227,
      "step": 7114
    },
    {
      "epoch": 9.39,
      "grad_norm": 140.0,
      "learning_rate": 9.201846965699207e-06,
      "loss": 2.5,
      "step": 7115
    },
    {
      "epoch": 9.39,
      "grad_norm": 19.25,
      "learning_rate": 9.182058047493403e-06,
      "loss": 0.2695,
      "step": 7116
    },
    {
      "epoch": 9.39,
      "grad_norm": 1.375,
      "learning_rate": 9.162269129287598e-06,
      "loss": 0.0154,
      "step": 7117
    },
    {
      "epoch": 9.39,
      "grad_norm": 1.734375,
      "learning_rate": 9.142480211081794e-06,
      "loss": 0.0156,
      "step": 7118
    },
    {
      "epoch": 9.39,
      "grad_norm": 247.0,
      "learning_rate": 9.122691292875989e-06,
      "loss": 4.2812,
      "step": 7119
    },
    {
      "epoch": 9.39,
      "grad_norm": 67.0,
      "learning_rate": 9.102902374670184e-06,
      "loss": 0.6875,
      "step": 7120
    },
    {
      "epoch": 9.39,
      "grad_norm": 28.875,
      "learning_rate": 9.083113456464378e-06,
      "loss": 0.123,
      "step": 7121
    },
    {
      "epoch": 9.4,
      "grad_norm": 114.0,
      "learning_rate": 9.063324538258575e-06,
      "loss": 1.3281,
      "step": 7122
    },
    {
      "epoch": 9.4,
      "grad_norm": 154.0,
      "learning_rate": 9.04353562005277e-06,
      "loss": 2.3438,
      "step": 7123
    },
    {
      "epoch": 9.4,
      "grad_norm": 18.5,
      "learning_rate": 9.023746701846966e-06,
      "loss": 0.2402,
      "step": 7124
    },
    {
      "epoch": 9.4,
      "grad_norm": 58.25,
      "learning_rate": 9.00395778364116e-06,
      "loss": 0.5586,
      "step": 7125
    },
    {
      "epoch": 9.4,
      "grad_norm": 32.75,
      "learning_rate": 8.984168865435355e-06,
      "loss": 0.168,
      "step": 7126
    },
    {
      "epoch": 9.4,
      "grad_norm": 217.0,
      "learning_rate": 8.964379947229551e-06,
      "loss": 3.3125,
      "step": 7127
    },
    {
      "epoch": 9.4,
      "grad_norm": 22.625,
      "learning_rate": 8.944591029023746e-06,
      "loss": 0.0933,
      "step": 7128
    },
    {
      "epoch": 9.41,
      "grad_norm": 11.9375,
      "learning_rate": 8.92480211081794e-06,
      "loss": 0.0791,
      "step": 7129
    },
    {
      "epoch": 9.41,
      "grad_norm": 21.5,
      "learning_rate": 8.905013192612135e-06,
      "loss": 0.2412,
      "step": 7130
    },
    {
      "epoch": 9.41,
      "grad_norm": 185.0,
      "learning_rate": 8.885224274406332e-06,
      "loss": 1.7969,
      "step": 7131
    },
    {
      "epoch": 9.41,
      "grad_norm": 33.25,
      "learning_rate": 8.865435356200526e-06,
      "loss": 0.3848,
      "step": 7132
    },
    {
      "epoch": 9.41,
      "grad_norm": 3.53125,
      "learning_rate": 8.845646437994723e-06,
      "loss": 0.0349,
      "step": 7133
    },
    {
      "epoch": 9.41,
      "grad_norm": 59.25,
      "learning_rate": 8.825857519788917e-06,
      "loss": 0.7461,
      "step": 7134
    },
    {
      "epoch": 9.41,
      "grad_norm": 117.5,
      "learning_rate": 8.806068601583114e-06,
      "loss": 1.9688,
      "step": 7135
    },
    {
      "epoch": 9.41,
      "grad_norm": 64.5,
      "learning_rate": 8.786279683377308e-06,
      "loss": 0.1895,
      "step": 7136
    },
    {
      "epoch": 9.42,
      "grad_norm": 34.0,
      "learning_rate": 8.766490765171503e-06,
      "loss": 0.7891,
      "step": 7137
    },
    {
      "epoch": 9.42,
      "grad_norm": 21.375,
      "learning_rate": 8.746701846965698e-06,
      "loss": 0.2383,
      "step": 7138
    },
    {
      "epoch": 9.42,
      "grad_norm": 103.5,
      "learning_rate": 8.726912928759894e-06,
      "loss": 1.8125,
      "step": 7139
    },
    {
      "epoch": 9.42,
      "grad_norm": 8.8125,
      "learning_rate": 8.707124010554089e-06,
      "loss": 0.0623,
      "step": 7140
    },
    {
      "epoch": 9.42,
      "grad_norm": 46.75,
      "learning_rate": 8.687335092348285e-06,
      "loss": 0.416,
      "step": 7141
    },
    {
      "epoch": 9.42,
      "grad_norm": 7.1875,
      "learning_rate": 8.66754617414248e-06,
      "loss": 0.062,
      "step": 7142
    },
    {
      "epoch": 9.42,
      "grad_norm": 15.25,
      "learning_rate": 8.647757255936675e-06,
      "loss": 0.2754,
      "step": 7143
    },
    {
      "epoch": 9.42,
      "grad_norm": 312.0,
      "learning_rate": 8.62796833773087e-06,
      "loss": 5.3125,
      "step": 7144
    },
    {
      "epoch": 9.43,
      "grad_norm": 2.171875,
      "learning_rate": 8.608179419525066e-06,
      "loss": 0.0153,
      "step": 7145
    },
    {
      "epoch": 9.43,
      "grad_norm": 28.875,
      "learning_rate": 8.58839050131926e-06,
      "loss": 0.1885,
      "step": 7146
    },
    {
      "epoch": 9.43,
      "grad_norm": 139.0,
      "learning_rate": 8.568601583113455e-06,
      "loss": 0.8516,
      "step": 7147
    },
    {
      "epoch": 9.43,
      "grad_norm": 21.625,
      "learning_rate": 8.548812664907651e-06,
      "loss": 0.3086,
      "step": 7148
    },
    {
      "epoch": 9.43,
      "grad_norm": 141.0,
      "learning_rate": 8.529023746701846e-06,
      "loss": 2.9219,
      "step": 7149
    },
    {
      "epoch": 9.43,
      "grad_norm": 29.75,
      "learning_rate": 8.509234828496042e-06,
      "loss": 0.6719,
      "step": 7150
    },
    {
      "epoch": 9.43,
      "grad_norm": 69.0,
      "learning_rate": 8.489445910290237e-06,
      "loss": 0.6953,
      "step": 7151
    },
    {
      "epoch": 9.44,
      "grad_norm": 150.0,
      "learning_rate": 8.469656992084432e-06,
      "loss": 2.2812,
      "step": 7152
    },
    {
      "epoch": 9.44,
      "grad_norm": 133.0,
      "learning_rate": 8.449868073878626e-06,
      "loss": 1.4141,
      "step": 7153
    },
    {
      "epoch": 9.44,
      "grad_norm": 37.5,
      "learning_rate": 8.430079155672823e-06,
      "loss": 0.4805,
      "step": 7154
    },
    {
      "epoch": 9.44,
      "grad_norm": 47.75,
      "learning_rate": 8.410290237467017e-06,
      "loss": 0.5273,
      "step": 7155
    },
    {
      "epoch": 9.44,
      "grad_norm": 4.9375,
      "learning_rate": 8.390501319261214e-06,
      "loss": 0.0221,
      "step": 7156
    },
    {
      "epoch": 9.44,
      "grad_norm": 172.0,
      "learning_rate": 8.370712401055408e-06,
      "loss": 2.9062,
      "step": 7157
    },
    {
      "epoch": 9.44,
      "grad_norm": 142.0,
      "learning_rate": 8.350923482849603e-06,
      "loss": 3.2188,
      "step": 7158
    },
    {
      "epoch": 9.44,
      "grad_norm": 7.5,
      "learning_rate": 8.3311345646438e-06,
      "loss": 0.054,
      "step": 7159
    },
    {
      "epoch": 9.45,
      "grad_norm": 127.0,
      "learning_rate": 8.311345646437994e-06,
      "loss": 2.9219,
      "step": 7160
    },
    {
      "epoch": 9.45,
      "grad_norm": 133.0,
      "learning_rate": 8.291556728232189e-06,
      "loss": 0.6875,
      "step": 7161
    },
    {
      "epoch": 9.45,
      "grad_norm": 10.6875,
      "learning_rate": 8.271767810026383e-06,
      "loss": 0.0796,
      "step": 7162
    },
    {
      "epoch": 9.45,
      "grad_norm": 116.5,
      "learning_rate": 8.25197889182058e-06,
      "loss": 2.125,
      "step": 7163
    },
    {
      "epoch": 9.45,
      "grad_norm": 107.0,
      "learning_rate": 8.232189973614774e-06,
      "loss": 3.375,
      "step": 7164
    },
    {
      "epoch": 9.45,
      "grad_norm": 32.25,
      "learning_rate": 8.21240105540897e-06,
      "loss": 0.6406,
      "step": 7165
    },
    {
      "epoch": 9.45,
      "grad_norm": 37.25,
      "learning_rate": 8.192612137203166e-06,
      "loss": 0.2061,
      "step": 7166
    },
    {
      "epoch": 9.46,
      "grad_norm": 39.25,
      "learning_rate": 8.172823218997362e-06,
      "loss": 0.3652,
      "step": 7167
    },
    {
      "epoch": 9.46,
      "grad_norm": 138.0,
      "learning_rate": 8.153034300791557e-06,
      "loss": 2.5,
      "step": 7168
    },
    {
      "epoch": 9.46,
      "grad_norm": 183.0,
      "learning_rate": 8.133245382585751e-06,
      "loss": 1.8047,
      "step": 7169
    },
    {
      "epoch": 9.46,
      "grad_norm": 28.0,
      "learning_rate": 8.113456464379946e-06,
      "loss": 0.1846,
      "step": 7170
    },
    {
      "epoch": 9.46,
      "grad_norm": 103.5,
      "learning_rate": 8.093667546174142e-06,
      "loss": 1.9453,
      "step": 7171
    },
    {
      "epoch": 9.46,
      "grad_norm": 48.75,
      "learning_rate": 8.073878627968337e-06,
      "loss": 0.4121,
      "step": 7172
    },
    {
      "epoch": 9.46,
      "grad_norm": 13.5,
      "learning_rate": 8.054089709762532e-06,
      "loss": 0.041,
      "step": 7173
    },
    {
      "epoch": 9.46,
      "grad_norm": 145.0,
      "learning_rate": 8.034300791556728e-06,
      "loss": 0.3828,
      "step": 7174
    },
    {
      "epoch": 9.47,
      "grad_norm": 169.0,
      "learning_rate": 8.014511873350923e-06,
      "loss": 3.2656,
      "step": 7175
    },
    {
      "epoch": 9.47,
      "grad_norm": 31.5,
      "learning_rate": 7.994722955145117e-06,
      "loss": 0.4023,
      "step": 7176
    },
    {
      "epoch": 9.47,
      "grad_norm": 119.0,
      "learning_rate": 7.974934036939314e-06,
      "loss": 3.0469,
      "step": 7177
    },
    {
      "epoch": 9.47,
      "grad_norm": 256.0,
      "learning_rate": 7.955145118733508e-06,
      "loss": 5.375,
      "step": 7178
    },
    {
      "epoch": 9.47,
      "grad_norm": 24.625,
      "learning_rate": 7.935356200527703e-06,
      "loss": 0.2129,
      "step": 7179
    },
    {
      "epoch": 9.47,
      "grad_norm": 52.5,
      "learning_rate": 7.9155672823219e-06,
      "loss": 0.4277,
      "step": 7180
    },
    {
      "epoch": 9.47,
      "grad_norm": 173.0,
      "learning_rate": 7.895778364116094e-06,
      "loss": 4.9062,
      "step": 7181
    },
    {
      "epoch": 9.47,
      "grad_norm": 144.0,
      "learning_rate": 7.87598944591029e-06,
      "loss": 1.9922,
      "step": 7182
    },
    {
      "epoch": 9.48,
      "grad_norm": 60.0,
      "learning_rate": 7.856200527704485e-06,
      "loss": 0.3691,
      "step": 7183
    },
    {
      "epoch": 9.48,
      "grad_norm": 216.0,
      "learning_rate": 7.83641160949868e-06,
      "loss": 7.5312,
      "step": 7184
    },
    {
      "epoch": 9.48,
      "grad_norm": 193.0,
      "learning_rate": 7.816622691292874e-06,
      "loss": 3.6562,
      "step": 7185
    },
    {
      "epoch": 9.48,
      "grad_norm": 178.0,
      "learning_rate": 7.79683377308707e-06,
      "loss": 4.3125,
      "step": 7186
    },
    {
      "epoch": 9.48,
      "grad_norm": 150.0,
      "learning_rate": 7.777044854881265e-06,
      "loss": 1.2344,
      "step": 7187
    },
    {
      "epoch": 9.48,
      "grad_norm": 18.375,
      "learning_rate": 7.757255936675462e-06,
      "loss": 0.1914,
      "step": 7188
    },
    {
      "epoch": 9.48,
      "grad_norm": 4.03125,
      "learning_rate": 7.737467018469657e-06,
      "loss": 0.0454,
      "step": 7189
    },
    {
      "epoch": 9.49,
      "grad_norm": 166.0,
      "learning_rate": 7.717678100263851e-06,
      "loss": 3.0156,
      "step": 7190
    },
    {
      "epoch": 9.49,
      "grad_norm": 7.53125,
      "learning_rate": 7.697889182058048e-06,
      "loss": 0.051,
      "step": 7191
    },
    {
      "epoch": 9.49,
      "grad_norm": 10.6875,
      "learning_rate": 7.678100263852242e-06,
      "loss": 0.0742,
      "step": 7192
    },
    {
      "epoch": 9.49,
      "grad_norm": 22.875,
      "learning_rate": 7.658311345646437e-06,
      "loss": 0.3223,
      "step": 7193
    },
    {
      "epoch": 9.49,
      "grad_norm": 26.375,
      "learning_rate": 7.638522427440632e-06,
      "loss": 0.3496,
      "step": 7194
    },
    {
      "epoch": 9.49,
      "grad_norm": 141.0,
      "learning_rate": 7.618733509234828e-06,
      "loss": 2.3125,
      "step": 7195
    },
    {
      "epoch": 9.49,
      "grad_norm": 49.5,
      "learning_rate": 7.598944591029023e-06,
      "loss": 0.4688,
      "step": 7196
    },
    {
      "epoch": 9.49,
      "grad_norm": 270.0,
      "learning_rate": 7.579155672823219e-06,
      "loss": 2.2969,
      "step": 7197
    },
    {
      "epoch": 9.5,
      "grad_norm": 229.0,
      "learning_rate": 7.559366754617414e-06,
      "loss": 5.625,
      "step": 7198
    },
    {
      "epoch": 9.5,
      "grad_norm": 11.875,
      "learning_rate": 7.539577836411609e-06,
      "loss": 0.0874,
      "step": 7199
    },
    {
      "epoch": 9.5,
      "grad_norm": 10.0,
      "learning_rate": 7.519788918205804e-06,
      "loss": 0.0591,
      "step": 7200
    },
    {
      "epoch": 9.5,
      "grad_norm": 159.0,
      "learning_rate": 7.499999999999999e-06,
      "loss": 2.875,
      "step": 7201
    },
    {
      "epoch": 9.5,
      "grad_norm": 66.5,
      "learning_rate": 7.480211081794195e-06,
      "loss": 0.123,
      "step": 7202
    },
    {
      "epoch": 9.5,
      "grad_norm": 32.25,
      "learning_rate": 7.46042216358839e-06,
      "loss": 1.1641,
      "step": 7203
    },
    {
      "epoch": 9.5,
      "grad_norm": 189.0,
      "learning_rate": 7.440633245382585e-06,
      "loss": 5.3438,
      "step": 7204
    },
    {
      "epoch": 9.51,
      "grad_norm": 9.5,
      "learning_rate": 7.42084432717678e-06,
      "loss": 0.0583,
      "step": 7205
    },
    {
      "epoch": 9.51,
      "grad_norm": 149.0,
      "learning_rate": 7.401055408970976e-06,
      "loss": 1.8906,
      "step": 7206
    },
    {
      "epoch": 9.51,
      "grad_norm": 1.8125,
      "learning_rate": 7.381266490765171e-06,
      "loss": 0.0164,
      "step": 7207
    },
    {
      "epoch": 9.51,
      "grad_norm": 3.96875,
      "learning_rate": 7.361477572559366e-06,
      "loss": 0.0435,
      "step": 7208
    },
    {
      "epoch": 9.51,
      "grad_norm": 23.5,
      "learning_rate": 7.341688654353561e-06,
      "loss": 0.4785,
      "step": 7209
    },
    {
      "epoch": 9.51,
      "grad_norm": 40.0,
      "learning_rate": 7.3218997361477565e-06,
      "loss": 0.4219,
      "step": 7210
    },
    {
      "epoch": 9.51,
      "grad_norm": 39.0,
      "learning_rate": 7.302110817941952e-06,
      "loss": 0.8906,
      "step": 7211
    },
    {
      "epoch": 9.51,
      "grad_norm": 119.5,
      "learning_rate": 7.2823218997361475e-06,
      "loss": 1.4062,
      "step": 7212
    },
    {
      "epoch": 9.52,
      "grad_norm": 32.5,
      "learning_rate": 7.262532981530342e-06,
      "loss": 0.8672,
      "step": 7213
    },
    {
      "epoch": 9.52,
      "grad_norm": 5.3125,
      "learning_rate": 7.242744063324538e-06,
      "loss": 0.0491,
      "step": 7214
    },
    {
      "epoch": 9.52,
      "grad_norm": 11.3125,
      "learning_rate": 7.222955145118732e-06,
      "loss": 0.1128,
      "step": 7215
    },
    {
      "epoch": 9.52,
      "grad_norm": 137.0,
      "learning_rate": 7.203166226912929e-06,
      "loss": 2.75,
      "step": 7216
    },
    {
      "epoch": 9.52,
      "grad_norm": 286.0,
      "learning_rate": 7.183377308707123e-06,
      "loss": 4.375,
      "step": 7217
    },
    {
      "epoch": 9.52,
      "grad_norm": 233.0,
      "learning_rate": 7.163588390501319e-06,
      "loss": 4.1875,
      "step": 7218
    },
    {
      "epoch": 9.52,
      "grad_norm": 28.75,
      "learning_rate": 7.143799472295514e-06,
      "loss": 0.4316,
      "step": 7219
    },
    {
      "epoch": 9.53,
      "grad_norm": 15.0625,
      "learning_rate": 7.124010554089708e-06,
      "loss": 0.1157,
      "step": 7220
    },
    {
      "epoch": 9.53,
      "grad_norm": 192.0,
      "learning_rate": 7.104221635883905e-06,
      "loss": 3.4062,
      "step": 7221
    },
    {
      "epoch": 9.53,
      "grad_norm": 184.0,
      "learning_rate": 7.084432717678099e-06,
      "loss": 2.8125,
      "step": 7222
    },
    {
      "epoch": 9.53,
      "grad_norm": 11.625,
      "learning_rate": 7.064643799472295e-06,
      "loss": 0.0825,
      "step": 7223
    },
    {
      "epoch": 9.53,
      "grad_norm": 12.125,
      "learning_rate": 7.0448548812664895e-06,
      "loss": 0.1089,
      "step": 7224
    },
    {
      "epoch": 9.53,
      "grad_norm": 12.75,
      "learning_rate": 7.025065963060686e-06,
      "loss": 0.0796,
      "step": 7225
    },
    {
      "epoch": 9.53,
      "grad_norm": 1.3359375,
      "learning_rate": 7.0052770448548805e-06,
      "loss": 0.012,
      "step": 7226
    },
    {
      "epoch": 9.53,
      "grad_norm": 118.5,
      "learning_rate": 6.985488126649076e-06,
      "loss": 2.9531,
      "step": 7227
    },
    {
      "epoch": 9.54,
      "grad_norm": 8.375,
      "learning_rate": 6.965699208443271e-06,
      "loss": 0.0767,
      "step": 7228
    },
    {
      "epoch": 9.54,
      "grad_norm": 6.78125,
      "learning_rate": 6.945910290237467e-06,
      "loss": 0.0552,
      "step": 7229
    },
    {
      "epoch": 9.54,
      "grad_norm": 13.0,
      "learning_rate": 6.926121372031662e-06,
      "loss": 0.063,
      "step": 7230
    },
    {
      "epoch": 9.54,
      "grad_norm": 201.0,
      "learning_rate": 6.906332453825857e-06,
      "loss": 3.0781,
      "step": 7231
    },
    {
      "epoch": 9.54,
      "grad_norm": 66.5,
      "learning_rate": 6.886543535620052e-06,
      "loss": 1.7266,
      "step": 7232
    },
    {
      "epoch": 9.54,
      "grad_norm": 272.0,
      "learning_rate": 6.8667546174142475e-06,
      "loss": 5.6875,
      "step": 7233
    },
    {
      "epoch": 9.54,
      "grad_norm": 33.0,
      "learning_rate": 6.846965699208443e-06,
      "loss": 0.793,
      "step": 7234
    },
    {
      "epoch": 9.54,
      "grad_norm": 22.25,
      "learning_rate": 6.8271767810026385e-06,
      "loss": 0.2002,
      "step": 7235
    },
    {
      "epoch": 9.55,
      "grad_norm": 316.0,
      "learning_rate": 6.807387862796833e-06,
      "loss": 6.75,
      "step": 7236
    },
    {
      "epoch": 9.55,
      "grad_norm": 5.0625,
      "learning_rate": 6.787598944591028e-06,
      "loss": 0.0547,
      "step": 7237
    },
    {
      "epoch": 9.55,
      "grad_norm": 7.375,
      "learning_rate": 6.767810026385223e-06,
      "loss": 0.0532,
      "step": 7238
    },
    {
      "epoch": 9.55,
      "grad_norm": 18.5,
      "learning_rate": 6.748021108179419e-06,
      "loss": 0.2275,
      "step": 7239
    },
    {
      "epoch": 9.55,
      "grad_norm": 149.0,
      "learning_rate": 6.728232189973614e-06,
      "loss": 1.3438,
      "step": 7240
    },
    {
      "epoch": 9.55,
      "grad_norm": 205.0,
      "learning_rate": 6.708443271767809e-06,
      "loss": 5.5938,
      "step": 7241
    },
    {
      "epoch": 9.55,
      "grad_norm": 34.0,
      "learning_rate": 6.688654353562005e-06,
      "loss": 0.4492,
      "step": 7242
    },
    {
      "epoch": 9.56,
      "grad_norm": 25.375,
      "learning_rate": 6.668865435356199e-06,
      "loss": 0.377,
      "step": 7243
    },
    {
      "epoch": 9.56,
      "grad_norm": 240.0,
      "learning_rate": 6.649076517150396e-06,
      "loss": 5.125,
      "step": 7244
    },
    {
      "epoch": 9.56,
      "grad_norm": 4.0625,
      "learning_rate": 6.62928759894459e-06,
      "loss": 0.0364,
      "step": 7245
    },
    {
      "epoch": 9.56,
      "grad_norm": 37.75,
      "learning_rate": 6.609498680738786e-06,
      "loss": 0.8633,
      "step": 7246
    },
    {
      "epoch": 9.56,
      "grad_norm": 133.0,
      "learning_rate": 6.5897097625329805e-06,
      "loss": 4.5938,
      "step": 7247
    },
    {
      "epoch": 9.56,
      "grad_norm": 12.0625,
      "learning_rate": 6.569920844327177e-06,
      "loss": 0.0874,
      "step": 7248
    },
    {
      "epoch": 9.56,
      "grad_norm": 29.875,
      "learning_rate": 6.5501319261213715e-06,
      "loss": 0.5039,
      "step": 7249
    },
    {
      "epoch": 9.56,
      "grad_norm": 0.8359375,
      "learning_rate": 6.530343007915567e-06,
      "loss": 0.0079,
      "step": 7250
    },
    {
      "epoch": 9.57,
      "grad_norm": 22.5,
      "learning_rate": 6.510554089709762e-06,
      "loss": 0.0835,
      "step": 7251
    },
    {
      "epoch": 9.57,
      "grad_norm": 83.0,
      "learning_rate": 6.490765171503956e-06,
      "loss": 0.4688,
      "step": 7252
    },
    {
      "epoch": 9.57,
      "grad_norm": 24.25,
      "learning_rate": 6.470976253298153e-06,
      "loss": 0.1289,
      "step": 7253
    },
    {
      "epoch": 9.57,
      "grad_norm": 155.0,
      "learning_rate": 6.451187335092347e-06,
      "loss": 2.8281,
      "step": 7254
    },
    {
      "epoch": 9.57,
      "grad_norm": 135.0,
      "learning_rate": 6.431398416886543e-06,
      "loss": 2.2344,
      "step": 7255
    },
    {
      "epoch": 9.57,
      "grad_norm": 81.5,
      "learning_rate": 6.411609498680738e-06,
      "loss": 2.2969,
      "step": 7256
    },
    {
      "epoch": 9.57,
      "grad_norm": 175.0,
      "learning_rate": 6.391820580474934e-06,
      "loss": 5.1875,
      "step": 7257
    },
    {
      "epoch": 9.58,
      "grad_norm": 137.0,
      "learning_rate": 6.372031662269129e-06,
      "loss": 2.7812,
      "step": 7258
    },
    {
      "epoch": 9.58,
      "grad_norm": 133.0,
      "learning_rate": 6.352242744063324e-06,
      "loss": 1.5703,
      "step": 7259
    },
    {
      "epoch": 9.58,
      "grad_norm": 68.0,
      "learning_rate": 6.332453825857519e-06,
      "loss": 0.0508,
      "step": 7260
    },
    {
      "epoch": 9.58,
      "grad_norm": 68.0,
      "learning_rate": 6.312664907651715e-06,
      "loss": 0.4922,
      "step": 7261
    },
    {
      "epoch": 9.58,
      "grad_norm": 1.9453125,
      "learning_rate": 6.29287598944591e-06,
      "loss": 0.0186,
      "step": 7262
    },
    {
      "epoch": 9.58,
      "grad_norm": 53.75,
      "learning_rate": 6.273087071240105e-06,
      "loss": 0.2812,
      "step": 7263
    },
    {
      "epoch": 9.58,
      "grad_norm": 24.0,
      "learning_rate": 6.2532981530343e-06,
      "loss": 0.5547,
      "step": 7264
    },
    {
      "epoch": 9.58,
      "grad_norm": 181.0,
      "learning_rate": 6.233509234828496e-06,
      "loss": 4.0312,
      "step": 7265
    },
    {
      "epoch": 9.59,
      "grad_norm": 5.90625,
      "learning_rate": 6.213720316622691e-06,
      "loss": 0.0503,
      "step": 7266
    },
    {
      "epoch": 9.59,
      "grad_norm": 117.5,
      "learning_rate": 6.193931398416886e-06,
      "loss": 0.9609,
      "step": 7267
    },
    {
      "epoch": 9.59,
      "grad_norm": 24.75,
      "learning_rate": 6.174142480211081e-06,
      "loss": 0.1641,
      "step": 7268
    },
    {
      "epoch": 9.59,
      "grad_norm": 4.5625,
      "learning_rate": 6.154353562005276e-06,
      "loss": 0.0349,
      "step": 7269
    },
    {
      "epoch": 9.59,
      "grad_norm": 9.0625,
      "learning_rate": 6.1345646437994715e-06,
      "loss": 0.0732,
      "step": 7270
    },
    {
      "epoch": 9.59,
      "grad_norm": 112.5,
      "learning_rate": 6.114775725593667e-06,
      "loss": 4.2812,
      "step": 7271
    },
    {
      "epoch": 9.59,
      "grad_norm": 143.0,
      "learning_rate": 6.0949868073878625e-06,
      "loss": 3.9531,
      "step": 7272
    },
    {
      "epoch": 9.59,
      "grad_norm": 161.0,
      "learning_rate": 6.075197889182057e-06,
      "loss": 2.8906,
      "step": 7273
    },
    {
      "epoch": 9.6,
      "grad_norm": 97.5,
      "learning_rate": 6.055408970976253e-06,
      "loss": 1.5781,
      "step": 7274
    },
    {
      "epoch": 9.6,
      "grad_norm": 19.875,
      "learning_rate": 6.035620052770447e-06,
      "loss": 0.5703,
      "step": 7275
    },
    {
      "epoch": 9.6,
      "grad_norm": 125.5,
      "learning_rate": 6.015831134564644e-06,
      "loss": 1.0625,
      "step": 7276
    },
    {
      "epoch": 9.6,
      "grad_norm": 34.5,
      "learning_rate": 5.996042216358838e-06,
      "loss": 0.4316,
      "step": 7277
    },
    {
      "epoch": 9.6,
      "grad_norm": 1.3359375,
      "learning_rate": 5.976253298153034e-06,
      "loss": 0.0164,
      "step": 7278
    },
    {
      "epoch": 9.6,
      "grad_norm": 17.5,
      "learning_rate": 5.956464379947229e-06,
      "loss": 0.2412,
      "step": 7279
    },
    {
      "epoch": 9.6,
      "grad_norm": 49.25,
      "learning_rate": 5.936675461741425e-06,
      "loss": 0.1182,
      "step": 7280
    },
    {
      "epoch": 9.61,
      "grad_norm": 9.5625,
      "learning_rate": 5.91688654353562e-06,
      "loss": 0.0718,
      "step": 7281
    },
    {
      "epoch": 9.61,
      "grad_norm": 10.375,
      "learning_rate": 5.897097625329815e-06,
      "loss": 0.0554,
      "step": 7282
    },
    {
      "epoch": 9.61,
      "grad_norm": 5.78125,
      "learning_rate": 5.87730870712401e-06,
      "loss": 0.052,
      "step": 7283
    },
    {
      "epoch": 9.61,
      "grad_norm": 1.171875,
      "learning_rate": 5.8575197889182045e-06,
      "loss": 0.0099,
      "step": 7284
    },
    {
      "epoch": 9.61,
      "grad_norm": 3.234375,
      "learning_rate": 5.837730870712401e-06,
      "loss": 0.0332,
      "step": 7285
    },
    {
      "epoch": 9.61,
      "grad_norm": 27.375,
      "learning_rate": 5.8179419525065955e-06,
      "loss": 0.9336,
      "step": 7286
    },
    {
      "epoch": 9.61,
      "grad_norm": 8.125,
      "learning_rate": 5.798153034300791e-06,
      "loss": 0.0557,
      "step": 7287
    },
    {
      "epoch": 9.61,
      "grad_norm": 134.0,
      "learning_rate": 5.778364116094986e-06,
      "loss": 2.7344,
      "step": 7288
    },
    {
      "epoch": 9.62,
      "grad_norm": 28.875,
      "learning_rate": 5.758575197889182e-06,
      "loss": 0.2715,
      "step": 7289
    },
    {
      "epoch": 9.62,
      "grad_norm": 167.0,
      "learning_rate": 5.738786279683377e-06,
      "loss": 3.25,
      "step": 7290
    },
    {
      "epoch": 9.62,
      "grad_norm": 18.125,
      "learning_rate": 5.718997361477572e-06,
      "loss": 0.1196,
      "step": 7291
    },
    {
      "epoch": 9.62,
      "grad_norm": 192.0,
      "learning_rate": 5.699208443271767e-06,
      "loss": 3.0156,
      "step": 7292
    },
    {
      "epoch": 9.62,
      "grad_norm": 21.75,
      "learning_rate": 5.679419525065963e-06,
      "loss": 0.2793,
      "step": 7293
    },
    {
      "epoch": 9.62,
      "grad_norm": 26.75,
      "learning_rate": 5.659630606860158e-06,
      "loss": 0.7148,
      "step": 7294
    },
    {
      "epoch": 9.62,
      "grad_norm": 146.0,
      "learning_rate": 5.6398416886543535e-06,
      "loss": 0.8203,
      "step": 7295
    },
    {
      "epoch": 9.63,
      "grad_norm": 12.3125,
      "learning_rate": 5.620052770448548e-06,
      "loss": 0.0457,
      "step": 7296
    },
    {
      "epoch": 9.63,
      "grad_norm": 119.0,
      "learning_rate": 5.600263852242744e-06,
      "loss": 3.1875,
      "step": 7297
    },
    {
      "epoch": 9.63,
      "grad_norm": 54.0,
      "learning_rate": 5.580474934036939e-06,
      "loss": 0.6094,
      "step": 7298
    },
    {
      "epoch": 9.63,
      "grad_norm": 13.625,
      "learning_rate": 5.560686015831134e-06,
      "loss": 0.1602,
      "step": 7299
    },
    {
      "epoch": 9.63,
      "grad_norm": 12.0,
      "learning_rate": 5.540897097625329e-06,
      "loss": 0.0359,
      "step": 7300
    },
    {
      "epoch": 9.63,
      "grad_norm": 330.0,
      "learning_rate": 5.521108179419524e-06,
      "loss": 6.7812,
      "step": 7301
    },
    {
      "epoch": 9.63,
      "grad_norm": 3.75,
      "learning_rate": 5.50131926121372e-06,
      "loss": 0.0299,
      "step": 7302
    },
    {
      "epoch": 9.63,
      "grad_norm": 53.0,
      "learning_rate": 5.481530343007915e-06,
      "loss": 0.8477,
      "step": 7303
    },
    {
      "epoch": 9.64,
      "grad_norm": 199.0,
      "learning_rate": 5.461741424802111e-06,
      "loss": 2.6719,
      "step": 7304
    },
    {
      "epoch": 9.64,
      "grad_norm": 5.0625,
      "learning_rate": 5.441952506596305e-06,
      "loss": 0.0498,
      "step": 7305
    },
    {
      "epoch": 9.64,
      "grad_norm": 13.5,
      "learning_rate": 5.422163588390501e-06,
      "loss": 0.0991,
      "step": 7306
    },
    {
      "epoch": 9.64,
      "grad_norm": 27.75,
      "learning_rate": 5.4023746701846955e-06,
      "loss": 0.6602,
      "step": 7307
    },
    {
      "epoch": 9.64,
      "grad_norm": 121.5,
      "learning_rate": 5.382585751978892e-06,
      "loss": 2.3594,
      "step": 7308
    },
    {
      "epoch": 9.64,
      "grad_norm": 2.75,
      "learning_rate": 5.3627968337730865e-06,
      "loss": 0.0141,
      "step": 7309
    },
    {
      "epoch": 9.64,
      "grad_norm": 17.5,
      "learning_rate": 5.343007915567282e-06,
      "loss": 0.1621,
      "step": 7310
    },
    {
      "epoch": 9.65,
      "grad_norm": 63.75,
      "learning_rate": 5.323218997361477e-06,
      "loss": 0.2734,
      "step": 7311
    },
    {
      "epoch": 9.65,
      "grad_norm": 28.625,
      "learning_rate": 5.303430079155673e-06,
      "loss": 0.2754,
      "step": 7312
    },
    {
      "epoch": 9.65,
      "grad_norm": 25.375,
      "learning_rate": 5.283641160949868e-06,
      "loss": 0.6484,
      "step": 7313
    },
    {
      "epoch": 9.65,
      "grad_norm": 312.0,
      "learning_rate": 5.263852242744062e-06,
      "loss": 2.875,
      "step": 7314
    },
    {
      "epoch": 9.65,
      "grad_norm": 88.0,
      "learning_rate": 5.244063324538258e-06,
      "loss": 0.7539,
      "step": 7315
    },
    {
      "epoch": 9.65,
      "grad_norm": 68.5,
      "learning_rate": 5.224274406332453e-06,
      "loss": 0.5078,
      "step": 7316
    },
    {
      "epoch": 9.65,
      "grad_norm": 3.6875,
      "learning_rate": 5.204485488126649e-06,
      "loss": 0.0275,
      "step": 7317
    },
    {
      "epoch": 9.65,
      "grad_norm": 106.0,
      "learning_rate": 5.184696569920844e-06,
      "loss": 1.3828,
      "step": 7318
    },
    {
      "epoch": 9.66,
      "grad_norm": 90.0,
      "learning_rate": 5.164907651715039e-06,
      "loss": 1.8047,
      "step": 7319
    },
    {
      "epoch": 9.66,
      "grad_norm": 26.625,
      "learning_rate": 5.145118733509234e-06,
      "loss": 0.4219,
      "step": 7320
    },
    {
      "epoch": 9.66,
      "grad_norm": 200.0,
      "learning_rate": 5.12532981530343e-06,
      "loss": 0.7969,
      "step": 7321
    },
    {
      "epoch": 9.66,
      "grad_norm": 9.875,
      "learning_rate": 5.105540897097625e-06,
      "loss": 0.063,
      "step": 7322
    },
    {
      "epoch": 9.66,
      "grad_norm": 109.0,
      "learning_rate": 5.08575197889182e-06,
      "loss": 2.0625,
      "step": 7323
    },
    {
      "epoch": 9.66,
      "grad_norm": 18.375,
      "learning_rate": 5.065963060686015e-06,
      "loss": 0.2676,
      "step": 7324
    },
    {
      "epoch": 9.66,
      "grad_norm": 255.0,
      "learning_rate": 5.0461741424802114e-06,
      "loss": 4.3125,
      "step": 7325
    },
    {
      "epoch": 9.66,
      "grad_norm": 5.125,
      "learning_rate": 5.026385224274406e-06,
      "loss": 0.0157,
      "step": 7326
    },
    {
      "epoch": 9.67,
      "grad_norm": 12.5625,
      "learning_rate": 5.006596306068602e-06,
      "loss": 0.0703,
      "step": 7327
    },
    {
      "epoch": 9.67,
      "grad_norm": 107.5,
      "learning_rate": 4.986807387862796e-06,
      "loss": 2.25,
      "step": 7328
    },
    {
      "epoch": 9.67,
      "grad_norm": 2.234375,
      "learning_rate": 4.967018469656992e-06,
      "loss": 0.0182,
      "step": 7329
    },
    {
      "epoch": 9.67,
      "grad_norm": 130.0,
      "learning_rate": 4.947229551451187e-06,
      "loss": 2.0625,
      "step": 7330
    },
    {
      "epoch": 9.67,
      "grad_norm": 97.0,
      "learning_rate": 4.927440633245382e-06,
      "loss": 1.4375,
      "step": 7331
    },
    {
      "epoch": 9.67,
      "grad_norm": 93.5,
      "learning_rate": 4.9076517150395775e-06,
      "loss": 2.4688,
      "step": 7332
    },
    {
      "epoch": 9.67,
      "grad_norm": 15.125,
      "learning_rate": 4.887862796833772e-06,
      "loss": 0.0728,
      "step": 7333
    },
    {
      "epoch": 9.68,
      "grad_norm": 18.375,
      "learning_rate": 4.868073878627968e-06,
      "loss": 0.167,
      "step": 7334
    },
    {
      "epoch": 9.68,
      "grad_norm": 2.375,
      "learning_rate": 4.848284960422163e-06,
      "loss": 0.0209,
      "step": 7335
    },
    {
      "epoch": 9.68,
      "grad_norm": 8.8125,
      "learning_rate": 4.828496042216359e-06,
      "loss": 0.0503,
      "step": 7336
    },
    {
      "epoch": 9.68,
      "grad_norm": 70.0,
      "learning_rate": 4.808707124010553e-06,
      "loss": 1.5547,
      "step": 7337
    },
    {
      "epoch": 9.68,
      "grad_norm": 9.5625,
      "learning_rate": 4.788918205804749e-06,
      "loss": 0.0815,
      "step": 7338
    },
    {
      "epoch": 9.68,
      "grad_norm": 37.75,
      "learning_rate": 4.769129287598944e-06,
      "loss": 0.2412,
      "step": 7339
    },
    {
      "epoch": 9.68,
      "grad_norm": 96.0,
      "learning_rate": 4.74934036939314e-06,
      "loss": 1.25,
      "step": 7340
    },
    {
      "epoch": 9.68,
      "grad_norm": 18.0,
      "learning_rate": 4.729551451187335e-06,
      "loss": 0.3633,
      "step": 7341
    },
    {
      "epoch": 9.69,
      "grad_norm": 28.875,
      "learning_rate": 4.70976253298153e-06,
      "loss": 1.3359,
      "step": 7342
    },
    {
      "epoch": 9.69,
      "grad_norm": 54.0,
      "learning_rate": 4.689973614775725e-06,
      "loss": 0.5,
      "step": 7343
    },
    {
      "epoch": 9.69,
      "grad_norm": 11.75,
      "learning_rate": 4.67018469656992e-06,
      "loss": 0.0554,
      "step": 7344
    },
    {
      "epoch": 9.69,
      "grad_norm": 30.25,
      "learning_rate": 4.650395778364116e-06,
      "loss": 0.3574,
      "step": 7345
    },
    {
      "epoch": 9.69,
      "grad_norm": 29.875,
      "learning_rate": 4.630606860158311e-06,
      "loss": 0.3906,
      "step": 7346
    },
    {
      "epoch": 9.69,
      "grad_norm": 125.5,
      "learning_rate": 4.610817941952506e-06,
      "loss": 5.8438,
      "step": 7347
    },
    {
      "epoch": 9.69,
      "grad_norm": 127.0,
      "learning_rate": 4.591029023746702e-06,
      "loss": 0.9609,
      "step": 7348
    },
    {
      "epoch": 9.7,
      "grad_norm": 4.84375,
      "learning_rate": 4.571240105540897e-06,
      "loss": 0.0449,
      "step": 7349
    },
    {
      "epoch": 9.7,
      "grad_norm": 169.0,
      "learning_rate": 4.551451187335092e-06,
      "loss": 1.7109,
      "step": 7350
    },
    {
      "epoch": 9.7,
      "grad_norm": 176.0,
      "learning_rate": 4.531662269129287e-06,
      "loss": 3.0,
      "step": 7351
    },
    {
      "epoch": 9.7,
      "grad_norm": 12.25,
      "learning_rate": 4.511873350923483e-06,
      "loss": 0.0444,
      "step": 7352
    },
    {
      "epoch": 9.7,
      "grad_norm": 1.859375,
      "learning_rate": 4.4920844327176775e-06,
      "loss": 0.0178,
      "step": 7353
    },
    {
      "epoch": 9.7,
      "grad_norm": 45.75,
      "learning_rate": 4.472295514511873e-06,
      "loss": 0.7734,
      "step": 7354
    },
    {
      "epoch": 9.7,
      "grad_norm": 60.5,
      "learning_rate": 4.452506596306068e-06,
      "loss": 0.1914,
      "step": 7355
    },
    {
      "epoch": 9.7,
      "grad_norm": 6.65625,
      "learning_rate": 4.432717678100263e-06,
      "loss": 0.062,
      "step": 7356
    },
    {
      "epoch": 9.71,
      "grad_norm": 24.125,
      "learning_rate": 4.412928759894459e-06,
      "loss": 0.5078,
      "step": 7357
    },
    {
      "epoch": 9.71,
      "grad_norm": 95.0,
      "learning_rate": 4.393139841688654e-06,
      "loss": 1.8672,
      "step": 7358
    },
    {
      "epoch": 9.71,
      "grad_norm": 25.75,
      "learning_rate": 4.373350923482849e-06,
      "loss": 0.2412,
      "step": 7359
    },
    {
      "epoch": 9.71,
      "grad_norm": 30.75,
      "learning_rate": 4.353562005277044e-06,
      "loss": 0.0588,
      "step": 7360
    },
    {
      "epoch": 9.71,
      "grad_norm": 114.5,
      "learning_rate": 4.33377308707124e-06,
      "loss": 0.6875,
      "step": 7361
    },
    {
      "epoch": 9.71,
      "grad_norm": 22.625,
      "learning_rate": 4.313984168865435e-06,
      "loss": 0.0967,
      "step": 7362
    },
    {
      "epoch": 9.71,
      "grad_norm": 120.5,
      "learning_rate": 4.29419525065963e-06,
      "loss": 2.3281,
      "step": 7363
    },
    {
      "epoch": 9.72,
      "grad_norm": 17.125,
      "learning_rate": 4.274406332453826e-06,
      "loss": 0.4473,
      "step": 7364
    },
    {
      "epoch": 9.72,
      "grad_norm": 38.75,
      "learning_rate": 4.254617414248021e-06,
      "loss": 0.1855,
      "step": 7365
    },
    {
      "epoch": 9.72,
      "grad_norm": 120.0,
      "learning_rate": 4.234828496042216e-06,
      "loss": 2.7031,
      "step": 7366
    },
    {
      "epoch": 9.72,
      "grad_norm": 20.25,
      "learning_rate": 4.215039577836411e-06,
      "loss": 0.1504,
      "step": 7367
    },
    {
      "epoch": 9.72,
      "grad_norm": 164.0,
      "learning_rate": 4.195250659630607e-06,
      "loss": 0.9648,
      "step": 7368
    },
    {
      "epoch": 9.72,
      "grad_norm": 226.0,
      "learning_rate": 4.1754617414248015e-06,
      "loss": 1.1953,
      "step": 7369
    },
    {
      "epoch": 9.72,
      "grad_norm": 380.0,
      "learning_rate": 4.155672823218997e-06,
      "loss": 5.625,
      "step": 7370
    },
    {
      "epoch": 9.72,
      "grad_norm": 334.0,
      "learning_rate": 4.135883905013192e-06,
      "loss": 2.0,
      "step": 7371
    },
    {
      "epoch": 9.73,
      "grad_norm": 5.34375,
      "learning_rate": 4.116094986807387e-06,
      "loss": 0.0337,
      "step": 7372
    },
    {
      "epoch": 9.73,
      "grad_norm": 50.25,
      "learning_rate": 4.096306068601583e-06,
      "loss": 1.0156,
      "step": 7373
    },
    {
      "epoch": 9.73,
      "grad_norm": 65.0,
      "learning_rate": 4.076517150395778e-06,
      "loss": 0.3164,
      "step": 7374
    },
    {
      "epoch": 9.73,
      "grad_norm": 142.0,
      "learning_rate": 4.056728232189973e-06,
      "loss": 2.4062,
      "step": 7375
    },
    {
      "epoch": 9.73,
      "grad_norm": 22.75,
      "learning_rate": 4.0369393139841685e-06,
      "loss": 0.2715,
      "step": 7376
    },
    {
      "epoch": 9.73,
      "grad_norm": 29.625,
      "learning_rate": 4.017150395778364e-06,
      "loss": 0.6406,
      "step": 7377
    },
    {
      "epoch": 9.73,
      "grad_norm": 20.625,
      "learning_rate": 3.997361477572559e-06,
      "loss": 0.4004,
      "step": 7378
    },
    {
      "epoch": 9.73,
      "grad_norm": 36.5,
      "learning_rate": 3.977572559366754e-06,
      "loss": 0.2373,
      "step": 7379
    },
    {
      "epoch": 9.74,
      "grad_norm": 112.0,
      "learning_rate": 3.95778364116095e-06,
      "loss": 2.4844,
      "step": 7380
    },
    {
      "epoch": 9.74,
      "grad_norm": 20.875,
      "learning_rate": 3.937994722955145e-06,
      "loss": 0.1226,
      "step": 7381
    },
    {
      "epoch": 9.74,
      "grad_norm": 9.25,
      "learning_rate": 3.91820580474934e-06,
      "loss": 0.0569,
      "step": 7382
    },
    {
      "epoch": 9.74,
      "grad_norm": 85.0,
      "learning_rate": 3.898416886543535e-06,
      "loss": 1.5625,
      "step": 7383
    },
    {
      "epoch": 9.74,
      "grad_norm": 39.75,
      "learning_rate": 3.878627968337731e-06,
      "loss": 0.3555,
      "step": 7384
    },
    {
      "epoch": 9.74,
      "grad_norm": 23.875,
      "learning_rate": 3.858839050131926e-06,
      "loss": 0.6289,
      "step": 7385
    },
    {
      "epoch": 9.74,
      "grad_norm": 398.0,
      "learning_rate": 3.839050131926121e-06,
      "loss": 4.0938,
      "step": 7386
    },
    {
      "epoch": 9.75,
      "grad_norm": 30.25,
      "learning_rate": 3.819261213720316e-06,
      "loss": 0.0513,
      "step": 7387
    },
    {
      "epoch": 9.75,
      "grad_norm": 85.5,
      "learning_rate": 3.7994722955145113e-06,
      "loss": 0.8477,
      "step": 7388
    },
    {
      "epoch": 9.75,
      "grad_norm": 21.625,
      "learning_rate": 3.779683377308707e-06,
      "loss": 0.7695,
      "step": 7389
    },
    {
      "epoch": 9.75,
      "grad_norm": 232.0,
      "learning_rate": 3.759894459102902e-06,
      "loss": 8.3125,
      "step": 7390
    },
    {
      "epoch": 9.75,
      "grad_norm": 25.375,
      "learning_rate": 3.7401055408970974e-06,
      "loss": 0.1826,
      "step": 7391
    },
    {
      "epoch": 9.75,
      "grad_norm": 17.375,
      "learning_rate": 3.7203166226912925e-06,
      "loss": 0.0742,
      "step": 7392
    },
    {
      "epoch": 9.75,
      "grad_norm": 28.375,
      "learning_rate": 3.700527704485488e-06,
      "loss": 0.2949,
      "step": 7393
    },
    {
      "epoch": 9.75,
      "grad_norm": 144.0,
      "learning_rate": 3.680738786279683e-06,
      "loss": 1.8125,
      "step": 7394
    },
    {
      "epoch": 9.76,
      "grad_norm": 29.375,
      "learning_rate": 3.6609498680738782e-06,
      "loss": 0.4277,
      "step": 7395
    },
    {
      "epoch": 9.76,
      "grad_norm": 4.875,
      "learning_rate": 3.6411609498680738e-06,
      "loss": 0.0427,
      "step": 7396
    },
    {
      "epoch": 9.76,
      "grad_norm": 22.375,
      "learning_rate": 3.621372031662269e-06,
      "loss": 0.1177,
      "step": 7397
    },
    {
      "epoch": 9.76,
      "grad_norm": 26.875,
      "learning_rate": 3.6015831134564644e-06,
      "loss": 0.4844,
      "step": 7398
    },
    {
      "epoch": 9.76,
      "grad_norm": 23.625,
      "learning_rate": 3.5817941952506595e-06,
      "loss": 0.1553,
      "step": 7399
    },
    {
      "epoch": 9.76,
      "grad_norm": 3.203125,
      "learning_rate": 3.562005277044854e-06,
      "loss": 0.0231,
      "step": 7400
    },
    {
      "epoch": 9.76,
      "grad_norm": 14.3125,
      "learning_rate": 3.5422163588390496e-06,
      "loss": 0.1211,
      "step": 7401
    },
    {
      "epoch": 9.77,
      "grad_norm": 52.75,
      "learning_rate": 3.5224274406332447e-06,
      "loss": 0.334,
      "step": 7402
    },
    {
      "epoch": 9.77,
      "grad_norm": 16.875,
      "learning_rate": 3.5026385224274403e-06,
      "loss": 0.3555,
      "step": 7403
    },
    {
      "epoch": 9.77,
      "grad_norm": 37.25,
      "learning_rate": 3.4828496042216354e-06,
      "loss": 0.2852,
      "step": 7404
    },
    {
      "epoch": 9.77,
      "grad_norm": 13.3125,
      "learning_rate": 3.463060686015831e-06,
      "loss": 0.0913,
      "step": 7405
    },
    {
      "epoch": 9.77,
      "grad_norm": 23.125,
      "learning_rate": 3.443271767810026e-06,
      "loss": 0.2246,
      "step": 7406
    },
    {
      "epoch": 9.77,
      "grad_norm": 0.90234375,
      "learning_rate": 3.4234828496042215e-06,
      "loss": 0.01,
      "step": 7407
    },
    {
      "epoch": 9.77,
      "grad_norm": 24.125,
      "learning_rate": 3.4036939313984166e-06,
      "loss": 0.2559,
      "step": 7408
    },
    {
      "epoch": 9.77,
      "grad_norm": 7.46875,
      "learning_rate": 3.3839050131926117e-06,
      "loss": 0.0325,
      "step": 7409
    },
    {
      "epoch": 9.78,
      "grad_norm": 34.5,
      "learning_rate": 3.364116094986807e-06,
      "loss": 0.5703,
      "step": 7410
    },
    {
      "epoch": 9.78,
      "grad_norm": 26.125,
      "learning_rate": 3.3443271767810023e-06,
      "loss": 0.2324,
      "step": 7411
    },
    {
      "epoch": 9.78,
      "grad_norm": 216.0,
      "learning_rate": 3.324538258575198e-06,
      "loss": 2.875,
      "step": 7412
    },
    {
      "epoch": 9.78,
      "grad_norm": 0.921875,
      "learning_rate": 3.304749340369393e-06,
      "loss": 0.0107,
      "step": 7413
    },
    {
      "epoch": 9.78,
      "grad_norm": 5.5625,
      "learning_rate": 3.2849604221635884e-06,
      "loss": 0.0496,
      "step": 7414
    },
    {
      "epoch": 9.78,
      "grad_norm": 250.0,
      "learning_rate": 3.2651715039577835e-06,
      "loss": 4.0625,
      "step": 7415
    },
    {
      "epoch": 9.78,
      "grad_norm": 184.0,
      "learning_rate": 3.245382585751978e-06,
      "loss": 2.7031,
      "step": 7416
    },
    {
      "epoch": 9.78,
      "grad_norm": 15.4375,
      "learning_rate": 3.2255936675461737e-06,
      "loss": 0.0762,
      "step": 7417
    },
    {
      "epoch": 9.79,
      "grad_norm": 86.0,
      "learning_rate": 3.205804749340369e-06,
      "loss": 0.7539,
      "step": 7418
    },
    {
      "epoch": 9.79,
      "grad_norm": 41.25,
      "learning_rate": 3.1860158311345643e-06,
      "loss": 0.9688,
      "step": 7419
    },
    {
      "epoch": 9.79,
      "grad_norm": 58.0,
      "learning_rate": 3.1662269129287594e-06,
      "loss": 1.0859,
      "step": 7420
    },
    {
      "epoch": 9.79,
      "grad_norm": 29.0,
      "learning_rate": 3.146437994722955e-06,
      "loss": 0.1094,
      "step": 7421
    },
    {
      "epoch": 9.79,
      "grad_norm": 10.3125,
      "learning_rate": 3.12664907651715e-06,
      "loss": 0.1182,
      "step": 7422
    },
    {
      "epoch": 9.79,
      "grad_norm": 5.3125,
      "learning_rate": 3.1068601583113455e-06,
      "loss": 0.0408,
      "step": 7423
    },
    {
      "epoch": 9.79,
      "grad_norm": 152.0,
      "learning_rate": 3.0870712401055406e-06,
      "loss": 3.3906,
      "step": 7424
    },
    {
      "epoch": 9.8,
      "grad_norm": 21.375,
      "learning_rate": 3.0672823218997357e-06,
      "loss": 1.2969,
      "step": 7425
    },
    {
      "epoch": 9.8,
      "grad_norm": 310.0,
      "learning_rate": 3.0474934036939313e-06,
      "loss": 3.4375,
      "step": 7426
    },
    {
      "epoch": 9.8,
      "grad_norm": 225.0,
      "learning_rate": 3.0277044854881264e-06,
      "loss": 0.8164,
      "step": 7427
    },
    {
      "epoch": 9.8,
      "grad_norm": 6.875,
      "learning_rate": 3.007915567282322e-06,
      "loss": 0.0659,
      "step": 7428
    },
    {
      "epoch": 9.8,
      "grad_norm": 18.5,
      "learning_rate": 2.988126649076517e-06,
      "loss": 0.0613,
      "step": 7429
    },
    {
      "epoch": 9.8,
      "grad_norm": 123.0,
      "learning_rate": 2.9683377308707125e-06,
      "loss": 1.6094,
      "step": 7430
    },
    {
      "epoch": 9.8,
      "grad_norm": 132.0,
      "learning_rate": 2.9485488126649076e-06,
      "loss": 2.9375,
      "step": 7431
    },
    {
      "epoch": 9.8,
      "grad_norm": 113.5,
      "learning_rate": 2.9287598944591022e-06,
      "loss": 2.1719,
      "step": 7432
    },
    {
      "epoch": 9.81,
      "grad_norm": 7.875,
      "learning_rate": 2.9089709762532978e-06,
      "loss": 0.0623,
      "step": 7433
    },
    {
      "epoch": 9.81,
      "grad_norm": 23.0,
      "learning_rate": 2.889182058047493e-06,
      "loss": 0.3457,
      "step": 7434
    },
    {
      "epoch": 9.81,
      "grad_norm": 207.0,
      "learning_rate": 2.8693931398416884e-06,
      "loss": 5.1875,
      "step": 7435
    },
    {
      "epoch": 9.81,
      "grad_norm": 139.0,
      "learning_rate": 2.8496042216358835e-06,
      "loss": 2.4531,
      "step": 7436
    },
    {
      "epoch": 9.81,
      "grad_norm": 10.0,
      "learning_rate": 2.829815303430079e-06,
      "loss": 0.1133,
      "step": 7437
    },
    {
      "epoch": 9.81,
      "grad_norm": 34.5,
      "learning_rate": 2.810026385224274e-06,
      "loss": 0.7852,
      "step": 7438
    },
    {
      "epoch": 9.81,
      "grad_norm": 25.375,
      "learning_rate": 2.7902374670184696e-06,
      "loss": 0.1992,
      "step": 7439
    },
    {
      "epoch": 9.82,
      "grad_norm": 6.53125,
      "learning_rate": 2.7704485488126647e-06,
      "loss": 0.0566,
      "step": 7440
    },
    {
      "epoch": 9.82,
      "grad_norm": 16.5,
      "learning_rate": 2.75065963060686e-06,
      "loss": 0.2598,
      "step": 7441
    },
    {
      "epoch": 9.82,
      "grad_norm": 53.75,
      "learning_rate": 2.7308707124010553e-06,
      "loss": 0.6094,
      "step": 7442
    },
    {
      "epoch": 9.82,
      "grad_norm": 5.0,
      "learning_rate": 2.7110817941952504e-06,
      "loss": 0.0483,
      "step": 7443
    },
    {
      "epoch": 9.82,
      "grad_norm": 19.375,
      "learning_rate": 2.691292875989446e-06,
      "loss": 0.1846,
      "step": 7444
    },
    {
      "epoch": 9.82,
      "grad_norm": 151.0,
      "learning_rate": 2.671503957783641e-06,
      "loss": 1.3672,
      "step": 7445
    },
    {
      "epoch": 9.82,
      "grad_norm": 1.6484375,
      "learning_rate": 2.6517150395778365e-06,
      "loss": 0.0134,
      "step": 7446
    },
    {
      "epoch": 9.82,
      "grad_norm": 132.0,
      "learning_rate": 2.631926121372031e-06,
      "loss": 1.9688,
      "step": 7447
    },
    {
      "epoch": 9.83,
      "grad_norm": 152.0,
      "learning_rate": 2.6121372031662263e-06,
      "loss": 2.5,
      "step": 7448
    },
    {
      "epoch": 9.83,
      "grad_norm": 3.671875,
      "learning_rate": 2.592348284960422e-06,
      "loss": 0.0201,
      "step": 7449
    },
    {
      "epoch": 9.83,
      "grad_norm": 219.0,
      "learning_rate": 2.572559366754617e-06,
      "loss": 1.6484,
      "step": 7450
    },
    {
      "epoch": 9.83,
      "grad_norm": 139.0,
      "learning_rate": 2.5527704485488124e-06,
      "loss": 2.625,
      "step": 7451
    },
    {
      "epoch": 9.83,
      "grad_norm": 49.75,
      "learning_rate": 2.5329815303430075e-06,
      "loss": 0.2344,
      "step": 7452
    },
    {
      "epoch": 9.83,
      "grad_norm": 5.3125,
      "learning_rate": 2.513192612137203e-06,
      "loss": 0.0378,
      "step": 7453
    },
    {
      "epoch": 9.83,
      "grad_norm": 10.75,
      "learning_rate": 2.493403693931398e-06,
      "loss": 0.168,
      "step": 7454
    },
    {
      "epoch": 9.84,
      "grad_norm": 113.0,
      "learning_rate": 2.4736147757255937e-06,
      "loss": 0.8047,
      "step": 7455
    },
    {
      "epoch": 9.84,
      "grad_norm": 167.0,
      "learning_rate": 2.4538258575197888e-06,
      "loss": 1.7734,
      "step": 7456
    },
    {
      "epoch": 9.84,
      "grad_norm": 42.25,
      "learning_rate": 2.434036939313984e-06,
      "loss": 0.6172,
      "step": 7457
    },
    {
      "epoch": 9.84,
      "grad_norm": 132.0,
      "learning_rate": 2.4142480211081794e-06,
      "loss": 1.4844,
      "step": 7458
    },
    {
      "epoch": 9.84,
      "grad_norm": 80.0,
      "learning_rate": 2.3944591029023745e-06,
      "loss": 0.4551,
      "step": 7459
    },
    {
      "epoch": 9.84,
      "grad_norm": 122.5,
      "learning_rate": 2.37467018469657e-06,
      "loss": 0.957,
      "step": 7460
    },
    {
      "epoch": 9.84,
      "grad_norm": 17.125,
      "learning_rate": 2.354881266490765e-06,
      "loss": 0.1055,
      "step": 7461
    },
    {
      "epoch": 9.84,
      "grad_norm": 13.625,
      "learning_rate": 2.33509234828496e-06,
      "loss": 0.0913,
      "step": 7462
    },
    {
      "epoch": 9.85,
      "grad_norm": 233.0,
      "learning_rate": 2.3153034300791557e-06,
      "loss": 3.5781,
      "step": 7463
    },
    {
      "epoch": 9.85,
      "grad_norm": 17.75,
      "learning_rate": 2.295514511873351e-06,
      "loss": 0.1865,
      "step": 7464
    },
    {
      "epoch": 9.85,
      "grad_norm": 73.5,
      "learning_rate": 2.275725593667546e-06,
      "loss": 1.0312,
      "step": 7465
    },
    {
      "epoch": 9.85,
      "grad_norm": 25.125,
      "learning_rate": 2.2559366754617414e-06,
      "loss": 0.3203,
      "step": 7466
    },
    {
      "epoch": 9.85,
      "grad_norm": 8.0,
      "learning_rate": 2.2361477572559365e-06,
      "loss": 0.0593,
      "step": 7467
    },
    {
      "epoch": 9.85,
      "grad_norm": 109.5,
      "learning_rate": 2.2163588390501316e-06,
      "loss": 2.5469,
      "step": 7468
    },
    {
      "epoch": 9.85,
      "grad_norm": 8.8125,
      "learning_rate": 2.196569920844327e-06,
      "loss": 0.0659,
      "step": 7469
    },
    {
      "epoch": 9.85,
      "grad_norm": 10.9375,
      "learning_rate": 2.176781002638522e-06,
      "loss": 0.0654,
      "step": 7470
    },
    {
      "epoch": 9.86,
      "grad_norm": 208.0,
      "learning_rate": 2.1569920844327173e-06,
      "loss": 2.7969,
      "step": 7471
    },
    {
      "epoch": 9.86,
      "grad_norm": 105.0,
      "learning_rate": 2.137203166226913e-06,
      "loss": 0.4512,
      "step": 7472
    },
    {
      "epoch": 9.86,
      "grad_norm": 12.0,
      "learning_rate": 2.117414248021108e-06,
      "loss": 0.063,
      "step": 7473
    },
    {
      "epoch": 9.86,
      "grad_norm": 1.6328125,
      "learning_rate": 2.0976253298153034e-06,
      "loss": 0.0192,
      "step": 7474
    },
    {
      "epoch": 9.86,
      "grad_norm": 364.0,
      "learning_rate": 2.0778364116094985e-06,
      "loss": 4.625,
      "step": 7475
    },
    {
      "epoch": 9.86,
      "grad_norm": 13.0,
      "learning_rate": 2.0580474934036936e-06,
      "loss": 0.1514,
      "step": 7476
    },
    {
      "epoch": 9.86,
      "grad_norm": 178.0,
      "learning_rate": 2.038258575197889e-06,
      "loss": 4.625,
      "step": 7477
    },
    {
      "epoch": 9.87,
      "grad_norm": 46.25,
      "learning_rate": 2.0184696569920842e-06,
      "loss": 0.2471,
      "step": 7478
    },
    {
      "epoch": 9.87,
      "grad_norm": 126.5,
      "learning_rate": 1.9986807387862793e-06,
      "loss": 2.6406,
      "step": 7479
    },
    {
      "epoch": 9.87,
      "grad_norm": 146.0,
      "learning_rate": 1.978891820580475e-06,
      "loss": 3.4531,
      "step": 7480
    },
    {
      "epoch": 9.87,
      "grad_norm": 31.125,
      "learning_rate": 1.95910290237467e-06,
      "loss": 0.8984,
      "step": 7481
    },
    {
      "epoch": 9.87,
      "grad_norm": 114.5,
      "learning_rate": 1.9393139841688655e-06,
      "loss": 1.0469,
      "step": 7482
    },
    {
      "epoch": 9.87,
      "grad_norm": 7.53125,
      "learning_rate": 1.9195250659630606e-06,
      "loss": 0.0679,
      "step": 7483
    },
    {
      "epoch": 9.87,
      "grad_norm": 0.412109375,
      "learning_rate": 1.8997361477572556e-06,
      "loss": 0.0044,
      "step": 7484
    },
    {
      "epoch": 9.87,
      "grad_norm": 158.0,
      "learning_rate": 1.879947229551451e-06,
      "loss": 8.0,
      "step": 7485
    },
    {
      "epoch": 9.88,
      "grad_norm": 21.875,
      "learning_rate": 1.8601583113456463e-06,
      "loss": 0.3613,
      "step": 7486
    },
    {
      "epoch": 9.88,
      "grad_norm": 175.0,
      "learning_rate": 1.8403693931398416e-06,
      "loss": 2.4688,
      "step": 7487
    },
    {
      "epoch": 9.88,
      "grad_norm": 28.25,
      "learning_rate": 1.8205804749340369e-06,
      "loss": 0.1494,
      "step": 7488
    },
    {
      "epoch": 9.88,
      "grad_norm": 106.0,
      "learning_rate": 1.8007915567282322e-06,
      "loss": 1.25,
      "step": 7489
    },
    {
      "epoch": 9.88,
      "grad_norm": 35.5,
      "learning_rate": 1.781002638522427e-06,
      "loss": 0.5703,
      "step": 7490
    },
    {
      "epoch": 9.88,
      "grad_norm": 5.375,
      "learning_rate": 1.7612137203166224e-06,
      "loss": 0.0425,
      "step": 7491
    },
    {
      "epoch": 9.88,
      "grad_norm": 41.25,
      "learning_rate": 1.7414248021108177e-06,
      "loss": 0.4688,
      "step": 7492
    },
    {
      "epoch": 9.89,
      "grad_norm": 101.5,
      "learning_rate": 1.721635883905013e-06,
      "loss": 0.7891,
      "step": 7493
    },
    {
      "epoch": 9.89,
      "grad_norm": 23.5,
      "learning_rate": 1.7018469656992083e-06,
      "loss": 0.6797,
      "step": 7494
    },
    {
      "epoch": 9.89,
      "grad_norm": 39.5,
      "learning_rate": 1.6820580474934036e-06,
      "loss": 0.3613,
      "step": 7495
    },
    {
      "epoch": 9.89,
      "grad_norm": 12.6875,
      "learning_rate": 1.662269129287599e-06,
      "loss": 0.0986,
      "step": 7496
    },
    {
      "epoch": 9.89,
      "grad_norm": 21.5,
      "learning_rate": 1.6424802110817942e-06,
      "loss": 0.9648,
      "step": 7497
    },
    {
      "epoch": 9.89,
      "grad_norm": 147.0,
      "learning_rate": 1.622691292875989e-06,
      "loss": 1.4766,
      "step": 7498
    },
    {
      "epoch": 9.89,
      "grad_norm": 60.75,
      "learning_rate": 1.6029023746701844e-06,
      "loss": 0.2188,
      "step": 7499
    },
    {
      "epoch": 9.89,
      "grad_norm": 20.25,
      "learning_rate": 1.5831134564643797e-06,
      "loss": 0.3242,
      "step": 7500
    },
    {
      "epoch": 9.9,
      "grad_norm": 23.25,
      "learning_rate": 1.563324538258575e-06,
      "loss": 0.1484,
      "step": 7501
    },
    {
      "epoch": 9.9,
      "grad_norm": 114.0,
      "learning_rate": 1.5435356200527703e-06,
      "loss": 2.3438,
      "step": 7502
    },
    {
      "epoch": 9.9,
      "grad_norm": 53.5,
      "learning_rate": 1.5237467018469656e-06,
      "loss": 0.2178,
      "step": 7503
    },
    {
      "epoch": 9.9,
      "grad_norm": 141.0,
      "learning_rate": 1.503957783641161e-06,
      "loss": 3.5938,
      "step": 7504
    },
    {
      "epoch": 9.9,
      "grad_norm": 90.0,
      "learning_rate": 1.4841688654353562e-06,
      "loss": 0.2598,
      "step": 7505
    },
    {
      "epoch": 9.9,
      "grad_norm": 7.5,
      "learning_rate": 1.4643799472295511e-06,
      "loss": 0.0469,
      "step": 7506
    },
    {
      "epoch": 9.9,
      "grad_norm": 136.0,
      "learning_rate": 1.4445910290237464e-06,
      "loss": 2.7031,
      "step": 7507
    },
    {
      "epoch": 9.91,
      "grad_norm": 5.09375,
      "learning_rate": 1.4248021108179417e-06,
      "loss": 0.0393,
      "step": 7508
    },
    {
      "epoch": 9.91,
      "grad_norm": 229.0,
      "learning_rate": 1.405013192612137e-06,
      "loss": 2.7344,
      "step": 7509
    },
    {
      "epoch": 9.91,
      "grad_norm": 22.125,
      "learning_rate": 1.3852242744063324e-06,
      "loss": 0.8359,
      "step": 7510
    },
    {
      "epoch": 9.91,
      "grad_norm": 42.5,
      "learning_rate": 1.3654353562005277e-06,
      "loss": 0.1611,
      "step": 7511
    },
    {
      "epoch": 9.91,
      "grad_norm": 13.125,
      "learning_rate": 1.345646437994723e-06,
      "loss": 0.0938,
      "step": 7512
    },
    {
      "epoch": 9.91,
      "grad_norm": 20.125,
      "learning_rate": 1.3258575197889183e-06,
      "loss": 0.1216,
      "step": 7513
    },
    {
      "epoch": 9.91,
      "grad_norm": 168.0,
      "learning_rate": 1.3060686015831132e-06,
      "loss": 2.4375,
      "step": 7514
    },
    {
      "epoch": 9.91,
      "grad_norm": 14.4375,
      "learning_rate": 1.2862796833773085e-06,
      "loss": 0.2324,
      "step": 7515
    },
    {
      "epoch": 9.92,
      "grad_norm": 39.0,
      "learning_rate": 1.2664907651715038e-06,
      "loss": 0.4688,
      "step": 7516
    },
    {
      "epoch": 9.92,
      "grad_norm": 20.125,
      "learning_rate": 1.246701846965699e-06,
      "loss": 0.3301,
      "step": 7517
    },
    {
      "epoch": 9.92,
      "grad_norm": 178.0,
      "learning_rate": 1.2269129287598944e-06,
      "loss": 3.9844,
      "step": 7518
    },
    {
      "epoch": 9.92,
      "grad_norm": 71.5,
      "learning_rate": 1.2071240105540897e-06,
      "loss": 0.209,
      "step": 7519
    },
    {
      "epoch": 9.92,
      "grad_norm": 196.0,
      "learning_rate": 1.187335092348285e-06,
      "loss": 2.1094,
      "step": 7520
    },
    {
      "epoch": 9.92,
      "grad_norm": 61.5,
      "learning_rate": 1.16754617414248e-06,
      "loss": 0.5703,
      "step": 7521
    },
    {
      "epoch": 9.92,
      "grad_norm": 35.5,
      "learning_rate": 1.1477572559366754e-06,
      "loss": 0.416,
      "step": 7522
    },
    {
      "epoch": 9.92,
      "grad_norm": 53.5,
      "learning_rate": 1.1279683377308707e-06,
      "loss": 0.2832,
      "step": 7523
    },
    {
      "epoch": 9.93,
      "grad_norm": 29.625,
      "learning_rate": 1.1081794195250658e-06,
      "loss": 0.4004,
      "step": 7524
    },
    {
      "epoch": 9.93,
      "grad_norm": 94.5,
      "learning_rate": 1.088390501319261e-06,
      "loss": 1.1797,
      "step": 7525
    },
    {
      "epoch": 9.93,
      "grad_norm": 141.0,
      "learning_rate": 1.0686015831134564e-06,
      "loss": 2.9688,
      "step": 7526
    },
    {
      "epoch": 9.93,
      "grad_norm": 60.5,
      "learning_rate": 1.0488126649076517e-06,
      "loss": 0.2314,
      "step": 7527
    },
    {
      "epoch": 9.93,
      "grad_norm": 37.0,
      "learning_rate": 1.0290237467018468e-06,
      "loss": 0.1797,
      "step": 7528
    },
    {
      "epoch": 9.93,
      "grad_norm": 16.25,
      "learning_rate": 1.0092348284960421e-06,
      "loss": 0.2393,
      "step": 7529
    },
    {
      "epoch": 9.93,
      "grad_norm": 122.0,
      "learning_rate": 9.894459102902374e-07,
      "loss": 2.5156,
      "step": 7530
    },
    {
      "epoch": 9.94,
      "grad_norm": 191.0,
      "learning_rate": 9.696569920844327e-07,
      "loss": 3.2969,
      "step": 7531
    },
    {
      "epoch": 9.94,
      "grad_norm": 120.5,
      "learning_rate": 9.498680738786278e-07,
      "loss": 1.4141,
      "step": 7532
    },
    {
      "epoch": 9.94,
      "grad_norm": 108.5,
      "learning_rate": 9.300791556728231e-07,
      "loss": 0.7812,
      "step": 7533
    },
    {
      "epoch": 9.94,
      "grad_norm": 207.0,
      "learning_rate": 9.102902374670184e-07,
      "loss": 1.9297,
      "step": 7534
    },
    {
      "epoch": 9.94,
      "grad_norm": 26.125,
      "learning_rate": 8.905013192612135e-07,
      "loss": 0.6094,
      "step": 7535
    },
    {
      "epoch": 9.94,
      "grad_norm": 87.0,
      "learning_rate": 8.707124010554088e-07,
      "loss": 1.3672,
      "step": 7536
    },
    {
      "epoch": 9.94,
      "grad_norm": 21.0,
      "learning_rate": 8.509234828496041e-07,
      "loss": 0.2373,
      "step": 7537
    },
    {
      "epoch": 9.94,
      "grad_norm": 3.484375,
      "learning_rate": 8.311345646437995e-07,
      "loss": 0.0332,
      "step": 7538
    },
    {
      "epoch": 9.95,
      "grad_norm": 144.0,
      "learning_rate": 8.113456464379945e-07,
      "loss": 2.2344,
      "step": 7539
    },
    {
      "epoch": 9.95,
      "grad_norm": 16.625,
      "learning_rate": 7.915567282321899e-07,
      "loss": 0.1279,
      "step": 7540
    },
    {
      "epoch": 9.95,
      "grad_norm": 149.0,
      "learning_rate": 7.717678100263852e-07,
      "loss": 1.8359,
      "step": 7541
    },
    {
      "epoch": 9.95,
      "grad_norm": 3.40625,
      "learning_rate": 7.519788918205805e-07,
      "loss": 0.017,
      "step": 7542
    },
    {
      "epoch": 9.95,
      "grad_norm": 4.9375,
      "learning_rate": 7.321899736147756e-07,
      "loss": 0.0486,
      "step": 7543
    },
    {
      "epoch": 9.95,
      "grad_norm": 170.0,
      "learning_rate": 7.124010554089709e-07,
      "loss": 1.3047,
      "step": 7544
    },
    {
      "epoch": 9.95,
      "grad_norm": 40.0,
      "learning_rate": 6.926121372031662e-07,
      "loss": 0.9883,
      "step": 7545
    },
    {
      "epoch": 9.96,
      "grad_norm": 14.9375,
      "learning_rate": 6.728232189973615e-07,
      "loss": 0.1963,
      "step": 7546
    },
    {
      "epoch": 9.96,
      "grad_norm": 246.0,
      "learning_rate": 6.530343007915566e-07,
      "loss": 1.3594,
      "step": 7547
    },
    {
      "epoch": 9.96,
      "grad_norm": 1064.0,
      "learning_rate": 6.332453825857519e-07,
      "loss": 7.125,
      "step": 7548
    },
    {
      "epoch": 9.96,
      "grad_norm": 7.125,
      "learning_rate": 6.134564643799472e-07,
      "loss": 0.0396,
      "step": 7549
    },
    {
      "epoch": 9.96,
      "grad_norm": 29.875,
      "learning_rate": 5.936675461741425e-07,
      "loss": 0.5352,
      "step": 7550
    },
    {
      "epoch": 9.96,
      "grad_norm": 34.25,
      "learning_rate": 5.738786279683377e-07,
      "loss": 0.2227,
      "step": 7551
    },
    {
      "epoch": 9.96,
      "grad_norm": 20.25,
      "learning_rate": 5.540897097625329e-07,
      "loss": 0.3125,
      "step": 7552
    },
    {
      "epoch": 9.96,
      "grad_norm": 101.0,
      "learning_rate": 5.343007915567282e-07,
      "loss": 2.0,
      "step": 7553
    },
    {
      "epoch": 9.97,
      "grad_norm": 3.515625,
      "learning_rate": 5.145118733509234e-07,
      "loss": 0.0278,
      "step": 7554
    },
    {
      "epoch": 9.97,
      "grad_norm": 19.375,
      "learning_rate": 4.947229551451187e-07,
      "loss": 0.1143,
      "step": 7555
    },
    {
      "epoch": 9.97,
      "grad_norm": 7.03125,
      "learning_rate": 4.749340369393139e-07,
      "loss": 0.0586,
      "step": 7556
    },
    {
      "epoch": 9.97,
      "grad_norm": 172.0,
      "learning_rate": 4.551451187335092e-07,
      "loss": 1.5,
      "step": 7557
    },
    {
      "epoch": 9.97,
      "grad_norm": 15.75,
      "learning_rate": 4.353562005277044e-07,
      "loss": 0.0742,
      "step": 7558
    },
    {
      "epoch": 9.97,
      "grad_norm": 154.0,
      "learning_rate": 4.155672823218997e-07,
      "loss": 2.8281,
      "step": 7559
    },
    {
      "epoch": 9.97,
      "grad_norm": 20.625,
      "learning_rate": 3.9577836411609493e-07,
      "loss": 0.1455,
      "step": 7560
    },
    {
      "epoch": 9.97,
      "grad_norm": 844.0,
      "learning_rate": 3.7598944591029023e-07,
      "loss": 3.9062,
      "step": 7561
    },
    {
      "epoch": 9.98,
      "grad_norm": 27.75,
      "learning_rate": 3.5620052770448543e-07,
      "loss": 0.8086,
      "step": 7562
    },
    {
      "epoch": 9.98,
      "grad_norm": 2.953125,
      "learning_rate": 3.3641160949868074e-07,
      "loss": 0.0308,
      "step": 7563
    },
    {
      "epoch": 9.98,
      "grad_norm": 112.0,
      "learning_rate": 3.1662269129287594e-07,
      "loss": 1.9609,
      "step": 7564
    },
    {
      "epoch": 9.98,
      "grad_norm": 1.3515625,
      "learning_rate": 2.9683377308707125e-07,
      "loss": 0.0089,
      "step": 7565
    },
    {
      "epoch": 9.98,
      "grad_norm": 17.0,
      "learning_rate": 2.7704485488126645e-07,
      "loss": 0.1162,
      "step": 7566
    },
    {
      "epoch": 9.98,
      "grad_norm": 143.0,
      "learning_rate": 2.572559366754617e-07,
      "loss": 1.8906,
      "step": 7567
    },
    {
      "epoch": 9.98,
      "grad_norm": 29.125,
      "learning_rate": 2.3746701846965696e-07,
      "loss": 0.5977,
      "step": 7568
    },
    {
      "epoch": 9.99,
      "grad_norm": 49.25,
      "learning_rate": 2.176781002638522e-07,
      "loss": 0.6289,
      "step": 7569
    },
    {
      "epoch": 9.99,
      "grad_norm": 6.15625,
      "learning_rate": 1.9788918205804746e-07,
      "loss": 0.0439,
      "step": 7570
    },
    {
      "epoch": 9.99,
      "grad_norm": 4.46875,
      "learning_rate": 1.7810026385224272e-07,
      "loss": 0.0422,
      "step": 7571
    },
    {
      "epoch": 9.99,
      "grad_norm": 4.21875,
      "learning_rate": 1.5831134564643797e-07,
      "loss": 0.0297,
      "step": 7572
    },
    {
      "epoch": 9.99,
      "grad_norm": 28.125,
      "learning_rate": 1.3852242744063322e-07,
      "loss": 0.252,
      "step": 7573
    },
    {
      "epoch": 9.99,
      "grad_norm": 255.0,
      "learning_rate": 1.1873350923482848e-07,
      "loss": 6.5312,
      "step": 7574
    },
    {
      "epoch": 9.99,
      "grad_norm": 45.5,
      "learning_rate": 9.894459102902373e-08,
      "loss": 0.377,
      "step": 7575
    },
    {
      "epoch": 9.99,
      "grad_norm": 346.0,
      "learning_rate": 7.915567282321899e-08,
      "loss": 5.6562,
      "step": 7576
    },
    {
      "epoch": 10.0,
      "grad_norm": 26.75,
      "learning_rate": 5.936675461741424e-08,
      "loss": 0.2773,
      "step": 7577
    },
    {
      "epoch": 10.0,
      "grad_norm": 24.0,
      "learning_rate": 3.957783641160949e-08,
      "loss": 0.2041,
      "step": 7578
    },
    {
      "epoch": 10.0,
      "grad_norm": 67.0,
      "learning_rate": 1.9788918205804746e-08,
      "loss": 0.2412,
      "step": 7579
    },
    {
      "epoch": 10.0,
      "grad_norm": 216.0,
      "learning_rate": 0.0,
      "loss": 4.1562,
      "step": 7580
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.6785869598388672,
      "eval_runtime": 18.3323,
      "eval_samples_per_second": 42.657,
      "eval_steps_per_second": 10.691,
      "step": 7580
    },
    {
      "epoch": 10.0,
      "step": 7580,
      "total_flos": 0.0,
      "train_loss": 1.6281782638429023,
      "train_runtime": 1727.1253,
      "train_samples_per_second": 17.549,
      "train_steps_per_second": 4.389
    }
  ],
  "logging_steps": 1,
  "max_steps": 7580,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
